{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fccda9b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-06 20:51:56.595400: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x14db67f10>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from torch import nn,optim\n",
    "import torch\n",
    "\n",
    "import algo\n",
    "import attack\n",
    "import scripts\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "rand_seed=24\n",
    "np.random.seed(rand_seed)\n",
    "torch.manual_seed(rand_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6bb23201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# purchase\n",
    "# load data with different seeds\n",
    "data_seed = {}\n",
    "for rand_seed in [1,3,13,24,42]:\n",
    "    data_seed[rand_seed] =  {}\n",
    "    \n",
    "    data_seed[rand_seed]['x_target_train'] = np.load('data/rs'+str(rand_seed)+'_x_target_train.npy')\n",
    "    data_seed[rand_seed]['y_target_train'] = np.load('data/rs'+str(rand_seed)+'_y_target_train.npy')\n",
    "    data_seed[rand_seed]['x_target_test'] = np.load('data/rs'+str(rand_seed)+'_x_target_test.npy')\n",
    "    data_seed[rand_seed]['y_target_test'] = np.load('data/rs'+str(rand_seed)+'_y_target_test.npy')\n",
    "    data_seed[rand_seed]['n_classes'] = len(np.unique(data_seed[rand_seed]['y_target_train']))\n",
    "    data_seed[rand_seed]['X_train_size'] = data_seed[rand_seed]['x_target_train'].shape[0]\n",
    "    data_seed[rand_seed]['X_test_size ']= data_seed[rand_seed]['x_target_test'].shape[0]\n",
    "\n",
    "def set_the_seed_and_data(seed):\n",
    "    np.random.seed(rand_seed)\n",
    "    torch.manual_seed(rand_seed)\n",
    "    random.seed(rand_seed)\n",
    "    \n",
    "    return data_seed[seed]['x_target_train'], data_seed[rand_seed]['y_target_train'], data_seed[rand_seed]['x_target_test'], data_seed[rand_seed]['y_target_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d372b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attack models\n",
    "from torch import nn\n",
    "\n",
    "class Net_attack(nn.Module):\n",
    "\n",
    "    def __init__(self, h_neurons, do, input_size):\n",
    "        super(Net_attack, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.h_neurons = h_neurons\n",
    "        self.do = do\n",
    "        self.fc1 = nn.Linear(input_size, h_neurons)\n",
    "        self.fc2 = nn.Linear(h_neurons, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.drop = nn.Dropout(do)\n",
    "        self.softmax = nn.Softmax(dim=1)   \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.input_size)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "path = 'mia'\n",
    "ams = {}\n",
    "for r,d,f in os.walk(path):\n",
    "    for file in f:\n",
    "        if \"best_mi_model\" in file:\n",
    "            ams[file] = Net_attack(h_neurons=64, do=0, input_size=200)\n",
    "            ams[file] = torch.load(r+'/'+file)      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88aa666",
   "metadata": {},
   "source": [
    "# MI on centralized "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e3882dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(683, 18)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'tm'\n",
    "tms_params = {}\n",
    "tms = {}\n",
    "for r,d,f in os.walk(path):\n",
    "    for file in f:\n",
    "        if \"target_model_params.json\" in file:\n",
    "            with open(path+'/'+file) as json_file:\n",
    "                tms_params[file.replace('_params.json', '')] = json.load(json_file)\n",
    "        if \"target_model.npy\" in file:\n",
    "            tms[file.replace('.npy', '')] = np.load(path+'/'+file)\n",
    "            \n",
    "df = pd.DataFrame.from_dict(tms_params, orient='index')\n",
    "df.shape            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b212250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attack every centralized target model\n",
    "for file in tms_params:\n",
    "    \n",
    "    if 'attack_acc_mean' in tms_params[file]:\n",
    "        continue\n",
    "    # set random seed and load the data    \n",
    "    rand_seed=int(file[file.find('rs')+2:file.find('_lr')])\n",
    "    x_target_train, y_target_train, x_target_test, y_target_test = set_the_seed_and_data(rand_seed)\n",
    "    \n",
    "    #attack\n",
    "    target_model = algo.LogisticRegression_DPSGD()\n",
    "    target_model.theta = tms[file]\n",
    "    params = tms_params[file]\n",
    "    scripts.set_model_params(target_model, params)\n",
    "    attack_dict = attack.test_mi_attack(ams, target_model, x_target_train, y_target_train, x_target_test, y_target_test)\n",
    "    \n",
    "    params.update(attack_dict)\n",
    "    if 'attack_acc' in params:\n",
    "        params.pop('attack_acc')\n",
    "        params.pop('attack_pre')\n",
    "        params.pop('attack_rec')\n",
    "    #write a new parameters file with attack results\n",
    "    with open('tm/'+file+'_params.json', 'w') as file:\n",
    "        json.dump(params, file)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd254e1",
   "metadata": {},
   "source": [
    "# Membership inference Federated Learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0c9a88dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'fl/'\n",
    "params = {}\n",
    "results = {}\n",
    "models = {}\n",
    "for r,d,f in os.walk(path):\n",
    "    for file in f:\n",
    "        if \"params.json\" in file:\n",
    "            with open(r+'/'+file) as json_file:\n",
    "                params[r] = json.load(json_file)\n",
    "        elif \"results.csv\" in file:\n",
    "\n",
    "#             with open(r+'/'+file, 'r') as f_open:\n",
    "#                 lines = f_open.readlines()\n",
    "#                 if 'HEAD' in lines[0]:   \n",
    "#                     for i,l in enumerate(lines):\n",
    "#                         if 'attack_acc_mean' in l:\n",
    "#                             index = i\n",
    "#                             break\n",
    "#                     with open(r+'/'+file, 'w') as f_write:\n",
    "#                         f_write.writelines(lines[i:-1])\n",
    "\n",
    "            results[r] = pd.read_csv(r+'/'+file)\n",
    "            it = []\n",
    "            client = []\n",
    "            model_filenames = []\n",
    "            if 'Unnamed: 0' in results[r].keys():\n",
    "                for k in results[r]['Unnamed: 0']:\n",
    "                    it.append(k[k.find('i')+1:k.find('_')])\n",
    "                    client.append(k[k.find('_')+1:])\n",
    "                    model_filenames.append(k+'.npy')\n",
    "                results[r]['it'] = it\n",
    "                results[r]['client'] = client\n",
    "                results[r]['file_name'] = model_filenames\n",
    "                results[r].pop('Unnamed: 0')\n",
    "        elif '.npy' in file:\n",
    "            if r not in models:\n",
    "                models[r] = {}\n",
    "#             print(r+'/'+file)\n",
    "            models[r][file] = np.load(r+'/'+file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d6fd90ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "279"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_files = results.keys()\n",
    "len(selected_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b45f198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fl/rs42_ncl32_fiter10_lr0.01_iter100_reg0.0001_outDPlocalTrue_eps0.5\n",
      "fl/rs42_ncl32_fiter10_lr0.01_iter100_reg0.0001_outDPlocalTrue_eps1\n",
      "fl/rs42_ncl4_fiter10_lr0.01_iter200_reg0.0001_sgdDPTrue_eps500_L20_C2\n",
      "fl/rs42_ncl32_fiter10_lr0.01_iter100_reg0.0001_sgdDPTrue_eps0.5_L20_C2\n"
     ]
    }
   ],
   "source": [
    "# attack every federated local/global model\n",
    "for file in selected_files:\n",
    "    \n",
    "    if 'attack_acc_mean' in results[file].keys():\n",
    "        continue\n",
    "        \n",
    "    # set random seed and load the data    \n",
    "    rand_seed=int(file[file.find('rs')+2:file.find('_ncl')])\n",
    "    x_target_train, y_target_train, x_target_test, y_target_test = set_the_seed_and_data(rand_seed)\n",
    "    #set number of client for following split of the training data between clients\n",
    "    number_of_clients = len(results[file]['client'].unique())-1\n",
    "    data_per_client = int(x_target_train.shape[0]/number_of_clients)\n",
    "\n",
    "    #attack\n",
    "    attack_results = {}\n",
    "    print(file)\n",
    "    for tm in results[file]['file_name']:\n",
    "        target_model = algo.LogisticRegression_DPSGD()\n",
    "        target_model.theta = models[file][tm]\n",
    "        tm_params = params[file]\n",
    "        scripts.set_model_params(target_model, tm_params)\n",
    "        if 'g' in tm:\n",
    "            target_model.x = x_target_train\n",
    "            target_model.y = y_target_train\n",
    "        else:\n",
    "            i = int(tm[tm.find('_c')+2:tm.find('.npy')])\n",
    "            target_model.x = x_target_train[i*data_per_client:(i+1)*data_per_client]\n",
    "            target_model.y = y_target_train[i*data_per_client:(i+1)*data_per_client]\n",
    "        attack_dict = attack.test_mi_attack(ams, target_model, target_model.x, target_model.y, x_target_test, y_target_test)\n",
    "        attack_results[tm] = attack_dict\n",
    "    attack_df = pd.DataFrame.from_dict(attack_results, orient='index')\n",
    "    result_df = results[file].set_index('file_name')\n",
    "    new_df = pd.merge(result_df, attack_df, left_index=True, right_index=True)\n",
    "    #save attack results in old results file\n",
    "    new_df.to_csv(file+'/results.csv')\n",
    "    results[file] = new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "63d068ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>it</th>\n",
       "      <th>client</th>\n",
       "      <th>attack_acc_mean</th>\n",
       "      <th>attack_acc_std</th>\n",
       "      <th>attack_pre_mean</th>\n",
       "      <th>attack_pre_std</th>\n",
       "      <th>attack_rec_mean</th>\n",
       "      <th>attack_rec_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>i0_c0.npy</th>\n",
       "      <td>0.019231</td>\n",
       "      <td>0.0127</td>\n",
       "      <td>0</td>\n",
       "      <td>c0</td>\n",
       "      <td>0.501335</td>\n",
       "      <td>0.005954</td>\n",
       "      <td>0.504275</td>\n",
       "      <td>0.014829</td>\n",
       "      <td>0.263355</td>\n",
       "      <td>0.130133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i0_c1.npy</th>\n",
       "      <td>0.012821</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0</td>\n",
       "      <td>c1</td>\n",
       "      <td>0.510417</td>\n",
       "      <td>0.012542</td>\n",
       "      <td>0.525921</td>\n",
       "      <td>0.032549</td>\n",
       "      <td>0.293269</td>\n",
       "      <td>0.084491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i0_c2.npy</th>\n",
       "      <td>0.032051</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0</td>\n",
       "      <td>c2</td>\n",
       "      <td>0.500801</td>\n",
       "      <td>0.011840</td>\n",
       "      <td>0.501221</td>\n",
       "      <td>0.028359</td>\n",
       "      <td>0.256410</td>\n",
       "      <td>0.119223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i0_c3.npy</th>\n",
       "      <td>0.016026</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>0</td>\n",
       "      <td>c3</td>\n",
       "      <td>0.514957</td>\n",
       "      <td>0.009191</td>\n",
       "      <td>0.530723</td>\n",
       "      <td>0.023144</td>\n",
       "      <td>0.309295</td>\n",
       "      <td>0.106892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i0_c4.npy</th>\n",
       "      <td>0.019231</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0</td>\n",
       "      <td>c4</td>\n",
       "      <td>0.512553</td>\n",
       "      <td>0.012901</td>\n",
       "      <td>0.532344</td>\n",
       "      <td>0.029894</td>\n",
       "      <td>0.238782</td>\n",
       "      <td>0.053496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i9_c28.npy</th>\n",
       "      <td>0.012821</td>\n",
       "      <td>0.0190</td>\n",
       "      <td>9</td>\n",
       "      <td>c28</td>\n",
       "      <td>0.509615</td>\n",
       "      <td>0.011921</td>\n",
       "      <td>0.514778</td>\n",
       "      <td>0.019638</td>\n",
       "      <td>0.365385</td>\n",
       "      <td>0.108754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i9_c29.npy</th>\n",
       "      <td>0.019231</td>\n",
       "      <td>0.0170</td>\n",
       "      <td>9</td>\n",
       "      <td>c29</td>\n",
       "      <td>0.505609</td>\n",
       "      <td>0.019091</td>\n",
       "      <td>0.510315</td>\n",
       "      <td>0.027369</td>\n",
       "      <td>0.344551</td>\n",
       "      <td>0.091159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i9_c30.npy</th>\n",
       "      <td>0.012821</td>\n",
       "      <td>0.0128</td>\n",
       "      <td>9</td>\n",
       "      <td>c30</td>\n",
       "      <td>0.506143</td>\n",
       "      <td>0.009225</td>\n",
       "      <td>0.532261</td>\n",
       "      <td>0.043521</td>\n",
       "      <td>0.221154</td>\n",
       "      <td>0.144776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i9_c31.npy</th>\n",
       "      <td>0.022436</td>\n",
       "      <td>0.0188</td>\n",
       "      <td>9</td>\n",
       "      <td>c31</td>\n",
       "      <td>0.521368</td>\n",
       "      <td>0.010121</td>\n",
       "      <td>0.539622</td>\n",
       "      <td>0.017579</td>\n",
       "      <td>0.292201</td>\n",
       "      <td>0.091359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i9_g.npy</th>\n",
       "      <td>0.035700</td>\n",
       "      <td>0.0383</td>\n",
       "      <td>9</td>\n",
       "      <td>g</td>\n",
       "      <td>0.498267</td>\n",
       "      <td>0.001834</td>\n",
       "      <td>0.496873</td>\n",
       "      <td>0.003310</td>\n",
       "      <td>0.241850</td>\n",
       "      <td>0.063132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>330 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            train_acc  test_acc it client  attack_acc_mean  attack_acc_std  \\\n",
       "i0_c0.npy    0.019231    0.0127  0     c0         0.501335        0.005954   \n",
       "i0_c1.npy    0.012821    0.0138  0     c1         0.510417        0.012542   \n",
       "i0_c2.npy    0.032051    0.0129  0     c2         0.500801        0.011840   \n",
       "i0_c3.npy    0.016026    0.0151  0     c3         0.514957        0.009191   \n",
       "i0_c4.npy    0.019231    0.0118  0     c4         0.512553        0.012901   \n",
       "...               ...       ... ..    ...              ...             ...   \n",
       "i9_c28.npy   0.012821    0.0190  9    c28         0.509615        0.011921   \n",
       "i9_c29.npy   0.019231    0.0170  9    c29         0.505609        0.019091   \n",
       "i9_c30.npy   0.012821    0.0128  9    c30         0.506143        0.009225   \n",
       "i9_c31.npy   0.022436    0.0188  9    c31         0.521368        0.010121   \n",
       "i9_g.npy     0.035700    0.0383  9      g         0.498267        0.001834   \n",
       "\n",
       "            attack_pre_mean  attack_pre_std  attack_rec_mean  attack_rec_std  \n",
       "i0_c0.npy          0.504275        0.014829         0.263355        0.130133  \n",
       "i0_c1.npy          0.525921        0.032549         0.293269        0.084491  \n",
       "i0_c2.npy          0.501221        0.028359         0.256410        0.119223  \n",
       "i0_c3.npy          0.530723        0.023144         0.309295        0.106892  \n",
       "i0_c4.npy          0.532344        0.029894         0.238782        0.053496  \n",
       "...                     ...             ...              ...             ...  \n",
       "i9_c28.npy         0.514778        0.019638         0.365385        0.108754  \n",
       "i9_c29.npy         0.510315        0.027369         0.344551        0.091159  \n",
       "i9_c30.npy         0.532261        0.043521         0.221154        0.144776  \n",
       "i9_c31.npy         0.539622        0.017579         0.292201        0.091359  \n",
       "i9_g.npy           0.496873        0.003310         0.241850        0.063132  \n",
       "\n",
       "[330 rows x 10 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6e06e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "968750ad",
   "metadata": {},
   "source": [
    "# MI LOAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1ace5cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'mia/loan/best_ams/'\n",
    "aparams = {}\n",
    "ams = {}\n",
    "for r,d,f in os.walk(path):\n",
    "    for file in f:\n",
    "        if \".json\" in file:\n",
    "            with open(r+'/'+file) as json_file:\n",
    "                aparams[r+file.replace('_params.json', '')] = json.load(json_file)\n",
    "            \n",
    "for r,d,f in os.walk(path):\n",
    "    for file in f:\n",
    "        if \".json\" not in file and '.DS_Store' not in file:\n",
    "            ams[r+file] = Net_attack(h_neurons=aparams[r+file]['h_neurons'], do=aparams[r+file]['do'], input_size=14)\n",
    "            ams[r+file] = torch.load(r+'/'+file)      \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a7d4354",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'loan/centr/'\n",
    "tms_params = {}\n",
    "tms = {}\n",
    "for r,d,f in os.walk(path):\n",
    "    for file in f:\n",
    "        if \".json\" in file:\n",
    "            with open(r+'/'+file) as json_file:\n",
    "                tms_params[file.replace('_params.json', '')] = json.load(json_file)\n",
    "        if \"target_model.npy\" in file:\n",
    "            tms[file.replace('.npy', '')] = np.load(path+'/'+file)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "73bcaa3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attack every centralized target model\n",
    "for file in tms_params:\n",
    "    \n",
    "    if 'attack_acc_mean' in tms_params[file]:\n",
    "        continue\n",
    "    # set random seed and load the data    \n",
    "    rand_seed=int(file[file.find('rs')+2:file.find('_lr')])\n",
    "    x_target_train, y_target_train, x_target_test, y_target_test = scripts.load_loan(rand_seed, tr_size=10000)\n",
    "    \n",
    "    #attack\n",
    "    target_model = algo.LogisticRegression_DPSGD()\n",
    "    target_model.theta = tms[file]\n",
    "    params = tms_params[file]\n",
    "    scripts.set_model_params(target_model, params)\n",
    "    attack_dict = attack.test_mi_attack(ams, target_model, x_target_train, y_target_train, x_target_test, y_target_test)\n",
    "    \n",
    "    params.update(attack_dict)\n",
    "    if 'attack_acc' in params:\n",
    "        params.pop('attack_acc')\n",
    "        params.pop('attack_pre')\n",
    "        params.pop('attack_rec')\n",
    "    #write a new parameters file with attack results\n",
    "    with open('loan/centr/'+file+'_params.json', 'w') as file:\n",
    "        json.dump(params, file)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075c2bd5",
   "metadata": {},
   "source": [
    "# Loan FL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b287edd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'loan/fl'\n",
    "params = {}\n",
    "results = {}\n",
    "models = {}\n",
    "for r,d,f in os.walk(path):\n",
    "    for file in f:\n",
    "        if \"params.json\" in file:\n",
    "            with open(r+'/'+file) as json_file:\n",
    "                params[r] = json.load(json_file)\n",
    "        elif \"results.csv\" in file:\n",
    "            results[r] = pd.read_csv(r+'/'+file)\n",
    "            it = []\n",
    "            client = []\n",
    "            model_filenames = []\n",
    "            if 'Unnamed: 0' in results[r].keys():\n",
    "                for k in results[r]['Unnamed: 0']:\n",
    "#                     print(k)\n",
    "#                     break\n",
    "                    it.append(k[k.find('i')+1:k.find('_')])\n",
    "                    client.append(k[k.find('_')+1:])\n",
    "                    model_filenames.append(k+'.npy')\n",
    "                results[r]['it'] = it\n",
    "                results[r]['client'] = client\n",
    "                results[r]['file_name'] = model_filenames\n",
    "                results[r].pop('Unnamed: 0')\n",
    "        elif '.npy' in file:\n",
    "            if r not in models:\n",
    "                models[r] = {}\n",
    "            models[r][file] = np.load(r+'/'+file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eb538587",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'mia/loan/best_ams/'\n",
    "aparams = {}\n",
    "ams = {}\n",
    "for r,d,f in os.walk(path):\n",
    "    for file in f:\n",
    "        if \".json\" in file:\n",
    "            with open(r+'/'+file) as json_file:\n",
    "                aparams[r+file.replace('_params.json', '')] = json.load(json_file)\n",
    "            \n",
    "for r,d,f in os.walk(path):\n",
    "    for file in f:\n",
    "        if \".json\" not in file and '.DS_Store' not in file:\n",
    "            ams[r+file] = Net_attack(h_neurons=aparams[r+file]['h_neurons'], do=aparams[r+file]['do'], input_size=14)\n",
    "            ams[r+file] = torch.load(r+'/'+file)      \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2e93edc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "587"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_files = results.keys()\n",
    "len(selected_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0bf7cf4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loan/fl/rs42_ncl128_fiter10_lr0.01_iter200_reg1e-06_outDPlocalTrue_eps100\n",
      "loan/fl/rs42_ncl128_fiter10_lr0.01_iter200_reg1e-06_outDPlocalTrue_eps5\n",
      "loan/fl/rs42_ncl128_fiter10_lr0.01_iter200_reg1e-06_outDPlocalTrue_eps0.1\n",
      "loan/fl/rs42_ncl128_fiter10_lr0.01_iter200_reg1e-06_outDPlocalTrue_eps10\n",
      "loan/fl/rs42_ncl64_fiter10_lr0.01_iter200_reg1e-06_outDPlocalTrue_eps1000\n",
      "loan/fl/rs42_ncl64_fiter10_lr0.01_iter200_reg1e-06_outDPlocalTrue_eps10000\n",
      "loan/fl/rs42_ncl64_fiter10_lr0.01_iter200_reg1e-06_outDPlocalTrue_eps5000\n",
      "loan/fl/rs42_ncl128_fiter10_lr0.01_iter200_reg1e-06_outDPlocalTrue_eps1\n",
      "loan/fl/rs42_ncl128_fiter10_lr0.01_iter200_reg1e-06_outDPlocalTrue_eps0.5\n",
      "loan/fl/rs42_ncl128_fiter10_lr0.01_iter200_reg1e-06_outDPlocalTrue_eps50\n"
     ]
    }
   ],
   "source": [
    "# attack every federated local/global model\n",
    "for file in selected_files:\n",
    "    \n",
    "    if 'attack_acc_mean' in results[file].keys():\n",
    "        continue\n",
    "        \n",
    "    # set random seed and load the data    \n",
    "    rand_seed=int(file[file.find('rs')+2:file.find('_ncl')])\n",
    "    x_target_train, y_target_train, x_target_test, y_target_test = scripts.load_loan(rand_seed, tr_size=10000)\n",
    "    #set number of client for following split of the training data between clients\n",
    "    number_of_clients = len(results[file]['client'].unique())-1\n",
    "    data_per_client = int(x_target_train.shape[0]/number_of_clients)\n",
    "\n",
    "    #attack\n",
    "    attack_results = {}\n",
    "    print(file)\n",
    "    for tm in results[file]['file_name']:\n",
    "        target_model = algo.LogisticRegression_DPSGD()\n",
    "        target_model.theta = models[file][tm]\n",
    "        tm_params = params[file]\n",
    "        scripts.set_model_params(target_model, tm_params)\n",
    "        if 'g' in tm:\n",
    "            target_model.x = x_target_train\n",
    "            target_model.y = y_target_train\n",
    "        else:\n",
    "            i = int(tm[tm.find('_c')+2:tm.find('.npy')])\n",
    "            target_model.x = x_target_train[i*data_per_client:(i+1)*data_per_client]\n",
    "            target_model.y = y_target_train[i*data_per_client:(i+1)*data_per_client]\n",
    "        attack_dict = attack.test_mi_attack(ams, target_model, target_model.x, target_model.y, x_target_test, y_target_test)\n",
    "        attack_results[tm] = attack_dict\n",
    "    attack_df = pd.DataFrame.from_dict(attack_results, orient='index')\n",
    "    result_df = results[file].set_index('file_name')\n",
    "    new_df = pd.merge(result_df, attack_df, left_index=True, right_index=True)\n",
    "    #save attack results in old results file\n",
    "    new_df.to_csv(file+'/results.csv')\n",
    "    results[file] = new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4f28fd",
   "metadata": {},
   "source": [
    "# Texas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "945214c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = 'mia/texas/best_mia/'\n",
    "aparams = {}\n",
    "ams = {}\n",
    "for r,d,f in os.walk(path):\n",
    "    for file in f:\n",
    "        if \".json\" in file:\n",
    "            with open(r+'/'+file) as json_file:\n",
    "                aparams[r+file.replace('.json', '')] = json.load(json_file)\n",
    "            \n",
    "for r,d,f in os.walk(path):\n",
    "    for file in f:\n",
    "        if \".json\" not in file and '.DS_Store' not in file:\n",
    "            ams[r+file] = Net_attack(h_neurons=aparams[r+file]['h_neurons'], do=aparams[r+file]['do'], input_size=100)\n",
    "            ams[r+file] = torch.load(r+'/'+file)      \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "687daa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'texas/centr/'\n",
    "tms_params = {}\n",
    "tms = {}\n",
    "for r,d,f in os.walk(path):\n",
    "    for file in f:\n",
    "        if \".json\" in file:\n",
    "            with open(r+'/'+file) as json_file:\n",
    "                tms_params[file.replace('_params.json', '')] = json.load(json_file)\n",
    "        if \"target_model.npy\" in file:\n",
    "            tms[file.replace('.npy', '')] = np.load(path+'/'+file)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8b7902ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rs42_lr0.01_iter50_reg0.0001_sgdDPTrue_eps10000_L5_C5_target_model\n",
      "rs42_lr0.01_iter50_reg0.0001_sgdDPTrue_eps10000_L5_C4_target_model\n",
      "rs42_lr0.01_iter100_reg0.0001_sgdDPTrue_eps10000_L20_C5_target_model\n",
      "rs42_lr0.01_iter50_reg0.0001_sgdDPTrue_eps10000_L5_C3_target_model\n"
     ]
    }
   ],
   "source": [
    "# attack every centralized target model\n",
    "for file in tms_params:\n",
    "    \n",
    "    if 'attack_acc_mean' in tms_params[file]:\n",
    "        continue\n",
    "    # set random seed and load the data\n",
    "    print(file)\n",
    "    rand_seed=int(file[file.find('rs')+2:file.find('_lr')])\n",
    "    x_target_train, y_target_train, x_target_test, y_target_test = scripts.load_texas()\n",
    "    \n",
    "    #attack\n",
    "    target_model = algo.LogisticRegression_DPSGD()\n",
    "    target_model.theta = tms[file]\n",
    "    params = tms_params[file]\n",
    "    scripts.set_model_params(target_model, params)\n",
    "    attack_dict = attack.test_mi_attack(ams, target_model, x_target_train, y_target_train, x_target_test, y_target_test)\n",
    "    \n",
    "    params.update(attack_dict)\n",
    "    if 'attack_acc' in params:\n",
    "        params.pop('attack_acc')\n",
    "        params.pop('attack_pre')\n",
    "        params.pop('attack_rec')\n",
    "    #write a new parameters file with attack results\n",
    "    with open('texas/centr/'+file+'_params.json', 'w') as file:\n",
    "        json.dump(params, file)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733b40f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
