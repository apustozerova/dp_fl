{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20337f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from torch import nn,optim\n",
    "import torch\n",
    "\n",
    "import algo\n",
    "import scripts\n",
    "import attack\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import json \n",
    "\n",
    "import os\n",
    "\n",
    "import random\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77caaa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# purchase\n",
    "rand_seed=42\n",
    "np.random.seed(rand_seed)\n",
    "torch.manual_seed(rand_seed)\n",
    "random.seed(rand_seed)\n",
    "\n",
    "x_target_train = np.load('data/rs'+str(rand_seed)+'_x_target_train.npy')\n",
    "y_target_train = np.load('data/rs'+str(rand_seed)+'_y_target_train.npy')\n",
    "x_target_test = np.load('data/rs'+str(rand_seed)+'_x_target_test.npy')\n",
    "y_target_test = np.load('data/rs'+str(rand_seed)+'_y_target_test.npy')\n",
    "n_classes = len(np.unique(y_target_train))\n",
    "X_train_size = x_target_train.shape[0]\n",
    "X_test_size = x_target_test.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dab267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_size = 5000\n",
    "# X_test_size = 5000\n",
    "# x_target_train = np.array(x_target_train [:X_train_size])\n",
    "# y_target_train = np.array(y_target_train [:X_train_size])\n",
    "# x_target_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c963533",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = algo.LogisticRegression_DPSGD()\n",
    "\n",
    "model.n_classes      = len(np.unique(y_target_test))\n",
    "model.alpha          = 0.01\n",
    "model.max_iter       = 100\n",
    "model.lambda_        = 1e-5\n",
    "model.tolerance      = 1e-5\n",
    "model.DP             = False\n",
    "model.L              = 1\n",
    "model.epsilon        = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb892b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_seed=42\n",
    "np.random.seed(rand_seed)\n",
    "torch.manual_seed(rand_seed)\n",
    "random.seed(rand_seed)\n",
    "\n",
    "X,y = model.init_theta(x_target_train, y_target_train)\n",
    "model.train(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b0dea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_target_train, y_target_train, acc=True)\n",
    "model.evaluate(x_target_test, y_target_test, acc=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ca33f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon_out_dp = 100\n",
    "noise_model = scripts.output_DP(target_model, x_target_train.shape[0], epsilon_out_dp)\n",
    "noise_model.train_acc = noise_model.evaluate(x_target_train, y_target_train)\n",
    "noise_model.test_acc = noise_model.evaluate(x_target_test, y_target_test)\n",
    "noise_model.mi_attack = attack.test_mi_attack(ams, model, x_target_train, y_target_train, x_target_test, y_target_test)\n",
    "noise_model.out_dp_mi_attack = attack.test_mi_attack(ams, noise_model, x_target_train, y_target_train, x_target_test, y_target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d7a115",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_model.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b362c3ec",
   "metadata": {},
   "source": [
    "# Centralized output DP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852aa6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# purchase\n",
    "# load data with different seeds\n",
    "data_seed = {}\n",
    "for rand_seed in [1,3,13,24,42]:\n",
    "    data_seed[rand_seed] =  {}\n",
    "    \n",
    "    data_seed[rand_seed]['x_target_train'] = np.load('data/rs'+str(rand_seed)+'_x_target_train.npy')\n",
    "    data_seed[rand_seed]['y_target_train'] = np.load('data/rs'+str(rand_seed)+'_y_target_train.npy')\n",
    "    data_seed[rand_seed]['x_target_test'] = np.load('data/rs'+str(rand_seed)+'_x_target_test.npy')\n",
    "    data_seed[rand_seed]['y_target_test'] = np.load('data/rs'+str(rand_seed)+'_y_target_test.npy')\n",
    "    data_seed[rand_seed]['n_classes'] = len(np.unique(y_target_train))\n",
    "    data_seed[rand_seed]['X_train_size'] = x_target_train.shape[0]\n",
    "    data_seed[rand_seed]['X_test_size ']= x_target_test.shape[0]\n",
    "\n",
    "def set_the_seed_and_data(seed):\n",
    "    np.random.seed(rand_seed)\n",
    "    torch.manual_seed(rand_seed)\n",
    "    random.seed(rand_seed)\n",
    "    \n",
    "    return data_seed[seed]['x_target_train'], data_seed[rand_seed]['y_target_train'], data_seed[rand_seed]['x_target_test'], data_seed[rand_seed]['y_target_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd41280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attack models\n",
    "from torch import nn\n",
    "\n",
    "class Net_attack(nn.Module):\n",
    "\n",
    "    def __init__(self, h_neurons, do, input_size):\n",
    "        super(Net_attack, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.h_neurons = h_neurons\n",
    "        self.do = do\n",
    "        self.fc1 = nn.Linear(input_size, h_neurons)\n",
    "        self.fc2 = nn.Linear(h_neurons, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.drop = nn.Dropout(do)\n",
    "        self.softmax = nn.Softmax(dim=1)   \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.input_size)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "path = 'mia'\n",
    "ams = {}\n",
    "for r,d,f in os.walk(path):\n",
    "    for file in f:\n",
    "        if \"best_mi_model\" in file:\n",
    "            ams[file] = Net_attack(h_neurons=64, do=0, input_size=200)\n",
    "            ams[file] = torch.load(r+'/'+file)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a44d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'tm'\n",
    "tms_params = {}\n",
    "tms = {}\n",
    "for r,d,f in os.walk(path):\n",
    "    for file in f:\n",
    "        if \"target_model_params.json\" in file:\n",
    "            with open(path+'/'+file) as json_file:\n",
    "                tms_params[file.replace('_params.json', '')] = json.load(json_file)\n",
    "        if \"target_model.npy\" in file:\n",
    "            tms[file.replace('.npy', '')] = np.load(path+'/'+file)\n",
    "            \n",
    "df = pd.DataFrame.from_dict(tms_params, orient='index')\n",
    "df.shape            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4daba02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'tm/rs42_lr0.001_iter100_reg0.005_DPFalse_target_model_params.json'\n",
    "with open(file) as json_file:\n",
    "    tm_params = json.load(json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf8a0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load model and parameters\n",
    "file = 'tm/rs42_lr0.001_iter100_reg0.005_DPFalse_target_model_params.json'\n",
    "with open(file) as json_file:\n",
    "    tm_params = json.load(json_file)\n",
    "\n",
    "rand_seed = int(file[file.find('rs')+2:file.find('_lr')])\n",
    "x_target_train, y_target_train, x_target_test, y_target_test = set_the_seed_and_data(rand_seed)\n",
    "\n",
    "target_model = algo.LogisticRegression_DPSGD()\n",
    "scripts.set_model_params(target_model, tm_params)\n",
    "target_model.theta = np.load('tm/rs42_lr0.001_iter100_reg0.005_DPFalse_target_model.npy')\n",
    "target_model.evaluate(x_target_train, y_target_train, acc=True)\n",
    "target_model.evaluate(x_target_test, y_target_test, acc=True)\n",
    "\n",
    "#Output DP\n",
    "noise_model = scripts.output_DP(target_model, epsilon_out_DP=10, delta_out_DP=1e-5, X_train_size=X_train_size)\n",
    "noise_model.train_acc = noise_model.evaluate(x_target_train, y_target_train, acc=True)\n",
    "noise_model.test_acc = noise_model.evaluate(x_target_test, y_target_test, acc=True)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392179de",
   "metadata": {},
   "source": [
    "# FL output DP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84212d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# purchase\n",
    "rand_seed=42\n",
    "np.random.seed(rand_seed)\n",
    "torch.manual_seed(rand_seed)\n",
    "random.seed(rand_seed)\n",
    "\n",
    "x_target_train = np.load('data/rs'+str(rand_seed)+'_x_target_train.npy')\n",
    "y_target_train = np.load('data/rs'+str(rand_seed)+'_y_target_train.npy')\n",
    "x_target_test = np.load('data/rs'+str(rand_seed)+'_x_target_test.npy')\n",
    "y_target_test = np.load('data/rs'+str(rand_seed)+'_y_target_test.npy')\n",
    "n_classes = len(np.unique(y_target_train))\n",
    "X_train_size = x_target_train.shape[0]\n",
    "X_test_size = x_target_test.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6a2776",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'fl'\n",
    "params = {}\n",
    "results = {}\n",
    "models = {}\n",
    "ouput_dp_results = {}\n",
    "for r,d,f in os.walk(path):\n",
    "    for file in f:\n",
    "        if \"params.json\" in file:\n",
    "            with open(r+'/'+file) as json_file:\n",
    "                params[r] = json.load(json_file)\n",
    "        elif \"results.csv\" in file:\n",
    "            results[r] = pd.read_csv(r+'/'+file)\n",
    "            it = []\n",
    "            client = []\n",
    "            for k in results[r]['Unnamed: 0']:\n",
    "                it.append(k[k.find('i')+1:k.find('_')])\n",
    "                client.append(k[k.find('_')+1:])\n",
    "            results[r]['it'] = it\n",
    "            results[r]['client'] = client\n",
    "        elif '.npy' in file:\n",
    "            if r not in models:\n",
    "                models[r] = {}\n",
    "            models[r][file] = np.load(r+'/'+file)\n",
    "        elif 'outputDP.json' in file:\n",
    "            with open(r+'/'+file) as json_file:\n",
    "                ouput_dp_results[r+'/'+file] = json.load(json_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab68a26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35128bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_file = 'fl/rs42_ncl2_fiter5_lr0.01_iter100_reg0.0001_DPFalse'\n",
    "print(results[fl_file])\n",
    "params[fl_file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74222aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(fl_file+f'/results_outDP.json'):\n",
    "    print('file exists')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfaf5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(rand_seed)\n",
    "torch.manual_seed(rand_seed)\n",
    "random.seed(rand_seed)\n",
    "\n",
    "vals = ['epsilon_out', 'train_acc', 'test_acc', 'out_dp_train_acc', 'out_dp_test_acc', 'mi_attack', 'out_dp_mi_attack']\n",
    "epses = [i/10 for i in range(1,10)] + [i for i in range(1,11)] + [i*10 for i in range(2,11)] + [i*100 for i in range(2,11)]+ [i*1000 for i in range(2,11)] + [i*10000 for i in range(2,11)]\n",
    "# epses = [1,5,10]\n",
    "\n",
    "number_of_clients = len(results[fl_file]['client'].unique())-1\n",
    "data_per_client = int(x_target_train.shape[0]/number_of_clients)\n",
    "clients = results[fl_file]['client'].unique()\n",
    "fl0 = {}\n",
    "fl0_out_dp = {}\n",
    "fl_iteration = 2\n",
    "\n",
    "out_eps_results = {}\n",
    "for epsilon_out_dp in epses:\n",
    "    out_eps_results[epsilon_out_dp] = {}\n",
    "#     if os.path.exists(fl_file+f'/i{fl_iteration}_{c}_outputDP.json'):\n",
    "#         print(\"file already exists\")\n",
    "#         continue\n",
    "    for i,c in enumerate(clients):\n",
    "        fl0[c] = algo.LogisticRegression_DPSGD()\n",
    "        scripts.set_model_params(fl0[c], params[fl_file])\n",
    "        if c == 'g':\n",
    "            fl0[c].x = x_target_train\n",
    "            fl0[c].y = y_target_train\n",
    "            fl0[c].theta = models[fl_file][f'i{fl_iteration}_{c}.npy']\n",
    "            fl0_out_dp[c] = algo.LogisticRegression_DPSGD()\n",
    "            scripts.set_model_params(fl0_out_dp[c], fl0_out_dp['c0'].__dict__)\n",
    "            fl0_out_dp[c].theta = sum([fl0_out_dp[c].theta for c in fl0_out_dp if c!='g'])/number_of_clients\n",
    "        else:\n",
    "            fl0[c].x = x_target_train[i*data_per_client:(i+1)*data_per_client]\n",
    "            fl0[c].y = y_target_train[i*data_per_client:(i+1)*data_per_client]\n",
    "            fl0[c].theta = models[fl_file][f'i{fl_iteration}_{c}.npy']\n",
    "            fl0_out_dp[c] = scripts.output_DP(fl0[c], fl0[c].x.shape[0], epsilon_out_dp)\n",
    "        fl0_out_dp[c].train_acc = fl0[c].evaluate(fl0[c].x, fl0[c].y)\n",
    "        fl0_out_dp[c].test_acc = fl0[c].evaluate(x_target_test, y_target_test)\n",
    "        fl0_out_dp[c].out_dp_train_acc = fl0_out_dp[c].evaluate(fl0[c].x, fl0[c].y)\n",
    "        fl0_out_dp[c].out_dp_test_acc = fl0_out_dp[c].evaluate(x_target_test, y_target_test)\n",
    "        fl0_out_dp[c].mi_attack = attack.test_mi_attack(ams, fl0[c], fl0[c].x, fl0[c].y, x_target_test, y_target_test)\n",
    "        fl0_out_dp[c].out_dp_mi_attack = attack.test_mi_attack(ams, fl0_out_dp[c], fl0[c].x, fl0[c].y, x_target_test, y_target_test)\n",
    "        \n",
    "        temp_d = dict(fl0_out_dp[c].__dict__)\n",
    "        out_eps_results[epsilon_out_dp][c] = {k: v for k, v in temp_d.items() if k in vals}\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a300187",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(fl_file+f'/fliter{fl_iteration}_results_outDP.json'):\n",
    "    print('file exists')\n",
    "else:\n",
    "    with open(fl_file+f'/fliter{fl_iteration}_results_outDP.json', 'w') as file:\n",
    "            json.dump(out_eps_results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c26aa9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_file+f'/fliter{fl_iteration}_results_outDP.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab08854f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'fl/rs42_ncl2_fiter5_lr0.01_iter100_reg0.0001_DPFalse/fliter2_results_outDP.json'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fe5d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output dp with fixed epsilon save files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79faf603",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(rand_seed)\n",
    "torch.manual_seed(rand_seed)\n",
    "random.seed(rand_seed)\n",
    "\n",
    "\n",
    "epsilon_out_dp = 100\n",
    "\n",
    "number_of_clients = len(results[fl_file]['client'].unique())-1\n",
    "data_per_client = int(x_target_train.shape[0]/number_of_clients)\n",
    "clients = results[fl_file]['client'].unique()\n",
    "fl0 = {}\n",
    "fl0_out_dp = {}\n",
    "fl_iteration = 0\n",
    "for fl_iteration in [0,1,2,3,4]:\n",
    "    if os.path.exists(fl_file+f'/i{fl_iteration}_{c}_outputDP.json'):\n",
    "#         print(\"file already exists\")\n",
    "        continue\n",
    "    for i,c in enumerate(clients):\n",
    "        fl0[c] = algo.LogisticRegression_DPSGD()\n",
    "        scripts.set_model_params(fl0[c], params[fl_file])\n",
    "        if c == 'g':\n",
    "            fl0[c].x = x_target_train\n",
    "            fl0[c].y = y_target_train\n",
    "            fl0[c].theta = models[fl_file][f'i{fl_iteration}_{c}.npy']\n",
    "            fl0_out_dp[c] = algo.LogisticRegression_DPSGD()\n",
    "            scripts.set_model_params(fl0_out_dp[c], fl0_out_dp['c0'].__dict__)\n",
    "            fl0_out_dp[c].theta = sum([fl0_out_dp[c].theta for c in fl0_out_dp if c!='g'])/number_of_clients\n",
    "        else:\n",
    "            fl0[c].x = x_target_train[i*data_per_client:(i+1)*data_per_client]\n",
    "            fl0[c].y = y_target_train[i*data_per_client:(i+1)*data_per_client]\n",
    "            fl0[c].theta = models[fl_file][f'i{fl_iteration}_{c}.npy']\n",
    "            fl0_out_dp[c] = scripts.output_DP(fl0[c], fl0[c].x.shape[0], epsilon_out_dp)\n",
    "        fl0_out_dp[c].train_acc = fl0[c].evaluate(fl0[c].x, fl0[c].y)\n",
    "        fl0_out_dp[c].test_acc = fl0[c].evaluate(x_target_test, y_target_test)\n",
    "        fl0_out_dp[c].out_dp_train_acc = fl0_out_dp[c].evaluate(fl0[c].x, fl0[c].y)\n",
    "        fl0_out_dp[c].out_dp_test_acc = fl0_out_dp[c].evaluate(x_target_test, y_target_test)\n",
    "        fl0_out_dp[c].mi_attack = attack.test_mi_attack(ams, fl0[c], fl0[c].x, fl0[c].y, x_target_test, y_target_test)\n",
    "        fl0_out_dp[c].out_dp_mi_attack = attack.test_mi_attack(ams, fl0_out_dp[c], fl0[c].x, fl0[c].y, x_target_test, y_target_test)\n",
    "\n",
    "#     np.save(fl_file+f'/i{fl_iteration}_{c}_outputDP.npy', fl0_out_dp[c].theta)\n",
    "    temp_d = dict(fl0_out_dp[c].__dict__)\n",
    "    temp_d.pop('theta')\n",
    "    with open(fl_file+f'/i{fl_iteration}_{c}_outputDP.json', 'w') as file:\n",
    "        json.dump(temp_d, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
