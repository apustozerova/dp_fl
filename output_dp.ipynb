{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a609b188",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-19 13:56:54.835414: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from torch import nn,optim\n",
    "import torch\n",
    "\n",
    "import algo\n",
    "import scripts\n",
    "import attack\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import json \n",
    "\n",
    "import os\n",
    "\n",
    "import random\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4d20ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# purchase\n",
    "rand_seed=42\n",
    "np.random.seed(rand_seed)\n",
    "torch.manual_seed(rand_seed)\n",
    "random.seed(rand_seed)\n",
    "\n",
    "x_target_train = np.load('data/rs'+str(rand_seed)+'_x_target_train.npy')\n",
    "y_target_train = np.load('data/rs'+str(rand_seed)+'_y_target_train.npy')\n",
    "x_target_test = np.load('data/rs'+str(rand_seed)+'_x_target_test.npy')\n",
    "y_target_test = np.load('data/rs'+str(rand_seed)+'_y_target_test.npy')\n",
    "n_classes = len(np.unique(y_target_train))\n",
    "X_train_size = x_target_train.shape[0]\n",
    "X_test_size = x_target_test.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32ecf7d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 600)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train_size = 5000\n",
    "# X_test_size = 5000\n",
    "# x_target_train = np.array(x_target_train [:X_train_size])\n",
    "# y_target_train = np.array(y_target_train [:X_train_size])\n",
    "# x_target_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30a2dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = algo.LogisticRegression_DPSGD()\n",
    "\n",
    "model.n_classes      = len(np.unique(y_target_test))\n",
    "model.alpha          = 0.01\n",
    "model.max_iter       = 100\n",
    "model.lambda_        = 1e-5\n",
    "model.tolerance      = 1e-5\n",
    "model.DP             = False\n",
    "model.L              = 1\n",
    "model.epsilon        = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d581ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_seed=42\n",
    "np.random.seed(rand_seed)\n",
    "torch.manual_seed(rand_seed)\n",
    "random.seed(rand_seed)\n",
    "\n",
    "X,y = model.init_theta(x_target_train, y_target_train)\n",
    "model.train(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2385fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_target_train, y_target_train, acc=True)\n",
    "model.evaluate(x_target_test, y_target_test, acc=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1071801",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon_out_dp = 100\n",
    "noise_model = scripts.output_DP(target_model, x_target_train.shape[0], epsilon_out_dp)\n",
    "noise_model.train_acc = noise_model.evaluate(x_target_train, y_target_train)\n",
    "noise_model.test_acc = noise_model.evaluate(x_target_test, y_target_test)\n",
    "noise_model.mi_attack = attack.test_mi_attack(ams, model, x_target_train, y_target_train, x_target_test, y_target_test)\n",
    "noise_model.out_dp_mi_attack = attack.test_mi_attack(ams, noise_model, x_target_train, y_target_train, x_target_test, y_target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161b7f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_model.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40df99d",
   "metadata": {},
   "source": [
    "# Centralized output DP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ad08b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# purchase\n",
    "# load data with different seeds\n",
    "data_seed = {}\n",
    "for rand_seed in [1,3,13,24,42]:\n",
    "    data_seed[rand_seed] =  {}\n",
    "    \n",
    "    data_seed[rand_seed]['x_target_train'] = np.load('data/rs'+str(rand_seed)+'_x_target_train.npy')\n",
    "    data_seed[rand_seed]['y_target_train'] = np.load('data/rs'+str(rand_seed)+'_y_target_train.npy')\n",
    "    data_seed[rand_seed]['x_target_test'] = np.load('data/rs'+str(rand_seed)+'_x_target_test.npy')\n",
    "    data_seed[rand_seed]['y_target_test'] = np.load('data/rs'+str(rand_seed)+'_y_target_test.npy')\n",
    "    data_seed[rand_seed]['n_classes'] = len(np.unique(y_target_train))\n",
    "    data_seed[rand_seed]['X_train_size'] = x_target_train.shape[0]\n",
    "    data_seed[rand_seed]['X_test_size ']= x_target_test.shape[0]\n",
    "\n",
    "def set_the_seed_and_data(seed):\n",
    "    np.random.seed(rand_seed)\n",
    "    torch.manual_seed(rand_seed)\n",
    "    random.seed(rand_seed)\n",
    "    \n",
    "    return data_seed[seed]['x_target_train'], data_seed[rand_seed]['y_target_train'], data_seed[rand_seed]['x_target_test'], data_seed[rand_seed]['y_target_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60650914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attack models\n",
    "from torch import nn\n",
    "\n",
    "class Net_attack(nn.Module):\n",
    "\n",
    "    def __init__(self, h_neurons, do, input_size):\n",
    "        super(Net_attack, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.h_neurons = h_neurons\n",
    "        self.do = do\n",
    "        self.fc1 = nn.Linear(input_size, h_neurons)\n",
    "        self.fc2 = nn.Linear(h_neurons, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.drop = nn.Dropout(do)\n",
    "        self.softmax = nn.Softmax(dim=1)   \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.input_size)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "path = 'mia'\n",
    "ams = {}\n",
    "for r,d,f in os.walk(path):\n",
    "    for file in f:\n",
    "        if \"best_mi_model\" in file:\n",
    "            ams[file] = Net_attack(h_neurons=64, do=0, input_size=200)\n",
    "            ams[file] = torch.load(r+'/'+file)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdf6ae22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(668, 21)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'tm'\n",
    "tms_params = {}\n",
    "tms = {}\n",
    "for r,d,f in os.walk(path):\n",
    "    for file in f:\n",
    "        if \"target_model_params.json\" in file:\n",
    "            with open(path+'/'+file) as json_file:\n",
    "                tms_params[file.replace('_params.json', '')] = json.load(json_file)\n",
    "        if \"target_model.npy\" in file:\n",
    "            tms[file.replace('.npy', '')] = np.load(path+'/'+file)\n",
    "            \n",
    "df = pd.DataFrame.from_dict(tms_params, orient='index')\n",
    "df.shape            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3efe982",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load model and parameters\n",
    "file = 'tm/rs42_lr0.001_iter100_reg0.005_DPFalse_target_model_params.json'\n",
    "with open(file) as json_file:\n",
    "    tm_params = json.load(json_file)\n",
    "            \n",
    "# x_target_train, y_target_train, x_target_test, y_target_test = attack.data_shuffle(rand_seed, X_raw, y_raw)\n",
    "target_model = algo.LogisticRegression_DPSGD()\n",
    "scripts.set_model_params(target_model, tm_params)\n",
    "target_model.theta = np.load('tm/rs42_lr0.001_iter100_reg0.005_DPFalse_target_model.npy')\n",
    "target_model.evaluate(x_target_train, y_target_train, acc=True)\n",
    "target_model.evaluate(x_target_test, y_target_test, acc=True)\n",
    "\n",
    "#Output DP\n",
    "noise_model = scripts.output_DP(target_model, epsilon_out_DP=10, delta_out_DP=1e-5, X_train_size=X_train_size)\n",
    "noise_model.train_acc = noise_model.evaluate(x_target_train, y_target_train, acc=True)\n",
    "noise_model.test_acc = noise_model.evaluate(x_target_test, y_target_test, acc=True)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2214c2c5",
   "metadata": {},
   "source": [
    "# FL output DP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b91fedc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# purchase\n",
    "rand_seed=42\n",
    "np.random.seed(rand_seed)\n",
    "torch.manual_seed(rand_seed)\n",
    "random.seed(rand_seed)\n",
    "\n",
    "x_target_train = np.load('data/rs'+str(rand_seed)+'_x_target_train.npy')\n",
    "y_target_train = np.load('data/rs'+str(rand_seed)+'_y_target_train.npy')\n",
    "x_target_test = np.load('data/rs'+str(rand_seed)+'_x_target_test.npy')\n",
    "y_target_test = np.load('data/rs'+str(rand_seed)+'_y_target_test.npy')\n",
    "n_classes = len(np.unique(y_target_train))\n",
    "X_train_size = x_target_train.shape[0]\n",
    "X_test_size = x_target_test.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "49cdcd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'fl'\n",
    "params = {}\n",
    "results = {}\n",
    "models = {}\n",
    "ouput_dp_results = {}\n",
    "for r,d,f in os.walk(path):\n",
    "    for file in f:\n",
    "        if \"params.json\" in file:\n",
    "            with open(r+'/'+file) as json_file:\n",
    "                params[r] = json.load(json_file)\n",
    "        elif \"results.csv\" in file:\n",
    "            results[r] = pd.read_csv(r+'/'+file)\n",
    "            it = []\n",
    "            client = []\n",
    "            for k in results[r]['Unnamed: 0']:\n",
    "                it.append(k[k.find('i')+1:k.find('_')])\n",
    "                client.append(k[k.find('_')+1:])\n",
    "            results[r]['it'] = it\n",
    "            results[r]['client'] = client\n",
    "        elif '.npy' in file:\n",
    "            if r not in models:\n",
    "                models[r] = {}\n",
    "            models[r][file] = np.load(r+'/'+file)\n",
    "        elif 'outputDP.json' in file:\n",
    "            with open(r+'/'+file) as json_file:\n",
    "                ouput_dp_results[r+'/'+file] = json.load(json_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "f98cd06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0       0       1 it client\n",
      "0       i0_c0  1.0000  0.4353  0     c0\n",
      "1       i0_c1  1.0000  0.4372  0     c1\n",
      "2        i0_g  0.9745  0.5214  0      g\n",
      "3       i1_c0  1.0000  0.4394  1     c0\n",
      "4       i1_c1  1.0000  0.4373  1     c1\n",
      "5        i1_g  0.9771  0.5243  1      g\n",
      "6       i2_c0  1.0000  0.4368  2     c0\n",
      "7       i2_c1  1.0000  0.4379  2     c1\n",
      "8        i2_g  0.9769  0.5211  2      g\n",
      "9       i3_c0  1.0000  0.4362  3     c0\n",
      "10      i3_c1  1.0000  0.4375  3     c1\n",
      "11       i3_g  0.9749  0.5206  3      g\n",
      "12      i4_c0  1.0000  0.4372  4     c0\n",
      "13      i4_c1  1.0000  0.4376  4     c1\n",
      "14       i4_g  0.9762  0.5219  4      g\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_classes': 100,\n",
       " 'alpha': 0.01,\n",
       " 'max_iter': 100,\n",
       " 'lambda_': 0.0001,\n",
       " 'tolerance': 1e-05,\n",
       " 'DP': False,\n",
       " 'L': 1,\n",
       " 'C': 1,\n",
       " 'epsilon': 0,\n",
       " 'delta': 1e-05}"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fl_file = 'fl/rs42_ncl2_fiter5_lr0.01_iter100_reg0.0001_DPFalse'\n",
    "print(results[fl_file])\n",
    "params[fl_file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "27c30c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(fl_file+f'/results_outDP.json'):\n",
    "    print('file exists')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "c3b46db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(rand_seed)\n",
    "torch.manual_seed(rand_seed)\n",
    "random.seed(rand_seed)\n",
    "\n",
    "vals = ['epsilon_out', 'train_acc', 'test_acc', 'out_dp_train_acc', 'out_dp_test_acc', 'mi_attack', 'out_dp_mi_attack']\n",
    "epses = [i/10 for i in range(1,10)] + [i for i in range(1,11)] + [i*10 for i in range(2,11)] + [i*100 for i in range(2,11)]+ [i*1000 for i in range(2,11)] + [i*10000 for i in range(2,11)]\n",
    "# epses = [1,5,10]\n",
    "\n",
    "number_of_clients = len(results[fl_file]['client'].unique())-1\n",
    "data_per_client = int(x_target_train.shape[0]/number_of_clients)\n",
    "clients = results[fl_file]['client'].unique()\n",
    "fl0 = {}\n",
    "fl0_out_dp = {}\n",
    "fl_iteration = 2\n",
    "\n",
    "out_eps_results = {}\n",
    "for epsilon_out_dp in epses:\n",
    "    out_eps_results[epsilon_out_dp] = {}\n",
    "#     if os.path.exists(fl_file+f'/i{fl_iteration}_{c}_outputDP.json'):\n",
    "#         print(\"file already exists\")\n",
    "#         continue\n",
    "    for i,c in enumerate(clients):\n",
    "        fl0[c] = algo.LogisticRegression_DPSGD()\n",
    "        scripts.set_model_params(fl0[c], params[fl_file])\n",
    "        if c == 'g':\n",
    "            fl0[c].x = x_target_train\n",
    "            fl0[c].y = y_target_train\n",
    "            fl0[c].theta = models[fl_file][f'i{fl_iteration}_{c}.npy']\n",
    "            fl0_out_dp[c] = algo.LogisticRegression_DPSGD()\n",
    "            scripts.set_model_params(fl0_out_dp[c], fl0_out_dp['c0'].__dict__)\n",
    "            fl0_out_dp[c].theta = sum([fl0_out_dp[c].theta for c in fl0_out_dp if c!='g'])/number_of_clients\n",
    "        else:\n",
    "            fl0[c].x = x_target_train[i*data_per_client:(i+1)*data_per_client]\n",
    "            fl0[c].y = y_target_train[i*data_per_client:(i+1)*data_per_client]\n",
    "            fl0[c].theta = models[fl_file][f'i{fl_iteration}_{c}.npy']\n",
    "            fl0_out_dp[c] = scripts.output_DP(fl0[c], fl0[c].x.shape[0], epsilon_out_dp)\n",
    "        fl0_out_dp[c].train_acc = fl0[c].evaluate(fl0[c].x, fl0[c].y)\n",
    "        fl0_out_dp[c].test_acc = fl0[c].evaluate(x_target_test, y_target_test)\n",
    "        fl0_out_dp[c].out_dp_train_acc = fl0_out_dp[c].evaluate(fl0[c].x, fl0[c].y)\n",
    "        fl0_out_dp[c].out_dp_test_acc = fl0_out_dp[c].evaluate(x_target_test, y_target_test)\n",
    "        fl0_out_dp[c].mi_attack = attack.test_mi_attack(ams, fl0[c], fl0[c].x, fl0[c].y, x_target_test, y_target_test)\n",
    "        fl0_out_dp[c].out_dp_mi_attack = attack.test_mi_attack(ams, fl0_out_dp[c], fl0[c].x, fl0[c].y, x_target_test, y_target_test)\n",
    "        \n",
    "        temp_d = dict(fl0_out_dp[c].__dict__)\n",
    "        out_eps_results[epsilon_out_dp][c] = {k: v for k, v in temp_d.items() if k in vals}\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "a6bfc47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(fl_file+f'/fliter{fl_iteration}_results_outDP.json'):\n",
    "    print('file exists')\n",
    "else:\n",
    "    with open(fl_file+f'/fliter{fl_iteration}_results_outDP.json', 'w') as file:\n",
    "            json.dump(out_eps_results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "19d6e514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fl/rs42_ncl2_fiter5_lr0.01_iter100_reg0.0001_DPFalse/fliter2_results_outDP.json'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fl_file+f'/fliter{fl_iteration}_results_outDP.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbc47d7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'fl/rs42_ncl2_fiter5_lr0.01_iter100_reg0.0001_DPFalse/fliter2_results_outDP.json'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e0bcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output dp with fixed epsilon save files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070d1943",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(rand_seed)\n",
    "torch.manual_seed(rand_seed)\n",
    "random.seed(rand_seed)\n",
    "\n",
    "\n",
    "epsilon_out_dp = 100\n",
    "\n",
    "number_of_clients = len(results[fl_file]['client'].unique())-1\n",
    "data_per_client = int(x_target_train.shape[0]/number_of_clients)\n",
    "clients = results[fl_file]['client'].unique()\n",
    "fl0 = {}\n",
    "fl0_out_dp = {}\n",
    "fl_iteration = 0\n",
    "for fl_iteration in [0,1,2,3,4]:\n",
    "    if os.path.exists(fl_file+f'/i{fl_iteration}_{c}_outputDP.json'):\n",
    "#         print(\"file already exists\")\n",
    "        continue\n",
    "    for i,c in enumerate(clients):\n",
    "        fl0[c] = algo.LogisticRegression_DPSGD()\n",
    "        scripts.set_model_params(fl0[c], params[fl_file])\n",
    "        if c == 'g':\n",
    "            fl0[c].x = x_target_train\n",
    "            fl0[c].y = y_target_train\n",
    "            fl0[c].theta = models[fl_file][f'i{fl_iteration}_{c}.npy']\n",
    "            fl0_out_dp[c] = algo.LogisticRegression_DPSGD()\n",
    "            scripts.set_model_params(fl0_out_dp[c], fl0_out_dp['c0'].__dict__)\n",
    "            fl0_out_dp[c].theta = sum([fl0_out_dp[c].theta for c in fl0_out_dp if c!='g'])/number_of_clients\n",
    "        else:\n",
    "            fl0[c].x = x_target_train[i*data_per_client:(i+1)*data_per_client]\n",
    "            fl0[c].y = y_target_train[i*data_per_client:(i+1)*data_per_client]\n",
    "            fl0[c].theta = models[fl_file][f'i{fl_iteration}_{c}.npy']\n",
    "            fl0_out_dp[c] = scripts.output_DP(fl0[c], fl0[c].x.shape[0], epsilon_out_dp)\n",
    "        fl0_out_dp[c].train_acc = fl0[c].evaluate(fl0[c].x, fl0[c].y)\n",
    "        fl0_out_dp[c].test_acc = fl0[c].evaluate(x_target_test, y_target_test)\n",
    "        fl0_out_dp[c].out_dp_train_acc = fl0_out_dp[c].evaluate(fl0[c].x, fl0[c].y)\n",
    "        fl0_out_dp[c].out_dp_test_acc = fl0_out_dp[c].evaluate(x_target_test, y_target_test)\n",
    "        fl0_out_dp[c].mi_attack = attack.test_mi_attack(ams, fl0[c], fl0[c].x, fl0[c].y, x_target_test, y_target_test)\n",
    "        fl0_out_dp[c].out_dp_mi_attack = attack.test_mi_attack(ams, fl0_out_dp[c], fl0[c].x, fl0[c].y, x_target_test, y_target_test)\n",
    "\n",
    "#     np.save(fl_file+f'/i{fl_iteration}_{c}_outputDP.npy', fl0_out_dp[c].theta)\n",
    "    temp_d = dict(fl0_out_dp[c].__dict__)\n",
    "    temp_d.pop('theta')\n",
    "    with open(fl_file+f'/i{fl_iteration}_{c}_outputDP.json', 'w') as file:\n",
    "        json.dump(temp_d, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
