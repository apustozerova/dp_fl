{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "718a424e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-26 22:16:36.569251: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "from torch import nn,optim\n",
    "import torch\n",
    "\n",
    "import algo\n",
    "import json\n",
    "\n",
    "rand_seed=42\n",
    "np.random.seed(rand_seed)\n",
    "torch.manual_seed(rand_seed)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import attack\n",
    "import random\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "545f33a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_attack(nn.Module):\n",
    "\n",
    "    def __init__(self, h_neurons, do, input_size):\n",
    "        super(Net_attack, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.h_neurons = h_neurons\n",
    "        self.do = do\n",
    "        self.fc1 = nn.Linear(input_size, h_neurons)\n",
    "        self.fc2 = nn.Linear(h_neurons, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.drop = nn.Dropout(do)\n",
    "        self.softmax = nn.Softmax(dim=1)   \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.input_size)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "class Train_args():\n",
    "\n",
    "    def __init__(self, learning_rate, weight_decay, epoch):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weight_decay = weight_decay\n",
    "        self.epoch = epoch\n",
    "         \n",
    "def train_attack_model(model, train_data, train_target, train_args):\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=train_args.learning_rate, weight_decay=train_args.weight_decay)\n",
    "    \n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(train_data)\n",
    "    loss = nn.CrossEntropyLoss()(output, train_target.to(torch.long))\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "\n",
    "    return model\n",
    "\n",
    "def attack_evaluation(model, x, y, dev=\"cpu\", extended=False):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output =  model(x)\n",
    "        out_target = output.argmax(1, keepdim=True)\n",
    "        correct = out_target.to(dev).eq(y.to(dev).view_as(out_target.to(dev))).sum().item()\n",
    "        acc = correct/y.shape[0]\n",
    "\n",
    "        predicted_positive = output.argmax(1, keepdim=True) == 1\n",
    "        labeled_positive = y == 1\n",
    "        tp = predicted_positive.to(dev) * labeled_positive.to(dev).view_as(out_target)\n",
    "        tp_count = tp.to(dev).sum().item()\n",
    "        \n",
    "        if predicted_positive.to(dev).sum().item() != 0:\n",
    "            pre = tp_count / predicted_positive.to(dev).sum().item()\n",
    "        else:\n",
    "            pre = 0\n",
    "        if labeled_positive.to(dev).sum().item() !=0:\n",
    "            rec = tp_count / labeled_positive.to(dev).sum().item()\n",
    "        else:\n",
    "            rec = 0\n",
    "    if extended:\n",
    "        predicted_negative = output.argmax(1, keepdim=True) == 0\n",
    "        labeled_negative = y == 0\n",
    "        tn = predicted_negative.to(dev) * labeled_negative.to(dev).view_as(out_target)\n",
    "        tn_count = tn.to(dev).sum().item()\n",
    "\n",
    "        fp_count = predicted_positive.to(dev).sum().item() - tp.to(dev).sum().item()\n",
    "        fn_count = labeled_positive.to(dev).sum().item() - tp.to(dev).sum().item()\n",
    "        \n",
    "        return acc, pre, rec, tp_count, tn_count, fp_count, fn_count\n",
    "    else:\n",
    "        return acc, pre, rec\n",
    "\n",
    "class model_params(object):\n",
    "\n",
    "    def __init__(self, model_name):\n",
    "        self.model_name      = model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b97d5cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_data = pd.read_csv('../datasets/dataset_purchase', )\n",
    "# y=raw_data['63']\n",
    "# X=raw_data.drop('63', axis=1)\n",
    "# y =  y.replace(100, 0)\n",
    "# print(y.nunique())\n",
    "\n",
    "# X_train, x_shadow, y_train, y_shadow = train_test_split(X, y, train_size=0.1, random_state=42)\n",
    "# print(X_train.shape, x_shadow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc381c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67329, 6170)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../datasets.nosync/texas/100/feats')\n",
    "target = pd.read_csv('../datasets.nosync/texas/100/labels')\n",
    "data['label'] = target\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4769da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = target.replace(100, 0)\n",
    "data['label'] = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "e444fe6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Texas\n",
    "y = data['label']\n",
    "X = data.drop('label', axis=1)\n",
    "# scaler = StandardScaler()\n",
    "# X = scaler.fit_transform(X)\n",
    "tr_size = 10000\n",
    "X_train, X_test, y_train, y_test = train_test_split(X[0:30000], y[0:30000], train_size=0.5, random_state=0)\n",
    "x_target_train = np.array(X_train)[:tr_size]\n",
    "y_target_train = np.array(y_train)[:tr_size]\n",
    "x_target_test = np.array(X_test)[:tr_size]\n",
    "y_target_test = np.array(y_test)[:tr_size]\n",
    "\n",
    "x_shadow = X[30000:]\n",
    "y_shadow = y[30000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "2c8335dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data/texas_x_target_train', x_target_train)\n",
    "np.save('data/texas_y_target_train', y_target_train)\n",
    "np.save('data/texas_x_target_test', x_target_test)\n",
    "np.save('data/texas_y_target_test', y_target_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "91925852",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_texas():\n",
    "\n",
    "    x_target_train = np.load(f'data/texas_x_target_train.npy')\n",
    "    y_target_train = np.load(f'data/texas_y_target_train.npy')\n",
    "    x_target_test = np.load(f'data/texas_x_target_test.npy')\n",
    "    y_target_test = np.load(f'data/texas_y_target_test.npy')\n",
    "\n",
    "    return x_target_train, y_target_train, x_target_test, y_target_test\n",
    "\n",
    "x_target_train, y_target_train, x_target_test, y_target_test = load_texas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "602ac2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = algo.LogisticRegression_DPSGD()\n",
    "\n",
    "model.n_classes      = len(np.unique(y))\n",
    "model.alpha          = 0.001\n",
    "model.max_iter       = 100\n",
    "model.lambda_        = 1e-5\n",
    "model.tolerance      = 1e-5\n",
    "model.DP             = False\n",
    "model.L              = 1\n",
    "model.epsilon        = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "f2b256ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model : 54.2 %\n",
      "The accuracy of the model : 27.500000000000004 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.275"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_seed=42\n",
    "np.random.seed(rand_seed)\n",
    "torch.manual_seed(rand_seed)\n",
    "random.seed(rand_seed)\n",
    "\n",
    "X,y = model.init_theta(x_target_train, y_target_train)\n",
    "model.train(X,y)\n",
    "model.evaluate(x_target_train, y_target_train, acc=True)\n",
    "model.evaluate(x_target_test, y_target_test, acc=True)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "2b54ef05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model : 54.2 %\n",
      "The accuracy of the model : 27.500000000000004 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.275"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_model.evaluate(x_target_train, y_target_train, acc=True)\n",
    "target_model.evaluate(x_target_test, y_target_test, acc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "c79e7f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model10k =model1k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fdb14330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model1k = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c2f620cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/66/0p0lnj8d6zj532q0yvm1zt580000gn/T/ipykernel_52169/513802048.py:7: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  y_shadow_train = np.array(y_shadow[:shadow_size])\n",
      "/var/folders/66/0p0lnj8d6zj532q0yvm1zt580000gn/T/ipykernel_52169/513802048.py:9: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  y_shadow_test = np.array(y_shadow[shadow_size:2*shadow_size])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shadow model:  0\n",
      "The accuracy of the model : 65.2 %\n",
      "The accuracy of the model : 36.7 %\n",
      "Shadow model:  1\n",
      "The accuracy of the model : 63.6 %\n",
      "The accuracy of the model : 37.5 %\n",
      "Shadow model:  2\n",
      "The accuracy of the model : 61.0 %\n",
      "The accuracy of the model : 32.300000000000004 %\n",
      "Shadow model:  3\n",
      "The accuracy of the model : 60.699999999999996 %\n",
      "The accuracy of the model : 33.0 %\n",
      "Shadow model:  4\n",
      "The accuracy of the model : 63.0 %\n",
      "The accuracy of the model : 37.4 %\n"
     ]
    }
   ],
   "source": [
    "s_ms = {}\n",
    "number_of_sms = 5\n",
    "shadow_size = 10000\n",
    "shadow_batch_size = int(shadow_size/number_of_sms)\n",
    "\n",
    "x_shadow_train = np.array(x_shadow[:shadow_size])\n",
    "y_shadow_train = np.array(y_shadow[:shadow_size])\n",
    "x_shadow_test = np.array(x_shadow[shadow_size:2*shadow_size])\n",
    "y_shadow_test = np.array(y_shadow[shadow_size:2*shadow_size])\n",
    "\n",
    "for i in range(number_of_sms):\n",
    "    batch_start = i*shadow_batch_size\n",
    "    batch_end = (i+1)*shadow_batch_size\n",
    "    \n",
    "    shadow_model = algo.LogisticRegression_DPSGD()\n",
    "\n",
    "    shadow_model.n_classes      = len(np.unique(y_target_test))\n",
    "    shadow_model.alpha          = 0.001\n",
    "    shadow_model.max_iter       = 100\n",
    "    shadow_model.lambda_        = 1e-5\n",
    "    shadow_model.tolerance      = 1e-5\n",
    "    shadow_model.DP             = False\n",
    "\n",
    "    X,y = shadow_model.init_theta(x_shadow_train[batch_start:batch_end], y_shadow_train[batch_start:batch_end] )\n",
    "    shadow_model.SGD(X,y)\n",
    "    print('Shadow model: ', i)\n",
    "    shadow_model.evaluate(x_shadow_train[batch_start:batch_end], y_shadow_train[batch_start:batch_end], acc=True)\n",
    "    shadow_model.evaluate(x_shadow_test[batch_start:batch_end], y_shadow_test[batch_start:batch_end], acc=True)\n",
    "    s_ms[i] = shadow_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "04dd133b",
   "metadata": {},
   "outputs": [],
   "source": [
    "shadow_train_pred = []\n",
    "shadow_test_pred = []\n",
    "\n",
    "for i in range(number_of_sms): \n",
    "    batch_start = i*shadow_batch_size\n",
    "    batch_end = (i+1)*shadow_batch_size\n",
    "    \n",
    "    train_prediciton = s_ms[i].predict(x_shadow_train[batch_start:batch_end], y_shadow_train[batch_start:batch_end])\n",
    "    test_prediciton = s_ms[i].predict(x_shadow_test[batch_start:batch_end], y_shadow_test[batch_start:batch_end])\n",
    "    \n",
    "    shadow_train_pred.append(train_prediciton)\n",
    "    shadow_test_pred.append(test_prediciton)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "608b26f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse=False)\n",
    "ohe.fit(np.arange(model.n_classes).reshape(-1, 1))\n",
    "\n",
    "y_shadow_train_ohe = ohe.transform(y_shadow_train.reshape(-1,1)) #encoode the target values\n",
    "y_shadow_test_ohe = ohe.transform(y_shadow_test.reshape(-1,1)) #encoode the target values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "fba08c67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 100)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_shadow_train_ohe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9b8a80b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 100)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_shadow_test_ohe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e0522fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sh_train_pred = np.concatenate(shadow_train_pred)\n",
    "sh_test_pred = np.concatenate(shadow_test_pred)\n",
    "\n",
    "# members\n",
    "labels = np.ones(sh_train_pred.shape[0])\n",
    "# non-members\n",
    "test_labels = np.zeros(sh_test_pred.shape[0])\n",
    "\n",
    "x_1 = np.concatenate((sh_train_pred, sh_test_pred))\n",
    "x_2 = np.concatenate((y_shadow_train_ohe, y_shadow_test_ohe))#.reshape((-1, 1))\n",
    "y_new = np.concatenate((labels, test_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "62f9fd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_train_data = np.concatenate((x_1,x_2),axis=1)\n",
    "attack_train_target = y_new\n",
    "df = pd.DataFrame(attack_train_data)\n",
    "df['a_target'] = attack_train_target\n",
    "df = df.sample(frac = 1)\n",
    "\n",
    "attack_train_data = torch.tensor(np.array(df.drop(['a_target'], axis=1)), dtype=torch.float, requires_grad=True)\n",
    "attack_train_target = torch.tensor(np.array(df['a_target']), dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f70dc25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: (0.5, 0, 0.0)\n",
      "epoch 1: (0.5, 0, 0.0)\n",
      "epoch 2: (0.5, 0, 0.0)\n",
      "epoch 3: (0.5, 0, 0.0)\n",
      "epoch 4: (0.5, 0, 0.0)\n",
      "epoch 5: (0.5, 0, 0.0)\n",
      "epoch 6: (0.5, 0, 0.0)\n",
      "epoch 7: (0.5, 0, 0.0)\n",
      "epoch 8: (0.50005, 1.0, 0.0001)\n",
      "epoch 9: (0.50045, 1.0, 0.0009)\n",
      "epoch 10: (0.5018, 0.95, 0.0038)\n",
      "epoch 11: (0.50325, 0.891566265060241, 0.0074)\n",
      "epoch 12: (0.5066, 0.7894736842105263, 0.018)\n",
      "epoch 13: (0.5083, 0.7207446808510638, 0.0271)\n",
      "epoch 14: (0.51125, 0.6817447495961227, 0.0422)\n",
      "epoch 15: (0.51825, 0.6574633304572908, 0.0762)\n",
      "epoch 16: (0.52665, 0.6427423674343867, 0.12)\n",
      "epoch 17: (0.53395, 0.6303262955854126, 0.1642)\n",
      "epoch 18: (0.54405, 0.6213164417515836, 0.2256)\n",
      "epoch 19: (0.55015, 0.6038947586492646, 0.2915)\n",
      "epoch 20: (0.5514, 0.5805390159824506, 0.3705)\n",
      "epoch 21: (0.56155, 0.5828956228956229, 0.4328)\n",
      "epoch 22: (0.5655, 0.5758277379022922, 0.4974)\n",
      "epoch 23: (0.5616, 0.5650063317855635, 0.5354)\n",
      "epoch 24: (0.5583, 0.5585341365461848, 0.5563)\n",
      "epoch 25: (0.55765, 0.5565806261654725, 0.5671)\n",
      "epoch 26: (0.55825, 0.5561770662551837, 0.5767)\n",
      "epoch 27: (0.55785, 0.5552267303102625, 0.5816)\n",
      "epoch 28: (0.55755, 0.5543591196750732, 0.5869)\n",
      "epoch 29: (0.55745, 0.554080768144592, 0.5886)\n",
      "epoch 30: (0.5559, 0.5521552528456801, 0.5918)\n",
      "epoch 31: (0.55485, 0.5510850330632393, 0.5917)\n",
      "epoch 32: (0.55465, 0.550775806002044, 0.5928)\n",
      "epoch 33: (0.55405, 0.550078754748448, 0.5937)\n",
      "epoch 34: (0.5544, 0.5506517690875232, 0.5914)\n",
      "epoch 35: (0.55465, 0.5512135694873957, 0.5882)\n",
      "epoch 36: (0.55535, 0.5520353483124941, 0.5872)\n",
      "epoch 37: (0.55575, 0.5526589213185983, 0.5851)\n",
      "epoch 38: (0.5558, 0.5528509187346088, 0.5837)\n",
      "epoch 39: (0.55645, 0.5536647970339386, 0.5824)\n",
      "epoch 40: (0.55775, 0.5552578700602813, 0.5803)\n",
      "epoch 41: (0.558, 0.555640828856485, 0.5792)\n",
      "epoch 42: (0.5588, 0.556877539175856, 0.5757)\n",
      "epoch 43: (0.5586, 0.5565746283066229, 0.5765)\n",
      "epoch 44: (0.5586, 0.5570260801868431, 0.5724)\n",
      "epoch 45: (0.5588, 0.5571206528074607, 0.5735)\n",
      "epoch 46: (0.5592, 0.5577110547865081, 0.5721)\n",
      "epoch 47: (0.55925, 0.5578895945285784, 0.571)\n",
      "epoch 48: (0.55995, 0.5587111938105964, 0.5705)\n",
      "epoch 49: (0.5607, 0.5587267801857585, 0.5775)\n",
      "epoch 50: (0.56015, 0.559045842740748, 0.5695)\n",
      "epoch 51: (0.5612, 0.5597189695550351, 0.5736)\n",
      "epoch 52: (0.5612, 0.5601769911504425, 0.5697)\n",
      "epoch 53: (0.56205, 0.5608751103698617, 0.5717)\n",
      "epoch 54: (0.56215, 0.5611051027430931, 0.5707)\n",
      "epoch 55: (0.5623, 0.5612465591820684, 0.5709)\n",
      "epoch 56: (0.56305, 0.5620876415558838, 0.5708)\n",
      "epoch 57: (0.5637, 0.5627709893575089, 0.5711)\n",
      "epoch 58: (0.56325, 0.5625680087051143, 0.5687)\n",
      "epoch 59: (0.56395, 0.563011134101882, 0.5714)\n",
      "epoch 60: (0.5641, 0.5636923688394276, 0.5673)\n",
      "epoch 61: (0.56415, 0.562775222624523, 0.5751)\n",
      "epoch 62: (0.565, 0.5644202180376611, 0.5695)\n",
      "epoch 63: (0.565, 0.5640899230920923, 0.5721)\n",
      "epoch 64: (0.5656, 0.5652606446478313, 0.5682)\n",
      "epoch 65: (0.5663, 0.5653717215539341, 0.5734)\n",
      "epoch 66: (0.56645, 0.5664167916041979, 0.5667)\n",
      "epoch 67: (0.5671, 0.5657198824681685, 0.5776)\n",
      "epoch 68: (0.5672, 0.5669456066945606, 0.5691)\n",
      "epoch 69: (0.56795, 0.5664157951324407, 0.5795)\n",
      "epoch 70: (0.5671, 0.5665146708961142, 0.5715)\n",
      "epoch 71: (0.56855, 0.5676502516530149, 0.5752)\n",
      "epoch 72: (0.5686, 0.5684357541899442, 0.5698)\n",
      "epoch 73: (0.56945, 0.5681483662054754, 0.579)\n",
      "epoch 74: (0.5693, 0.569078947368421, 0.5709)\n",
      "epoch 75: (0.56955, 0.5688954928182268, 0.5743)\n",
      "epoch 76: (0.56945, 0.5691664176874813, 0.5715)\n",
      "epoch 77: (0.57015, 0.5696554463310496, 0.5737)\n",
      "epoch 78: (0.57, 0.569888178913738, 0.5708)\n",
      "epoch 79: (0.57105, 0.5698005698005698, 0.58)\n",
      "epoch 80: (0.57105, 0.571385511905958, 0.5687)\n",
      "epoch 81: (0.57195, 0.5704356338717572, 0.5827)\n",
      "epoch 82: (0.57145, 0.57154300590768, 0.5708)\n",
      "epoch 83: (0.57195, 0.5706153695161449, 0.5814)\n",
      "epoch 84: (0.5722, 0.5724317817014446, 0.5706)\n",
      "epoch 85: (0.5728, 0.5715127701375246, 0.5818)\n",
      "epoch 86: (0.5734, 0.5736356340288925, 0.5718)\n",
      "epoch 87: (0.57325, 0.5720468181371102, 0.5816)\n",
      "epoch 88: (0.57455, 0.5749321539853252, 0.572)\n",
      "epoch 89: (0.574, 0.5727058361171153, 0.5829)\n",
      "epoch 90: (0.5751, 0.5756141763995167, 0.5717)\n",
      "epoch 91: (0.57575, 0.57466732380483, 0.583)\n",
      "epoch 92: (0.5763, 0.5767451217058942, 0.5734)\n",
      "epoch 93: (0.57605, 0.5748302666535472, 0.5842)\n",
      "epoch 94: (0.57755, 0.5777443609022557, 0.5763)\n",
      "epoch 95: (0.57745, 0.5764485243312605, 0.584)\n",
      "epoch 96: (0.5786, 0.5793939393939394, 0.5736)\n",
      "epoch 97: (0.57785, 0.5766466476321749, 0.5857)\n",
      "epoch 98: (0.5789, 0.579648697758934, 0.5742)\n",
      "epoch 99: (0.5788, 0.5776354679802955, 0.5863)\n",
      "epoch 100: (0.58, 0.5807428340734759, 0.5754)\n",
      "epoch 101: (0.5801, 0.5792755344418052, 0.5853)\n",
      "epoch 102: (0.58095, 0.5820744195478049, 0.5741)\n",
      "epoch 103: (0.5812, 0.5801263074797711, 0.5879)\n",
      "epoch 104: (0.5821, 0.5831813576494428, 0.5756)\n",
      "epoch 105: (0.58265, 0.5817750074205996, 0.588)\n",
      "epoch 106: (0.5834, 0.5847733279121773, 0.5753)\n",
      "epoch 107: (0.58375, 0.5827814569536424, 0.5896)\n",
      "epoch 108: (0.58435, 0.5856780091416963, 0.5766)\n",
      "epoch 109: (0.58495, 0.5842340109072881, 0.5892)\n",
      "epoch 110: (0.5858, 0.5871065989847716, 0.5783)\n",
      "epoch 111: (0.58545, 0.5848307356299017, 0.5891)\n",
      "epoch 112: (0.5873, 0.5888097660223804, 0.5788)\n",
      "epoch 113: (0.58655, 0.5859910581222056, 0.5898)\n",
      "epoch 114: (0.588, 0.5897592819257446, 0.5782)\n",
      "epoch 115: (0.5884, 0.588065351663678, 0.5903)\n",
      "epoch 116: (0.5884, 0.5901121304791029, 0.5789)\n",
      "epoch 117: (0.58995, 0.5896720167480809, 0.5915)\n",
      "epoch 118: (0.58965, 0.591601103504649, 0.579)\n",
      "epoch 119: (0.5909, 0.5906461906661348, 0.5923)\n",
      "epoch 120: (0.5905, 0.5925168677162135, 0.5796)\n",
      "epoch 121: (0.5921, 0.5919345178678379, 0.593)\n",
      "epoch 122: (0.59185, 0.5939834237184078, 0.5805)\n",
      "epoch 123: (0.59355, 0.5933353287438891, 0.5947)\n",
      "epoch 124: (0.59295, 0.5954410103706747, 0.5799)\n",
      "epoch 125: (0.5949, 0.5945784333266892, 0.5966)\n",
      "epoch 126: (0.59445, 0.5969812095697711, 0.5814)\n",
      "epoch 127: (0.597, 0.5967677573822825, 0.5982)\n",
      "epoch 128: (0.59625, 0.5986875833077002, 0.5839)\n",
      "epoch 129: (0.5982, 0.5978672513454255, 0.5999)\n",
      "epoch 130: (0.59785, 0.6004723277543895, 0.5848)\n",
      "epoch 131: (0.59935, 0.5992408350814105, 0.5999)\n",
      "epoch 132: (0.59925, 0.6020775480818678, 0.5854)\n",
      "epoch 133: (0.6003, 0.6002198241406874, 0.6007)\n",
      "epoch 134: (0.60035, 0.603442944026389, 0.5854)\n",
      "epoch 135: (0.6018, 0.6018815052041633, 0.6014)\n",
      "epoch 136: (0.6022, 0.60546955624355, 0.5867)\n",
      "epoch 137: (0.603, 0.6031031031031031, 0.6025)\n",
      "epoch 138: (0.60285, 0.6063708759954494, 0.5863)\n",
      "epoch 139: (0.60475, 0.6050335906948762, 0.6034)\n",
      "epoch 140: (0.6047, 0.6084075377925037, 0.5876)\n",
      "epoch 141: (0.6058, 0.6061822561220394, 0.604)\n",
      "epoch 142: (0.6052, 0.6089478044739023, 0.588)\n",
      "epoch 143: (0.60605, 0.6067438349270257, 0.6028)\n",
      "epoch 144: (0.6068, 0.6108113716538701, 0.5887)\n",
      "epoch 145: (0.60685, 0.6076140598247558, 0.6033)\n",
      "epoch 146: (0.6071, 0.6110995850622407, 0.5891)\n",
      "epoch 147: (0.60775, 0.6086737266767523, 0.6035)\n",
      "epoch 148: (0.6077, 0.6117683686176837, 0.5895)\n",
      "epoch 149: (0.60865, 0.6097807416388805, 0.6035)\n",
      "epoch 150: (0.60915, 0.6134969325153374, 0.59)\n",
      "epoch 151: (0.609, 0.6101455133387227, 0.6038)\n",
      "epoch 152: (0.60965, 0.6138747533492575, 0.5911)\n",
      "epoch 153: (0.60945, 0.6105890673941599, 0.6043)\n",
      "epoch 154: (0.611, 0.6156490935611586, 0.5909)\n",
      "epoch 155: (0.61025, 0.6114199090449722, 0.605)\n",
      "epoch 156: (0.61165, 0.6163869488168456, 0.5913)\n",
      "epoch 157: (0.6112, 0.6123005453443748, 0.6063)\n",
      "epoch 158: (0.61265, 0.6172582491932965, 0.593)\n",
      "epoch 159: (0.6127, 0.6141843971631206, 0.6062)\n",
      "epoch 160: (0.6144, 0.6194154488517746, 0.5934)\n",
      "epoch 161: (0.613, 0.6143956266450699, 0.6069)\n",
      "epoch 162: (0.61465, 0.6198139826523148, 0.5931)\n",
      "epoch 163: (0.6145, 0.615984602917342, 0.6081)\n",
      "epoch 164: (0.6159, 0.6211582688689107, 0.5942)\n",
      "epoch 165: (0.615, 0.6165146909827761, 0.6085)\n",
      "epoch 166: (0.61625, 0.6214352867439674, 0.5949)\n",
      "epoch 167: (0.6169, 0.6190670197596252, 0.6078)\n",
      "epoch 168: (0.61715, 0.622785871501939, 0.5942)\n",
      "epoch 169: (0.6172, 0.6191541276941847, 0.609)\n",
      "epoch 170: (0.61795, 0.623598449125013, 0.5951)\n",
      "epoch 171: (0.6183, 0.6207389263114922, 0.6082)\n",
      "epoch 172: (0.61855, 0.624514231698351, 0.5946)\n",
      "epoch 173: (0.61945, 0.6219997957307731, 0.609)\n",
      "epoch 174: (0.61875, 0.6246719160104987, 0.595)\n",
      "epoch 175: (0.6202, 0.6227783452502553, 0.6097)\n",
      "epoch 176: (0.62, 0.6262360614348832, 0.5953)\n",
      "epoch 177: (0.6205, 0.6230345109250561, 0.6102)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 178: (0.62115, 0.6273520445705876, 0.5968)\n",
      "epoch 179: (0.6216, 0.6243353783231084, 0.6106)\n",
      "epoch 180: (0.622, 0.6285292878213232, 0.5966)\n",
      "epoch 181: (0.62185, 0.6247057619486235, 0.6104)\n",
      "epoch 182: (0.6228, 0.6296452702702703, 0.5964)\n",
      "epoch 183: (0.6226, 0.6256147540983606, 0.6106)\n",
      "epoch 184: (0.6236, 0.6305725755334882, 0.5969)\n",
      "epoch 185: (0.62315, 0.6262688403568133, 0.6108)\n",
      "epoch 186: (0.6242, 0.6310679611650486, 0.598)\n",
      "epoch 187: (0.62385, 0.6270647378680619, 0.6112)\n",
      "epoch 188: (0.62475, 0.6316900665048031, 0.5984)\n",
      "epoch 189: (0.6246, 0.6282156822391438, 0.6105)\n",
      "epoch 190: (0.62565, 0.6327522451135763, 0.5989)\n",
      "epoch 191: (0.62515, 0.6284248332478194, 0.6124)\n",
      "epoch 192: (0.6259, 0.6330585499894315, 0.599)\n",
      "epoch 193: (0.62585, 0.629728893928461, 0.6109)\n",
      "epoch 194: (0.6256, 0.6330790421699513, 0.5975)\n",
      "epoch 195: (0.62635, 0.6301369863013698, 0.6118)\n",
      "epoch 196: (0.626, 0.6337295690936107, 0.5971)\n",
      "epoch 197: (0.62735, 0.6310859495625322, 0.6131)\n",
      "epoch 198: (0.62625, 0.6337252409702362, 0.5983)\n",
      "epoch 199: (0.62825, 0.6322301268171977, 0.6132)\n",
      "epoch 200: (0.62665, 0.6342626947948691, 0.5983)\n",
      "epoch 201: (0.62945, 0.6333024405313562, 0.615)\n",
      "epoch 202: (0.62805, 0.6358044331318273, 0.5995)\n",
      "epoch 203: (0.62975, 0.6335013890317934, 0.6157)\n",
      "epoch 204: (0.62875, 0.6363155108523028, 0.601)\n",
      "epoch 205: (0.6303, 0.63416392092257, 0.6159)\n",
      "epoch 206: (0.629, 0.6364790520524757, 0.6016)\n",
      "epoch 207: (0.6304, 0.6344607135491854, 0.6153)\n",
      "epoch 208: (0.62975, 0.6374324753733714, 0.6018)\n",
      "epoch 209: (0.63075, 0.6350025813113062, 0.615)\n",
      "epoch 210: (0.62985, 0.6376842328491146, 0.6014)\n",
      "epoch 211: (0.6314, 0.635519801980198, 0.6162)\n",
      "epoch 212: (0.62995, 0.637848732364485, 0.6013)\n",
      "epoch 213: (0.63185, 0.6363354358391066, 0.6154)\n",
      "epoch 214: (0.6303, 0.6381760339342524, 0.6018)\n",
      "epoch 215: (0.63225, 0.6362699639361155, 0.6175)\n",
      "epoch 216: (0.63095, 0.6385274516026658, 0.6036)\n",
      "epoch 217: (0.63265, 0.6370492819506147, 0.6166)\n",
      "epoch 218: (0.6314, 0.6392834428662285, 0.6031)\n",
      "epoch 219: (0.6329, 0.6373785404176142, 0.6166)\n",
      "epoch 220: (0.63195, 0.6399702980799831, 0.6033)\n",
      "epoch 221: (0.6334, 0.6376392901361948, 0.618)\n",
      "epoch 222: (0.632, 0.6399194403222387, 0.6037)\n",
      "epoch 223: (0.63325, 0.6376407395930173, 0.6173)\n",
      "epoch 224: (0.6325, 0.6405090137857901, 0.604)\n",
      "epoch 225: (0.6336, 0.6381592554291624, 0.6171)\n",
      "epoch 226: (0.63245, 0.6407694760335849, 0.6029)\n",
      "epoch 227: (0.6343, 0.638797023563456, 0.6181)\n",
      "epoch 228: (0.63355, 0.6420291396362863, 0.6037)\n",
      "epoch 229: (0.63425, 0.6385877980799008, 0.6186)\n",
      "epoch 230: (0.63385, 0.6423179160021265, 0.6041)\n",
      "epoch 231: (0.6346, 0.6390783219673486, 0.6185)\n",
      "epoch 232: (0.63435, 0.642879931936616, 0.6045)\n",
      "epoch 233: (0.63515, 0.6396321934084099, 0.6191)\n",
      "epoch 234: (0.6345, 0.6432374866879659, 0.604)\n",
      "epoch 235: (0.6357, 0.6402728964234029, 0.6194)\n",
      "epoch 236: (0.63525, 0.6442974501226928, 0.6039)\n",
      "epoch 237: (0.63625, 0.6408268733850129, 0.62)\n",
      "epoch 238: (0.63585, 0.6449685199018248, 0.6044)\n",
      "epoch 239: (0.63645, 0.6409461832455325, 0.6205)\n",
      "epoch 240: (0.63615, 0.6453196712562707, 0.6046)\n",
      "epoch 241: (0.6369, 0.6413380136279165, 0.6212)\n",
      "epoch 242: (0.63665, 0.6456046883324454, 0.6059)\n",
      "epoch 243: (0.638, 0.6429163214581607, 0.6208)\n",
      "epoch 244: (0.6367, 0.6457666879931755, 0.6056)\n",
      "epoch 245: (0.6384, 0.6432415648933968, 0.6215)\n",
      "epoch 246: (0.63725, 0.6464624906626828, 0.6058)\n",
      "epoch 247: (0.6395, 0.6443202979515829, 0.6228)\n",
      "epoch 248: (0.6374, 0.6464818763326226, 0.6064)\n",
      "epoch 249: (0.6397, 0.6447368421052632, 0.6223)\n",
      "epoch 250: (0.63775, 0.6469646857996373, 0.6064)\n",
      "epoch 251: (0.6401, 0.6450610892524332, 0.623)\n",
      "epoch 252: (0.6388, 0.6481956011103993, 0.6071)\n",
      "epoch 253: (0.64075, 0.6459002798797554, 0.6231)\n",
      "epoch 254: (0.63855, 0.6479444741057128, 0.6068)\n",
      "epoch 255: (0.6403, 0.6453886010362694, 0.6228)\n",
      "epoch 256: (0.6394, 0.6489634537294293, 0.6073)\n",
      "epoch 257: (0.64095, 0.646471994180609, 0.6221)\n",
      "epoch 258: (0.6398, 0.6493908954904895, 0.6077)\n",
      "epoch 259: (0.64105, 0.6463022508038585, 0.6231)\n",
      "epoch 260: (0.63975, 0.6493534252431334, 0.6076)\n",
      "epoch 261: (0.64205, 0.647860934735089, 0.6224)\n",
      "epoch 262: (0.64045, 0.6502942750133761, 0.6077)\n",
      "epoch 263: (0.642, 0.6473640514736405, 0.6238)\n",
      "epoch 264: (0.6409, 0.6507919520547946, 0.6081)\n",
      "epoch 265: (0.642, 0.6473946439692755, 0.6237)\n",
      "epoch 266: (0.6419, 0.6518621575342466, 0.6091)\n",
      "epoch 267: (0.6429, 0.6486374037861452, 0.6236)\n",
      "epoch 268: (0.64225, 0.6523508621612938, 0.6091)\n",
      "epoch 269: (0.64295, 0.6487358235355322, 0.6235)\n",
      "epoch 270: (0.6432, 0.6535162950257289, 0.6096)\n",
      "epoch 271: (0.6434, 0.6494061262763076, 0.6233)\n",
      "epoch 272: (0.64355, 0.654073199527745, 0.6094)\n",
      "epoch 273: (0.6442, 0.6501457725947521, 0.6244)\n",
      "epoch 274: (0.6436, 0.6541434091884929, 0.6094)\n",
      "epoch 275: (0.6443, 0.6505634390651085, 0.6235)\n",
      "epoch 276: (0.64415, 0.6549167114454594, 0.6094)\n",
      "epoch 277: (0.6445, 0.650709219858156, 0.6239)\n",
      "epoch 278: (0.6444, 0.6553690553044975, 0.6091)\n",
      "epoch 279: (0.6445, 0.6509611366485583, 0.6231)\n",
      "epoch 280: (0.6449, 0.6561085972850679, 0.609)\n",
      "epoch 281: (0.6453, 0.6517969076473047, 0.6239)\n",
      "epoch 282: (0.6455, 0.6566537467700259, 0.6099)\n",
      "epoch 283: (0.64545, 0.6523515240389651, 0.6228)\n",
      "epoch 284: (0.64605, 0.6573984265545856, 0.61)\n",
      "epoch 285: (0.64575, 0.6526657588771342, 0.6231)\n",
      "epoch 286: (0.6461, 0.6575711820534944, 0.6097)\n",
      "epoch 287: (0.64595, 0.6532283464566929, 0.6222)\n",
      "epoch 288: (0.64635, 0.6578918977235948, 0.6098)\n",
      "epoch 289: (0.64615, 0.6531489049565127, 0.6233)\n",
      "epoch 290: (0.64715, 0.6588578214401382, 0.6103)\n",
      "epoch 291: (0.6466, 0.6534435838392296, 0.6243)\n",
      "epoch 292: (0.6478, 0.6596112311015119, 0.6108)\n",
      "epoch 293: (0.64705, 0.6542212899842685, 0.6238)\n",
      "epoch 294: (0.6479, 0.659753726506805, 0.6108)\n",
      "epoch 295: (0.6473, 0.6543378038558256, 0.6245)\n",
      "epoch 296: (0.6484, 0.6603284356093345, 0.6112)\n",
      "epoch 297: (0.6476, 0.654911838790932, 0.624)\n",
      "epoch 298: (0.64835, 0.6605693256845979, 0.6103)\n",
      "epoch 299: (0.648, 0.6553968920621588, 0.6242)\n",
      "epoch 300: (0.6488, 0.661004111664142, 0.6109)\n",
      "epoch 301: (0.64835, 0.6560429157462923, 0.6237)\n",
      "epoch 302: (0.6492, 0.6614718614718614, 0.6112)\n",
      "epoch 303: (0.64865, 0.6560629921259843, 0.6249)\n",
      "epoch 304: (0.64975, 0.6620144974575354, 0.6119)\n",
      "epoch 305: (0.64895, 0.6567729712661825, 0.624)\n",
      "epoch 306: (0.6499, 0.6621592384249243, 0.6121)\n",
      "epoch 307: (0.6497, 0.6572148708254568, 0.6258)\n",
      "epoch 308: (0.6502, 0.6626245127760936, 0.612)\n",
      "epoch 309: (0.64975, 0.6576813730651785, 0.6246)\n",
      "epoch 310: (0.65025, 0.6628726287262873, 0.6115)\n",
      "epoch 311: (0.65065, 0.6588967408501213, 0.6247)\n",
      "epoch 312: (0.6507, 0.6635199652777778, 0.6115)\n",
      "epoch 313: (0.65095, 0.6590789335019496, 0.6254)\n",
      "epoch 314: (0.6506, 0.6635179153094463, 0.6111)\n",
      "epoch 315: (0.6515, 0.6598101265822784, 0.6255)\n",
      "epoch 316: (0.65155, 0.6646745626426165, 0.6117)\n",
      "epoch 317: (0.65145, 0.6600105652403592, 0.6247)\n",
      "epoch 318: (0.65145, 0.6646374605935428, 0.6114)\n",
      "epoch 319: (0.65225, 0.6609918578830496, 0.6251)\n",
      "epoch 320: (0.6523, 0.6657957761811453, 0.6116)\n",
      "epoch 321: (0.65275, 0.6614522777719057, 0.6258)\n",
      "epoch 322: (0.65235, 0.6657599825916658, 0.6119)\n",
      "epoch 323: (0.6532, 0.6621164021164021, 0.6257)\n",
      "epoch 324: (0.65285, 0.6663401893568397, 0.6123)\n",
      "epoch 325: (0.6531, 0.6618393234672304, 0.6261)\n",
      "epoch 326: (0.6528, 0.6663038746190684, 0.6122)\n",
      "epoch 327: (0.6533, 0.6624284806102988, 0.6252)\n",
      "epoch 328: (0.6532, 0.6669208977990848, 0.6121)\n",
      "epoch 329: (0.65365, 0.6623349181193872, 0.6269)\n",
      "epoch 330: (0.654, 0.6678657074340527, 0.6127)\n",
      "epoch 331: (0.6544, 0.6631790319171422, 0.6275)\n",
      "epoch 332: (0.65445, 0.6683745775645917, 0.6131)\n",
      "epoch 333: (0.65465, 0.66335692405197, 0.628)\n",
      "epoch 334: (0.6543, 0.6682660850599782, 0.6128)\n",
      "epoch 335: (0.65535, 0.6643741403026134, 0.6279)\n",
      "epoch 336: (0.65475, 0.6688857361126269, 0.6129)\n",
      "epoch 337: (0.6556, 0.6643777730826115, 0.6289)\n",
      "epoch 338: (0.65485, 0.6691056022714863, 0.6127)\n",
      "epoch 339: (0.65515, 0.6641277901195388, 0.6278)\n",
      "epoch 340: (0.65525, 0.6696165191740413, 0.6129)\n",
      "epoch 341: (0.6555, 0.6643763213530656, 0.6285)\n",
      "epoch 342: (0.65545, 0.6698721451207519, 0.613)\n",
      "epoch 343: (0.6557, 0.664727041895895, 0.6283)\n",
      "epoch 344: (0.6559, 0.6703080620493773, 0.6136)\n",
      "epoch 345: (0.65625, 0.6652914418703058, 0.6289)\n",
      "epoch 346: (0.6563, 0.6709317585301837, 0.6135)\n",
      "epoch 347: (0.6567, 0.6661365564037319, 0.6283)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 348: (0.65675, 0.6715176715176715, 0.6137)\n",
      "epoch 349: (0.657, 0.6661727349703641, 0.6294)\n",
      "epoch 350: (0.657, 0.6718852638493541, 0.6137)\n",
      "epoch 351: (0.6573, 0.6666313559322034, 0.6293)\n",
      "epoch 352: (0.6572, 0.6722550953320184, 0.6135)\n",
      "epoch 353: (0.6574, 0.6666313783612111, 0.6297)\n",
      "epoch 354: (0.65735, 0.6723627998685507, 0.6138)\n",
      "epoch 355: (0.6579, 0.6674798472634705, 0.6293)\n",
      "epoch 356: (0.6578, 0.6728368017524644, 0.6143)\n",
      "epoch 357: (0.65815, 0.6677272245200976, 0.6296)\n",
      "epoch 358: (0.6584, 0.6736461302345976, 0.6145)\n",
      "epoch 359: (0.6587, 0.668399830220713, 0.6299)\n",
      "epoch 360: (0.65825, 0.6735007126411577, 0.6143)\n",
      "epoch 361: (0.6592, 0.6688229056203605, 0.6307)\n",
      "epoch 362: (0.6584, 0.6736461302345976, 0.6145)\n",
      "epoch 363: (0.65945, 0.6692854867820363, 0.6304)\n",
      "epoch 364: (0.65865, 0.6742832033395584, 0.6138)\n",
      "epoch 365: (0.66005, 0.6699224970803694, 0.631)\n",
      "epoch 366: (0.6591, 0.6746049165935031, 0.6147)\n",
      "epoch 367: (0.6603, 0.6704231341696789, 0.6306)\n",
      "epoch 368: (0.6597, 0.6754559437486267, 0.6148)\n",
      "epoch 369: (0.66025, 0.6702794602061417, 0.6308)\n",
      "epoch 370: (0.6602, 0.6760052735662492, 0.6153)\n",
      "epoch 371: (0.66025, 0.6703156552237219, 0.6307)\n",
      "epoch 372: (0.6606, 0.676522312596175, 0.6155)\n",
      "epoch 373: (0.6613, 0.671522756273926, 0.6315)\n",
      "epoch 374: (0.6607, 0.6767099186276666, 0.6154)\n",
      "epoch 375: (0.66105, 0.6712751249601191, 0.6312)\n",
      "epoch 376: (0.661, 0.6770008795074758, 0.6158)\n",
      "epoch 377: (0.66125, 0.6714149037950462, 0.6316)\n",
      "epoch 378: (0.66155, 0.6777423258884365, 0.616)\n",
      "epoch 379: (0.6613, 0.6716322621834433, 0.6312)\n",
      "epoch 380: (0.6621, 0.6785242290748899, 0.6161)\n",
      "epoch 381: (0.6616, 0.6719514790380932, 0.6315)\n",
      "epoch 382: (0.6624, 0.6788546255506608, 0.6164)\n",
      "epoch 383: (0.6619, 0.6723073648361004, 0.6317)\n",
      "epoch 384: (0.66285, 0.6796866379785943, 0.616)\n",
      "epoch 385: (0.66225, 0.6728454245232769, 0.6316)\n",
      "epoch 386: (0.663, 0.6799911660777385, 0.6158)\n",
      "epoch 387: (0.6628, 0.6734128674904133, 0.6322)\n",
      "epoch 388: (0.66315, 0.6800971409647864, 0.6161)\n",
      "epoch 389: (0.6633, 0.6740938166311301, 0.6323)\n",
      "epoch 390: (0.6631, 0.6800220750551876, 0.6161)\n",
      "epoch 391: (0.6633, 0.6742052485598464, 0.632)\n",
      "epoch 392: (0.6636, 0.6806936160812901, 0.6163)\n",
      "epoch 393: (0.66375, 0.6745177448577214, 0.6329)\n",
      "epoch 394: (0.6645, 0.6818483307539244, 0.6168)\n",
      "epoch 395: (0.6641, 0.6750960307298336, 0.6327)\n",
      "epoch 396: (0.66495, 0.6823659480375899, 0.6172)\n",
      "epoch 397: (0.664, 0.6751388295600171, 0.6322)\n",
      "epoch 398: (0.665, 0.6822801590808661, 0.6176)\n",
      "epoch 399: (0.66465, 0.675739139716085, 0.6331)\n",
      "epoch 0: (0.5, 0, 0.0)\n",
      "epoch 1: (0.5, 0, 0.0)\n",
      "epoch 2: (0.5, 0, 0.0)\n",
      "epoch 3: (0.50005, 1.0, 0.0001)\n",
      "epoch 4: (0.50005, 1.0, 0.0001)\n",
      "epoch 5: (0.50005, 1.0, 0.0001)\n",
      "epoch 6: (0.4999, 0.375, 0.0003)\n",
      "epoch 7: (0.49995, 0.49295774647887325, 0.0035)\n",
      "epoch 8: (0.49995, 0.4982078853046595, 0.0139)\n",
      "epoch 9: (0.5029, 0.5420289855072464, 0.0374)\n",
      "epoch 10: (0.5062, 0.5506535947712419, 0.0674)\n",
      "epoch 11: (0.50965, 0.5521339816315505, 0.1022)\n",
      "epoch 12: (0.5196, 0.5736288504883547, 0.1527)\n",
      "epoch 13: (0.525, 0.5745823389021479, 0.1926)\n",
      "epoch 14: (0.53325, 0.5817154091914475, 0.2367)\n",
      "epoch 15: (0.5367, 0.5761726857617269, 0.2776)\n",
      "epoch 16: (0.53865, 0.5648381144103338, 0.3367)\n",
      "epoch 17: (0.5425, 0.5647865853658537, 0.3705)\n",
      "epoch 18: (0.54865, 0.5643093192333113, 0.4269)\n",
      "epoch 19: (0.54995, 0.5681725126245394, 0.4163)\n",
      "epoch 20: (0.55165, 0.5647648902821316, 0.4504)\n",
      "epoch 21: (0.55195, 0.5606113639015284, 0.4805)\n",
      "epoch 22: (0.5544, 0.564317805627808, 0.4773)\n",
      "epoch 23: (0.5517, 0.5562812976268234, 0.511)\n",
      "epoch 24: (0.556, 0.562625810780586, 0.5031)\n",
      "epoch 25: (0.55285, 0.5550463493386105, 0.5329)\n",
      "epoch 26: (0.55215, 0.5534597642234751, 0.5399)\n",
      "epoch 27: (0.554, 0.5573005093378608, 0.5252)\n",
      "epoch 28: (0.5526, 0.5531850353892821, 0.5471)\n",
      "epoch 29: (0.5533, 0.5533319991995197, 0.553)\n",
      "epoch 30: (0.55465, 0.5539539934840557, 0.5611)\n",
      "epoch 31: (0.5542, 0.5520053732488965, 0.5753)\n",
      "epoch 32: (0.55445, 0.5530753484745102, 0.5674)\n",
      "epoch 33: (0.5535, 0.5499067164179104, 0.5895)\n",
      "epoch 34: (0.5539, 0.5485323248694399, 0.6092)\n",
      "epoch 35: (0.557, 0.5531914893617021, 0.5928)\n",
      "epoch 36: (0.5576, 0.5544732362398336, 0.5863)\n",
      "epoch 37: (0.5569, 0.5529400818756978, 0.5943)\n",
      "epoch 38: (0.55775, 0.5558564658090724, 0.5747)\n",
      "epoch 39: (0.5549, 0.5511458915595304, 0.5916)\n",
      "epoch 40: (0.556, 0.5521221146686522, 0.5932)\n",
      "epoch 41: (0.5562, 0.551787688905271, 0.5988)\n",
      "epoch 42: (0.55665, 0.5523615860985304, 0.5976)\n",
      "epoch 43: (0.55915, 0.5560504122050601, 0.5868)\n",
      "epoch 44: (0.55725, 0.5545082357421689, 0.5824)\n",
      "epoch 45: (0.5578, 0.5534097209388283, 0.5989)\n",
      "epoch 46: (0.55605, 0.5513701768857117, 0.6016)\n",
      "epoch 47: (0.5554, 0.5507511909124221, 0.6012)\n",
      "epoch 48: (0.5568, 0.5520814230698698, 0.6021)\n",
      "epoch 49: (0.5591, 0.5554617117117117, 0.5919)\n",
      "epoch 50: (0.55825, 0.5544748901150285, 0.5929)\n",
      "epoch 51: (0.558, 0.5531817348248671, 0.6033)\n",
      "epoch 52: (0.56075, 0.5564538611653193, 0.5988)\n",
      "epoch 53: (0.5599, 0.5545140152894066, 0.6093)\n",
      "epoch 54: (0.5611, 0.5571990263995507, 0.5952)\n",
      "epoch 55: (0.5612, 0.556740218802151, 0.6005)\n",
      "epoch 56: (0.5604, 0.5551598173515981, 0.6079)\n",
      "epoch 57: (0.56295, 0.5583572819134143, 0.6023)\n",
      "epoch 58: (0.56555, 0.5626134301270418, 0.589)\n",
      "epoch 59: (0.56635, 0.5646749195828054, 0.5793)\n",
      "epoch 60: (0.5669, 0.5645503666538016, 0.5851)\n",
      "epoch 61: (0.56565, 0.5617649825947878, 0.5971)\n",
      "epoch 62: (0.5686, 0.5657970458469211, 0.5899)\n",
      "epoch 63: (0.5656, 0.5605612998522895, 0.6072)\n",
      "epoch 64: (0.5673, 0.5635265244478006, 0.597)\n",
      "epoch 65: (0.5677, 0.5632710280373832, 0.6027)\n",
      "epoch 66: (0.5688, 0.5648934163365402, 0.5989)\n",
      "epoch 67: (0.57145, 0.5694971306293162, 0.5855)\n",
      "epoch 68: (0.57135, 0.5707486365889936, 0.5756)\n",
      "epoch 69: (0.57005, 0.5674790482612465, 0.5891)\n",
      "epoch 70: (0.5711, 0.5680643308443424, 0.5934)\n",
      "epoch 71: (0.57, 0.5655799138092561, 0.6037)\n",
      "epoch 72: (0.5703, 0.5653102935711631, 0.6085)\n",
      "epoch 73: (0.57005, 0.5639784455201389, 0.6175)\n",
      "epoch 74: (0.5716, 0.5666542543288028, 0.6087)\n",
      "epoch 75: (0.5748, 0.5708736024256206, 0.6025)\n",
      "epoch 76: (0.5746, 0.5720216257964859, 0.5925)\n",
      "epoch 77: (0.5738, 0.56912701386287, 0.6076)\n",
      "epoch 78: (0.57655, 0.5745883269999026, 0.5897)\n",
      "epoch 79: (0.57835, 0.5775512224091854, 0.5835)\n",
      "epoch 80: (0.57815, 0.5777225261064147, 0.5809)\n",
      "epoch 81: (0.57555, 0.5720965741005821, 0.5995)\n",
      "epoch 82: (0.5779, 0.5771287128712871, 0.5829)\n",
      "epoch 83: (0.57865, 0.5769042730028356, 0.59)\n",
      "epoch 84: (0.5779, 0.5743604429171439, 0.6017)\n",
      "epoch 85: (0.57915, 0.5772119793190909, 0.5917)\n",
      "epoch 86: (0.5806, 0.5802149681528662, 0.583)\n",
      "epoch 87: (0.5821, 0.5829460497070115, 0.577)\n",
      "epoch 88: (0.58115, 0.5792403085636169, 0.5932)\n",
      "epoch 89: (0.58, 0.5774443368828654, 0.5965)\n",
      "epoch 90: (0.5804, 0.5781189273221919, 0.595)\n",
      "epoch 91: (0.5806, 0.576981852913085, 0.6041)\n",
      "epoch 92: (0.58125, 0.5793379552778049, 0.5933)\n",
      "epoch 93: (0.58155, 0.5805432098765432, 0.5878)\n",
      "epoch 94: (0.582, 0.5787552823665002, 0.6026)\n",
      "epoch 95: (0.58285, 0.5818110002962378, 0.5892)\n",
      "epoch 96: (0.5845, 0.582859384192979, 0.5944)\n",
      "epoch 97: (0.58445, 0.5819505094614265, 0.5997)\n",
      "epoch 98: (0.58405, 0.5808561808561808, 0.6038)\n",
      "epoch 99: (0.5857, 0.5851211760031784, 0.5891)\n",
      "epoch 100: (0.58535, 0.583033369004767, 0.5993)\n",
      "epoch 101: (0.586, 0.5858454781393492, 0.5869)\n",
      "epoch 102: (0.58455, 0.582287104622871, 0.5983)\n",
      "epoch 103: (0.5854, 0.5835943617854347, 0.5962)\n",
      "epoch 104: (0.58605, 0.5838122138891595, 0.5994)\n",
      "epoch 105: (0.58665, 0.5850593894178855, 0.596)\n",
      "epoch 106: (0.58845, 0.588957055214724, 0.5856)\n",
      "epoch 107: (0.5873, 0.5861286503551697, 0.5941)\n",
      "epoch 108: (0.58975, 0.5911075017764694, 0.5823)\n",
      "epoch 109: (0.5891, 0.5880086922165152, 0.5953)\n",
      "epoch 110: (0.5897, 0.5898077693231878, 0.5891)\n",
      "epoch 111: (0.59055, 0.5935530530013431, 0.5745)\n",
      "epoch 112: (0.59135, 0.5917445013558301, 0.5892)\n",
      "epoch 113: (0.5916, 0.593089430894309, 0.5836)\n",
      "epoch 114: (0.5915, 0.5935391535473319, 0.5806)\n",
      "epoch 115: (0.5926, 0.5919563058589871, 0.5961)\n",
      "epoch 116: (0.59325, 0.5954745571823488, 0.5816)\n",
      "epoch 117: (0.5926, 0.592304625199362, 0.5942)\n",
      "epoch 118: (0.595, 0.59765625, 0.5814)\n",
      "epoch 119: (0.5957, 0.5990683229813665, 0.5787)\n",
      "epoch 120: (0.59725, 0.5993868165559529, 0.5865)\n",
      "epoch 121: (0.5964, 0.5957679316511028, 0.5997)\n",
      "epoch 122: (0.59805, 0.599959221123458, 0.5885)\n",
      "epoch 123: (0.59935, 0.6011607779248549, 0.5904)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 124: (0.60095, 0.6039328734685473, 0.5866)\n",
      "epoch 125: (0.6009, 0.60380658436214, 0.5869)\n",
      "epoch 126: (0.6004, 0.6015166835187058, 0.5949)\n",
      "epoch 127: (0.60185, 0.604708543230184, 0.5882)\n",
      "epoch 128: (0.60215, 0.6039906342257966, 0.5933)\n",
      "epoch 129: (0.602, 0.6066053511705686, 0.5804)\n",
      "epoch 130: (0.6033, 0.6052149113872479, 0.5942)\n",
      "epoch 131: (0.603, 0.6088104796112402, 0.5763)\n",
      "epoch 132: (0.60475, 0.6068114612011828, 0.5951)\n",
      "epoch 133: (0.60415, 0.6064819548103466, 0.5932)\n",
      "epoch 134: (0.60365, 0.6040140491721023, 0.6019)\n",
      "epoch 135: (0.603, 0.6051664284255667, 0.5927)\n",
      "epoch 136: (0.60205, 0.6008299575140796, 0.6081)\n",
      "epoch 137: (0.6032, 0.6047503045066992, 0.5958)\n",
      "epoch 138: (0.60425, 0.6078411089272784, 0.5876)\n",
      "epoch 139: (0.60535, 0.6058687569088533, 0.6029)\n",
      "epoch 140: (0.60505, 0.6055036657627799, 0.6029)\n",
      "epoch 141: (0.6063, 0.6079626244160065, 0.5986)\n",
      "epoch 142: (0.6068, 0.6092918542775276, 0.5954)\n",
      "epoch 143: (0.60695, 0.6091215182124273, 0.597)\n",
      "epoch 144: (0.6078, 0.6076492909926103, 0.6085)\n",
      "epoch 145: (0.60775, 0.6068842376748338, 0.6118)\n",
      "epoch 146: (0.60795, 0.6073595226255595, 0.6107)\n",
      "epoch 147: (0.6081, 0.6049107142857143, 0.6233)\n",
      "epoch 148: (0.6098, 0.6104405552202776, 0.6069)\n",
      "epoch 149: (0.6119, 0.6149578795972879, 0.5986)\n",
      "epoch 150: (0.6131, 0.6192283364958887, 0.5874)\n",
      "epoch 151: (0.61275, 0.6197302750345121, 0.5836)\n",
      "epoch 152: (0.61225, 0.6159727244550057, 0.5962)\n",
      "epoch 153: (0.61225, 0.6127574083375188, 0.61)\n",
      "epoch 154: (0.6149, 0.617894520829058, 0.6022)\n",
      "epoch 155: (0.616, 0.6220538720538721, 0.5912)\n",
      "epoch 156: (0.61745, 0.6233588908728075, 0.5935)\n",
      "epoch 157: (0.6168, 0.6220480668756531, 0.5953)\n",
      "epoch 158: (0.61635, 0.6176559813934674, 0.6108)\n",
      "epoch 159: (0.6164, 0.6214524207011686, 0.5956)\n",
      "epoch 160: (0.61745, 0.6216468151216986, 0.6002)\n",
      "epoch 161: (0.61745, 0.6173913043478261, 0.6177)\n",
      "epoch 162: (0.61665, 0.614329118886602, 0.6268)\n",
      "epoch 163: (0.61775, 0.6188313654253709, 0.6132)\n",
      "epoch 164: (0.6179, 0.6228636932055023, 0.5977)\n",
      "epoch 165: (0.61845, 0.6223277909738717, 0.6026)\n",
      "epoch 166: (0.61825, 0.6212447452066031, 0.6059)\n",
      "epoch 167: (0.62005, 0.6226627158475528, 0.6094)\n",
      "epoch 168: (0.6187, 0.626357249308069, 0.5884)\n",
      "epoch 169: (0.61715, 0.6281868913447861, 0.5741)\n",
      "epoch 170: (0.619, 0.624921268108335, 0.5953)\n",
      "epoch 171: (0.6186, 0.624422996223248, 0.5952)\n",
      "epoch 172: (0.6193, 0.6210675867667952, 0.612)\n",
      "epoch 173: (0.6194, 0.6261889663918834, 0.5925)\n",
      "epoch 174: (0.61895, 0.6233793174981849, 0.601)\n",
      "epoch 175: (0.61885, 0.6200868950186925, 0.6137)\n",
      "epoch 176: (0.61995, 0.6267568424389729, 0.5931)\n",
      "epoch 177: (0.61905, 0.6287723093564088, 0.5813)\n",
      "epoch 178: (0.6199, 0.626503481747204, 0.5938)\n",
      "epoch 179: (0.6219, 0.6234555398014989, 0.6156)\n",
      "epoch 180: (0.62225, 0.6254489481785531, 0.6095)\n",
      "epoch 181: (0.6221, 0.6255656108597285, 0.6083)\n",
      "epoch 182: (0.6216, 0.6284326151246303, 0.595)\n",
      "epoch 183: (0.62065, 0.6303056485581596, 0.5836)\n",
      "epoch 184: (0.62255, 0.6283918281822944, 0.5998)\n",
      "epoch 185: (0.6225, 0.6275775880024995, 0.6026)\n",
      "epoch 186: (0.6236, 0.625, 0.618)\n",
      "epoch 187: (0.62265, 0.6285774190166684, 0.5996)\n",
      "epoch 188: (0.6228, 0.6248221183167311, 0.6147)\n",
      "epoch 189: (0.62355, 0.6261615439599714, 0.6132)\n",
      "epoch 190: (0.6245, 0.631690289824413, 0.5972)\n",
      "epoch 191: (0.6239, 0.6316404589885253, 0.5945)\n",
      "epoch 192: (0.6248, 0.6282367447595562, 0.6114)\n",
      "epoch 193: (0.6249, 0.6319737954353339, 0.5981)\n",
      "epoch 194: (0.62545, 0.6304732189287572, 0.6062)\n",
      "epoch 195: (0.62675, 0.6292707802141765, 0.617)\n",
      "epoch 196: (0.6266, 0.6343093570973902, 0.5979)\n",
      "epoch 197: (0.6269, 0.6315844048112816, 0.6091)\n",
      "epoch 198: (0.6263, 0.6351669520547946, 0.5935)\n",
      "epoch 199: (0.6268, 0.6354411450544756, 0.5949)\n",
      "epoch 200: (0.6269, 0.6395732512098549, 0.5815)\n",
      "epoch 201: (0.62755, 0.6349307098275679, 0.6002)\n",
      "epoch 202: (0.6284, 0.6329743164871583, 0.6112)\n",
      "epoch 203: (0.62875, 0.6334058646772355, 0.6113)\n",
      "epoch 204: (0.62825, 0.6312826287235132, 0.6167)\n",
      "epoch 205: (0.6288, 0.6339434276206323, 0.6096)\n",
      "epoch 206: (0.6285, 0.6295885437676483, 0.6243)\n",
      "epoch 207: (0.6304, 0.6349896480331263, 0.6134)\n",
      "epoch 208: (0.63115, 0.6387390246482598, 0.6038)\n",
      "epoch 209: (0.6314, 0.6390770533446232, 0.6038)\n",
      "epoch 210: (0.6309, 0.6339541547277937, 0.6195)\n",
      "epoch 211: (0.63235, 0.6391839310127247, 0.6078)\n",
      "epoch 212: (0.63145, 0.6341737266510156, 0.6213)\n",
      "epoch 213: (0.6322, 0.6395103419164204, 0.606)\n",
      "epoch 214: (0.6323, 0.6428725701943845, 0.5953)\n",
      "epoch 215: (0.6309, 0.6350041254125413, 0.6157)\n",
      "epoch 216: (0.6321, 0.6358215093563644, 0.6184)\n",
      "epoch 217: (0.63135, 0.6359027418520434, 0.6146)\n",
      "epoch 218: (0.63165, 0.6412099109728628, 0.5978)\n",
      "epoch 219: (0.63235, 0.6363449057381271, 0.6177)\n",
      "epoch 220: (0.63285, 0.6428341038598, 0.5979)\n",
      "epoch 221: (0.63275, 0.6382668472034163, 0.6128)\n",
      "epoch 222: (0.63185, 0.6413941018766756, 0.5981)\n",
      "epoch 223: (0.63115, 0.6356116223761762, 0.6147)\n",
      "epoch 224: (0.63255, 0.6407560794308166, 0.6034)\n",
      "epoch 225: (0.63275, 0.6377217553688141, 0.6147)\n",
      "epoch 226: (0.6334, 0.64381198792583, 0.5972)\n",
      "epoch 227: (0.6336, 0.6388196176226102, 0.6148)\n",
      "epoch 228: (0.6341, 0.6402132998745295, 0.6123)\n",
      "epoch 229: (0.63425, 0.6442152755398002, 0.5997)\n",
      "epoch 230: (0.63445, 0.6408000837784061, 0.6119)\n",
      "epoch 231: (0.6342, 0.6409960075646144, 0.6101)\n",
      "epoch 232: (0.63345, 0.638189914051983, 0.6163)\n",
      "epoch 233: (0.63525, 0.6388461143619751, 0.6223)\n",
      "epoch 234: (0.6362, 0.6414917930604612, 0.6175)\n",
      "epoch 235: (0.63515, 0.6462187601428108, 0.5973)\n",
      "epoch 236: (0.635, 0.6443541488451668, 0.6026)\n",
      "epoch 237: (0.63455, 0.6490858725761773, 0.5858)\n",
      "epoch 238: (0.6355, 0.6441796126835497, 0.6054)\n",
      "epoch 239: (0.63605, 0.6389825314128103, 0.6255)\n",
      "epoch 240: (0.6361, 0.6431727330107301, 0.6114)\n",
      "epoch 241: (0.6366, 0.6498793065613342, 0.5923)\n",
      "epoch 242: (0.6373, 0.6451067427605157, 0.6104)\n",
      "epoch 243: (0.63715, 0.6447493403693931, 0.6109)\n",
      "epoch 244: (0.6369, 0.6442267172355668, 0.6115)\n",
      "epoch 245: (0.63715, 0.6486398612766879, 0.5985)\n",
      "epoch 246: (0.6379, 0.6484391819160388, 0.6024)\n",
      "epoch 247: (0.638, 0.6430051813471502, 0.6205)\n",
      "epoch 248: (0.63695, 0.6450587861455355, 0.609)\n",
      "epoch 249: (0.6373, 0.6438298763880159, 0.6146)\n",
      "epoch 250: (0.63855, 0.6450937270918421, 0.616)\n",
      "epoch 251: (0.6396, 0.6491134372997223, 0.6077)\n",
      "epoch 252: (0.63905, 0.6436615352825705, 0.623)\n",
      "epoch 253: (0.64025, 0.6511803384714886, 0.6041)\n",
      "epoch 254: (0.63905, 0.6455563697267874, 0.6167)\n",
      "epoch 255: (0.6398, 0.6423045602605864, 0.631)\n",
      "epoch 256: (0.6402, 0.6478279207085618, 0.6144)\n",
      "epoch 257: (0.6405, 0.6524853483828956, 0.6012)\n",
      "epoch 258: (0.64, 0.6483050847457628, 0.612)\n",
      "epoch 259: (0.6393, 0.6529088913282107, 0.5948)\n",
      "epoch 260: (0.64045, 0.6472685330816819, 0.6173)\n",
      "epoch 261: (0.63985, 0.6494922501336183, 0.6076)\n",
      "epoch 262: (0.64075, 0.6504221438495245, 0.6086)\n",
      "epoch 263: (0.64145, 0.648785105711581, 0.6168)\n",
      "epoch 264: (0.6408, 0.6516587677725119, 0.605)\n",
      "epoch 265: (0.6404, 0.6503856041131105, 0.6072)\n",
      "epoch 266: (0.6408, 0.6559246954595792, 0.5923)\n",
      "epoch 267: (0.642, 0.6543813872580996, 0.6019)\n",
      "epoch 268: (0.64235, 0.6513234825130222, 0.6127)\n",
      "epoch 269: (0.6414, 0.6524692689238732, 0.6051)\n",
      "epoch 270: (0.6411, 0.6547827994734533, 0.5969)\n",
      "epoch 271: (0.6416, 0.6493986073011184, 0.6155)\n",
      "epoch 272: (0.6418, 0.6539965247610773, 0.6022)\n",
      "epoch 273: (0.64295, 0.6513178786916481, 0.6153)\n",
      "epoch 274: (0.64295, 0.6480886770952036, 0.6256)\n",
      "epoch 275: (0.6431, 0.6509493670886076, 0.6171)\n",
      "epoch 276: (0.64275, 0.6550787615426399, 0.603)\n",
      "epoch 277: (0.64455, 0.6528174225605243, 0.6175)\n",
      "epoch 278: (0.64375, 0.6585070018745176, 0.5972)\n",
      "epoch 279: (0.644, 0.6530937699340846, 0.6143)\n",
      "epoch 280: (0.6419, 0.6563808684152523, 0.5956)\n",
      "epoch 281: (0.6438, 0.653011278995531, 0.6137)\n",
      "epoch 282: (0.644, 0.6567261645624728, 0.6034)\n",
      "epoch 283: (0.6447, 0.6526371308016877, 0.6187)\n",
      "epoch 284: (0.64595, 0.6499845853458021, 0.6325)\n",
      "epoch 285: (0.6456, 0.6547948118222411, 0.6159)\n",
      "epoch 286: (0.64565, 0.6565960649392538, 0.6107)\n",
      "epoch 287: (0.6463, 0.6533221546845525, 0.6234)\n",
      "epoch 288: (0.64525, 0.6567051461862121, 0.6087)\n",
      "epoch 289: (0.64435, 0.6566127807312575, 0.6052)\n",
      "epoch 290: (0.6464, 0.6542676501580611, 0.6209)\n",
      "epoch 291: (0.64615, 0.659291553133515, 0.6049)\n",
      "epoch 292: (0.646, 0.661504424778761, 0.598)\n",
      "epoch 293: (0.64635, 0.6595791080580089, 0.6049)\n",
      "epoch 294: (0.64725, 0.6563993627190653, 0.618)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 295: (0.64655, 0.6588617886178861, 0.6078)\n",
      "epoch 296: (0.6478, 0.6538301415487094, 0.6282)\n",
      "epoch 297: (0.6483, 0.6607065452969224, 0.6097)\n",
      "epoch 298: (0.6492, 0.6582184517497349, 0.6207)\n",
      "epoch 299: (0.6483, 0.6553204859656473, 0.6257)\n",
      "epoch 300: (0.6472, 0.6556683587140439, 0.62)\n",
      "epoch 301: (0.6465, 0.6586871750433275, 0.6081)\n",
      "epoch 302: (0.6456, 0.6586056644880174, 0.6046)\n",
      "epoch 303: (0.6474, 0.6551905664350389, 0.6223)\n",
      "epoch 304: (0.64725, 0.6566322731624296, 0.6173)\n",
      "epoch 305: (0.64735, 0.6631963672610477, 0.5988)\n",
      "epoch 306: (0.6476, 0.6563228129633553, 0.6197)\n",
      "epoch 307: (0.64895, 0.6616035586416404, 0.6098)\n",
      "epoch 308: (0.64775, 0.658343157217876, 0.6143)\n",
      "epoch 309: (0.6487, 0.6618415324336091, 0.6081)\n",
      "epoch 310: (0.648, 0.6644809957768393, 0.5979)\n",
      "epoch 311: (0.6484, 0.6580068143100511, 0.618)\n",
      "epoch 312: (0.6491, 0.6639182058047494, 0.6039)\n",
      "epoch 313: (0.6481, 0.6564546799070357, 0.6214)\n",
      "epoch 314: (0.6488, 0.6626940739120927, 0.6061)\n",
      "epoch 315: (0.6493, 0.6645360370288738, 0.603)\n",
      "epoch 316: (0.64905, 0.6613619140413555, 0.6109)\n",
      "epoch 317: (0.64895, 0.6672655811341943, 0.5942)\n",
      "epoch 318: (0.64945, 0.6638526477359938, 0.6055)\n",
      "epoch 319: (0.65025, 0.6637959228169629, 0.6089)\n",
      "epoch 320: (0.6507, 0.6578671694950765, 0.628)\n",
      "epoch 321: (0.65075, 0.6622537939941879, 0.6153)\n",
      "epoch 322: (0.65185, 0.6653599041707503, 0.611)\n",
      "epoch 323: (0.65155, 0.6669236700077101, 0.6055)\n",
      "epoch 324: (0.65235, 0.6634130644642282, 0.6185)\n",
      "epoch 325: (0.65275, 0.6684309185136178, 0.6062)\n",
      "epoch 326: (0.6526, 0.666775956284153, 0.6101)\n",
      "epoch 327: (0.652, 0.6696428571428571, 0.6)\n",
      "epoch 328: (0.6527, 0.6669217315260166, 0.6101)\n",
      "epoch 329: (0.652, 0.6675485008818343, 0.6056)\n",
      "epoch 330: (0.65265, 0.663594470046083, 0.6192)\n",
      "epoch 331: (0.6537, 0.6642796066695169, 0.6215)\n",
      "epoch 332: (0.6522, 0.6665207877461706, 0.6092)\n",
      "epoch 333: (0.65355, 0.6614107011458005, 0.6292)\n",
      "epoch 334: (0.65335, 0.6683499835327698, 0.6088)\n",
      "epoch 335: (0.65345, 0.6654090762099817, 0.6173)\n",
      "epoch 336: (0.65515, 0.6654227529587377, 0.6241)\n",
      "epoch 337: (0.65545, 0.6637522384915201, 0.6301)\n",
      "epoch 338: (0.6544, 0.6677531508039982, 0.6146)\n",
      "epoch 339: (0.65445, 0.6659503599441281, 0.6198)\n",
      "epoch 340: (0.6554, 0.6650031853896793, 0.6263)\n",
      "epoch 341: (0.6538, 0.6680874316939891, 0.6113)\n",
      "epoch 342: (0.65405, 0.6669556735667064, 0.6154)\n",
      "epoch 343: (0.65405, 0.66645056726094, 0.6168)\n",
      "epoch 344: (0.65465, 0.6631157050943993, 0.6287)\n",
      "epoch 345: (0.6538, 0.6677574171029669, 0.6122)\n",
      "epoch 346: (0.65365, 0.6726210538141781, 0.5987)\n",
      "epoch 347: (0.65475, 0.6705234159779614, 0.6085)\n",
      "epoch 348: (0.65495, 0.6703308783115313, 0.6098)\n",
      "epoch 349: (0.65385, 0.6691588785046729, 0.6086)\n",
      "epoch 350: (0.6548, 0.6706725468577729, 0.6083)\n",
      "epoch 351: (0.65595, 0.6689050146214665, 0.6176)\n",
      "epoch 352: (0.65465, 0.6694051922444956, 0.6111)\n",
      "epoch 353: (0.65605, 0.6699335729064576, 0.6152)\n",
      "epoch 354: (0.6561, 0.6748823661214429, 0.6024)\n",
      "epoch 355: (0.6581, 0.6690186016677357, 0.6258)\n",
      "epoch 356: (0.65615, 0.6735192799199912, 0.6061)\n",
      "epoch 357: (0.6572, 0.6683083511777302, 0.6242)\n",
      "epoch 358: (0.6558, 0.6743899708976941, 0.6025)\n",
      "epoch 359: (0.657, 0.6711731356301788, 0.6156)\n",
      "epoch 360: (0.6575, 0.6670555791260077, 0.6289)\n",
      "epoch 361: (0.6569, 0.6718134034165572, 0.6135)\n",
      "epoch 362: (0.6565, 0.6740435943060499, 0.6061)\n",
      "epoch 363: (0.65825, 0.6681900308215538, 0.6287)\n",
      "epoch 364: (0.65675, 0.6723095525997581, 0.6116)\n",
      "epoch 365: (0.6581, 0.6673370025402201, 0.6305)\n",
      "epoch 366: (0.6581, 0.6746575342465754, 0.6107)\n",
      "epoch 367: (0.6589, 0.6730182926829268, 0.6181)\n",
      "epoch 368: (0.6575, 0.6753897550111359, 0.6065)\n",
      "epoch 369: (0.6593, 0.6722162162162162, 0.6218)\n",
      "epoch 370: (0.65935, 0.6701911780412261, 0.6275)\n",
      "epoch 371: (0.65865, 0.6732554330020749, 0.6165)\n",
      "epoch 372: (0.6599, 0.6687420852680456, 0.6337)\n",
      "epoch 373: (0.6592, 0.6708521141875939, 0.6251)\n",
      "epoch 374: (0.658, 0.6721132897603486, 0.617)\n",
      "epoch 375: (0.6592, 0.6705957993999143, 0.6258)\n",
      "epoch 376: (0.6575, 0.6757028112449799, 0.6057)\n",
      "epoch 377: (0.6605, 0.6710722660413558, 0.6296)\n",
      "epoch 378: (0.65895, 0.6747663551401869, 0.6137)\n",
      "epoch 379: (0.6586, 0.6764182424916574, 0.6081)\n",
      "epoch 380: (0.6587, 0.6716046712802768, 0.6211)\n",
      "epoch 381: (0.65905, 0.6744543161127564, 0.6149)\n",
      "epoch 382: (0.6594, 0.6782200357781754, 0.6066)\n",
      "epoch 383: (0.6605, 0.6725435390238659, 0.6256)\n",
      "epoch 384: (0.65965, 0.677526965417547, 0.6093)\n",
      "epoch 385: (0.6613, 0.6735528297826555, 0.626)\n",
      "epoch 386: (0.66115, 0.6781647318960752, 0.6134)\n",
      "epoch 387: (0.66115, 0.6786387318479105, 0.6122)\n",
      "epoch 388: (0.6626, 0.6751777634130576, 0.6267)\n",
      "epoch 389: (0.66255, 0.6793952102416951, 0.6156)\n",
      "epoch 390: (0.6617, 0.6815629912418594, 0.607)\n",
      "epoch 391: (0.6615, 0.6809726580008965, 0.6077)\n",
      "epoch 392: (0.66235, 0.679372445033698, 0.6149)\n",
      "epoch 393: (0.662, 0.6750594337583747, 0.6247)\n",
      "epoch 394: (0.6618, 0.6793393925958767, 0.6129)\n",
      "epoch 395: (0.6628, 0.6743040685224839, 0.6298)\n",
      "epoch 396: (0.6629, 0.6785792589344442, 0.619)\n",
      "epoch 397: (0.66355, 0.6726121372031663, 0.6373)\n",
      "epoch 398: (0.66255, 0.6786067465113724, 0.6176)\n",
      "epoch 399: (0.66325, 0.6821376771170367, 0.6114)\n",
      "epoch 0: (0.5, 0.5, 1.0)\n",
      "epoch 1: (0.5, 0.5, 1.0)\n",
      "epoch 2: (0.5, 0.5, 1.0)\n",
      "epoch 3: (0.5, 0.5, 1.0)\n",
      "epoch 4: (0.5, 0.5, 1.0)\n",
      "epoch 5: (0.5, 0.5, 1.0)\n",
      "epoch 6: (0.5, 0.5, 1.0)\n",
      "epoch 7: (0.5, 0.5, 1.0)\n",
      "epoch 8: (0.5, 0.5, 1.0)\n",
      "epoch 9: (0.5, 0.5, 1.0)\n",
      "epoch 10: (0.5, 0.5, 1.0)\n",
      "epoch 11: (0.5, 0.5, 1.0)\n",
      "epoch 12: (0.5, 0.5, 1.0)\n",
      "epoch 13: (0.5001, 0.5000500250125063, 0.9996)\n",
      "epoch 14: (0.5033, 0.5016670034350373, 0.9931)\n",
      "epoch 15: (0.51215, 0.506325160081212, 0.9726)\n",
      "epoch 16: (0.52465, 0.5135880050713852, 0.9317)\n",
      "epoch 17: (0.5299, 0.5176672181517372, 0.8761)\n",
      "epoch 18: (0.5315, 0.519746740220662, 0.8291)\n",
      "epoch 19: (0.5466, 0.531452483801296, 0.7874)\n",
      "epoch 20: (0.56175, 0.5462442896727328, 0.7294)\n",
      "epoch 21: (0.5674, 0.555119398102715, 0.6788)\n",
      "epoch 22: (0.5637, 0.5552951388888889, 0.6397)\n",
      "epoch 23: (0.5633, 0.5569142240604208, 0.6194)\n",
      "epoch 24: (0.5625, 0.5578596556193297, 0.6026)\n",
      "epoch 25: (0.5625, 0.5593655015197568, 0.5889)\n",
      "epoch 26: (0.56225, 0.5602205668956177, 0.5791)\n",
      "epoch 27: (0.5615, 0.5602586713697825, 0.5718)\n",
      "epoch 28: (0.56105, 0.5602368031573755, 0.5678)\n",
      "epoch 29: (0.56105, 0.56036784336992, 0.5667)\n",
      "epoch 30: (0.56095, 0.5606045540419609, 0.5638)\n",
      "epoch 31: (0.56105, 0.5608856088560885, 0.5624)\n",
      "epoch 32: (0.5609, 0.5609975961538461, 0.5601)\n",
      "epoch 33: (0.56175, 0.562116487274922, 0.5588)\n",
      "epoch 34: (0.5619, 0.561592039800995, 0.5644)\n",
      "epoch 35: (0.56335, 0.5636747411800181, 0.5608)\n",
      "epoch 36: (0.5631, 0.5625743752479175, 0.5673)\n",
      "epoch 37: (0.5643, 0.564571199035951, 0.5622)\n",
      "epoch 38: (0.56325, 0.5626423690205011, 0.5681)\n",
      "epoch 39: (0.564, 0.5634668782229274, 0.5682)\n",
      "epoch 40: (0.5643, 0.5634999012443216, 0.5706)\n",
      "epoch 41: (0.56475, 0.5640391652655524, 0.5703)\n",
      "epoch 42: (0.56405, 0.563801175415878, 0.566)\n",
      "epoch 43: (0.565, 0.5642038719873568, 0.5712)\n",
      "epoch 44: (0.5646, 0.5638339920948616, 0.5706)\n",
      "epoch 45: (0.5648, 0.5639684106614018, 0.5713)\n",
      "epoch 46: (0.56505, 0.5642596068359182, 0.5712)\n",
      "epoch 47: (0.56595, 0.5651229386787795, 0.5723)\n",
      "epoch 48: (0.5661, 0.5652775034564488, 0.5724)\n",
      "epoch 49: (0.5672, 0.5665083135391924, 0.5724)\n",
      "epoch 50: (0.5669, 0.5660284247927359, 0.5735)\n",
      "epoch 51: (0.5677, 0.5669634025717112, 0.5732)\n",
      "epoch 52: (0.56825, 0.5674873924651439, 0.5739)\n",
      "epoch 53: (0.5691, 0.5687699044585988, 0.5715)\n",
      "epoch 54: (0.5693, 0.5683027794204613, 0.5766)\n",
      "epoch 55: (0.57005, 0.5698056801195814, 0.5718)\n",
      "epoch 56: (0.5699, 0.568664047151277, 0.5789)\n",
      "epoch 57: (0.57215, 0.5727979013217637, 0.5677)\n",
      "epoch 58: (0.57155, 0.5703194103194104, 0.5803)\n",
      "epoch 59: (0.5722, 0.5727089627391743, 0.5687)\n",
      "epoch 60: (0.57265, 0.57151294418742, 0.5806)\n",
      "epoch 61: (0.5733, 0.5736091584655554, 0.5712)\n",
      "epoch 62: (0.573, 0.5718928501083317, 0.5807)\n",
      "epoch 63: (0.5738, 0.5746963562753037, 0.5678)\n",
      "epoch 64: (0.57385, 0.5726798543450448, 0.5819)\n",
      "epoch 65: (0.5748, 0.5762176482575911, 0.5655)\n",
      "epoch 66: (0.57505, 0.5742260903965978, 0.5806)\n",
      "epoch 67: (0.5751, 0.5755685248540954, 0.572)\n",
      "epoch 68: (0.57535, 0.5746261265722492, 0.5802)\n",
      "epoch 69: (0.5767, 0.5782812818942641, 0.5666)\n",
      "epoch 70: (0.5764, 0.5755986542647932, 0.5817)\n",
      "epoch 71: (0.57745, 0.5790386774160629, 0.5674)\n",
      "epoch 72: (0.5782, 0.577579365079365, 0.5822)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 73: (0.5784, 0.5794004456147458, 0.5721)\n",
      "epoch 74: (0.57885, 0.5778457893178004, 0.5853)\n",
      "epoch 75: (0.57935, 0.5809446087932265, 0.5695)\n",
      "epoch 76: (0.5794, 0.5785050425153253, 0.5851)\n",
      "epoch 77: (0.5808, 0.5825331971399387, 0.5703)\n",
      "epoch 78: (0.5805, 0.5797187561893444, 0.5854)\n",
      "epoch 79: (0.58215, 0.5831898734177215, 0.5759)\n",
      "epoch 80: (0.58175, 0.580884535470466, 0.5871)\n",
      "epoch 81: (0.58415, 0.586422922871521, 0.571)\n",
      "epoch 82: (0.58285, 0.5822659120246252, 0.5864)\n",
      "epoch 83: (0.58565, 0.5879995890270214, 0.5723)\n",
      "epoch 84: (0.5846, 0.5840787119856887, 0.5877)\n",
      "epoch 85: (0.587, 0.5898018166804294, 0.5714)\n",
      "epoch 86: (0.5858, 0.5854751942618052, 0.5877)\n",
      "epoch 87: (0.58815, 0.5908107551251675, 0.5735)\n",
      "epoch 88: (0.58815, 0.5882470717789569, 0.5876)\n",
      "epoch 89: (0.5909, 0.5944121312837557, 0.5723)\n",
      "epoch 90: (0.58915, 0.5894272243956264, 0.5876)\n",
      "epoch 91: (0.59205, 0.5949262658554192, 0.5769)\n",
      "epoch 92: (0.5911, 0.591118223644729, 0.591)\n",
      "epoch 93: (0.59365, 0.5975825778889237, 0.5735)\n",
      "epoch 94: (0.5931, 0.5936996779388084, 0.5899)\n",
      "epoch 95: (0.5953, 0.5994365609348915, 0.5745)\n",
      "epoch 96: (0.5951, 0.5960606060606061, 0.5901)\n",
      "epoch 97: (0.59625, 0.6010923222350594, 0.5723)\n",
      "epoch 98: (0.59675, 0.5980143855739034, 0.5903)\n",
      "epoch 99: (0.59735, 0.6016710182767624, 0.5761)\n",
      "epoch 100: (0.5983, 0.5994939271255061, 0.5923)\n",
      "epoch 101: (0.59855, 0.6037696114562493, 0.5734)\n",
      "epoch 102: (0.59975, 0.6014441167497203, 0.5914)\n",
      "epoch 103: (0.60035, 0.6056649468253132, 0.5752)\n",
      "epoch 104: (0.6009, 0.6027494908350306, 0.5919)\n",
      "epoch 105: (0.60135, 0.606943125461644, 0.5752)\n",
      "epoch 106: (0.60265, 0.6047983665135274, 0.5924)\n",
      "epoch 107: (0.60275, 0.6087416657847391, 0.5752)\n",
      "epoch 108: (0.6034, 0.6056611485796035, 0.5927)\n",
      "epoch 109: (0.60375, 0.6099395994489775, 0.5756)\n",
      "epoch 110: (0.60475, 0.6071611253196931, 0.5935)\n",
      "epoch 111: (0.6054, 0.6118895966029724, 0.5764)\n",
      "epoch 112: (0.6061, 0.6087535875358754, 0.5939)\n",
      "epoch 113: (0.60575, 0.612344629767343, 0.5764)\n",
      "epoch 114: (0.60725, 0.6099436186570989, 0.595)\n",
      "epoch 115: (0.60725, 0.614083608126795, 0.5773)\n",
      "epoch 116: (0.6082, 0.6108379430444582, 0.5963)\n",
      "epoch 117: (0.60865, 0.6156466205428419, 0.5784)\n",
      "epoch 118: (0.60915, 0.6119831743100441, 0.5965)\n",
      "epoch 119: (0.61045, 0.6174875013296458, 0.5805)\n",
      "epoch 120: (0.60985, 0.6126320106633856, 0.5975)\n",
      "epoch 121: (0.6112, 0.6181972789115646, 0.5816)\n",
      "epoch 122: (0.61095, 0.6136200716845878, 0.5992)\n",
      "epoch 123: (0.6126, 0.6199659066695078, 0.5819)\n",
      "epoch 124: (0.6118, 0.614431934493347, 0.6003)\n",
      "epoch 125: (0.6136, 0.6209797657082002, 0.5831)\n",
      "epoch 126: (0.6133, 0.6161098585775774, 0.6012)\n",
      "epoch 127: (0.61415, 0.6217340300735843, 0.583)\n",
      "epoch 128: (0.61405, 0.616914402870323, 0.6018)\n",
      "epoch 129: (0.61485, 0.622585121144199, 0.5833)\n",
      "epoch 130: (0.6154, 0.6183347005742412, 0.603)\n",
      "epoch 131: (0.61545, 0.6230941464974944, 0.5844)\n",
      "epoch 132: (0.6164, 0.6194091095609355, 0.6038)\n",
      "epoch 133: (0.61645, 0.6243459690336359, 0.5847)\n",
      "epoch 134: (0.6171, 0.6202258726899385, 0.6041)\n",
      "epoch 135: (0.6174, 0.6253202391118702, 0.5858)\n",
      "epoch 136: (0.61785, 0.6210829137984177, 0.6045)\n",
      "epoch 137: (0.618, 0.6259069568928723, 0.5866)\n",
      "epoch 138: (0.6186, 0.6217909221606079, 0.6055)\n",
      "epoch 139: (0.6196, 0.6277504806665243, 0.5877)\n",
      "epoch 140: (0.61905, 0.6222404764349523, 0.606)\n",
      "epoch 141: (0.62005, 0.6283545386507003, 0.5877)\n",
      "epoch 142: (0.61975, 0.6230603226800946, 0.6063)\n",
      "epoch 143: (0.6211, 0.6295187165775401, 0.5886)\n",
      "epoch 144: (0.62085, 0.624190730654609, 0.6074)\n",
      "epoch 145: (0.6227, 0.6313985864210752, 0.5896)\n",
      "epoch 146: (0.6219, 0.6252054231717338, 0.6087)\n",
      "epoch 147: (0.6239, 0.6324850299401198, 0.5915)\n",
      "epoch 148: (0.62295, 0.626504784442844, 0.6089)\n",
      "epoch 149: (0.62395, 0.6323827832959521, 0.5921)\n",
      "epoch 150: (0.62375, 0.6271970397779834, 0.6102)\n",
      "epoch 151: (0.6252, 0.6338464827881121, 0.5929)\n",
      "epoch 152: (0.6247, 0.6282921810699589, 0.6107)\n",
      "epoch 153: (0.6257, 0.6344385026737968, 0.5932)\n",
      "epoch 154: (0.62475, 0.6283040213925744, 0.6109)\n",
      "epoch 155: (0.62595, 0.6347779561262707, 0.5932)\n",
      "epoch 156: (0.62505, 0.6285068338300277, 0.6116)\n",
      "epoch 157: (0.6266, 0.6355170199100835, 0.5937)\n",
      "epoch 158: (0.6262, 0.6300226663919225, 0.6115)\n",
      "epoch 159: (0.6271, 0.6360813704496788, 0.5941)\n",
      "epoch 160: (0.62715, 0.6308531439744777, 0.613)\n",
      "epoch 161: (0.6281, 0.6370053475935828, 0.5956)\n",
      "epoch 162: (0.6277, 0.6315952184666117, 0.6129)\n",
      "epoch 163: (0.6292, 0.6383001498608435, 0.5963)\n",
      "epoch 164: (0.62785, 0.6315735309251826, 0.6137)\n",
      "epoch 165: (0.6295, 0.638680659670165, 0.5964)\n",
      "epoch 166: (0.62925, 0.6331239056545473, 0.6147)\n",
      "epoch 167: (0.63055, 0.63955104222341, 0.5983)\n",
      "epoch 168: (0.62925, 0.6328775573146911, 0.6156)\n",
      "epoch 169: (0.6314, 0.6405949069120479, 0.5987)\n",
      "epoch 170: (0.63005, 0.6338100627636588, 0.616)\n",
      "epoch 171: (0.63195, 0.6412287273894894, 0.5991)\n",
      "epoch 172: (0.6304, 0.634322208487845, 0.6158)\n",
      "epoch 173: (0.6325, 0.6422589649989263, 0.5982)\n",
      "epoch 174: (0.63095, 0.6345422788451659, 0.6176)\n",
      "epoch 175: (0.6328, 0.6426116838487973, 0.5984)\n",
      "epoch 176: (0.63165, 0.6352336928608115, 0.6184)\n",
      "epoch 177: (0.6333, 0.6432717110920034, 0.5985)\n",
      "epoch 178: (0.63335, 0.637233714109293, 0.6192)\n",
      "epoch 179: (0.63405, 0.6441862966548348, 0.5989)\n",
      "epoch 180: (0.63375, 0.6372780457764549, 0.6209)\n",
      "epoch 181: (0.6343, 0.6444707401032702, 0.5991)\n",
      "epoch 182: (0.6345, 0.6381470829909613, 0.6213)\n",
      "epoch 183: (0.63485, 0.6450779989241527, 0.5996)\n",
      "epoch 184: (0.63515, 0.638828967642527, 0.6219)\n",
      "epoch 185: (0.63555, 0.6461770732233366, 0.5992)\n",
      "epoch 186: (0.63595, 0.639880646157012, 0.6219)\n",
      "epoch 187: (0.63675, 0.647534793397346, 0.6002)\n",
      "epoch 188: (0.6368, 0.6407697057007615, 0.6227)\n",
      "epoch 189: (0.63665, 0.647809626825311, 0.5989)\n",
      "epoch 190: (0.63685, 0.6408936476886646, 0.6225)\n",
      "epoch 191: (0.63745, 0.6483540205072855, 0.6007)\n",
      "epoch 192: (0.63825, 0.642481706688653, 0.6234)\n",
      "epoch 193: (0.6376, 0.6488211118321436, 0.5999)\n",
      "epoch 194: (0.63885, 0.6429233144621719, 0.6246)\n",
      "epoch 195: (0.63805, 0.649098174748893, 0.601)\n",
      "epoch 196: (0.63985, 0.6441603958354809, 0.6249)\n",
      "epoch 197: (0.6392, 0.6506819657934618, 0.6011)\n",
      "epoch 198: (0.64, 0.6442109600329625, 0.6254)\n",
      "epoch 199: (0.64005, 0.6511602806260118, 0.6033)\n",
      "epoch 200: (0.6406, 0.644918573490002, 0.6257)\n",
      "epoch 201: (0.64085, 0.6520237452779277, 0.6041)\n",
      "epoch 202: (0.6414, 0.6459838942804047, 0.6257)\n",
      "epoch 203: (0.64155, 0.652746304089781, 0.6049)\n",
      "epoch 204: (0.6419, 0.6465303593556382, 0.6261)\n",
      "epoch 205: (0.64205, 0.6533520457735075, 0.6052)\n",
      "epoch 206: (0.6428, 0.6477343265052762, 0.6261)\n",
      "epoch 207: (0.64355, 0.6553403311329943, 0.6056)\n",
      "epoch 208: (0.64295, 0.6480580010357327, 0.6257)\n",
      "epoch 209: (0.6442, 0.656060606060606, 0.6062)\n",
      "epoch 210: (0.64355, 0.6487102455195276, 0.6262)\n",
      "epoch 211: (0.6444, 0.6564463705308776, 0.6059)\n",
      "epoch 212: (0.64385, 0.6491755677693664, 0.626)\n",
      "epoch 213: (0.645, 0.656960381034856, 0.6069)\n",
      "epoch 214: (0.6443, 0.6495646766169154, 0.6267)\n",
      "epoch 215: (0.6456, 0.6577806675335934, 0.607)\n",
      "epoch 216: (0.6448, 0.6501451679800913, 0.627)\n",
      "epoch 217: (0.64585, 0.658205879162599, 0.6068)\n",
      "epoch 218: (0.64565, 0.6511990034257241, 0.6273)\n",
      "epoch 219: (0.6468, 0.6594612209428633, 0.6071)\n",
      "epoch 220: (0.6461, 0.6514931563666528, 0.6283)\n",
      "epoch 221: (0.64785, 0.6606192286800652, 0.6081)\n",
      "epoch 222: (0.64675, 0.6521513737687922, 0.629)\n",
      "epoch 223: (0.64775, 0.6607201131295551, 0.6074)\n",
      "epoch 224: (0.6473, 0.653023062538957, 0.6286)\n",
      "epoch 225: (0.64875, 0.6620546900533827, 0.6077)\n",
      "epoch 226: (0.64795, 0.6536823517191233, 0.6293)\n",
      "epoch 227: (0.6489, 0.6622357812159512, 0.6078)\n",
      "epoch 228: (0.64885, 0.6547779972964543, 0.6297)\n",
      "epoch 229: (0.64965, 0.6628577647186854, 0.6091)\n",
      "epoch 230: (0.64915, 0.6553484012082075, 0.6292)\n",
      "epoch 231: (0.65005, 0.6634709663362022, 0.609)\n",
      "epoch 232: (0.6497, 0.6558725531028738, 0.6299)\n",
      "epoch 233: (0.65055, 0.6641229695846506, 0.6092)\n",
      "epoch 234: (0.6509, 0.6571547594251198, 0.631)\n",
      "epoch 235: (0.6514, 0.6653199388512776, 0.6093)\n",
      "epoch 236: (0.65085, 0.6572173006774361, 0.6306)\n",
      "epoch 237: (0.652, 0.6656856333115326, 0.6107)\n",
      "epoch 238: (0.651, 0.6573244425922067, 0.6309)\n",
      "epoch 239: (0.65225, 0.6660486421638129, 0.6107)\n",
      "epoch 240: (0.6515, 0.6579111944965603, 0.6312)\n",
      "epoch 241: (0.65245, 0.6664483022163992, 0.6104)\n",
      "epoch 242: (0.65225, 0.6588088035881924, 0.6316)\n",
      "epoch 243: (0.65265, 0.6668853175904669, 0.61)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 244: (0.65275, 0.6592638932332395, 0.6323)\n",
      "epoch 245: (0.6528, 0.6673970201577564, 0.6092)\n",
      "epoch 246: (0.6533, 0.6599540901502504, 0.6325)\n",
      "epoch 247: (0.65375, 0.6684931506849315, 0.61)\n",
      "epoch 248: (0.654, 0.6609531772575251, 0.6324)\n",
      "epoch 249: (0.65365, 0.6685313151255896, 0.6095)\n",
      "epoch 250: (0.6546, 0.6614790056402757, 0.6333)\n",
      "epoch 251: (0.6542, 0.6690418767814076, 0.6103)\n",
      "epoch 252: (0.65495, 0.6621324683478079, 0.6328)\n",
      "epoch 253: (0.6544, 0.6697076280501209, 0.6093)\n",
      "epoch 254: (0.655, 0.6619644723092999, 0.6335)\n",
      "epoch 255: (0.6552, 0.6709627671293237, 0.6091)\n",
      "epoch 256: (0.6552, 0.6622751986616479, 0.6334)\n",
      "epoch 257: (0.6552, 0.6710381309235177, 0.6089)\n",
      "epoch 258: (0.6561, 0.6631821032824587, 0.6344)\n",
      "epoch 259: (0.65555, 0.671745611129513, 0.6084)\n",
      "epoch 260: (0.6569, 0.6641556811048337, 0.6348)\n",
      "epoch 261: (0.656, 0.6722995361166335, 0.6087)\n",
      "epoch 262: (0.65755, 0.6649565490524553, 0.6351)\n",
      "epoch 263: (0.6568, 0.6732596685082873, 0.6093)\n",
      "epoch 264: (0.6581, 0.6655497382198953, 0.6356)\n",
      "epoch 265: (0.65685, 0.6736026563364693, 0.6086)\n",
      "epoch 266: (0.65815, 0.6657235670124698, 0.6353)\n",
      "epoch 267: (0.6575, 0.6744186046511628, 0.609)\n",
      "epoch 268: (0.65855, 0.6661775495231108, 0.6356)\n",
      "epoch 269: (0.6579, 0.6751719547370757, 0.6086)\n",
      "epoch 270: (0.6594, 0.6670159262363788, 0.6366)\n",
      "epoch 271: (0.6584, 0.6758436944937833, 0.6088)\n",
      "epoch 272: (0.6598, 0.6678218861583701, 0.6359)\n",
      "epoch 273: (0.6594, 0.6772686832740213, 0.609)\n",
      "epoch 274: (0.6603, 0.6681350954478708, 0.637)\n",
      "epoch 275: (0.65985, 0.6776703345559631, 0.6097)\n",
      "epoch 276: (0.6613, 0.6696109358569926, 0.6368)\n",
      "epoch 277: (0.6604, 0.6786589440855424, 0.6093)\n",
      "epoch 278: (0.66185, 0.6701713805067816, 0.6374)\n",
      "epoch 279: (0.6608, 0.679384203480589, 0.609)\n",
      "epoch 280: (0.662, 0.6704186829370924, 0.6373)\n",
      "epoch 281: (0.661, 0.6795672540709347, 0.6093)\n",
      "epoch 282: (0.66265, 0.6714812862414339, 0.6369)\n",
      "epoch 283: (0.661, 0.6797677534613666, 0.6088)\n",
      "epoch 284: (0.6631, 0.6719738506959089, 0.6373)\n",
      "epoch 285: (0.66215, 0.680950786742551, 0.6102)\n",
      "epoch 286: (0.66375, 0.6728232189973615, 0.6375)\n",
      "epoch 287: (0.66205, 0.6809199508764096, 0.6099)\n",
      "epoch 288: (0.66445, 0.6737820987002008, 0.6376)\n",
      "epoch 289: (0.66215, 0.68107202680067, 0.6099)\n",
      "epoch 290: (0.6649, 0.6741288278775079, 0.6384)\n",
      "epoch 291: (0.66295, 0.6821280876271376, 0.6103)\n",
      "epoch 292: (0.6656, 0.6747204051487655, 0.6395)\n",
      "epoch 293: (0.66325, 0.6824633955515815, 0.6106)\n",
      "epoch 294: (0.66575, 0.6751928971567488, 0.6388)\n",
      "epoch 295: (0.66405, 0.6835627167953452, 0.6109)\n",
      "epoch 296: (0.66595, 0.6753301637612256, 0.6392)\n",
      "epoch 297: (0.6644, 0.684304932735426, 0.6104)\n",
      "epoch 298: (0.6663, 0.6757556541957302, 0.6394)\n",
      "epoch 299: (0.66485, 0.6845404679279078, 0.6115)\n",
      "epoch 300: (0.66635, 0.6759758806728022, 0.639)\n",
      "epoch 301: (0.66485, 0.6847472823041578, 0.611)\n",
      "epoch 302: (0.6667, 0.6765141889030072, 0.6389)\n",
      "epoch 303: (0.66605, 0.6860087375378067, 0.6124)\n",
      "epoch 304: (0.66735, 0.6772963237631106, 0.6393)\n",
      "epoch 305: (0.66635, 0.6864283312787179, 0.6125)\n",
      "epoch 306: (0.66765, 0.6776894541600424, 0.6394)\n",
      "epoch 307: (0.667, 0.6873877917414721, 0.6126)\n",
      "epoch 308: (0.66795, 0.6780074191838897, 0.6397)\n",
      "epoch 309: (0.6678, 0.6883700044903458, 0.6132)\n",
      "epoch 310: (0.6681, 0.6782986847687739, 0.6395)\n",
      "epoch 311: (0.6683, 0.688846499102334, 0.6139)\n",
      "epoch 312: (0.6689, 0.6790712468193384, 0.6405)\n",
      "epoch 313: (0.6684, 0.6890011223344557, 0.6139)\n",
      "epoch 314: (0.66915, 0.6794314203882466, 0.6405)\n",
      "epoch 315: (0.66895, 0.6898101336928435, 0.614)\n",
      "epoch 316: (0.6696, 0.6800806965385432, 0.6405)\n",
      "epoch 317: (0.6688, 0.6897055518093954, 0.6137)\n",
      "epoch 318: (0.66975, 0.6801825708523511, 0.6408)\n",
      "epoch 319: (0.66915, 0.6903341960166536, 0.6135)\n",
      "epoch 320: (0.67045, 0.6809640089181441, 0.6414)\n",
      "epoch 321: (0.67025, 0.6916150815981992, 0.6145)\n",
      "epoch 322: (0.6712, 0.6818568090078606, 0.6419)\n",
      "epoch 323: (0.6708, 0.6923423423423424, 0.6148)\n",
      "epoch 324: (0.67135, 0.6821903242955875, 0.6416)\n",
      "epoch 325: (0.67125, 0.6927839693797141, 0.6154)\n",
      "epoch 326: (0.672, 0.6828231292517006, 0.6424)\n",
      "epoch 327: (0.67165, 0.6935392941707069, 0.6151)\n",
      "epoch 328: (0.672, 0.682745431364216, 0.6426)\n",
      "epoch 329: (0.67195, 0.6938338406042159, 0.6155)\n",
      "epoch 330: (0.6725, 0.6835106382978723, 0.6425)\n",
      "epoch 331: (0.67275, 0.6947356555067072, 0.6163)\n",
      "epoch 332: (0.67275, 0.6836398426703518, 0.6431)\n",
      "epoch 333: (0.6729, 0.6951907879882592, 0.6158)\n",
      "epoch 334: (0.67295, 0.6837352597471582, 0.6436)\n",
      "epoch 335: (0.6733, 0.695554051004288, 0.6164)\n",
      "epoch 336: (0.6734, 0.6843896214376861, 0.6436)\n",
      "epoch 337: (0.67325, 0.69578483444457, 0.6157)\n",
      "epoch 338: (0.67415, 0.68512809609865, 0.6445)\n",
      "epoch 339: (0.67385, 0.6962854239584509, 0.6167)\n",
      "epoch 340: (0.67415, 0.6852068488780176, 0.6443)\n",
      "epoch 341: (0.67395, 0.6965758842807097, 0.6164)\n",
      "epoch 342: (0.6749, 0.685945141399107, 0.6452)\n",
      "epoch 343: (0.6742, 0.6967028003613369, 0.617)\n",
      "epoch 344: (0.67535, 0.686403741894334, 0.6457)\n",
      "epoch 345: (0.6744, 0.6969286359530262, 0.6172)\n",
      "epoch 346: (0.67595, 0.6872406087049058, 0.6458)\n",
      "epoch 347: (0.6747, 0.697535052012664, 0.6169)\n",
      "epoch 348: (0.67585, 0.6870943717416746, 0.6458)\n",
      "epoch 349: (0.67495, 0.6976166271320456, 0.6176)\n",
      "epoch 350: (0.67625, 0.687639731715107, 0.6459)\n",
      "epoch 351: (0.6754, 0.6985960144927537, 0.617)\n",
      "epoch 352: (0.6765, 0.688005965061781, 0.6459)\n",
      "epoch 353: (0.6756, 0.698867497168743, 0.6171)\n",
      "epoch 354: (0.6772, 0.6889931740614335, 0.646)\n",
      "epoch 355: (0.6759, 0.6992975300249263, 0.6172)\n",
      "epoch 356: (0.6771, 0.6890881913303438, 0.6454)\n",
      "epoch 357: (0.67645, 0.700124758988318, 0.6173)\n",
      "epoch 358: (0.678, 0.6900085397096499, 0.6464)\n",
      "epoch 359: (0.67645, 0.7000793740786937, 0.6174)\n",
      "epoch 360: (0.6783, 0.6902881536819637, 0.6468)\n",
      "epoch 361: (0.6769, 0.7004759746146872, 0.6181)\n",
      "epoch 362: (0.6783, 0.6904507583849605, 0.6464)\n",
      "epoch 363: (0.67705, 0.7011246166079745, 0.6172)\n",
      "epoch 364: (0.6789, 0.6911324786324786, 0.6469)\n",
      "epoch 365: (0.6776, 0.7019558790084148, 0.6173)\n",
      "epoch 366: (0.67915, 0.6912973838761346, 0.6474)\n",
      "epoch 367: (0.67745, 0.7018082565677243, 0.6171)\n",
      "epoch 368: (0.6792, 0.6912894961571306, 0.6476)\n",
      "epoch 369: (0.67775, 0.702287470126323, 0.6171)\n",
      "epoch 370: (0.6797, 0.6919461653492843, 0.6478)\n",
      "epoch 371: (0.6778, 0.7024134790528234, 0.617)\n",
      "epoch 372: (0.67995, 0.6924804791956359, 0.6474)\n",
      "epoch 373: (0.6781, 0.7030323757409941, 0.6167)\n",
      "epoch 374: (0.68, 0.6923076923076923, 0.648)\n",
      "epoch 375: (0.67855, 0.703522170295224, 0.6172)\n",
      "epoch 376: (0.6805, 0.6925949637217242, 0.6491)\n",
      "epoch 377: (0.67895, 0.7039781146700103, 0.6176)\n",
      "epoch 378: (0.681, 0.6935001069061364, 0.6487)\n",
      "epoch 379: (0.679, 0.7041980378736026, 0.6173)\n",
      "epoch 380: (0.68115, 0.6936397648316408, 0.6489)\n",
      "epoch 381: (0.6793, 0.7044936131386861, 0.6177)\n",
      "epoch 382: (0.68165, 0.6942988554925661, 0.6491)\n",
      "epoch 383: (0.67975, 0.7050770108385624, 0.618)\n",
      "epoch 384: (0.6817, 0.69428999144568, 0.6493)\n",
      "epoch 385: (0.67975, 0.7051706426207054, 0.6178)\n",
      "epoch 386: (0.6819, 0.6946287181682003, 0.6492)\n",
      "epoch 387: (0.68015, 0.7057211373758137, 0.618)\n",
      "epoch 388: (0.68235, 0.6950058817238798, 0.6499)\n",
      "epoch 389: (0.68045, 0.7059696381691588, 0.6185)\n",
      "epoch 390: (0.68195, 0.6943702595876509, 0.65)\n",
      "epoch 391: (0.68075, 0.7064063035286057, 0.6186)\n",
      "epoch 392: (0.68235, 0.6951310861423221, 0.6496)\n",
      "epoch 393: (0.6813, 0.707010733044074, 0.6192)\n",
      "epoch 394: (0.68295, 0.6957312506686637, 0.6503)\n",
      "epoch 395: (0.68135, 0.7069024529378208, 0.6196)\n",
      "epoch 396: (0.6833, 0.6962947097879632, 0.6502)\n",
      "epoch 397: (0.68155, 0.7075568766434206, 0.6189)\n",
      "epoch 398: (0.6833, 0.696252676659529, 0.6503)\n",
      "epoch 399: (0.6822, 0.7083714547118024, 0.6194)\n",
      "epoch 0: (0.5017, 1.0, 0.0034)\n",
      "epoch 1: (0.5029, 0.9393939393939394, 0.0062)\n",
      "epoch 2: (0.5055, 0.8716216216216216, 0.0129)\n",
      "epoch 3: (0.5095, 0.7987421383647799, 0.0254)\n",
      "epoch 4: (0.5103, 0.6645367412140575, 0.0416)\n",
      "epoch 5: (0.51385, 0.66429418742586, 0.056)\n",
      "epoch 6: (0.5222, 0.6124620060790273, 0.1209)\n",
      "epoch 7: (0.5247, 0.5838424983027835, 0.172)\n",
      "epoch 8: (0.5218, 0.5642688679245284, 0.1914)\n",
      "epoch 9: (0.52605, 0.5752672637965905, 0.1991)\n",
      "epoch 10: (0.54185, 0.5911169170476812, 0.2715)\n",
      "epoch 11: (0.5501, 0.5981198589894242, 0.3054)\n",
      "epoch 12: (0.55075, 0.5916230366492147, 0.3277)\n",
      "epoch 13: (0.5483, 0.5812584118438762, 0.3455)\n",
      "epoch 14: (0.5528, 0.5898876404494382, 0.3465)\n",
      "epoch 15: (0.5589, 0.5780959957570936, 0.436)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16: (0.55815, 0.5699338544798557, 0.4739)\n",
      "epoch 17: (0.5591, 0.5651598676957001, 0.5126)\n",
      "epoch 18: (0.55795, 0.5590422822210902, 0.5487)\n",
      "epoch 19: (0.55835, 0.5608382858930248, 0.5379)\n",
      "epoch 20: (0.55935, 0.5588264446426802, 0.5638)\n",
      "epoch 21: (0.5617, 0.5611375346809354, 0.5663)\n",
      "epoch 22: (0.56135, 0.5602001766264351, 0.5709)\n",
      "epoch 23: (0.56265, 0.562369337979094, 0.5649)\n",
      "epoch 24: (0.5618, 0.5575526168746507, 0.5987)\n",
      "epoch 25: (0.5624, 0.5586466165413534, 0.5944)\n",
      "epoch 26: (0.56525, 0.5625539257981018, 0.5868)\n",
      "epoch 27: (0.5618, 0.5565416285452882, 0.6083)\n",
      "epoch 28: (0.5619, 0.5564574972637724, 0.6101)\n",
      "epoch 29: (0.5638, 0.5577793877920667, 0.6159)\n",
      "epoch 30: (0.56575, 0.5613625758282781, 0.6015)\n",
      "epoch 31: (0.56765, 0.5640564340498059, 0.5957)\n",
      "epoch 32: (0.5676, 0.5633077355309983, 0.6015)\n",
      "epoch 33: (0.56935, 0.5655667958778482, 0.5982)\n",
      "epoch 34: (0.5696, 0.5648406931246507, 0.6063)\n",
      "epoch 35: (0.57125, 0.5686350062614391, 0.5903)\n",
      "epoch 36: (0.569, 0.5642099385817979, 0.6063)\n",
      "epoch 37: (0.5722, 0.5687226346849419, 0.5975)\n",
      "epoch 38: (0.57075, 0.5658445788738948, 0.608)\n",
      "epoch 39: (0.5732, 0.5702495201535509, 0.5942)\n",
      "epoch 40: (0.57475, 0.5728770595690748, 0.5876)\n",
      "epoch 41: (0.5754, 0.573791348600509, 0.5863)\n",
      "epoch 42: (0.57675, 0.5756978005720486, 0.5837)\n",
      "epoch 43: (0.57185, 0.5673320213663199, 0.6054)\n",
      "epoch 44: (0.5701, 0.5641941391941392, 0.6161)\n",
      "epoch 45: (0.57095, 0.5666635347176548, 0.6031)\n",
      "epoch 46: (0.57525, 0.571687148709155, 0.6001)\n",
      "epoch 47: (0.5738, 0.5701654306902453, 0.5997)\n",
      "epoch 48: (0.5747, 0.5712378409307648, 0.599)\n",
      "epoch 49: (0.5766, 0.5740955697426968, 0.5935)\n",
      "epoch 50: (0.5769, 0.5742134723026443, 0.595)\n",
      "epoch 51: (0.5752, 0.5712391057218643, 0.603)\n",
      "epoch 52: (0.577, 0.5719895287958116, 0.6118)\n",
      "epoch 53: (0.57765, 0.5731512011304758, 0.6084)\n",
      "epoch 54: (0.57925, 0.5758010521281683, 0.602)\n",
      "epoch 55: (0.5782, 0.5727848101265823, 0.6154)\n",
      "epoch 56: (0.57855, 0.5747170170265385, 0.6042)\n",
      "epoch 57: (0.57855, 0.5741107651665251, 0.6085)\n",
      "epoch 58: (0.581, 0.5787019043917606, 0.5956)\n",
      "epoch 59: (0.58035, 0.5756805123857963, 0.6112)\n",
      "epoch 60: (0.5818, 0.578472755180353, 0.603)\n",
      "epoch 61: (0.5835, 0.5808012386297658, 0.6002)\n",
      "epoch 62: (0.58345, 0.5813590718533684, 0.5963)\n",
      "epoch 63: (0.5831, 0.5806482919254659, 0.5983)\n",
      "epoch 64: (0.5866, 0.5858786195953987, 0.5908)\n",
      "epoch 65: (0.58675, 0.5845434168209727, 0.5998)\n",
      "epoch 66: (0.58715, 0.5830553702468312, 0.6118)\n",
      "epoch 67: (0.5879, 0.5840504876649455, 0.6108)\n",
      "epoch 68: (0.58825, 0.5872294158347336, 0.5941)\n",
      "epoch 69: (0.5885, 0.5862909516380655, 0.6013)\n",
      "epoch 70: (0.5895, 0.5872659906396256, 0.6023)\n",
      "epoch 71: (0.58925, 0.5881481481481482, 0.5955)\n",
      "epoch 72: (0.5907, 0.5874301137459033, 0.6094)\n",
      "epoch 73: (0.59225, 0.5914724838869608, 0.5965)\n",
      "epoch 74: (0.59125, 0.587731948851072, 0.6113)\n",
      "epoch 75: (0.59375, 0.5914723387647576, 0.6062)\n",
      "epoch 76: (0.59435, 0.5916464303059737, 0.6091)\n",
      "epoch 77: (0.5951, 0.5937869822485207, 0.6021)\n",
      "epoch 78: (0.59655, 0.5983698420784513, 0.5873)\n",
      "epoch 79: (0.5974, 0.597147416716537, 0.5987)\n",
      "epoch 80: (0.59815, 0.598971463144096, 0.594)\n",
      "epoch 81: (0.59865, 0.5959723708531959, 0.6126)\n",
      "epoch 82: (0.59985, 0.5998400159984002, 0.5999)\n",
      "epoch 83: (0.59905, 0.5998588567395907, 0.595)\n",
      "epoch 84: (0.59945, 0.5967694852583438, 0.6133)\n",
      "epoch 85: (0.59975, 0.5986939744731374, 0.6051)\n",
      "epoch 86: (0.6037, 0.6065775950668038, 0.5902)\n",
      "epoch 87: (0.6017, 0.6007329635499208, 0.6065)\n",
      "epoch 88: (0.6042, 0.6084061589679567, 0.5848)\n",
      "epoch 89: (0.6037, 0.603328019131128, 0.6055)\n",
      "epoch 90: (0.60445, 0.6033646709549728, 0.6097)\n",
      "epoch 91: (0.6068, 0.6051595116187476, 0.6146)\n",
      "epoch 92: (0.60595, 0.6055384002390677, 0.6079)\n",
      "epoch 93: (0.60635, 0.6056212136259808, 0.6098)\n",
      "epoch 94: (0.6076, 0.6076215243048609, 0.6075)\n",
      "epoch 95: (0.6076, 0.6041424699961285, 0.6242)\n",
      "epoch 96: (0.6081, 0.6084470304975923, 0.6065)\n",
      "epoch 97: (0.60925, 0.6096117186716163, 0.6076)\n",
      "epoch 98: (0.61065, 0.6113067095865607, 0.6077)\n",
      "epoch 99: (0.61125, 0.6164311878597593, 0.589)\n",
      "epoch 100: (0.61185, 0.6144713949442226, 0.6004)\n",
      "epoch 101: (0.61285, 0.6179822268687925, 0.5911)\n",
      "epoch 102: (0.6119, 0.6130074732377297, 0.607)\n",
      "epoch 103: (0.61355, 0.6152674855344635, 0.6061)\n",
      "epoch 104: (0.6137, 0.6172164948453608, 0.5987)\n",
      "epoch 105: (0.6147, 0.6170886075949367, 0.6045)\n",
      "epoch 106: (0.61465, 0.6171930900541757, 0.6038)\n",
      "epoch 107: (0.6156, 0.6180555555555556, 0.6052)\n",
      "epoch 108: (0.61435, 0.6178258629572385, 0.5996)\n",
      "epoch 109: (0.61525, 0.6165672094669769, 0.6096)\n",
      "epoch 110: (0.6167, 0.6222245496439045, 0.5941)\n",
      "epoch 111: (0.6187, 0.62053208773355, 0.6111)\n",
      "epoch 112: (0.61975, 0.6201705970898144, 0.618)\n",
      "epoch 113: (0.61955, 0.6250130712119628, 0.5977)\n",
      "epoch 114: (0.6191, 0.6186964321307554, 0.6208)\n",
      "epoch 115: (0.6208, 0.6227392806340175, 0.6129)\n",
      "epoch 116: (0.6212, 0.6251807477793844, 0.6053)\n",
      "epoch 117: (0.62105, 0.6287628975640889, 0.5911)\n",
      "epoch 118: (0.61995, 0.6227863650322448, 0.6084)\n",
      "epoch 119: (0.6212, 0.6242057798729248, 0.6091)\n",
      "epoch 120: (0.621, 0.6252847380410023, 0.6039)\n",
      "epoch 121: (0.62235, 0.6314319475776131, 0.5878)\n",
      "epoch 122: (0.6232, 0.6285475792988314, 0.6024)\n",
      "epoch 123: (0.6224, 0.6296610169491526, 0.5944)\n",
      "epoch 124: (0.6232, 0.6259456143937845, 0.6123)\n",
      "epoch 125: (0.62225, 0.6267233336788639, 0.6046)\n",
      "epoch 126: (0.6212, 0.6304067140090381, 0.5859)\n",
      "epoch 127: (0.62315, 0.6271553949406299, 0.6074)\n",
      "epoch 128: (0.62365, 0.6232432971195057, 0.6253)\n",
      "epoch 129: (0.62455, 0.6295641319047124, 0.6052)\n",
      "epoch 130: (0.62635, 0.632428466617755, 0.6034)\n",
      "epoch 131: (0.6256, 0.6343028229255774, 0.5932)\n",
      "epoch 132: (0.6271, 0.6346113111628893, 0.5992)\n",
      "epoch 133: (0.6273, 0.6294751830756713, 0.6189)\n",
      "epoch 134: (0.62765, 0.6357834272949686, 0.5977)\n",
      "epoch 135: (0.62865, 0.633468202095653, 0.6106)\n",
      "epoch 136: (0.62895, 0.6370205079162682, 0.5995)\n",
      "epoch 137: (0.6317, 0.634938524590164, 0.6197)\n",
      "epoch 138: (0.63085, 0.639305866070478, 0.6005)\n",
      "epoch 139: (0.63245, 0.6350290549495361, 0.6229)\n",
      "epoch 140: (0.63065, 0.6375697588712225, 0.6055)\n",
      "epoch 141: (0.6309, 0.637876553612808, 0.6056)\n",
      "epoch 142: (0.63065, 0.6406502314565615, 0.5951)\n",
      "epoch 143: (0.63295, 0.6390835861491788, 0.6109)\n",
      "epoch 144: (0.63355, 0.6349944405134944, 0.6282)\n",
      "epoch 145: (0.63295, 0.6383886749245342, 0.6133)\n",
      "epoch 146: (0.6328, 0.6416986769099445, 0.6014)\n",
      "epoch 147: (0.634, 0.6393221043876066, 0.6149)\n",
      "epoch 148: (0.6343, 0.6411010716537088, 0.6102)\n",
      "epoch 149: (0.6338, 0.6439019143901914, 0.5987)\n",
      "epoch 150: (0.63595, 0.6429998948143473, 0.6113)\n",
      "epoch 151: (0.636, 0.6398313798067037, 0.6223)\n",
      "epoch 152: (0.6357, 0.6462599698210821, 0.5996)\n",
      "epoch 153: (0.63705, 0.6439752074797773, 0.613)\n",
      "epoch 154: (0.6363, 0.6457130639298696, 0.604)\n",
      "epoch 155: (0.63525, 0.6462320250837928, 0.5977)\n",
      "epoch 156: (0.63505, 0.6440226085101844, 0.6039)\n",
      "epoch 157: (0.63625, 0.6441036488630354, 0.609)\n",
      "epoch 158: (0.6367, 0.6460158085879085, 0.6048)\n",
      "epoch 159: (0.63715, 0.645609937360654, 0.6081)\n",
      "epoch 160: (0.63745, 0.6499400021817389, 0.5958)\n",
      "epoch 161: (0.6388, 0.6442527541051757, 0.6199)\n",
      "epoch 162: (0.63895, 0.6502974580854516, 0.6012)\n",
      "epoch 163: (0.63875, 0.6488574187318957, 0.6048)\n",
      "epoch 164: (0.63835, 0.6466659599279126, 0.61)\n",
      "epoch 165: (0.63885, 0.6442597402597403, 0.6201)\n",
      "epoch 166: (0.63825, 0.6483528275566048, 0.6042)\n",
      "epoch 167: (0.63815, 0.6421442535240252, 0.6241)\n",
      "epoch 168: (0.6394, 0.6492505353319058, 0.6064)\n",
      "epoch 169: (0.6405, 0.6474910770522779, 0.6168)\n",
      "epoch 170: (0.6408, 0.6528773072747014, 0.6013)\n",
      "epoch 171: (0.6408, 0.6488686825967435, 0.6137)\n",
      "epoch 172: (0.64175, 0.6546307407003382, 0.6001)\n",
      "epoch 173: (0.64205, 0.6501109584698299, 0.6152)\n",
      "epoch 174: (0.6399, 0.6531640026275455, 0.5966)\n",
      "epoch 175: (0.64235, 0.6501740689946197, 0.6163)\n",
      "epoch 176: (0.6402, 0.6479527226677924, 0.614)\n",
      "epoch 177: (0.64145, 0.6481927710843374, 0.6187)\n",
      "epoch 178: (0.64275, 0.6509783183500794, 0.6155)\n",
      "epoch 179: (0.6425, 0.6546895353886235, 0.6031)\n",
      "epoch 180: (0.6432, 0.6555507277862264, 0.6035)\n",
      "epoch 181: (0.64325, 0.6501729741063005, 0.6202)\n",
      "epoch 182: (0.64235, 0.6542420630620869, 0.6038)\n",
      "epoch 183: (0.6433, 0.6587284005316792, 0.5947)\n",
      "epoch 184: (0.64455, 0.653466397706763, 0.6155)\n",
      "epoch 185: (0.6455, 0.6598198594024605, 0.6007)\n",
      "epoch 186: (0.64635, 0.6550482042589257, 0.6183)\n",
      "epoch 187: (0.64685, 0.6599150604377655, 0.606)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 188: (0.6475, 0.6545149800963754, 0.6248)\n",
      "epoch 189: (0.647, 0.659297789336801, 0.6084)\n",
      "epoch 190: (0.6484, 0.6547768043387567, 0.6278)\n",
      "epoch 191: (0.64725, 0.6596898384123197, 0.6083)\n",
      "epoch 192: (0.64775, 0.6553791145230834, 0.6232)\n",
      "epoch 193: (0.64885, 0.6585703632683498, 0.6182)\n",
      "epoch 194: (0.64985, 0.6587562241762899, 0.6218)\n",
      "epoch 195: (0.6494, 0.6612694300518135, 0.6126)\n",
      "epoch 196: (0.6505, 0.6578229865771812, 0.6273)\n",
      "epoch 197: (0.65005, 0.6577978756967083, 0.6255)\n",
      "epoch 198: (0.6508, 0.6665930181175431, 0.6034)\n",
      "epoch 199: (0.65105, 0.6591843186847929, 0.6255)\n",
      "epoch 200: (0.6515, 0.6655014201441992, 0.6092)\n",
      "epoch 201: (0.65235, 0.6572726334262413, 0.6367)\n",
      "epoch 202: (0.6523, 0.6615743687672395, 0.6236)\n",
      "epoch 203: (0.652, 0.6695293330359134, 0.6003)\n",
      "epoch 204: (0.65305, 0.6637073483795058, 0.6205)\n",
      "epoch 205: (0.6529, 0.657824112303881, 0.6373)\n",
      "epoch 206: (0.6524, 0.6628553109638812, 0.6203)\n",
      "epoch 207: (0.6531, 0.6574454956807898, 0.6393)\n",
      "epoch 208: (0.65315, 0.6652638394302364, 0.6165)\n",
      "epoch 209: (0.65235, 0.6608255040641824, 0.626)\n",
      "epoch 210: (0.6526, 0.6682098765432098, 0.6062)\n",
      "epoch 211: (0.65285, 0.6611152102877622, 0.6272)\n",
      "epoch 212: (0.6541, 0.6667388011252976, 0.6162)\n",
      "epoch 213: (0.65565, 0.6655674928199128, 0.6257)\n",
      "epoch 214: (0.65465, 0.6652420130355807, 0.6226)\n",
      "epoch 215: (0.6561, 0.6627397831526272, 0.6357)\n",
      "epoch 216: (0.6544, 0.6684853775643823, 0.6126)\n",
      "epoch 217: (0.65635, 0.6639060698186393, 0.6333)\n",
      "epoch 218: (0.65525, 0.6691729323308271, 0.6141)\n",
      "epoch 219: (0.65635, 0.6683536125767201, 0.6207)\n",
      "epoch 220: (0.65695, 0.66980417613329, 0.6191)\n",
      "epoch 221: (0.65675, 0.6701030927835051, 0.6175)\n",
      "epoch 222: (0.65645, 0.6726630614722436, 0.6095)\n",
      "epoch 223: (0.658, 0.6685872812633376, 0.6266)\n",
      "epoch 224: (0.6565, 0.6683519793459552, 0.6213)\n",
      "epoch 225: (0.65795, 0.6673376416993325, 0.6299)\n",
      "epoch 226: (0.65725, 0.6727832106361938, 0.6123)\n",
      "epoch 227: (0.6574, 0.6732716864817261, 0.6116)\n",
      "epoch 228: (0.6584, 0.6674772679213364, 0.6313)\n",
      "epoch 229: (0.65855, 0.6710540511382026, 0.622)\n",
      "epoch 230: (0.6586, 0.6736369608057806, 0.6153)\n",
      "epoch 231: (0.65825, 0.6751134225959943, 0.6101)\n",
      "epoch 232: (0.65965, 0.6689954482904625, 0.632)\n",
      "epoch 233: (0.65835, 0.6729278147865021, 0.6162)\n",
      "epoch 234: (0.6606, 0.6689103912494742, 0.636)\n",
      "epoch 235: (0.6606, 0.6712153518123667, 0.6296)\n",
      "epoch 236: (0.6595, 0.6763600176912871, 0.6117)\n",
      "epoch 237: (0.6608, 0.669049621530698, 0.6364)\n",
      "epoch 238: (0.66005, 0.6778135762693034, 0.6101)\n",
      "epoch 239: (0.6598, 0.6687790452049007, 0.6332)\n",
      "epoch 240: (0.6606, 0.6775370329427371, 0.6129)\n",
      "epoch 241: (0.6609, 0.6697973828619671, 0.6347)\n",
      "epoch 242: (0.6613, 0.6781533024077756, 0.614)\n",
      "epoch 243: (0.66245, 0.6712704269899842, 0.6367)\n",
      "epoch 244: (0.6609, 0.6774762850209575, 0.6142)\n",
      "epoch 245: (0.6616, 0.6705360911777121, 0.6354)\n",
      "epoch 246: (0.66115, 0.6762165117550574, 0.6184)\n",
      "epoch 247: (0.66205, 0.6688900468994268, 0.6418)\n",
      "epoch 248: (0.66155, 0.6756933115823818, 0.6213)\n",
      "epoch 249: (0.66225, 0.669098488796248, 0.642)\n",
      "epoch 250: (0.662, 0.6770491803278689, 0.6195)\n",
      "epoch 251: (0.6617, 0.6765669360122297, 0.6196)\n",
      "epoch 252: (0.66235, 0.6706970875827989, 0.6379)\n",
      "epoch 253: (0.66255, 0.6784498847293885, 0.618)\n",
      "epoch 254: (0.66295, 0.6751585510050522, 0.6281)\n",
      "epoch 255: (0.66385, 0.6708016261857604, 0.6435)\n",
      "epoch 256: (0.6645, 0.680531167690957, 0.6201)\n",
      "epoch 257: (0.66505, 0.685846188492287, 0.6091)\n",
      "epoch 258: (0.66645, 0.6788438809498227, 0.6318)\n",
      "epoch 259: (0.66585, 0.6762674035497928, 0.6363)\n",
      "epoch 260: (0.6643, 0.6831661092530658, 0.6128)\n",
      "epoch 261: (0.6663, 0.676990208599404, 0.6361)\n",
      "epoch 262: (0.66545, 0.6840173506840174, 0.615)\n",
      "epoch 263: (0.6671, 0.6758577141654388, 0.6422)\n",
      "epoch 264: (0.66815, 0.6811375632877302, 0.6323)\n",
      "epoch 265: (0.66965, 0.6891937102709936, 0.618)\n",
      "epoch 266: (0.6686, 0.6793617021276596, 0.6386)\n",
      "epoch 267: (0.6684, 0.6865307930881701, 0.6198)\n",
      "epoch 268: (0.669, 0.6797489895766858, 0.6391)\n",
      "epoch 269: (0.6684, 0.6865721249723022, 0.6197)\n",
      "epoch 270: (0.6689, 0.680719024181468, 0.6362)\n",
      "epoch 271: (0.6683, 0.6834532374100719, 0.627)\n",
      "epoch 272: (0.66945, 0.684525754110857, 0.6286)\n",
      "epoch 273: (0.67065, 0.6791224939645218, 0.647)\n",
      "epoch 274: (0.6706, 0.6871845512398508, 0.6263)\n",
      "epoch 275: (0.66975, 0.685417804478427, 0.6275)\n",
      "epoch 276: (0.6696, 0.6902198295199641, 0.6154)\n",
      "epoch 277: (0.6697, 0.6815750053498824, 0.637)\n",
      "epoch 278: (0.6704, 0.6880794701986755, 0.6234)\n",
      "epoch 279: (0.6711, 0.6809050539226053, 0.644)\n",
      "epoch 280: (0.6714, 0.6891414698742, 0.6245)\n",
      "epoch 281: (0.6715, 0.683933933933934, 0.6377)\n",
      "epoch 282: (0.6713, 0.6935155896972436, 0.6139)\n",
      "epoch 283: (0.67245, 0.6852508325276614, 0.6379)\n",
      "epoch 284: (0.673, 0.6932097386642841, 0.6207)\n",
      "epoch 285: (0.6736, 0.6847988077496274, 0.6433)\n",
      "epoch 286: (0.675, 0.6965850370703213, 0.6201)\n",
      "epoch 287: (0.6741, 0.6845061466723188, 0.6459)\n",
      "epoch 288: (0.6742, 0.6919347730277655, 0.628)\n",
      "epoch 289: (0.67395, 0.6874663218019184, 0.6379)\n",
      "epoch 290: (0.67385, 0.688414435894657, 0.6352)\n",
      "epoch 291: (0.674, 0.6917144116350815, 0.6278)\n",
      "epoch 292: (0.67455, 0.6841438970355522, 0.6485)\n",
      "epoch 293: (0.6743, 0.6925541316836058, 0.6269)\n",
      "epoch 294: (0.67515, 0.6951967012147554, 0.6238)\n",
      "epoch 295: (0.6748, 0.6854838709677419, 0.646)\n",
      "epoch 296: (0.67515, 0.6956764607306446, 0.6227)\n",
      "epoch 297: (0.6756, 0.6886143931256713, 0.6411)\n",
      "epoch 298: (0.67495, 0.6954967035422952, 0.6224)\n",
      "epoch 299: (0.67675, 0.6865435356200528, 0.6505)\n",
      "epoch 300: (0.676, 0.6958602270198085, 0.6253)\n",
      "epoch 301: (0.67715, 0.6981765298131782, 0.6241)\n",
      "epoch 302: (0.677, 0.6878183361629882, 0.6482)\n",
      "epoch 303: (0.6771, 0.6993471409275102, 0.6213)\n",
      "epoch 304: (0.6775, 0.6917260747461654, 0.6404)\n",
      "epoch 305: (0.6768, 0.6967505007789896, 0.6261)\n",
      "epoch 306: (0.6787, 0.6915326902465166, 0.6452)\n",
      "epoch 307: (0.6774, 0.6950307827616534, 0.6322)\n",
      "epoch 308: (0.6771, 0.6952160493827161, 0.6307)\n",
      "epoch 309: (0.67685, 0.7030191711628975, 0.6124)\n",
      "epoch 310: (0.679, 0.6952017448200655, 0.6375)\n",
      "epoch 311: (0.67765, 0.7024040104819415, 0.6165)\n",
      "epoch 312: (0.68005, 0.6968835429196282, 0.6373)\n",
      "epoch 313: (0.68015, 0.7020751542344363, 0.6259)\n",
      "epoch 314: (0.68055, 0.6980800877674164, 0.6363)\n",
      "epoch 315: (0.68025, 0.7060235455480627, 0.6177)\n",
      "epoch 316: (0.67995, 0.6954066673905962, 0.6404)\n",
      "epoch 317: (0.6796, 0.703121465731735, 0.6217)\n",
      "epoch 318: (0.681, 0.7, 0.6335)\n",
      "epoch 319: (0.68015, 0.7004562145321019, 0.6295)\n",
      "epoch 320: (0.6802, 0.7003557927507227, 0.6299)\n",
      "epoch 321: (0.6814, 0.7007081212657668, 0.6333)\n",
      "epoch 322: (0.6813, 0.692095783004874, 0.6532)\n",
      "epoch 323: (0.6806, 0.7042524315765664, 0.6227)\n",
      "epoch 324: (0.68065, 0.7029091317533416, 0.6258)\n",
      "epoch 325: (0.68125, 0.6944116700632843, 0.6474)\n",
      "epoch 326: (0.68145, 0.7000330724286187, 0.635)\n",
      "epoch 327: (0.68275, 0.698792559556184, 0.6424)\n",
      "epoch 328: (0.6818, 0.7033557046979866, 0.6288)\n",
      "epoch 329: (0.68245, 0.6950293960448958, 0.6502)\n",
      "epoch 330: (0.68225, 0.7059089368432946, 0.6248)\n",
      "epoch 331: (0.68235, 0.6966885988566498, 0.6459)\n",
      "epoch 332: (0.6813, 0.703023516237402, 0.6278)\n",
      "epoch 333: (0.6825, 0.6983695652173914, 0.6425)\n",
      "epoch 334: (0.6825, 0.7040930440617311, 0.6296)\n",
      "epoch 335: (0.68365, 0.6957263135457743, 0.6528)\n",
      "epoch 336: (0.6834, 0.7063456345634563, 0.6278)\n",
      "epoch 337: (0.68415, 0.6991887506760411, 0.6464)\n",
      "epoch 338: (0.6827, 0.7090867475394828, 0.6196)\n",
      "epoch 339: (0.68515, 0.6997087692805523, 0.6487)\n",
      "epoch 340: (0.68525, 0.7066830302354122, 0.6334)\n",
      "epoch 341: (0.6851, 0.696956799319004, 0.655)\n",
      "epoch 342: (0.68345, 0.7072178922399187, 0.6261)\n",
      "epoch 343: (0.68465, 0.7048707422611783, 0.6353)\n",
      "epoch 344: (0.6861, 0.6970563320626854, 0.6583)\n",
      "epoch 345: (0.6838, 0.7077305605786618, 0.6262)\n",
      "epoch 346: (0.68495, 0.6956107879428873, 0.6577)\n",
      "epoch 347: (0.6853, 0.7063014918726341, 0.6344)\n",
      "epoch 348: (0.6851, 0.6952531645569621, 0.6591)\n",
      "epoch 349: (0.6851, 0.7090108401084011, 0.6279)\n",
      "epoch 350: (0.6863, 0.6977707006369427, 0.6573)\n",
      "epoch 351: (0.6864, 0.7098626435487503, 0.6305)\n",
      "epoch 352: (0.68745, 0.7014941416747286, 0.6526)\n",
      "epoch 353: (0.6858, 0.7089518668466037, 0.6304)\n",
      "epoch 354: (0.68745, 0.703949515830704, 0.647)\n",
      "epoch 355: (0.68505, 0.7076646840983055, 0.6306)\n",
      "epoch 356: (0.68845, 0.7077041772291414, 0.6421)\n",
      "epoch 357: (0.68825, 0.7014877448357059, 0.6554)\n",
      "epoch 358: (0.68765, 0.7070049641478213, 0.6409)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 359: (0.68805, 0.7023130715438408, 0.6528)\n",
      "epoch 360: (0.6872, 0.7090685727049364, 0.6349)\n",
      "epoch 361: (0.6873, 0.708018658374056, 0.6375)\n",
      "epoch 362: (0.68645, 0.7097064447193792, 0.631)\n",
      "epoch 363: (0.6889, 0.7018593716606112, 0.6568)\n",
      "epoch 364: (0.68835, 0.7151342090234152, 0.6261)\n",
      "epoch 365: (0.6877, 0.7022629310344828, 0.6517)\n",
      "epoch 366: (0.68755, 0.713100784001818, 0.6276)\n",
      "epoch 367: (0.68815, 0.704089380626966, 0.6491)\n",
      "epoch 368: (0.68835, 0.7059595407326408, 0.6456)\n",
      "epoch 369: (0.6889, 0.7039075993091537, 0.6521)\n",
      "epoch 370: (0.6895, 0.7148526077097506, 0.6305)\n",
      "epoch 371: (0.6905, 0.7063921993499458, 0.652)\n",
      "epoch 372: (0.68875, 0.71500170862285, 0.6277)\n",
      "epoch 373: (0.6897, 0.7043300301594141, 0.6539)\n",
      "epoch 374: (0.68935, 0.716721986952043, 0.6262)\n",
      "epoch 375: (0.6902, 0.7039459575380657, 0.6565)\n",
      "epoch 376: (0.6904, 0.7152385258874068, 0.6327)\n",
      "epoch 377: (0.6897, 0.7190025398291388, 0.6228)\n",
      "epoch 378: (0.69145, 0.7086648501362398, 0.6502)\n",
      "epoch 379: (0.6909, 0.716784010901658, 0.6312)\n",
      "epoch 380: (0.6917, 0.7057308435286542, 0.6576)\n",
      "epoch 381: (0.6915, 0.7149270482603816, 0.637)\n",
      "epoch 382: (0.69055, 0.71889718552556, 0.6258)\n",
      "epoch 383: (0.6918, 0.7209168394379175, 0.6259)\n",
      "epoch 384: (0.69265, 0.7094249374932058, 0.6526)\n",
      "epoch 385: (0.6918, 0.717411017909771, 0.6329)\n",
      "epoch 386: (0.693, 0.7126018946904604, 0.6469)\n",
      "epoch 387: (0.6937, 0.7155575339416871, 0.643)\n",
      "epoch 388: (0.69255, 0.7184840576421196, 0.6332)\n",
      "epoch 389: (0.6943, 0.7074081981212639, 0.6627)\n",
      "epoch 390: (0.69215, 0.7159716758457907, 0.637)\n",
      "epoch 391: (0.69375, 0.7080872086779079, 0.6593)\n",
      "epoch 392: (0.69315, 0.7179776548922243, 0.6362)\n",
      "epoch 393: (0.6946, 0.7130968024529128, 0.6512)\n",
      "epoch 394: (0.69375, 0.7229830820577742, 0.6282)\n",
      "epoch 395: (0.69625, 0.7128755830350363, 0.6572)\n",
      "epoch 396: (0.6943, 0.7209460996133727, 0.634)\n",
      "epoch 397: (0.69625, 0.7109534558744491, 0.6614)\n",
      "epoch 398: (0.6942, 0.7209831588529814, 0.6336)\n",
      "epoch 399: (0.6953, 0.7148987676056338, 0.6497)\n",
      "epoch 0: (0.5, 0, 0.0)\n",
      "epoch 1: (0.5, 0, 0.0)\n",
      "epoch 2: (0.5, 0, 0.0)\n",
      "epoch 3: (0.5, 0, 0.0)\n",
      "epoch 4: (0.5, 0, 0.0)\n",
      "epoch 5: (0.5, 0, 0.0)\n",
      "epoch 6: (0.5013, 0.8611111111111112, 0.0031)\n",
      "epoch 7: (0.50455, 0.6194225721784777, 0.0236)\n",
      "epoch 8: (0.52285, 0.6778210116731518, 0.0871)\n",
      "epoch 9: (0.543, 0.651301900070373, 0.1851)\n",
      "epoch 10: (0.5349, 0.5725270157938487, 0.2755)\n",
      "epoch 11: (0.53855, 0.5651292448048657, 0.3345)\n",
      "epoch 12: (0.55155, 0.5730273409831421, 0.4045)\n",
      "epoch 13: (0.5603, 0.5708245243128964, 0.486)\n",
      "epoch 14: (0.5602, 0.5630630630630631, 0.5375)\n",
      "epoch 15: (0.56105, 0.5599882087059055, 0.5699)\n",
      "epoch 16: (0.5601, 0.5575229709035222, 0.5825)\n",
      "epoch 17: (0.56025, 0.5572773077288715, 0.5862)\n",
      "epoch 18: (0.5596, 0.5560571858540256, 0.5912)\n",
      "epoch 19: (0.55905, 0.5563507968317588, 0.583)\n",
      "epoch 20: (0.55785, 0.554457309611221, 0.589)\n",
      "epoch 21: (0.55705, 0.5544838124343424, 0.5806)\n",
      "epoch 22: (0.55725, 0.5543117351294944, 0.5843)\n",
      "epoch 23: (0.55745, 0.5552350735506202, 0.5775)\n",
      "epoch 24: (0.55765, 0.5549518635020494, 0.5822)\n",
      "epoch 25: (0.5587, 0.5570456754130223, 0.5732)\n",
      "epoch 26: (0.55845, 0.5562073276276565, 0.5784)\n",
      "epoch 27: (0.5619, 0.5607816182246661, 0.5711)\n",
      "epoch 28: (0.562, 0.5605587028716547, 0.5739)\n",
      "epoch 29: (0.56395, 0.5633356442507675, 0.5688)\n",
      "epoch 30: (0.56365, 0.5624693296692511, 0.5731)\n",
      "epoch 31: (0.56585, 0.5658434156584341, 0.5659)\n",
      "epoch 32: (0.5644, 0.5628170113148654, 0.577)\n",
      "epoch 33: (0.56655, 0.5666900491031166, 0.5655)\n",
      "epoch 34: (0.56675, 0.5652173913043478, 0.5785)\n",
      "epoch 35: (0.5681, 0.5685800604229607, 0.5646)\n",
      "epoch 36: (0.56825, 0.566630869862345, 0.5804)\n",
      "epoch 37: (0.5694, 0.5701577031945007, 0.564)\n",
      "epoch 38: (0.5699, 0.5682883939038686, 0.5817)\n",
      "epoch 39: (0.57095, 0.5715005542678625, 0.5671)\n",
      "epoch 40: (0.57275, 0.5711909188766024, 0.5837)\n",
      "epoch 41: (0.5718, 0.5726279587295164, 0.5661)\n",
      "epoch 42: (0.57355, 0.5717490976490098, 0.5861)\n",
      "epoch 43: (0.5737, 0.5743843358901898, 0.5691)\n",
      "epoch 44: (0.57555, 0.573901985718478, 0.5867)\n",
      "epoch 45: (0.5747, 0.5753479927375429, 0.5704)\n",
      "epoch 46: (0.5769, 0.5747472783825817, 0.5913)\n",
      "epoch 47: (0.5764, 0.5771561300747324, 0.5715)\n",
      "epoch 48: (0.5775, 0.5751697381183317, 0.593)\n",
      "epoch 49: (0.57825, 0.5787936763669318, 0.5748)\n",
      "epoch 50: (0.57895, 0.5764945257242515, 0.595)\n",
      "epoch 51: (0.57935, 0.5797247061187581, 0.577)\n",
      "epoch 52: (0.58005, 0.5775302663438256, 0.5963)\n",
      "epoch 53: (0.5815, 0.5820579943616593, 0.5781)\n",
      "epoch 54: (0.5818, 0.5790796597061099, 0.599)\n",
      "epoch 55: (0.5839, 0.5845425231761386, 0.5801)\n",
      "epoch 56: (0.58375, 0.5808007718282682, 0.602)\n",
      "epoch 57: (0.58555, 0.5860404304535854, 0.5827)\n",
      "epoch 58: (0.5857, 0.5828179358330112, 0.6031)\n",
      "epoch 59: (0.5873, 0.5882709807886755, 0.5818)\n",
      "epoch 60: (0.58785, 0.5847727492038984, 0.606)\n",
      "epoch 61: (0.58885, 0.5897021706208986, 0.5841)\n",
      "epoch 62: (0.59005, 0.5873678082856312, 0.6054)\n",
      "epoch 63: (0.5927, 0.593978102189781, 0.5859)\n",
      "epoch 64: (0.59155, 0.5887198371935265, 0.6075)\n",
      "epoch 65: (0.5944, 0.5960130187144019, 0.586)\n",
      "epoch 66: (0.59395, 0.5914533242480288, 0.6076)\n",
      "epoch 67: (0.59625, 0.5980042765502495, 0.5873)\n",
      "epoch 68: (0.5957, 0.5930933852140078, 0.6097)\n",
      "epoch 69: (0.59875, 0.6007961620904358, 0.5886)\n",
      "epoch 70: (0.59795, 0.5954771420216395, 0.6109)\n",
      "epoch 71: (0.60085, 0.6032770097286226, 0.5891)\n",
      "epoch 72: (0.6001, 0.5977921062915201, 0.6119)\n",
      "epoch 73: (0.60315, 0.6060232295199918, 0.5896)\n",
      "epoch 74: (0.60275, 0.6006070694213258, 0.6134)\n",
      "epoch 75: (0.60505, 0.6083324739610189, 0.5899)\n",
      "epoch 76: (0.60525, 0.6031155089644362, 0.6156)\n",
      "epoch 77: (0.60705, 0.6106002686227916, 0.591)\n",
      "epoch 78: (0.60775, 0.605772062432512, 0.6171)\n",
      "epoch 79: (0.60855, 0.6125453602903058, 0.5908)\n",
      "epoch 80: (0.60915, 0.6073149149542818, 0.6177)\n",
      "epoch 81: (0.6101, 0.6141879278158059, 0.5922)\n",
      "epoch 82: (0.60945, 0.6078643934167735, 0.6168)\n",
      "epoch 83: (0.61185, 0.6163044608505771, 0.5927)\n",
      "epoch 84: (0.61165, 0.6103369898211286, 0.6176)\n",
      "epoch 85: (0.61275, 0.617533618263317, 0.5924)\n",
      "epoch 86: (0.61355, 0.6122812221892614, 0.6192)\n",
      "epoch 87: (0.6136, 0.6187290969899666, 0.592)\n",
      "epoch 88: (0.6141, 0.6130374479889042, 0.6188)\n",
      "epoch 89: (0.6159, 0.6214375523889355, 0.5931)\n",
      "epoch 90: (0.61505, 0.614102945551919, 0.6192)\n",
      "epoch 91: (0.6167, 0.622352694485217, 0.5936)\n",
      "epoch 92: (0.61695, 0.6160103164368614, 0.621)\n",
      "epoch 93: (0.61825, 0.6242252337430403, 0.5942)\n",
      "epoch 94: (0.61735, 0.6165226889087478, 0.6209)\n",
      "epoch 95: (0.61835, 0.6243041697300704, 0.5944)\n",
      "epoch 96: (0.6189, 0.6182378679395386, 0.6217)\n",
      "epoch 97: (0.62015, 0.6263008514664143, 0.5958)\n",
      "epoch 98: (0.6201, 0.6194074368661762, 0.623)\n",
      "epoch 99: (0.6209, 0.6272631578947369, 0.5959)\n",
      "epoch 100: (0.621, 0.6203501094091903, 0.6237)\n",
      "epoch 101: (0.6224, 0.6290050590219224, 0.5968)\n",
      "epoch 102: (0.6227, 0.6223818073010173, 0.624)\n",
      "epoch 103: (0.6236, 0.6303522463615271, 0.5977)\n",
      "epoch 104: (0.62415, 0.6241872561768531, 0.624)\n",
      "epoch 105: (0.6241, 0.6310177364864865, 0.5977)\n",
      "epoch 106: (0.6245, 0.6244502199120352, 0.6247)\n",
      "epoch 107: (0.62495, 0.6322362154725367, 0.5974)\n",
      "epoch 108: (0.62615, 0.6261373862613738, 0.6262)\n",
      "epoch 109: (0.62665, 0.6342342342342342, 0.5984)\n",
      "epoch 110: (0.62615, 0.6259359089547769, 0.627)\n",
      "epoch 111: (0.62755, 0.6350449973530968, 0.5998)\n",
      "epoch 112: (0.62775, 0.6280445023554174, 0.6266)\n",
      "epoch 113: (0.6281, 0.6359295415959253, 0.5993)\n",
      "epoch 114: (0.6287, 0.6288804326056479, 0.628)\n",
      "epoch 115: (0.6288, 0.6366143402630462, 0.6002)\n",
      "epoch 116: (0.6299, 0.6300560672807369, 0.6293)\n",
      "epoch 117: (0.6297, 0.6379493724739417, 0.5998)\n",
      "epoch 118: (0.6301, 0.6303868510723591, 0.629)\n",
      "epoch 119: (0.6303, 0.6388237800980183, 0.5996)\n",
      "epoch 120: (0.63035, 0.6304674206786107, 0.6299)\n",
      "epoch 121: (0.6314, 0.6400255754475703, 0.6006)\n",
      "epoch 122: (0.6317, 0.631858229875851, 0.6311)\n",
      "epoch 123: (0.6321, 0.6410420670510356, 0.6004)\n",
      "epoch 124: (0.63235, 0.6328148519819368, 0.6306)\n",
      "epoch 125: (0.6328, 0.6421232876712328, 0.6)\n",
      "epoch 126: (0.63285, 0.6332096660984659, 0.6315)\n",
      "epoch 127: (0.6344, 0.6439588688946015, 0.6012)\n",
      "epoch 128: (0.63325, 0.6341758131104622, 0.6298)\n",
      "epoch 129: (0.6346, 0.6445136353875885, 0.6003)\n",
      "epoch 130: (0.6343, 0.6351650563607085, 0.6311)\n",
      "epoch 131: (0.63475, 0.6448146157979581, 0.6)\n",
      "epoch 132: (0.63445, 0.6354659949622167, 0.6307)\n",
      "epoch 133: (0.63575, 0.6459520481668638, 0.6008)\n",
      "epoch 134: (0.63595, 0.6371431453646726, 0.6316)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 135: (0.636, 0.646551724137931, 0.6)\n",
      "epoch 136: (0.6367, 0.6379971734302443, 0.632)\n",
      "epoch 137: (0.6374, 0.648124191461837, 0.6012)\n",
      "epoch 138: (0.63715, 0.6385213614786385, 0.6322)\n",
      "epoch 139: (0.63845, 0.6492078887811187, 0.6024)\n",
      "epoch 140: (0.63785, 0.6393973101425827, 0.6323)\n",
      "epoch 141: (0.6393, 0.6504969749351772, 0.6021)\n",
      "epoch 142: (0.6382, 0.6400486420753952, 0.6316)\n",
      "epoch 143: (0.64095, 0.6525598008442473, 0.6029)\n",
      "epoch 144: (0.63805, 0.6399391789153573, 0.6313)\n",
      "epoch 145: (0.64145, 0.6531672983216026, 0.6032)\n",
      "epoch 146: (0.63865, 0.640547389761784, 0.6319)\n",
      "epoch 147: (0.6419, 0.6537045060658578, 0.6035)\n",
      "epoch 148: (0.63915, 0.641283379023251, 0.6316)\n",
      "epoch 149: (0.64275, 0.6546754794668979, 0.6042)\n",
      "epoch 150: (0.6401, 0.6424938974776241, 0.6317)\n",
      "epoch 151: (0.6427, 0.6545710571923743, 0.6043)\n",
      "epoch 152: (0.64095, 0.6435189899195601, 0.632)\n",
      "epoch 153: (0.64315, 0.6553445469343462, 0.6039)\n",
      "epoch 154: (0.64215, 0.645154702338405, 0.6318)\n",
      "epoch 155: (0.64435, 0.657192638571273, 0.6035)\n",
      "epoch 156: (0.6432, 0.646481178396072, 0.632)\n",
      "epoch 157: (0.64475, 0.6579378068739771, 0.603)\n",
      "epoch 158: (0.64425, 0.6474496575692528, 0.6334)\n",
      "epoch 159: (0.6457, 0.6589570150556404, 0.604)\n",
      "epoch 160: (0.6447, 0.6479852730619758, 0.6336)\n",
      "epoch 161: (0.647, 0.6608667104399212, 0.6039)\n",
      "epoch 162: (0.64555, 0.648930727514581, 0.6342)\n",
      "epoch 163: (0.64785, 0.661814599978111, 0.6047)\n",
      "epoch 164: (0.6457, 0.6491605241605242, 0.6341)\n",
      "epoch 165: (0.6486, 0.6628314705237782, 0.6049)\n",
      "epoch 166: (0.64715, 0.6507838917921919, 0.6351)\n",
      "epoch 167: (0.6492, 0.6638480122995827, 0.6045)\n",
      "epoch 168: (0.64795, 0.651728027894575, 0.6355)\n",
      "epoch 169: (0.64915, 0.6638470833791058, 0.6043)\n",
      "epoch 170: (0.6487, 0.6523565573770492, 0.6367)\n",
      "epoch 171: (0.64945, 0.6643571978444958, 0.6041)\n",
      "epoch 172: (0.6498, 0.6536725482150184, 0.6372)\n",
      "epoch 173: (0.65035, 0.6657479880939257, 0.6039)\n",
      "epoch 174: (0.65045, 0.6543868650590046, 0.6377)\n",
      "epoch 175: (0.6505, 0.6659316427783903, 0.604)\n",
      "epoch 176: (0.6511, 0.6553567756528892, 0.6374)\n",
      "epoch 177: (0.6514, 0.6671819787985865, 0.6042)\n",
      "epoch 178: (0.6516, 0.6561277033985582, 0.6371)\n",
      "epoch 179: (0.65215, 0.6684006640841174, 0.6039)\n",
      "epoch 180: (0.6523, 0.6569779426922284, 0.6374)\n",
      "epoch 181: (0.65295, 0.6693610895803344, 0.6045)\n",
      "epoch 182: (0.65355, 0.6581196581196581, 0.6391)\n",
      "epoch 183: (0.6531, 0.6696210946155551, 0.6044)\n",
      "epoch 184: (0.6542, 0.6589690721649485, 0.6392)\n",
      "epoch 185: (0.65445, 0.6713255684969496, 0.6052)\n",
      "epoch 186: (0.65475, 0.6596842431121659, 0.6393)\n",
      "epoch 187: (0.65475, 0.67181081381148, 0.6051)\n",
      "epoch 188: (0.6549, 0.6596578025149453, 0.64)\n",
      "epoch 189: (0.655, 0.6719928983577452, 0.6056)\n",
      "epoch 190: (0.6558, 0.6609171658748193, 0.6399)\n",
      "epoch 191: (0.6554, 0.6729741763134461, 0.6046)\n",
      "epoch 192: (0.65645, 0.6616052060737527, 0.6405)\n",
      "epoch 193: (0.65595, 0.6737604456824513, 0.6047)\n",
      "epoch 194: (0.65715, 0.6622277278827294, 0.6415)\n",
      "epoch 195: (0.65675, 0.6748076279692204, 0.6051)\n",
      "epoch 196: (0.658, 0.6632568712543914, 0.6419)\n",
      "epoch 197: (0.65655, 0.6747795020654237, 0.6044)\n",
      "epoch 198: (0.65875, 0.6640487754469361, 0.6426)\n",
      "epoch 199: (0.65675, 0.6751200983130377, 0.6043)\n",
      "epoch 200: (0.6595, 0.6649431230610134, 0.643)\n",
      "epoch 201: (0.65695, 0.6756575265808618, 0.6037)\n",
      "epoch 202: (0.6597, 0.6651499482936918, 0.6432)\n",
      "epoch 203: (0.6579, 0.6767801164352889, 0.6045)\n",
      "epoch 204: (0.6603, 0.6658733443708609, 0.6435)\n",
      "epoch 205: (0.659, 0.6781712236665173, 0.6052)\n",
      "epoch 206: (0.6605, 0.6662523306401492, 0.6432)\n",
      "epoch 207: (0.6599, 0.6793002915451894, 0.6058)\n",
      "epoch 208: (0.66095, 0.6667357298249249, 0.6436)\n",
      "epoch 209: (0.6606, 0.680327868852459, 0.6059)\n",
      "epoch 210: (0.6625, 0.6682542969558914, 0.6454)\n",
      "epoch 211: (0.6613, 0.6813582190240611, 0.606)\n",
      "epoch 212: (0.66295, 0.6688426069837322, 0.6455)\n",
      "epoch 213: (0.66185, 0.682119950489479, 0.6062)\n",
      "epoch 214: (0.6639, 0.6698093659345213, 0.6465)\n",
      "epoch 215: (0.66235, 0.6828471674738146, 0.6063)\n",
      "epoch 216: (0.6642, 0.6702260004146796, 0.6465)\n",
      "epoch 217: (0.66275, 0.6835457313634826, 0.6061)\n",
      "epoch 218: (0.6648, 0.6711318795430945, 0.6463)\n",
      "epoch 219: (0.664, 0.6851851851851852, 0.6068)\n",
      "epoch 220: (0.66525, 0.6714745252671993, 0.6471)\n",
      "epoch 221: (0.6646, 0.6861148801447309, 0.6068)\n",
      "epoch 222: (0.66565, 0.6722470624935011, 0.6465)\n",
      "epoch 223: (0.66535, 0.6870686729268016, 0.6073)\n",
      "epoch 224: (0.66665, 0.6732508576775132, 0.6476)\n",
      "epoch 225: (0.66555, 0.6875070789443878, 0.607)\n",
      "epoch 226: (0.66725, 0.6740918080566254, 0.6476)\n",
      "epoch 227: (0.6664, 0.6882778909255488, 0.6083)\n",
      "epoch 228: (0.66765, 0.6745445080687142, 0.6479)\n",
      "epoch 229: (0.667, 0.6890423364274394, 0.6087)\n",
      "epoch 230: (0.6684, 0.6754166666666667, 0.6484)\n",
      "epoch 231: (0.6675, 0.6898232094288305, 0.6087)\n",
      "epoch 232: (0.66895, 0.6762282257223323, 0.6483)\n",
      "epoch 233: (0.6676, 0.6898074745186863, 0.6091)\n",
      "epoch 234: (0.66915, 0.6764736567553469, 0.6484)\n",
      "epoch 235: (0.66835, 0.6907648725212464, 0.6096)\n",
      "epoch 236: (0.66975, 0.6769519441259252, 0.6494)\n",
      "epoch 237: (0.6687, 0.6913132229530505, 0.6096)\n",
      "epoch 238: (0.67015, 0.6777023498694517, 0.6489)\n",
      "epoch 239: (0.66875, 0.6915654444318311, 0.6092)\n",
      "epoch 240: (0.67015, 0.6777023498694517, 0.6489)\n",
      "epoch 241: (0.66935, 0.6924213157595728, 0.6094)\n",
      "epoch 242: (0.6716, 0.679235429287654, 0.6503)\n",
      "epoch 243: (0.66975, 0.6929635102875981, 0.6096)\n",
      "epoch 244: (0.67185, 0.6795153034576413, 0.6505)\n",
      "epoch 245: (0.6696, 0.6929465301478953, 0.6091)\n",
      "epoch 246: (0.67195, 0.679807591759908, 0.6501)\n",
      "epoch 247: (0.67015, 0.6937265171353751, 0.6093)\n",
      "epoch 248: (0.6723, 0.6802678384599289, 0.6502)\n",
      "epoch 249: (0.6707, 0.6945520857077729, 0.6094)\n",
      "epoch 250: (0.6727, 0.6805352289358143, 0.651)\n",
      "epoch 251: (0.6706, 0.6945267958950969, 0.6091)\n",
      "epoch 252: (0.67315, 0.6809110855709957, 0.6517)\n",
      "epoch 253: (0.67145, 0.6955629063533706, 0.6098)\n",
      "epoch 254: (0.67305, 0.6807310704960835, 0.6518)\n",
      "epoch 255: (0.6718, 0.6960292104062072, 0.61)\n",
      "epoch 256: (0.67335, 0.6811200501514993, 0.6519)\n",
      "epoch 257: (0.67255, 0.6969973741294668, 0.6105)\n",
      "epoch 258: (0.6738, 0.6816471571906354, 0.6522)\n",
      "epoch 259: (0.6732, 0.6978072179077204, 0.611)\n",
      "epoch 260: (0.6738, 0.6817991631799163, 0.6518)\n",
      "epoch 261: (0.67365, 0.6984344646326134, 0.6112)\n",
      "epoch 262: (0.6744, 0.6825031393888656, 0.6522)\n",
      "epoch 263: (0.6741, 0.6989714285714286, 0.6116)\n",
      "epoch 264: (0.67505, 0.6829727187206021, 0.6534)\n",
      "epoch 265: (0.67405, 0.6990735445499257, 0.6112)\n",
      "epoch 266: (0.6753, 0.6832915098285236, 0.6535)\n",
      "epoch 267: (0.67405, 0.6992558672009158, 0.6108)\n",
      "epoch 268: (0.6758, 0.6838143036386449, 0.654)\n",
      "epoch 269: (0.6745, 0.699793908861919, 0.6112)\n",
      "epoch 270: (0.67605, 0.6840949492836976, 0.6542)\n",
      "epoch 271: (0.67475, 0.7001030573686019, 0.6114)\n",
      "epoch 272: (0.6763, 0.6844528143963172, 0.6542)\n",
      "epoch 273: (0.67515, 0.7007449856733524, 0.6114)\n",
      "epoch 274: (0.6766, 0.6848440443793176, 0.6543)\n",
      "epoch 275: (0.67585, 0.7016859731620598, 0.6118)\n",
      "epoch 276: (0.6767, 0.6849100041858518, 0.6545)\n",
      "epoch 277: (0.67575, 0.7014326647564469, 0.612)\n",
      "epoch 278: (0.67705, 0.6853732593445713, 0.6546)\n",
      "epoch 279: (0.67615, 0.7020764024320294, 0.612)\n",
      "epoch 280: (0.6776, 0.6860075408462505, 0.655)\n",
      "epoch 281: (0.6763, 0.7025505514705882, 0.6115)\n",
      "epoch 282: (0.6781, 0.6866093880972338, 0.6553)\n",
      "epoch 283: (0.6768, 0.7034522439585731, 0.6113)\n",
      "epoch 284: (0.6788, 0.6874213836477987, 0.6558)\n",
      "epoch 285: (0.6771, 0.7037505752416015, 0.6117)\n",
      "epoch 286: (0.67935, 0.6878994237820849, 0.6566)\n",
      "epoch 287: (0.67745, 0.7040358744394619, 0.6123)\n",
      "epoch 288: (0.67965, 0.6880167451596023, 0.6574)\n",
      "epoch 289: (0.67785, 0.7044958031505116, 0.6127)\n",
      "epoch 290: (0.6798, 0.6880359757372935, 0.6579)\n",
      "epoch 291: (0.6778, 0.7045559134836631, 0.6124)\n",
      "epoch 292: (0.68075, 0.6889306992787708, 0.6591)\n",
      "epoch 293: (0.678, 0.7047860101242522, 0.6126)\n",
      "epoch 294: (0.68095, 0.6890212054737282, 0.6596)\n",
      "epoch 295: (0.6784, 0.7051989878076834, 0.6131)\n",
      "epoch 296: (0.6815, 0.6895759348234802, 0.6602)\n",
      "epoch 297: (0.6788, 0.7056117755289788, 0.6136)\n",
      "epoch 298: (0.6817, 0.6897848339252142, 0.6604)\n",
      "epoch 299: (0.6794, 0.7063017479300828, 0.6142)\n",
      "epoch 300: (0.68205, 0.6901702705525958, 0.6607)\n",
      "epoch 301: (0.6797, 0.7066942719116632, 0.6144)\n",
      "epoch 302: (0.68265, 0.6908767896331905, 0.6611)\n",
      "epoch 303: (0.6798, 0.7068092937658155, 0.6145)\n",
      "epoch 304: (0.6831, 0.691487136582305, 0.6612)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 305: (0.68035, 0.7075612843825526, 0.6148)\n",
      "epoch 306: (0.68335, 0.691528256554894, 0.662)\n",
      "epoch 307: (0.6808, 0.7080073630924989, 0.6154)\n",
      "epoch 308: (0.6834, 0.6916405433646813, 0.6619)\n",
      "epoch 309: (0.68095, 0.7083477259643063, 0.6152)\n",
      "epoch 310: (0.68375, 0.6920263350402341, 0.6622)\n",
      "epoch 311: (0.6812, 0.7085635359116023, 0.6156)\n",
      "epoch 312: (0.68385, 0.6920505588634702, 0.6625)\n",
      "epoch 313: (0.68165, 0.7090093199861927, 0.6162)\n",
      "epoch 314: (0.68455, 0.6928623680635385, 0.663)\n",
      "epoch 315: (0.68185, 0.7094322238857538, 0.616)\n",
      "epoch 316: (0.6845, 0.6926289413238672, 0.6634)\n",
      "epoch 317: (0.6819, 0.7094656840165822, 0.6161)\n",
      "epoch 318: (0.68505, 0.6930620761606677, 0.6643)\n",
      "epoch 319: (0.6828, 0.7105990783410139, 0.6168)\n",
      "epoch 320: (0.68565, 0.6936880542514345, 0.6649)\n",
      "epoch 321: (0.68305, 0.7109113953220417, 0.617)\n",
      "epoch 322: (0.68615, 0.6941691874413268, 0.6655)\n",
      "epoch 323: (0.6831, 0.7110419548178885, 0.6169)\n",
      "epoch 324: (0.6868, 0.6949081803005008, 0.666)\n",
      "epoch 325: (0.68355, 0.7117803161416869, 0.6169)\n",
      "epoch 326: (0.68705, 0.6951893978921005, 0.6662)\n",
      "epoch 327: (0.6839, 0.7121107266435986, 0.6174)\n",
      "epoch 328: (0.68735, 0.6953393806693775, 0.6669)\n",
      "epoch 329: (0.68415, 0.7123256082093854, 0.6178)\n",
      "epoch 330: (0.6874, 0.6951270304039984, 0.6676)\n",
      "epoch 331: (0.6846, 0.7127708621484555, 0.6184)\n",
      "epoch 332: (0.6872, 0.6948782011242973, 0.6675)\n",
      "epoch 333: (0.68485, 0.71318187060316, 0.6184)\n",
      "epoch 334: (0.6874, 0.6950864043306267, 0.6677)\n",
      "epoch 335: (0.6849, 0.71316578279917, 0.6186)\n",
      "epoch 336: (0.68805, 0.6959466499947901, 0.6679)\n",
      "epoch 337: (0.6854, 0.7136929460580913, 0.6192)\n",
      "epoch 338: (0.6882, 0.695837669094693, 0.6687)\n",
      "epoch 339: (0.6857, 0.713841547673883, 0.6199)\n",
      "epoch 340: (0.6886, 0.6962130669995839, 0.6692)\n",
      "epoch 341: (0.6863, 0.7147798017062486, 0.62)\n",
      "epoch 342: (0.6886, 0.6962130669995839, 0.6692)\n",
      "epoch 343: (0.68685, 0.7153890489913545, 0.6206)\n",
      "epoch 344: (0.6896, 0.6975823259691538, 0.6694)\n",
      "epoch 345: (0.6867, 0.7153899400092294, 0.6201)\n",
      "epoch 346: (0.68995, 0.6977615825091098, 0.6702)\n",
      "epoch 347: (0.6871, 0.7159012231710131, 0.6204)\n",
      "epoch 348: (0.69025, 0.6981564420372878, 0.6703)\n",
      "epoch 349: (0.68735, 0.7162146566647433, 0.6206)\n",
      "epoch 350: (0.69055, 0.698468909488595, 0.6706)\n",
      "epoch 351: (0.6881, 0.7171052631578947, 0.6213)\n",
      "epoch 352: (0.69085, 0.6988642284047099, 0.6707)\n",
      "epoch 353: (0.6886, 0.7176321255481191, 0.6219)\n",
      "epoch 354: (0.6912, 0.69920816836841, 0.6711)\n",
      "epoch 355: (0.68885, 0.7178451955242819, 0.6223)\n",
      "epoch 356: (0.69115, 0.6992183428869203, 0.6709)\n",
      "epoch 357: (0.68885, 0.7179457587997692, 0.6221)\n",
      "epoch 358: (0.69145, 0.6994063118425164, 0.6715)\n",
      "epoch 359: (0.68875, 0.7179812911421642, 0.6217)\n",
      "epoch 360: (0.6917, 0.699438202247191, 0.6723)\n",
      "epoch 361: (0.6889, 0.7182805639010862, 0.6216)\n",
      "epoch 362: (0.6918, 0.6994177583697234, 0.6727)\n",
      "epoch 363: (0.68925, 0.718609217973894, 0.6221)\n",
      "epoch 364: (0.692, 0.699501246882793, 0.6732)\n",
      "epoch 365: (0.68955, 0.7187031268028152, 0.6229)\n",
      "epoch 366: (0.6923, 0.6996470099667774, 0.6739)\n",
      "epoch 367: (0.6897, 0.7186995619091537, 0.6234)\n",
      "epoch 368: (0.69255, 0.6998028432084674, 0.6744)\n",
      "epoch 369: (0.6901, 0.7192112546125461, 0.6237)\n",
      "epoch 370: (0.6926, 0.6997510889856876, 0.6747)\n",
      "epoch 371: (0.69025, 0.7194601453454839, 0.6237)\n",
      "epoch 372: (0.6929, 0.7000622277535781, 0.675)\n",
      "epoch 373: (0.69055, 0.71985692857967, 0.6239)\n",
      "epoch 374: (0.69315, 0.7001761840605244, 0.6756)\n",
      "epoch 375: (0.69075, 0.7201384881708021, 0.624)\n",
      "epoch 376: (0.6933, 0.700269374222959, 0.6759)\n",
      "epoch 377: (0.6912, 0.7205814490078449, 0.6246)\n",
      "epoch 378: (0.69355, 0.7005491658895451, 0.6761)\n",
      "epoch 379: (0.69155, 0.7209087763810402, 0.6251)\n",
      "epoch 380: (0.6937, 0.7006837961044343, 0.6763)\n",
      "epoch 381: (0.6916, 0.7209409594095941, 0.6252)\n",
      "epoch 382: (0.69335, 0.7001760016564862, 0.6763)\n",
      "epoch 383: (0.69155, 0.7209087763810402, 0.6251)\n",
      "epoch 384: (0.6936, 0.7004555808656037, 0.6765)\n",
      "epoch 385: (0.69185, 0.7212037357315808, 0.6255)\n",
      "epoch 386: (0.6939, 0.700807787903894, 0.6767)\n",
      "epoch 387: (0.69215, 0.7214475048980062, 0.626)\n",
      "epoch 388: (0.6943, 0.7012637248808784, 0.677)\n",
      "epoch 389: (0.69225, 0.7215627521032615, 0.6261)\n",
      "epoch 390: (0.6944, 0.7013256006628004, 0.6772)\n",
      "epoch 391: (0.6925, 0.721927599723311, 0.6262)\n",
      "epoch 392: (0.69435, 0.701128014074304, 0.6775)\n",
      "epoch 393: (0.6925, 0.721927599723311, 0.6262)\n",
      "epoch 394: (0.69465, 0.7013551256853212, 0.678)\n",
      "epoch 395: (0.6927, 0.7220557732196359, 0.6266)\n",
      "epoch 396: (0.6948, 0.7015311400786262, 0.6781)\n",
      "epoch 397: (0.6929, 0.7223374827109267, 0.6267)\n",
      "epoch 398: (0.6949, 0.7017180707927966, 0.678)\n",
      "epoch 399: (0.6929, 0.7223887479824763, 0.6266)\n",
      "epoch 0: (0.50945, 0.5071978063828166, 0.6659)\n",
      "epoch 1: (0.5226, 0.5206770356816103, 0.5691)\n",
      "epoch 2: (0.527, 0.523709167544784, 0.5964)\n",
      "epoch 3: (0.52805, 0.5259074535882516, 0.5694)\n",
      "epoch 4: (0.53135, 0.5307624374448042, 0.5409)\n",
      "epoch 5: (0.53595, 0.5340145709149399, 0.5644)\n",
      "epoch 6: (0.5362, 0.5370825650481459, 0.5243)\n",
      "epoch 7: (0.54385, 0.5397299990939567, 0.5957)\n",
      "epoch 8: (0.54585, 0.5425443073211469, 0.5847)\n",
      "epoch 9: (0.54855, 0.5440362811791383, 0.5998)\n",
      "epoch 10: (0.54785, 0.5455064194008559, 0.5736)\n",
      "epoch 11: (0.5455, 0.5436827956989247, 0.5663)\n",
      "epoch 12: (0.5506, 0.5515170026471187, 0.5417)\n",
      "epoch 13: (0.5513, 0.5541596283783784, 0.5249)\n",
      "epoch 14: (0.5523, 0.5526686807653575, 0.5488)\n",
      "epoch 15: (0.5511, 0.5510183706070287, 0.5519)\n",
      "epoch 16: (0.5544, 0.5584443489471422, 0.5198)\n",
      "epoch 17: (0.55355, 0.5557058150421305, 0.5342)\n",
      "epoch 18: (0.5563, 0.5572969672297985, 0.5476)\n",
      "epoch 19: (0.55395, 0.5520300896904233, 0.5724)\n",
      "epoch 20: (0.55585, 0.5549434333497295, 0.5641)\n",
      "epoch 21: (0.5567, 0.5551020408163265, 0.5712)\n",
      "epoch 22: (0.55605, 0.555031909671085, 0.5653)\n",
      "epoch 23: (0.55925, 0.560502399673236, 0.5489)\n",
      "epoch 24: (0.5607, 0.5597323361543003, 0.5688)\n",
      "epoch 25: (0.56155, 0.5630570638254278, 0.5496)\n",
      "epoch 26: (0.56465, 0.5637134128313788, 0.572)\n",
      "epoch 27: (0.56705, 0.5652808879369098, 0.5806)\n",
      "epoch 28: (0.56615, 0.5638451886883505, 0.5842)\n",
      "epoch 29: (0.56715, 0.568695652173913, 0.5559)\n",
      "epoch 30: (0.5651, 0.5627893518518519, 0.5835)\n",
      "epoch 31: (0.5652, 0.5652652652652652, 0.5647)\n",
      "epoch 32: (0.5643, 0.5616018394328416, 0.5862)\n",
      "epoch 33: (0.5651, 0.5637610186092067, 0.5756)\n",
      "epoch 34: (0.56415, 0.5600599194831944, 0.5982)\n",
      "epoch 35: (0.56405, 0.5589507593189139, 0.6073)\n",
      "epoch 36: (0.5663, 0.562160135008438, 0.5996)\n",
      "epoch 37: (0.5668, 0.5632096896290689, 0.5952)\n",
      "epoch 38: (0.57045, 0.5693610318007286, 0.5783)\n",
      "epoch 39: (0.5723, 0.5702897141746063, 0.5866)\n",
      "epoch 40: (0.57055, 0.5669799677204975, 0.5972)\n",
      "epoch 41: (0.57225, 0.5683344367729122, 0.6009)\n",
      "epoch 42: (0.574, 0.5710172744721689, 0.595)\n",
      "epoch 43: (0.5769, 0.5757934161245811, 0.5842)\n",
      "epoch 44: (0.5757, 0.5711733734486649, 0.6075)\n",
      "epoch 45: (0.57775, 0.5767749580329812, 0.5841)\n",
      "epoch 46: (0.57945, 0.5801634547472505, 0.575)\n",
      "epoch 47: (0.57655, 0.5733026907976635, 0.5987)\n",
      "epoch 48: (0.57905, 0.5778280988480851, 0.5869)\n",
      "epoch 49: (0.58085, 0.58072890664004, 0.5816)\n",
      "epoch 50: (0.58005, 0.5773355231378611, 0.5976)\n",
      "epoch 51: (0.5852, 0.5890468227424749, 0.5636)\n",
      "epoch 52: (0.5883, 0.592791088692728, 0.5641)\n",
      "epoch 53: (0.58785, 0.5875785066294487, 0.5894)\n",
      "epoch 54: (0.58965, 0.5902002213502364, 0.5866)\n",
      "epoch 55: (0.59165, 0.5908055087684534, 0.5963)\n",
      "epoch 56: (0.59395, 0.5986558857502888, 0.5701)\n",
      "epoch 57: (0.59525, 0.5936486087896962, 0.6038)\n",
      "epoch 58: (0.59555, 0.5978294256168731, 0.5839)\n",
      "epoch 59: (0.5958, 0.6024379811804962, 0.5634)\n",
      "epoch 60: (0.59725, 0.5983813859382904, 0.5915)\n",
      "epoch 61: (0.59965, 0.6040513730813407, 0.5785)\n",
      "epoch 62: (0.5983, 0.5981821813823411, 0.5989)\n",
      "epoch 63: (0.5992, 0.5970455879475641, 0.6103)\n",
      "epoch 64: (0.60005, 0.5995225305878842, 0.6027)\n",
      "epoch 65: (0.60125, 0.6063438714420755, 0.5773)\n",
      "epoch 66: (0.60175, 0.6022715850839281, 0.5992)\n",
      "epoch 67: (0.6023, 0.6107622347336509, 0.5641)\n",
      "epoch 68: (0.60095, 0.6030417474737164, 0.5908)\n",
      "epoch 69: (0.6047, 0.6085199004975125, 0.5871)\n",
      "epoch 70: (0.605, 0.6124437781109445, 0.5719)\n",
      "epoch 71: (0.60725, 0.6106240330067045, 0.592)\n",
      "epoch 72: (0.609, 0.6206553021917202, 0.5607)\n",
      "epoch 73: (0.60925, 0.6132476417539131, 0.5916)\n",
      "epoch 74: (0.6115, 0.6249159758010306, 0.5578)\n",
      "epoch 75: (0.6121, 0.6211629917855599, 0.5747)\n",
      "epoch 76: (0.61175, 0.6170034551355879, 0.5893)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 77: (0.6124, 0.6228952547561776, 0.5697)\n",
      "epoch 78: (0.61325, 0.6165003600452629, 0.5993)\n",
      "epoch 79: (0.61455, 0.6208715838345468, 0.5884)\n",
      "epoch 80: (0.61525, 0.6261907368882076, 0.5719)\n",
      "epoch 81: (0.6161, 0.6286284068247285, 0.5674)\n",
      "epoch 82: (0.61655, 0.620365589176908, 0.6007)\n",
      "epoch 83: (0.61755, 0.6258161190195869, 0.5847)\n",
      "epoch 84: (0.6169, 0.628858024691358, 0.5705)\n",
      "epoch 85: (0.61665, 0.6196042243412283, 0.6043)\n",
      "epoch 86: (0.61675, 0.613846903949293, 0.6295)\n",
      "epoch 87: (0.62135, 0.6301619650327148, 0.5875)\n",
      "epoch 88: (0.6198, 0.6244804655029094, 0.601)\n",
      "epoch 89: (0.6196, 0.6182285488335311, 0.6254)\n",
      "epoch 90: (0.6201, 0.6244043919618811, 0.6028)\n",
      "epoch 91: (0.62215, 0.6290271469314461, 0.5955)\n",
      "epoch 92: (0.621, 0.6303036829636012, 0.5853)\n",
      "epoch 93: (0.6204, 0.620375924815037, 0.6205)\n",
      "epoch 94: (0.6238, 0.6314783347493628, 0.5946)\n",
      "epoch 95: (0.62515, 0.6401612722589316, 0.5716)\n",
      "epoch 96: (0.6264, 0.6340971780182474, 0.5977)\n",
      "epoch 97: (0.6248, 0.6244763614602035, 0.6261)\n",
      "epoch 98: (0.62635, 0.6357872111767867, 0.5916)\n",
      "epoch 99: (0.6248, 0.6253767329716697, 0.6225)\n",
      "epoch 100: (0.6268, 0.6351236146632566, 0.596)\n",
      "epoch 101: (0.6265, 0.6329619508093336, 0.6022)\n",
      "epoch 102: (0.628, 0.6372801372801373, 0.5942)\n",
      "epoch 103: (0.62765, 0.628640532097148, 0.6238)\n",
      "epoch 104: (0.6311, 0.640725633319021, 0.5969)\n",
      "epoch 105: (0.63175, 0.639344262295082, 0.6045)\n",
      "epoch 106: (0.63095, 0.647019198383294, 0.5763)\n",
      "epoch 107: (0.63355, 0.6408903892815698, 0.6075)\n",
      "epoch 108: (0.632, 0.631578947368421, 0.6336)\n",
      "epoch 109: (0.6345, 0.6423280423280423, 0.607)\n",
      "epoch 110: (0.63485, 0.6354051611607591, 0.6328)\n",
      "epoch 111: (0.6367, 0.6386972402597403, 0.6295)\n",
      "epoch 112: (0.6365, 0.6461769115442278, 0.6034)\n",
      "epoch 113: (0.63595, 0.636537109571156, 0.6338)\n",
      "epoch 114: (0.63735, 0.6478949068590503, 0.6017)\n",
      "epoch 115: (0.6348, 0.6351242983159583, 0.6336)\n",
      "epoch 116: (0.63735, 0.6501913613996719, 0.5946)\n",
      "epoch 117: (0.6342, 0.636299004671948, 0.6265)\n",
      "epoch 118: (0.6373, 0.6482721382289417, 0.6003)\n",
      "epoch 119: (0.635, 0.6375585897697167, 0.6257)\n",
      "epoch 120: (0.63885, 0.6513681456448273, 0.5975)\n",
      "epoch 121: (0.638, 0.6393657846899616, 0.6331)\n",
      "epoch 122: (0.64105, 0.6505175541564401, 0.6096)\n",
      "epoch 123: (0.6386, 0.6574642126789366, 0.5787)\n",
      "epoch 124: (0.64055, 0.6485572349645915, 0.6136)\n",
      "epoch 125: (0.64115, 0.6426766400485192, 0.6358)\n",
      "epoch 126: (0.6417, 0.6570257092198581, 0.5929)\n",
      "epoch 127: (0.6414, 0.6444626072742133, 0.6308)\n",
      "epoch 128: (0.64305, 0.656116992251446, 0.6012)\n",
      "epoch 129: (0.64315, 0.6462355705383593, 0.6326)\n",
      "epoch 130: (0.64285, 0.6530590378227794, 0.6095)\n",
      "epoch 131: (0.64505, 0.6502019260639951, 0.6279)\n",
      "epoch 132: (0.64345, 0.6595129545201823, 0.5931)\n",
      "epoch 133: (0.64565, 0.6521148825065274, 0.6244)\n",
      "epoch 134: (0.6447, 0.662256111235703, 0.5906)\n",
      "epoch 135: (0.6447, 0.6476229340950826, 0.6348)\n",
      "epoch 136: (0.6454, 0.6593599298553267, 0.6016)\n",
      "epoch 137: (0.6446, 0.6505936263278483, 0.6247)\n",
      "epoch 138: (0.64425, 0.6622062296188013, 0.5889)\n",
      "epoch 139: (0.64455, 0.6557818730466645, 0.6085)\n",
      "epoch 140: (0.6463, 0.6544552364864865, 0.6199)\n",
      "epoch 141: (0.64545, 0.6583215413083705, 0.6048)\n",
      "epoch 142: (0.6457, 0.6536271615352172, 0.6199)\n",
      "epoch 143: (0.64495, 0.6606450182866009, 0.5961)\n",
      "epoch 144: (0.64835, 0.6532699659055687, 0.6323)\n",
      "epoch 145: (0.6453, 0.6614803289619916, 0.5952)\n",
      "epoch 146: (0.6492, 0.6540049545829892, 0.6336)\n",
      "epoch 147: (0.6468, 0.6644633654492493, 0.5931)\n",
      "epoch 148: (0.6495, 0.6585702163767501, 0.6209)\n",
      "epoch 149: (0.64745, 0.6679193713700035, 0.5865)\n",
      "epoch 150: (0.6496, 0.6581061086451068, 0.6227)\n",
      "epoch 151: (0.6489, 0.664494034467521, 0.6015)\n",
      "epoch 152: (0.64945, 0.6593793324090861, 0.6183)\n",
      "epoch 153: (0.6486, 0.6508017048914146, 0.6413)\n",
      "epoch 154: (0.6487, 0.6646368467670505, 0.6003)\n",
      "epoch 155: (0.64985, 0.6537711646998461, 0.6371)\n",
      "epoch 156: (0.65065, 0.6634479765650428, 0.6115)\n",
      "epoch 157: (0.6502, 0.6544314209335801, 0.6365)\n",
      "epoch 158: (0.65015, 0.6586706118567051, 0.6233)\n",
      "epoch 159: (0.65135, 0.67374583859488, 0.5869)\n",
      "epoch 160: (0.65185, 0.6591885941922634, 0.6288)\n",
      "epoch 161: (0.65185, 0.6744399770246985, 0.5871)\n",
      "epoch 162: (0.6525, 0.6608989238235915, 0.6264)\n",
      "epoch 163: (0.65235, 0.6703186137506987, 0.5996)\n",
      "epoch 164: (0.6532, 0.6601505331381978, 0.6315)\n",
      "epoch 165: (0.65265, 0.6707685423425439, 0.5996)\n",
      "epoch 166: (0.6547, 0.6604771784232365, 0.6367)\n",
      "epoch 167: (0.65445, 0.6742637932979804, 0.5976)\n",
      "epoch 168: (0.65475, 0.6609799230209091, 0.6354)\n",
      "epoch 169: (0.65455, 0.6727780883174959, 0.6018)\n",
      "epoch 170: (0.65395, 0.663342175066313, 0.6252)\n",
      "epoch 171: (0.6551, 0.6738009861048857, 0.6013)\n",
      "epoch 172: (0.6551, 0.658848832445719, 0.6433)\n",
      "epoch 173: (0.6549, 0.671729490022173, 0.6059)\n",
      "epoch 174: (0.6566, 0.6605495181464015, 0.6443)\n",
      "epoch 175: (0.65475, 0.6704107477150094, 0.6088)\n",
      "epoch 176: (0.65675, 0.6651216685979142, 0.6314)\n",
      "epoch 177: (0.657, 0.6778029445073612, 0.5985)\n",
      "epoch 178: (0.6585, 0.66472666805238, 0.6396)\n",
      "epoch 179: (0.6586, 0.677484333034915, 0.6054)\n",
      "epoch 180: (0.6596, 0.6639276910435498, 0.6464)\n",
      "epoch 181: (0.65945, 0.679016503873358, 0.6048)\n",
      "epoch 182: (0.6594, 0.6642283123840923, 0.6447)\n",
      "epoch 183: (0.6598, 0.6725701943844492, 0.6228)\n",
      "epoch 184: (0.66005, 0.6729335494327391, 0.6228)\n",
      "epoch 185: (0.6598, 0.6641331142152835, 0.6466)\n",
      "epoch 186: (0.6601, 0.6764770723104057, 0.6137)\n",
      "epoch 187: (0.66175, 0.6670453371888877, 0.6459)\n",
      "epoch 188: (0.66075, 0.6806788805215241, 0.6056)\n",
      "epoch 189: (0.66085, 0.6726414081785983, 0.6267)\n",
      "epoch 190: (0.6616, 0.6865189289012004, 0.5948)\n",
      "epoch 191: (0.6618, 0.6695305951383068, 0.639)\n",
      "epoch 192: (0.6627, 0.6888785697701416, 0.5934)\n",
      "epoch 193: (0.66325, 0.6716433603196299, 0.6388)\n",
      "epoch 194: (0.66275, 0.6828035493653825, 0.6079)\n",
      "epoch 195: (0.66375, 0.6705551505051557, 0.6438)\n",
      "epoch 196: (0.6632, 0.6857500569087184, 0.6025)\n",
      "epoch 197: (0.66365, 0.6720277514979501, 0.6393)\n",
      "epoch 198: (0.66285, 0.6848677488931775, 0.6033)\n",
      "epoch 199: (0.665, 0.6711263223397635, 0.6471)\n",
      "epoch 200: (0.66425, 0.68607680978815, 0.6056)\n",
      "epoch 201: (0.665, 0.6726663876098786, 0.6428)\n",
      "epoch 202: (0.6648, 0.6889474891080027, 0.6009)\n",
      "epoch 203: (0.66625, 0.6769935058021931, 0.6359)\n",
      "epoch 204: (0.6638, 0.6875429356537669, 0.6005)\n",
      "epoch 205: (0.66515, 0.6751882889572505, 0.6365)\n",
      "epoch 206: (0.666, 0.6893248175182481, 0.6044)\n",
      "epoch 207: (0.6676, 0.6780705482362941, 0.6382)\n",
      "epoch 208: (0.6669, 0.6903512773722628, 0.6053)\n",
      "epoch 209: (0.66845, 0.6792593380866234, 0.6383)\n",
      "epoch 210: (0.66815, 0.6939222696344136, 0.6017)\n",
      "epoch 211: (0.66945, 0.680285136716672, 0.6394)\n",
      "epoch 212: (0.66805, 0.6914227132930858, 0.607)\n",
      "epoch 213: (0.66855, 0.6817642618354363, 0.6322)\n",
      "epoch 214: (0.66945, 0.6878811398159441, 0.6204)\n",
      "epoch 215: (0.66975, 0.6830583414213307, 0.6334)\n",
      "epoch 216: (0.66935, 0.6946775491435797, 0.6043)\n",
      "epoch 217: (0.66955, 0.6843135123382976, 0.6295)\n",
      "epoch 218: (0.672, 0.6812052254530131, 0.6466)\n",
      "epoch 219: (0.6692, 0.6996224634261444, 0.593)\n",
      "epoch 220: (0.6714, 0.6844994617868676, 0.6359)\n",
      "epoch 221: (0.6707, 0.6993227463801962, 0.5989)\n",
      "epoch 222: (0.67075, 0.6796422935297212, 0.646)\n",
      "epoch 223: (0.67215, 0.6975329890992542, 0.6079)\n",
      "epoch 224: (0.67265, 0.6820242488139167, 0.6469)\n",
      "epoch 225: (0.67315, 0.6955834180503784, 0.6158)\n",
      "epoch 226: (0.6744, 0.6862054238735853, 0.6427)\n",
      "epoch 227: (0.6722, 0.6975676916016521, 0.608)\n",
      "epoch 228: (0.6748, 0.6815160955347871, 0.6563)\n",
      "epoch 229: (0.67095, 0.6987097524119493, 0.6011)\n",
      "epoch 230: (0.67255, 0.6847628225720098, 0.6395)\n",
      "epoch 231: (0.6724, 0.6970736168267032, 0.6098)\n",
      "epoch 232: (0.674, 0.6814389989572471, 0.6535)\n",
      "epoch 233: (0.67325, 0.6982038668344583, 0.6103)\n",
      "epoch 234: (0.6755, 0.6863057324840764, 0.6465)\n",
      "epoch 235: (0.67365, 0.6983438035408338, 0.6114)\n",
      "epoch 236: (0.67485, 0.6812480563905877, 0.6572)\n",
      "epoch 237: (0.6744, 0.7004136980004597, 0.6095)\n",
      "epoch 238: (0.67485, 0.6834539922358619, 0.6514)\n",
      "epoch 239: (0.6754, 0.6963286321916274, 0.6221)\n",
      "epoch 240: (0.6752, 0.6832252666806108, 0.6533)\n",
      "epoch 241: (0.6759, 0.7055386772610422, 0.6038)\n",
      "epoch 242: (0.6759, 0.6875266524520256, 0.6449)\n",
      "epoch 243: (0.67575, 0.702313802233222, 0.6101)\n",
      "epoch 244: (0.67735, 0.6878110769882453, 0.6495)\n",
      "epoch 245: (0.677, 0.7049559981472904, 0.6088)\n",
      "epoch 246: (0.67925, 0.6900243824870137, 0.6509)\n",
      "epoch 247: (0.67655, 0.706418800420905, 0.6042)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 248: (0.6788, 0.6927970670692258, 0.6425)\n",
      "epoch 249: (0.67895, 0.703653123933083, 0.6183)\n",
      "epoch 250: (0.6779, 0.6859322742474916, 0.6563)\n",
      "epoch 251: (0.6772, 0.7041004376871689, 0.6113)\n",
      "epoch 252: (0.6786, 0.6880395872815329, 0.6535)\n",
      "epoch 253: (0.67795, 0.701917621695223, 0.6186)\n",
      "epoch 254: (0.67785, 0.6900309862164761, 0.6458)\n",
      "epoch 255: (0.6767, 0.7003855749603085, 0.6176)\n",
      "epoch 256: (0.68015, 0.687129947023995, 0.6615)\n",
      "epoch 257: (0.67895, 0.7060449050086356, 0.6132)\n",
      "epoch 258: (0.6813, 0.6886183936745734, 0.6619)\n",
      "epoch 259: (0.6795, 0.7067495968670813, 0.6136)\n",
      "epoch 260: (0.68275, 0.6914213889179847, 0.6601)\n",
      "epoch 261: (0.6793, 0.7087796925943176, 0.6087)\n",
      "epoch 262: (0.6832, 0.695684682760094, 0.6513)\n",
      "epoch 263: (0.67985, 0.7106218526759573, 0.6068)\n",
      "epoch 264: (0.68305, 0.6917356237561537, 0.6604)\n",
      "epoch 265: (0.6806, 0.7097073850441245, 0.6112)\n",
      "epoch 266: (0.6838, 0.6933108960875053, 0.6592)\n",
      "epoch 267: (0.68205, 0.7097108628038244, 0.6161)\n",
      "epoch 268: (0.6836, 0.6971649484536082, 0.6492)\n",
      "epoch 269: (0.6811, 0.710385687732342, 0.6115)\n",
      "epoch 270: (0.6829, 0.697260569456428, 0.6465)\n",
      "epoch 271: (0.6798, 0.7103416003743566, 0.6072)\n",
      "epoch 272: (0.6844, 0.691644148825608, 0.6655)\n",
      "epoch 273: (0.6793, 0.7086824953445066, 0.6089)\n",
      "epoch 274: (0.684, 0.6934805467928497, 0.6595)\n",
      "epoch 275: (0.6803, 0.7096024180423157, 0.6104)\n",
      "epoch 276: (0.6824, 0.6915966386554622, 0.6584)\n",
      "epoch 277: (0.6806, 0.7097560975609756, 0.6111)\n",
      "epoch 278: (0.6842, 0.6963752665245203, 0.6532)\n",
      "epoch 279: (0.6817, 0.7116728797763281, 0.6109)\n",
      "epoch 280: (0.68435, 0.6958877908830092, 0.6549)\n",
      "epoch 281: (0.6819, 0.7142016015073009, 0.6065)\n",
      "epoch 282: (0.6857, 0.6971337579617835, 0.6567)\n",
      "epoch 283: (0.6824, 0.7092703074804957, 0.6182)\n",
      "epoch 284: (0.68645, 0.696077400357556, 0.6619)\n",
      "epoch 285: (0.6828, 0.7156168907761264, 0.6067)\n",
      "epoch 286: (0.68775, 0.7011247991430102, 0.6545)\n",
      "epoch 287: (0.685, 0.7161720028043935, 0.6129)\n",
      "epoch 288: (0.68745, 0.6998187826457734, 0.6565)\n",
      "epoch 289: (0.68405, 0.7116246981717834, 0.6189)\n",
      "epoch 290: (0.6874, 0.6961482101737492, 0.6651)\n",
      "epoch 291: (0.68395, 0.7155243116578793, 0.6107)\n",
      "epoch 292: (0.6882, 0.6975230898404702, 0.6646)\n",
      "epoch 293: (0.6851, 0.7132979949297074, 0.619)\n",
      "epoch 294: (0.68745, 0.6936667011054861, 0.6714)\n",
      "epoch 295: (0.6849, 0.7158029878618114, 0.6133)\n",
      "epoch 296: (0.68845, 0.6987659529585487, 0.6625)\n",
      "epoch 297: (0.686, 0.7174929840972872, 0.6136)\n",
      "epoch 298: (0.68785, 0.701534170153417, 0.6539)\n",
      "epoch 299: (0.68615, 0.7153267784846732, 0.6184)\n",
      "epoch 300: (0.68985, 0.705532099166396, 0.6517)\n",
      "epoch 301: (0.6876, 0.71548357454629, 0.6229)\n",
      "epoch 302: (0.6905, 0.7000209995800084, 0.6667)\n",
      "epoch 303: (0.6866, 0.7183477650362743, 0.6139)\n",
      "epoch 304: (0.6905, 0.7020577004666949, 0.6619)\n",
      "epoch 305: (0.6879, 0.7174768518518518, 0.6199)\n",
      "epoch 306: (0.69245, 0.7045816944828319, 0.6628)\n",
      "epoch 307: (0.68755, 0.7179546775130738, 0.6178)\n",
      "epoch 308: (0.6912, 0.6999163529903806, 0.6694)\n",
      "epoch 309: (0.6878, 0.7184737087017218, 0.6176)\n",
      "epoch 310: (0.6925, 0.7016129032258065, 0.6699)\n",
      "epoch 311: (0.6899, 0.7208139534883721, 0.6199)\n",
      "epoch 312: (0.69215, 0.7034840622683469, 0.6643)\n",
      "epoch 313: (0.69035, 0.7225014611338398, 0.6181)\n",
      "epoch 314: (0.6937, 0.7035947025436199, 0.6694)\n",
      "epoch 315: (0.6889, 0.7193960511033681, 0.6194)\n",
      "epoch 316: (0.6949, 0.7042548731922029, 0.672)\n",
      "epoch 317: (0.6898, 0.7221441947565543, 0.617)\n",
      "epoch 318: (0.69355, 0.702648937284054, 0.6711)\n",
      "epoch 319: (0.69135, 0.719463241197385, 0.6273)\n",
      "epoch 320: (0.6923, 0.6994813278008298, 0.6743)\n",
      "epoch 321: (0.6904, 0.7203703703703703, 0.6224)\n",
      "epoch 322: (0.69285, 0.7019583202429573, 0.6703)\n",
      "epoch 323: (0.6897, 0.7210440456769984, 0.6188)\n",
      "epoch 324: (0.6935, 0.7013527575442248, 0.674)\n",
      "epoch 325: (0.69125, 0.7207155222158107, 0.6245)\n",
      "epoch 326: (0.69505, 0.7043050172829161, 0.6724)\n",
      "epoch 327: (0.6903, 0.7221055088702147, 0.6187)\n",
      "epoch 328: (0.6948, 0.7041500733598827, 0.6719)\n",
      "epoch 329: (0.6914, 0.7226099092812281, 0.6213)\n",
      "epoch 330: (0.6955, 0.7082002129925452, 0.665)\n",
      "epoch 331: (0.6926, 0.7202149554081866, 0.6299)\n",
      "epoch 332: (0.6957, 0.7026299440878029, 0.6786)\n",
      "epoch 333: (0.69095, 0.7230463730872562, 0.619)\n",
      "epoch 334: (0.69535, 0.7044479330193616, 0.6731)\n",
      "epoch 335: (0.6932, 0.724808005585292, 0.6229)\n",
      "epoch 336: (0.6961, 0.7069875448596158, 0.6698)\n",
      "epoch 337: (0.692, 0.7226861517049409, 0.6231)\n",
      "epoch 338: (0.695, 0.708377858516777, 0.6629)\n",
      "epoch 339: (0.6931, 0.7207866453235765, 0.6304)\n",
      "epoch 340: (0.6938, 0.7132951793968743, 0.6481)\n",
      "epoch 341: (0.69385, 0.7142225660293955, 0.6463)\n",
      "epoch 342: (0.6957, 0.7043224055126331, 0.6746)\n",
      "epoch 343: (0.69235, 0.7258954785672342, 0.6181)\n",
      "epoch 344: (0.69695, 0.7066414856783129, 0.6735)\n",
      "epoch 345: (0.6934, 0.7235838150289018, 0.6259)\n",
      "epoch 346: (0.69685, 0.7087265401336019, 0.6684)\n",
      "epoch 347: (0.69445, 0.719941183124081, 0.6365)\n",
      "epoch 348: (0.6978, 0.7059987502603624, 0.6779)\n",
      "epoch 349: (0.69415, 0.7260449412038654, 0.6236)\n",
      "epoch 350: (0.69805, 0.7091120261851969, 0.6716)\n",
      "epoch 351: (0.6945, 0.7259526022304833, 0.6249)\n",
      "epoch 352: (0.69785, 0.7069777173344493, 0.6758)\n",
      "epoch 353: (0.69385, 0.7274433884782353, 0.62)\n",
      "epoch 354: (0.69905, 0.7082330787739304, 0.677)\n",
      "epoch 355: (0.6938, 0.7229636447307869, 0.6284)\n",
      "epoch 356: (0.6998, 0.7084724540901502, 0.679)\n",
      "epoch 357: (0.69615, 0.7276314262504352, 0.627)\n",
      "epoch 358: (0.69785, 0.7085925144965736, 0.6721)\n",
      "epoch 359: (0.6959, 0.7267361111111111, 0.6279)\n",
      "epoch 360: (0.6988, 0.7082111436950147, 0.6762)\n",
      "epoch 361: (0.69675, 0.72891215823153, 0.6265)\n",
      "epoch 362: (0.7008, 0.7095595908996034, 0.6799)\n",
      "epoch 363: (0.69765, 0.7325567713848689, 0.6226)\n",
      "epoch 364: (0.7006, 0.71173738653156, 0.6743)\n",
      "epoch 365: (0.69685, 0.7326557144545562, 0.6199)\n",
      "epoch 366: (0.6998, 0.7125531914893617, 0.6698)\n",
      "epoch 367: (0.69665, 0.7326392996569265, 0.6193)\n",
      "epoch 368: (0.7007, 0.7120667793744717, 0.6739)\n",
      "epoch 369: (0.6957, 0.7295331925873798, 0.622)\n",
      "epoch 370: (0.7002, 0.7113597972972973, 0.6738)\n",
      "epoch 371: (0.69785, 0.7288606130711394, 0.6301)\n",
      "epoch 372: (0.69965, 0.7073854783421627, 0.681)\n",
      "epoch 373: (0.698, 0.7299651567944251, 0.6285)\n",
      "epoch 374: (0.6982, 0.7109408258833546, 0.668)\n",
      "epoch 375: (0.6973, 0.729578775890156, 0.627)\n",
      "epoch 376: (0.7006, 0.7099644128113879, 0.6783)\n",
      "epoch 377: (0.69925, 0.7331772966647162, 0.6265)\n",
      "epoch 378: (0.70025, 0.7107672876539312, 0.6753)\n",
      "epoch 379: (0.6995, 0.7320307048150733, 0.6294)\n",
      "epoch 380: (0.70135, 0.7089776855215361, 0.6831)\n",
      "epoch 381: (0.69875, 0.7284220204574187, 0.6338)\n",
      "epoch 382: (0.7012, 0.7096270056261721, 0.6811)\n",
      "epoch 383: (0.6988, 0.7298265895953757, 0.6313)\n",
      "epoch 384: (0.70195, 0.7162437091765713, 0.6689)\n",
      "epoch 385: (0.6988, 0.7357685009487666, 0.6204)\n",
      "epoch 386: (0.703, 0.7166488794023479, 0.6715)\n",
      "epoch 387: (0.69815, 0.7297924156326104, 0.6293)\n",
      "epoch 388: (0.70185, 0.7097142857142857, 0.6831)\n",
      "epoch 389: (0.6981, 0.7297077922077922, 0.6293)\n",
      "epoch 390: (0.70235, 0.707389566465102, 0.6902)\n",
      "epoch 391: (0.69905, 0.7298233460339453, 0.6321)\n",
      "epoch 392: (0.70315, 0.70980068160694, 0.6873)\n",
      "epoch 393: (0.69945, 0.731568559154766, 0.6301)\n",
      "epoch 394: (0.70265, 0.7137883743010867, 0.6766)\n",
      "epoch 395: (0.69905, 0.7368233194527067, 0.6193)\n",
      "epoch 396: (0.70095, 0.7127580730545262, 0.6732)\n",
      "epoch 397: (0.69895, 0.7301862779127618, 0.6311)\n",
      "epoch 398: (0.70395, 0.7125143273939772, 0.6838)\n",
      "epoch 399: (0.6988, 0.7308943089430894, 0.6293)\n",
      "epoch 0: (0.5, 0.5, 1.0)\n",
      "epoch 1: (0.5, 0.5, 1.0)\n",
      "epoch 2: (0.5, 0.5, 1.0)\n",
      "epoch 3: (0.52225, 0.5124852701868582, 0.9133)\n",
      "epoch 4: (0.55625, 0.5580675131619697, 0.5406)\n",
      "epoch 5: (0.5556, 0.5644861980978891, 0.4867)\n",
      "epoch 6: (0.5558, 0.572429906542056, 0.441)\n",
      "epoch 7: (0.56015, 0.5563044088739119, 0.5943)\n",
      "epoch 8: (0.56755, 0.578264395782644, 0.4991)\n",
      "epoch 9: (0.5601, 0.5539400466702566, 0.6172)\n",
      "epoch 10: (0.5749, 0.5900890064950686, 0.4906)\n",
      "epoch 11: (0.5676, 0.5603248259860789, 0.6279)\n",
      "epoch 12: (0.58085, 0.600547195622435, 0.4829)\n",
      "epoch 13: (0.57415, 0.5645175324110328, 0.6488)\n",
      "epoch 14: (0.5877, 0.612291933418694, 0.4782)\n",
      "epoch 15: (0.5813, 0.5697973901098901, 0.6637)\n",
      "epoch 16: (0.5918, 0.6183599793708097, 0.4796)\n",
      "epoch 17: (0.58375, 0.5706810701325006, 0.6762)\n",
      "epoch 18: (0.5987, 0.6268637532133676, 0.4877)\n",
      "epoch 19: (0.587, 0.5721034311287917, 0.6903)\n",
      "epoch 20: (0.6022, 0.6296296296296297, 0.4964)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21: (0.59095, 0.5749855717701376, 0.6974)\n",
      "epoch 22: (0.6049, 0.6325499115491534, 0.5006)\n",
      "epoch 23: (0.5928, 0.5750202101859337, 0.7113)\n",
      "epoch 24: (0.607, 0.6325569871159564, 0.5106)\n",
      "epoch 25: (0.5976, 0.5786969843573617, 0.7177)\n",
      "epoch 26: (0.60885, 0.6350663854076188, 0.5118)\n",
      "epoch 27: (0.60035, 0.5801581595974119, 0.7263)\n",
      "epoch 28: (0.61215, 0.6377933407052463, 0.5191)\n",
      "epoch 29: (0.6015, 0.5806707995549197, 0.7306)\n",
      "epoch 30: (0.6129, 0.637750122010737, 0.5227)\n",
      "epoch 31: (0.6031, 0.581040716868417, 0.7392)\n",
      "epoch 32: (0.61595, 0.6411098941219423, 0.5268)\n",
      "epoch 33: (0.6044, 0.5814225549836219, 0.7455)\n",
      "epoch 34: (0.61845, 0.644292849311731, 0.5289)\n",
      "epoch 35: (0.60625, 0.582537093140682, 0.7499)\n",
      "epoch 36: (0.6199, 0.6458282656288008, 0.531)\n",
      "epoch 37: (0.6064, 0.5821494749845584, 0.754)\n",
      "epoch 38: (0.6234, 0.6510403916768666, 0.5319)\n",
      "epoch 39: (0.60695, 0.582250249942321, 0.7571)\n",
      "epoch 40: (0.62495, 0.652471018913972, 0.5347)\n",
      "epoch 41: (0.6105, 0.584934665641814, 0.761)\n",
      "epoch 42: (0.62565, 0.654760438477645, 0.5316)\n",
      "epoch 43: (0.6111, 0.5853302611367127, 0.7621)\n",
      "epoch 44: (0.6262, 0.6559565002471577, 0.5308)\n",
      "epoch 45: (0.6132, 0.5869431643625193, 0.7642)\n",
      "epoch 46: (0.6277, 0.6583188693280436, 0.531)\n",
      "epoch 47: (0.61265, 0.5863152248869818, 0.7652)\n",
      "epoch 48: (0.62935, 0.6601857585139319, 0.5331)\n",
      "epoch 49: (0.6124, 0.585985312117503, 0.766)\n",
      "epoch 50: (0.63005, 0.6618543870566272, 0.5318)\n",
      "epoch 51: (0.6122, 0.5857011915673694, 0.7668)\n",
      "epoch 52: (0.63015, 0.6622211142963979, 0.5313)\n",
      "epoch 53: (0.61245, 0.5858069439145365, 0.7677)\n",
      "epoch 54: (0.6308, 0.664321608040201, 0.5288)\n",
      "epoch 55: (0.6126, 0.5862306631949763, 0.7655)\n",
      "epoch 56: (0.63115, 0.6654472057524915, 0.5275)\n",
      "epoch 57: (0.6134, 0.5868965517241379, 0.7659)\n",
      "epoch 58: (0.63165, 0.6671321569125301, 0.5255)\n",
      "epoch 59: (0.6136, 0.5871834228702993, 0.7651)\n",
      "epoch 60: (0.6325, 0.6695240532241555, 0.5233)\n",
      "epoch 61: (0.6137, 0.5873674504379899, 0.7644)\n",
      "epoch 62: (0.63295, 0.6710848024707244, 0.5215)\n",
      "epoch 63: (0.6143, 0.5878960319901568, 0.7645)\n",
      "epoch 64: (0.63295, 0.6717478361968738, 0.52)\n",
      "epoch 65: (0.61435, 0.5879412443282319, 0.7645)\n",
      "epoch 66: (0.6328, 0.6723332468206592, 0.5181)\n",
      "epoch 67: (0.61455, 0.5882579551583327, 0.7635)\n",
      "epoch 68: (0.63255, 0.6734720586310692, 0.5146)\n",
      "epoch 69: (0.6153, 0.5890072564458855, 0.763)\n",
      "epoch 70: (0.6321, 0.6738615425111871, 0.512)\n",
      "epoch 71: (0.6159, 0.5895810789921162, 0.7628)\n",
      "epoch 72: (0.63155, 0.6745852687458527, 0.5083)\n",
      "epoch 73: (0.61645, 0.5902083817491672, 0.7619)\n",
      "epoch 74: (0.6317, 0.6749933563646027, 0.508)\n",
      "epoch 75: (0.6167, 0.590297121634169, 0.7629)\n",
      "epoch 76: (0.63155, 0.6761279957156245, 0.505)\n",
      "epoch 77: (0.61665, 0.5903353209943468, 0.7623)\n",
      "epoch 78: (0.63115, 0.6761111857123674, 0.5035)\n",
      "epoch 79: (0.6166, 0.5903455757012243, 0.7619)\n",
      "epoch 80: (0.63115, 0.6763479897808256, 0.503)\n",
      "epoch 81: (0.61665, 0.5904333669276688, 0.7616)\n",
      "epoch 82: (0.63095, 0.6763161437996499, 0.5023)\n",
      "epoch 83: (0.6168, 0.5906128782001552, 0.7613)\n",
      "epoch 84: (0.6312, 0.6771058315334774, 0.5016)\n",
      "epoch 85: (0.6169, 0.5907045313469894, 0.7613)\n",
      "epoch 86: (0.63115, 0.677205783002297, 0.5012)\n",
      "epoch 87: (0.61685, 0.5906587012180929, 0.7613)\n",
      "epoch 88: (0.6311, 0.6770664505672609, 0.5013)\n",
      "epoch 89: (0.61685, 0.5906305747304739, 0.7615)\n",
      "epoch 90: (0.6311, 0.677497969130788, 0.5004)\n",
      "epoch 91: (0.61685, 0.5906305747304739, 0.7615)\n",
      "epoch 92: (0.63135, 0.6781016949152542, 0.5001)\n",
      "epoch 93: (0.6168, 0.5905988209742475, 0.7614)\n",
      "epoch 94: (0.63145, 0.6784792939579091, 0.4997)\n",
      "epoch 95: (0.617, 0.5907398790134947, 0.7617)\n",
      "epoch 96: (0.63125, 0.678256145592829, 0.4994)\n",
      "epoch 97: (0.6169, 0.5906482630272953, 0.7617)\n",
      "epoch 98: (0.6315, 0.6789602612955906, 0.4989)\n",
      "epoch 99: (0.6169, 0.5906623235613464, 0.7616)\n",
      "epoch 100: (0.6315, 0.6792529989094874, 0.4983)\n",
      "epoch 101: (0.61685, 0.5906587012180929, 0.7613)\n",
      "epoch 102: (0.6315, 0.6794976794976795, 0.4978)\n",
      "epoch 103: (0.61685, 0.5907009236978965, 0.761)\n",
      "epoch 104: (0.63125, 0.6794258373205742, 0.497)\n",
      "epoch 105: (0.6168, 0.5906832298136646, 0.7608)\n",
      "epoch 106: (0.63125, 0.6796714579055442, 0.4965)\n",
      "epoch 107: (0.6166, 0.5904857985410523, 0.7609)\n",
      "epoch 108: (0.6313, 0.6802086192698326, 0.4956)\n",
      "epoch 109: (0.61655, 0.590454016298021, 0.7608)\n",
      "epoch 110: (0.63185, 0.6809386578839028, 0.4962)\n",
      "epoch 111: (0.6165, 0.5903380893300249, 0.7613)\n",
      "epoch 112: (0.6316, 0.6808189062929376, 0.4955)\n",
      "epoch 113: (0.61665, 0.5904333669276688, 0.7616)\n",
      "epoch 114: (0.6317, 0.6811056105610561, 0.4953)\n",
      "epoch 115: (0.61675, 0.590524928277894, 0.7616)\n",
      "epoch 116: (0.6316, 0.6811674008810573, 0.4948)\n",
      "epoch 117: (0.6168, 0.590584768109198, 0.7615)\n",
      "epoch 118: (0.6314, 0.6811913954771097, 0.494)\n",
      "epoch 119: (0.6167, 0.5905212534905367, 0.7613)\n",
      "epoch 120: (0.63155, 0.6816236366146624, 0.4937)\n",
      "epoch 121: (0.6167, 0.5905072126570498, 0.7614)\n",
      "epoch 122: (0.6315, 0.681881051175657, 0.493)\n",
      "epoch 123: (0.6167, 0.5905212534905367, 0.7613)\n",
      "epoch 124: (0.6314, 0.6819440598172252, 0.4925)\n",
      "epoch 125: (0.6168, 0.590626939788951, 0.7612)\n",
      "epoch 126: (0.6314, 0.6821963394342762, 0.492)\n",
      "epoch 127: (0.61665, 0.5904894887906291, 0.7612)\n",
      "epoch 128: (0.6315, 0.6823349972268441, 0.4921)\n",
      "epoch 129: (0.61665, 0.5904894887906291, 0.7612)\n",
      "epoch 130: (0.63155, 0.6824802330420308, 0.492)\n",
      "epoch 131: (0.61665, 0.5904894887906291, 0.7612)\n",
      "epoch 132: (0.63155, 0.682429621411732, 0.4921)\n",
      "epoch 133: (0.61665, 0.5904894887906291, 0.7612)\n",
      "epoch 134: (0.6314, 0.682246879334258, 0.4919)\n",
      "epoch 135: (0.61665, 0.5904894887906291, 0.7612)\n",
      "epoch 136: (0.63135, 0.6821522673692969, 0.4919)\n",
      "epoch 137: (0.61665, 0.5904894887906291, 0.7612)\n",
      "epoch 138: (0.63135, 0.6821522673692969, 0.4919)\n",
      "epoch 139: (0.6167, 0.5905212534905367, 0.7613)\n",
      "epoch 140: (0.63145, 0.6822909443905145, 0.492)\n",
      "epoch 141: (0.6167, 0.5905212534905367, 0.7613)\n",
      "epoch 142: (0.6314, 0.6823480432972523, 0.4917)\n",
      "epoch 143: (0.61665, 0.590475451795548, 0.7613)\n",
      "epoch 144: (0.63155, 0.682530872762592, 0.4919)\n",
      "epoch 145: (0.6166, 0.5904296572049015, 0.7613)\n",
      "epoch 146: (0.63125, 0.6822157434402333, 0.4914)\n",
      "epoch 147: (0.6166, 0.5904296572049015, 0.7613)\n",
      "epoch 148: (0.6312, 0.6821716189947237, 0.4913)\n",
      "epoch 149: (0.61665, 0.590475451795548, 0.7613)\n",
      "epoch 150: (0.6312, 0.6821716189947237, 0.4913)\n",
      "epoch 151: (0.61665, 0.590475451795548, 0.7613)\n",
      "epoch 152: (0.6312, 0.6821716189947237, 0.4913)\n",
      "epoch 153: (0.6166, 0.5904296572049015, 0.7613)\n",
      "epoch 154: (0.63125, 0.6822663518955701, 0.4913)\n",
      "epoch 155: (0.61665, 0.590475451795548, 0.7613)\n",
      "epoch 156: (0.63125, 0.6824690671486167, 0.4909)\n",
      "epoch 157: (0.61665, 0.5904894887906291, 0.7612)\n",
      "epoch 158: (0.6307, 0.6826439351593069, 0.4885)\n",
      "epoch 159: (0.6167, 0.5905212534905367, 0.7613)\n",
      "epoch 160: (0.63065, 0.6825485538633506, 0.4885)\n",
      "epoch 161: (0.61675, 0.5905530132630109, 0.7614)\n",
      "epoch 162: (0.6308, 0.6828859060402684, 0.4884)\n",
      "epoch 163: (0.61675, 0.5905530132630109, 0.7614)\n",
      "epoch 164: (0.6308, 0.6828347777467151, 0.4885)\n",
      "epoch 165: (0.61675, 0.5905530132630109, 0.7614)\n",
      "epoch 166: (0.6307, 0.6826439351593069, 0.4885)\n",
      "epoch 167: (0.61685, 0.5906305747304739, 0.7615)\n",
      "epoch 168: (0.6307, 0.6826949958065418, 0.4884)\n",
      "epoch 169: (0.6169, 0.5906763884579584, 0.7615)\n",
      "epoch 170: (0.6306, 0.6828107502799552, 0.4878)\n",
      "epoch 171: (0.61685, 0.5906305747304739, 0.7615)\n",
      "epoch 172: (0.6306, 0.6827595857822558, 0.4879)\n",
      "epoch 173: (0.61685, 0.5906305747304739, 0.7615)\n",
      "epoch 174: (0.6306, 0.6827595857822558, 0.4879)\n",
      "epoch 175: (0.6169, 0.5906763884579584, 0.7615)\n",
      "epoch 176: (0.6306, 0.6827595857822558, 0.4879)\n",
      "epoch 177: (0.6169, 0.5906763884579584, 0.7615)\n",
      "epoch 178: (0.6306, 0.6827595857822558, 0.4879)\n",
      "epoch 179: (0.61685, 0.5906305747304739, 0.7615)\n",
      "epoch 180: (0.63055, 0.6828175325584652, 0.4876)\n",
      "epoch 181: (0.6169, 0.5906763884579584, 0.7615)\n",
      "epoch 182: (0.63045, 0.6826263474730505, 0.4876)\n",
      "epoch 183: (0.617, 0.5907539559416692, 0.7616)\n",
      "epoch 184: (0.6305, 0.6826196473551638, 0.4878)\n",
      "epoch 185: (0.617, 0.5907398790134947, 0.7617)\n",
      "epoch 186: (0.63055, 0.682664054848188, 0.4879)\n",
      "epoch 187: (0.6171, 0.59083152342538, 0.7617)\n",
      "epoch 188: (0.63055, 0.6826129528605399, 0.488)\n",
      "epoch 189: (0.6171, 0.59083152342538, 0.7617)\n",
      "epoch 190: (0.6306, 0.6826573426573427, 0.4881)\n",
      "epoch 191: (0.6171, 0.59083152342538, 0.7617)\n",
      "epoch 192: (0.63055, 0.6825618794574185, 0.4881)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 193: (0.6171, 0.59083152342538, 0.7617)\n",
      "epoch 194: (0.6307, 0.6827460850111857, 0.4883)\n",
      "epoch 195: (0.61715, 0.5908632591328628, 0.7618)\n",
      "epoch 196: (0.63075, 0.6828415606208922, 0.4883)\n",
      "epoch 197: (0.6171, 0.5908033498759305, 0.7619)\n",
      "epoch 198: (0.63075, 0.6828415606208922, 0.4883)\n",
      "epoch 199: (0.61725, 0.5908985192650593, 0.7622)\n",
      "epoch 200: (0.6307, 0.6828483491885842, 0.4881)\n",
      "epoch 201: (0.61725, 0.5908985192650593, 0.7622)\n",
      "epoch 202: (0.6306, 0.6827084499160604, 0.488)\n",
      "epoch 203: (0.61725, 0.5908985192650593, 0.7622)\n",
      "epoch 204: (0.6306, 0.6827084499160604, 0.488)\n",
      "epoch 205: (0.6172, 0.5908386296698186, 0.7623)\n",
      "epoch 206: (0.6306, 0.6827084499160604, 0.488)\n",
      "epoch 207: (0.61715, 0.5908069141926983, 0.7622)\n",
      "epoch 208: (0.63055, 0.682664054848188, 0.4879)\n",
      "epoch 209: (0.61725, 0.5908844275637547, 0.7623)\n",
      "epoch 210: (0.63065, 0.6828039736952568, 0.488)\n",
      "epoch 211: (0.6172, 0.5908386296698186, 0.7623)\n",
      "epoch 212: (0.6306, 0.6827084499160604, 0.488)\n",
      "epoch 213: (0.6172, 0.5908386296698186, 0.7623)\n",
      "epoch 214: (0.6306, 0.6828619434332119, 0.4877)\n",
      "epoch 215: (0.61725, 0.5908844275637547, 0.7623)\n",
      "epoch 216: (0.63045, 0.6826263474730505, 0.4876)\n",
      "epoch 217: (0.61725, 0.5908844275637547, 0.7623)\n",
      "epoch 218: (0.6306, 0.6827595857822558, 0.4879)\n",
      "epoch 219: (0.6173, 0.5909302325581396, 0.7623)\n",
      "epoch 220: (0.6306, 0.6827595857822558, 0.4879)\n",
      "epoch 221: (0.6173, 0.5909302325581396, 0.7623)\n",
      "epoch 222: (0.6305, 0.6826196473551638, 0.4878)\n",
      "epoch 223: (0.61735, 0.5909760446546244, 0.7623)\n",
      "epoch 224: (0.6306, 0.6828107502799552, 0.4878)\n",
      "epoch 225: (0.6173, 0.5909302325581396, 0.7623)\n",
      "epoch 226: (0.6306, 0.6827595857822558, 0.4879)\n",
      "epoch 227: (0.6173, 0.5909302325581396, 0.7623)\n",
      "epoch 228: (0.63065, 0.6828039736952568, 0.488)\n",
      "epoch 229: (0.6174, 0.5910218638548612, 0.7623)\n",
      "epoch 230: (0.6306, 0.6827595857822558, 0.4879)\n",
      "epoch 231: (0.6173, 0.5909302325581396, 0.7623)\n",
      "epoch 232: (0.63055, 0.682664054848188, 0.4879)\n",
      "epoch 233: (0.6173, 0.5909302325581396, 0.7623)\n",
      "epoch 234: (0.63065, 0.682752832563995, 0.4881)\n",
      "epoch 235: (0.6174, 0.5910218638548612, 0.7623)\n",
      "epoch 236: (0.6306, 0.6826573426573427, 0.4881)\n",
      "epoch 237: (0.61735, 0.5909760446546244, 0.7623)\n",
      "epoch 238: (0.6306, 0.6827084499160604, 0.488)\n",
      "epoch 239: (0.6174, 0.5910359801488834, 0.7622)\n",
      "epoch 240: (0.63035, 0.6824863502729945, 0.4875)\n",
      "epoch 241: (0.61755, 0.5911735050027147, 0.7622)\n",
      "epoch 242: (0.63025, 0.6823974233300658, 0.4873)\n",
      "epoch 243: (0.6176, 0.5912193608439342, 0.7622)\n",
      "epoch 244: (0.6303, 0.6824418930271633, 0.4874)\n",
      "epoch 245: (0.61755, 0.5911735050027147, 0.7622)\n",
      "epoch 246: (0.6301, 0.6822128851540616, 0.4871)\n",
      "epoch 247: (0.61755, 0.5911735050027147, 0.7622)\n",
      "epoch 248: (0.6301, 0.6822128851540616, 0.4871)\n",
      "epoch 249: (0.6176, 0.5912193608439342, 0.7622)\n",
      "epoch 250: (0.6302, 0.682301876225147, 0.4873)\n",
      "epoch 251: (0.61755, 0.5911735050027147, 0.7622)\n",
      "epoch 252: (0.6301, 0.6821108622620381, 0.4873)\n",
      "epoch 253: (0.61755, 0.5911735050027147, 0.7622)\n",
      "epoch 254: (0.6301, 0.6821618594231308, 0.4872)\n",
      "epoch 255: (0.6176, 0.5912193608439342, 0.7622)\n",
      "epoch 256: (0.6302, 0.6822508398656215, 0.4874)\n",
      "epoch 257: (0.61765, 0.59126522379955, 0.7622)\n",
      "epoch 258: (0.6303, 0.6823397705009796, 0.4876)\n",
      "epoch 259: (0.61755, 0.5911876502986579, 0.7621)\n",
      "epoch 260: (0.6302, 0.6822508398656215, 0.4874)\n",
      "epoch 261: (0.6175, 0.591155934833204, 0.762)\n",
      "epoch 262: (0.63015, 0.6821553533939818, 0.4874)\n",
      "epoch 263: (0.61755, 0.5912017999844829, 0.762)\n",
      "epoch 264: (0.63025, 0.6822953114065781, 0.4875)\n",
      "epoch 265: (0.61755, 0.5911876502986579, 0.7621)\n",
      "epoch 266: (0.63025, 0.6823974233300658, 0.4873)\n",
      "epoch 267: (0.61755, 0.5911876502986579, 0.7621)\n",
      "epoch 268: (0.63035, 0.6824352694191742, 0.4876)\n",
      "epoch 269: (0.6176, 0.591233514352211, 0.7621)\n",
      "epoch 270: (0.63035, 0.6824863502729945, 0.4875)\n",
      "epoch 271: (0.61755, 0.5911876502986579, 0.7621)\n",
      "epoch 272: (0.63025, 0.6823463530729386, 0.4874)\n",
      "epoch 273: (0.61755, 0.5911876502986579, 0.7621)\n",
      "epoch 274: (0.6303, 0.6824418930271633, 0.4874)\n",
      "epoch 275: (0.61765, 0.5912510664701777, 0.7623)\n",
      "epoch 276: (0.63035, 0.6824863502729945, 0.4875)\n",
      "epoch 277: (0.6177, 0.591296928327645, 0.7623)\n",
      "epoch 278: (0.63035, 0.6824863502729945, 0.4875)\n",
      "epoch 279: (0.61765, 0.5912510664701777, 0.7623)\n",
      "epoch 280: (0.63035, 0.6824863502729945, 0.4875)\n",
      "epoch 281: (0.61765, 0.5912510664701777, 0.7623)\n",
      "epoch 282: (0.63025, 0.6823463530729386, 0.4874)\n",
      "epoch 283: (0.61765, 0.5912510664701777, 0.7623)\n",
      "epoch 284: (0.6303, 0.6824418930271633, 0.4874)\n",
      "epoch 285: (0.6176, 0.5912052117263844, 0.7623)\n",
      "epoch 286: (0.6303, 0.6824418930271633, 0.4874)\n",
      "epoch 287: (0.6176, 0.5912052117263844, 0.7623)\n",
      "epoch 288: (0.63035, 0.6824863502729945, 0.4875)\n",
      "epoch 289: (0.61765, 0.5912510664701777, 0.7623)\n",
      "epoch 290: (0.6303, 0.6824418930271633, 0.4874)\n",
      "epoch 291: (0.61765, 0.5912510664701777, 0.7623)\n",
      "epoch 292: (0.63045, 0.6825752274317705, 0.4877)\n",
      "epoch 293: (0.6176, 0.5912052117263844, 0.7623)\n",
      "epoch 294: (0.6303, 0.6823908174692049, 0.4875)\n",
      "epoch 295: (0.61755, 0.5911593640946103, 0.7623)\n",
      "epoch 296: (0.6303, 0.6824418930271633, 0.4874)\n",
      "epoch 297: (0.6176, 0.5912052117263844, 0.7623)\n",
      "epoch 298: (0.6304, 0.6825819098291795, 0.4875)\n",
      "epoch 299: (0.61755, 0.5911593640946103, 0.7623)\n",
      "epoch 300: (0.6303, 0.6824929971988796, 0.4873)\n",
      "epoch 301: (0.6176, 0.5912052117263844, 0.7623)\n",
      "epoch 302: (0.63035, 0.6825885978428351, 0.4873)\n",
      "epoch 303: (0.6175, 0.5910993952550783, 0.7624)\n",
      "epoch 304: (0.6302, 0.6824551569506726, 0.487)\n",
      "epoch 305: (0.6175, 0.5910993952550783, 0.7624)\n",
      "epoch 306: (0.6303, 0.6825952914798207, 0.4871)\n",
      "epoch 307: (0.6174, 0.5910077519379845, 0.7624)\n",
      "epoch 308: (0.63025, 0.6824996497127644, 0.4871)\n",
      "epoch 309: (0.61745, 0.5910394543058678, 0.7625)\n",
      "epoch 310: (0.6303, 0.6825441300084057, 0.4872)\n",
      "epoch 311: (0.6177, 0.5912686104218362, 0.7625)\n",
      "epoch 312: (0.6303, 0.6825441300084057, 0.4872)\n",
      "epoch 313: (0.6176, 0.5911769266552954, 0.7625)\n",
      "epoch 314: (0.6302, 0.6823529411764706, 0.4872)\n",
      "epoch 315: (0.61765, 0.5912227649841049, 0.7625)\n",
      "epoch 316: (0.63025, 0.682448522201989, 0.4872)\n",
      "epoch 317: (0.61765, 0.5912369135323768, 0.7624)\n",
      "epoch 318: (0.6304, 0.6825819098291795, 0.4875)\n",
      "epoch 319: (0.6176, 0.5911910669975186, 0.7624)\n",
      "epoch 320: (0.63035, 0.6825374597395323, 0.4874)\n",
      "epoch 321: (0.6176, 0.5911910669975186, 0.7624)\n",
      "epoch 322: (0.63045, 0.6825752274317705, 0.4877)\n",
      "epoch 323: (0.61755, 0.5911452275723036, 0.7624)\n",
      "epoch 324: (0.63045, 0.6825752274317705, 0.4877)\n",
      "epoch 325: (0.6176, 0.5911910669975186, 0.7624)\n",
      "epoch 326: (0.63035, 0.6824352694191742, 0.4876)\n",
      "epoch 327: (0.61765, 0.5912369135323768, 0.7624)\n",
      "epoch 328: (0.63035, 0.6824863502729945, 0.4875)\n",
      "epoch 329: (0.61765, 0.5912369135323768, 0.7624)\n",
      "epoch 330: (0.63035, 0.6824863502729945, 0.4875)\n",
      "epoch 331: (0.6177, 0.5912827671785327, 0.7624)\n",
      "epoch 332: (0.63035, 0.6824863502729945, 0.4875)\n",
      "epoch 333: (0.61765, 0.5912369135323768, 0.7624)\n",
      "epoch 334: (0.6304, 0.6825307950727884, 0.4876)\n",
      "epoch 335: (0.61765, 0.5912369135323768, 0.7624)\n",
      "epoch 336: (0.63035, 0.6824352694191742, 0.4876)\n",
      "epoch 337: (0.61765, 0.5912369135323768, 0.7624)\n",
      "epoch 338: (0.6304, 0.6825307950727884, 0.4876)\n",
      "epoch 339: (0.6176, 0.5911910669975186, 0.7624)\n",
      "epoch 340: (0.6304, 0.6824797089280716, 0.4877)\n",
      "epoch 341: (0.6176, 0.5911910669975186, 0.7624)\n",
      "epoch 342: (0.6304, 0.6825307950727884, 0.4876)\n",
      "epoch 343: (0.6176, 0.5911910669975186, 0.7624)\n",
      "epoch 344: (0.6305, 0.6826707726763718, 0.4877)\n",
      "epoch 345: (0.6176, 0.5911910669975186, 0.7624)\n",
      "epoch 346: (0.6305, 0.6826707726763718, 0.4877)\n",
      "epoch 347: (0.61755, 0.5911452275723036, 0.7624)\n",
      "epoch 348: (0.63055, 0.6827663446731065, 0.4877)\n",
      "epoch 349: (0.6176, 0.5911910669975186, 0.7624)\n",
      "epoch 350: (0.63055, 0.6827663446731065, 0.4877)\n",
      "epoch 351: (0.61765, 0.5912369135323768, 0.7624)\n",
      "epoch 352: (0.6306, 0.6827595857822558, 0.4879)\n",
      "epoch 353: (0.6176, 0.5911910669975186, 0.7624)\n",
      "epoch 354: (0.6308, 0.68303946263644, 0.4881)\n",
      "epoch 355: (0.61755, 0.5911452275723036, 0.7624)\n",
      "epoch 356: (0.63075, 0.6829951014695591, 0.488)\n",
      "epoch 357: (0.61755, 0.5911452275723036, 0.7624)\n",
      "epoch 358: (0.63075, 0.6829951014695591, 0.488)\n",
      "epoch 359: (0.6176, 0.5911910669975186, 0.7624)\n",
      "epoch 360: (0.6308, 0.68303946263644, 0.4881)\n",
      "epoch 361: (0.61755, 0.5911452275723036, 0.7624)\n",
      "epoch 362: (0.63075, 0.6829951014695591, 0.488)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 363: (0.61755, 0.5911452275723036, 0.7624)\n",
      "epoch 364: (0.63075, 0.6829951014695591, 0.488)\n",
      "epoch 365: (0.6176, 0.5911910669975186, 0.7624)\n",
      "epoch 366: (0.63085, 0.6831350594821554, 0.4881)\n",
      "epoch 367: (0.61755, 0.5911452275723036, 0.7624)\n",
      "epoch 368: (0.63085, 0.6831350594821554, 0.4881)\n",
      "epoch 369: (0.61765, 0.5912510664701777, 0.7623)\n",
      "epoch 370: (0.63055, 0.6828687491245272, 0.4875)\n",
      "epoch 371: (0.61765, 0.5912510664701777, 0.7623)\n",
      "epoch 372: (0.6304, 0.6827354260089686, 0.4872)\n",
      "epoch 373: (0.61765, 0.59126522379955, 0.7622)\n",
      "epoch 374: (0.6303, 0.6825952914798207, 0.4871)\n",
      "epoch 375: (0.61765, 0.59126522379955, 0.7622)\n",
      "epoch 376: (0.63035, 0.6826397646069777, 0.4872)\n",
      "epoch 377: (0.6177, 0.591311093871218, 0.7622)\n",
      "epoch 378: (0.6303, 0.6825952914798207, 0.4871)\n",
      "epoch 379: (0.61775, 0.5913711492201443, 0.7621)\n",
      "epoch 380: (0.63015, 0.6824617972802467, 0.4868)\n",
      "epoch 381: (0.61775, 0.5913711492201443, 0.7621)\n",
      "epoch 382: (0.6301, 0.6823150224215246, 0.4869)\n",
      "epoch 383: (0.6177, 0.5913252638112974, 0.7621)\n",
      "epoch 384: (0.6301, 0.6824172742568705, 0.4867)\n",
      "epoch 385: (0.61775, 0.5913711492201443, 0.7621)\n",
      "epoch 386: (0.6301, 0.6824172742568705, 0.4867)\n",
      "epoch 387: (0.6177, 0.591296928327645, 0.7623)\n",
      "epoch 388: (0.6302, 0.6825063078216989, 0.4869)\n",
      "epoch 389: (0.61765, 0.5912510664701777, 0.7623)\n",
      "epoch 390: (0.6302, 0.6825063078216989, 0.4869)\n",
      "epoch 391: (0.61765, 0.5912510664701777, 0.7623)\n",
      "epoch 392: (0.63015, 0.682615406201768, 0.4865)\n",
      "epoch 393: (0.6177, 0.591296928327645, 0.7623)\n",
      "epoch 394: (0.6301, 0.6825196408529742, 0.4865)\n",
      "epoch 395: (0.61765, 0.5912510664701777, 0.7623)\n",
      "epoch 396: (0.63005, 0.6824750947102568, 0.4864)\n",
      "epoch 397: (0.61765, 0.5912510664701777, 0.7623)\n",
      "epoch 398: (0.6301, 0.6825196408529742, 0.4865)\n",
      "epoch 399: (0.61775, 0.5913427973004421, 0.7623)\n",
      "epoch 0: (0.49955, 0.23529411764705882, 0.0004)\n",
      "epoch 1: (0.53905, 0.5541684006103482, 0.3995)\n",
      "epoch 2: (0.55015, 0.5356052538161165, 0.7544)\n",
      "epoch 3: (0.55305, 0.5637696838562327, 0.469)\n",
      "epoch 4: (0.5569, 0.5422985429675885, 0.7295)\n",
      "epoch 5: (0.56195, 0.5681293302540416, 0.5166)\n",
      "epoch 6: (0.5568, 0.542426053181954, 0.7262)\n",
      "epoch 7: (0.56675, 0.5796254324227603, 0.4859)\n",
      "epoch 8: (0.56545, 0.5515070433619265, 0.7008)\n",
      "epoch 9: (0.57475, 0.5829725829725829, 0.5252)\n",
      "epoch 10: (0.5664, 0.5512266625520753, 0.7145)\n",
      "epoch 11: (0.5801, 0.5934219734079776, 0.5088)\n",
      "epoch 12: (0.5687, 0.5527487714987716, 0.7199)\n",
      "epoch 13: (0.58025, 0.6112883095271113, 0.4408)\n",
      "epoch 14: (0.5801, 0.5625390381011868, 0.7205)\n",
      "epoch 15: (0.58475, 0.6184817559066126, 0.4424)\n",
      "epoch 16: (0.57915, 0.5600759013282732, 0.7379)\n",
      "epoch 17: (0.5901, 0.6282014797951053, 0.4415)\n",
      "epoch 18: (0.58795, 0.5688993341167254, 0.7262)\n",
      "epoch 19: (0.5943, 0.6257668711656442, 0.4692)\n",
      "epoch 20: (0.5967, 0.5785540211210398, 0.7122)\n",
      "epoch 21: (0.5977, 0.6353560543086728, 0.4586)\n",
      "epoch 22: (0.59295, 0.5717705196509922, 0.7405)\n",
      "epoch 23: (0.6027, 0.6318356867779205, 0.4922)\n",
      "epoch 24: (0.59775, 0.5756989080771315, 0.7434)\n",
      "epoch 25: (0.60595, 0.6495412844036698, 0.4602)\n",
      "epoch 26: (0.59385, 0.569751021924935, 0.7666)\n",
      "epoch 27: (0.6064, 0.65748963883955, 0.4442)\n",
      "epoch 28: (0.5967, 0.5722936602870813, 0.7655)\n",
      "epoch 29: (0.60985, 0.657989357112038, 0.4575)\n",
      "epoch 30: (0.5966, 0.5716298383508824, 0.7709)\n",
      "epoch 31: (0.6117, 0.6699117736537876, 0.4404)\n",
      "epoch 32: (0.59785, 0.5723475046210721, 0.7741)\n",
      "epoch 33: (0.6138, 0.6696481812760883, 0.4492)\n",
      "epoch 34: (0.60295, 0.5763101326810466, 0.7775)\n",
      "epoch 35: (0.61195, 0.6696983477338184, 0.4418)\n",
      "epoch 36: (0.60405, 0.5771140591417773, 0.7787)\n",
      "epoch 37: (0.6108, 0.6746532156368222, 0.428)\n",
      "epoch 38: (0.6041, 0.5751841687129857, 0.7964)\n",
      "epoch 39: (0.61445, 0.6669097272859851, 0.4573)\n",
      "epoch 40: (0.6075, 0.578204568601775, 0.7948)\n",
      "epoch 41: (0.6168, 0.6731396383041802, 0.4541)\n",
      "epoch 42: (0.6089, 0.5804283604135894, 0.7859)\n",
      "epoch 43: (0.6159, 0.6720605700712589, 0.4527)\n",
      "epoch 44: (0.6077, 0.5793078055964654, 0.7867)\n",
      "epoch 45: (0.61765, 0.6738070616043729, 0.4561)\n",
      "epoch 46: (0.6097, 0.582655213984328, 0.7733)\n",
      "epoch 47: (0.6181, 0.6778614457831326, 0.4501)\n",
      "epoch 48: (0.6082, 0.5785994479151533, 0.7965)\n",
      "epoch 49: (0.61945, 0.6784700433288511, 0.4541)\n",
      "epoch 50: (0.6085, 0.579185520361991, 0.7936)\n",
      "epoch 51: (0.62075, 0.6818798011748758, 0.4527)\n",
      "epoch 52: (0.6075, 0.5772714203565268, 0.8031)\n",
      "epoch 53: (0.6203, 0.6770158917010006, 0.4601)\n",
      "epoch 54: (0.6116, 0.5808930124673819, 0.8014)\n",
      "epoch 55: (0.62045, 0.6757111597374179, 0.4632)\n",
      "epoch 56: (0.6123, 0.5820546543913488, 0.7966)\n",
      "epoch 57: (0.6201, 0.6760997067448681, 0.4611)\n",
      "epoch 58: (0.61545, 0.584263922341435, 0.8005)\n",
      "epoch 59: (0.6181, 0.6713580963435868, 0.4627)\n",
      "epoch 60: (0.61475, 0.5836919261906498, 0.8003)\n",
      "epoch 61: (0.6198, 0.6806393244873341, 0.4514)\n",
      "epoch 62: (0.61465, 0.5829294755877035, 0.8059)\n",
      "epoch 63: (0.6211, 0.6917960088691796, 0.4368)\n",
      "epoch 64: (0.61535, 0.583375496928081, 0.8071)\n",
      "epoch 65: (0.6199, 0.6894154818325434, 0.4364)\n",
      "epoch 66: (0.6157, 0.5838648883734415, 0.8055)\n",
      "epoch 67: (0.6211, 0.6981348167539267, 0.4267)\n",
      "epoch 68: (0.61715, 0.5852309930883958, 0.8044)\n",
      "epoch 69: (0.62215, 0.7008055235903338, 0.4263)\n",
      "epoch 70: (0.61945, 0.5895225961178145, 0.7866)\n",
      "epoch 71: (0.62205, 0.6949992011503435, 0.435)\n",
      "epoch 72: (0.6183, 0.5868703186958437, 0.7992)\n",
      "epoch 73: (0.62315, 0.6949501345575432, 0.439)\n",
      "epoch 74: (0.6183, 0.5867556468172485, 0.8001)\n",
      "epoch 75: (0.62235, 0.6971161591751248, 0.4327)\n",
      "epoch 76: (0.61895, 0.5864273777519436, 0.8071)\n",
      "epoch 77: (0.62175, 0.6961495086193008, 0.4321)\n",
      "epoch 78: (0.618, 0.5860936815992995, 0.8033)\n",
      "epoch 79: (0.6215, 0.6993110236220472, 0.4263)\n",
      "epoch 80: (0.6195, 0.5877643948296122, 0.8003)\n",
      "epoch 81: (0.6225, 0.6984769928710305, 0.4311)\n",
      "epoch 82: (0.62, 0.5872473462265523, 0.8077)\n",
      "epoch 83: (0.6218, 0.7058823529411765, 0.4176)\n",
      "epoch 84: (0.6197, 0.5869281045751634, 0.8082)\n",
      "epoch 85: (0.62485, 0.7051766639276911, 0.4291)\n",
      "epoch 86: (0.6198, 0.5876243417203043, 0.8034)\n",
      "epoch 87: (0.62545, 0.7098879036305838, 0.4243)\n",
      "epoch 88: (0.62025, 0.5870304697112253, 0.8111)\n",
      "epoch 89: (0.62595, 0.7102320146886997, 0.4255)\n",
      "epoch 90: (0.6213, 0.5892830855292213, 0.8006)\n",
      "epoch 91: (0.62525, 0.7123241227326665, 0.4202)\n",
      "epoch 92: (0.6208, 0.5883040935672514, 0.8048)\n",
      "epoch 93: (0.62615, 0.71007493755204, 0.4264)\n",
      "epoch 94: (0.6202, 0.5870131750398146, 0.8109)\n",
      "epoch 95: (0.62885, 0.7039088463364457, 0.4448)\n",
      "epoch 96: (0.62255, 0.5890172150795381, 0.8109)\n",
      "epoch 97: (0.62905, 0.7069103735770402, 0.4409)\n",
      "epoch 98: (0.6201, 0.5862911337835895, 0.816)\n",
      "epoch 99: (0.62735, 0.7091476432911809, 0.4318)\n",
      "epoch 100: (0.6229, 0.5901290701085362, 0.8047)\n",
      "epoch 101: (0.6242, 0.7077617932418869, 0.4231)\n",
      "epoch 102: (0.6243, 0.5919650784255697, 0.8001)\n",
      "epoch 103: (0.62875, 0.7189998299030448, 0.4227)\n",
      "epoch 104: (0.6225, 0.5901398086828551, 0.802)\n",
      "epoch 105: (0.62925, 0.7199251318700017, 0.4231)\n",
      "epoch 106: (0.6238, 0.5906428466832625, 0.8067)\n",
      "epoch 107: (0.6293, 0.7125246548323472, 0.4335)\n",
      "epoch 108: (0.6229, 0.5894598922696171, 0.8098)\n",
      "epoch 109: (0.62775, 0.7199173695988983, 0.4182)\n",
      "epoch 110: (0.62375, 0.5914161187855507, 0.8006)\n",
      "epoch 111: (0.62825, 0.7163826556436645, 0.4246)\n",
      "epoch 112: (0.61965, 0.5865962220453065, 0.8105)\n",
      "epoch 113: (0.6291, 0.7153102068045364, 0.4289)\n",
      "epoch 114: (0.62095, 0.587906097826877, 0.8089)\n",
      "epoch 115: (0.6306, 0.7198653198653199, 0.4276)\n",
      "epoch 116: (0.62345, 0.5910599690196946, 0.8013)\n",
      "epoch 117: (0.6285, 0.7252015422362426, 0.4138)\n",
      "epoch 118: (0.6221, 0.5897002644725242, 0.8027)\n",
      "epoch 119: (0.63005, 0.7262919784235253, 0.4174)\n",
      "epoch 120: (0.6233, 0.591428147708735, 0.7976)\n",
      "epoch 121: (0.6288, 0.720926243567753, 0.4203)\n",
      "epoch 122: (0.62585, 0.5940653262575678, 0.7948)\n",
      "epoch 123: (0.62855, 0.7128663686040735, 0.4305)\n",
      "epoch 124: (0.6236, 0.5913390481820869, 0.8002)\n",
      "epoch 125: (0.6307, 0.7179059686562187, 0.4306)\n",
      "epoch 126: (0.6218, 0.5885431811573132, 0.8096)\n",
      "epoch 127: (0.6295, 0.717063359034529, 0.4278)\n",
      "epoch 128: (0.62255, 0.5881845002518529, 0.8174)\n",
      "epoch 129: (0.62895, 0.7183742591024556, 0.4242)\n",
      "epoch 130: (0.6237, 0.5896376811594203, 0.8137)\n",
      "epoch 131: (0.6294, 0.7215753424657534, 0.4214)\n",
      "epoch 132: (0.6252, 0.5923985239852398, 0.8027)\n",
      "epoch 133: (0.62695, 0.7160115705291815, 0.4208)\n",
      "epoch 134: (0.6242, 0.5913772807533844, 0.8038)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 135: (0.6283, 0.716211661611055, 0.425)\n",
      "epoch 136: (0.6254, 0.5925734534179832, 0.8027)\n",
      "epoch 137: (0.6282, 0.7147403685092127, 0.4267)\n",
      "epoch 138: (0.62475, 0.5928406638386544, 0.7966)\n",
      "epoch 139: (0.62885, 0.7199180747567845, 0.4218)\n",
      "epoch 140: (0.62445, 0.5920692461344973, 0.8003)\n",
      "epoch 141: (0.63005, 0.7200135340889866, 0.4256)\n",
      "epoch 142: (0.62745, 0.5944144010667457, 0.8024)\n",
      "epoch 143: (0.6288, 0.7205479452054795, 0.4208)\n",
      "epoch 144: (0.6272, 0.5946146980065456, 0.7994)\n",
      "epoch 145: (0.6303, 0.7180388219544847, 0.4291)\n",
      "epoch 146: (0.626, 0.5922941693524758, 0.8086)\n",
      "epoch 147: (0.62975, 0.7187658067779464, 0.4263)\n",
      "epoch 148: (0.62725, 0.5939183703594361, 0.8047)\n",
      "epoch 149: (0.6305, 0.7167774086378738, 0.4315)\n",
      "epoch 150: (0.62695, 0.5925089266195438, 0.8131)\n",
      "epoch 151: (0.62985, 0.7137448559670782, 0.4336)\n",
      "epoch 152: (0.62765, 0.5942971116200044, 0.8045)\n",
      "epoch 153: (0.62795, 0.7249077166461593, 0.4124)\n",
      "epoch 154: (0.6298, 0.5969235364396654, 0.7994)\n",
      "epoch 155: (0.6279, 0.7186324786324786, 0.4204)\n",
      "epoch 156: (0.62795, 0.5949113567242786, 0.802)\n",
      "epoch 157: (0.63005, 0.7218147705952584, 0.4232)\n",
      "epoch 158: (0.62695, 0.5943235010030463, 0.7999)\n",
      "epoch 159: (0.62955, 0.7194646789767914, 0.4247)\n",
      "epoch 160: (0.62765, 0.5954107182898573, 0.7966)\n",
      "epoch 161: (0.6295, 0.7230451257320014, 0.4198)\n",
      "epoch 162: (0.6277, 0.595440956651719, 0.7967)\n",
      "epoch 163: (0.63105, 0.7185988323603002, 0.4308)\n",
      "epoch 164: (0.62925, 0.5967078189300411, 0.7975)\n",
      "epoch 165: (0.62905, 0.7192118226600985, 0.4234)\n",
      "epoch 166: (0.62865, 0.594408160270052, 0.81)\n",
      "epoch 167: (0.6298, 0.7159015302727878, 0.4304)\n",
      "epoch 168: (0.6296, 0.5952801058667843, 0.8097)\n",
      "epoch 169: (0.62825, 0.7203986939336656, 0.4192)\n",
      "epoch 170: (0.62995, 0.596252129471891, 0.805)\n",
      "epoch 171: (0.6282, 0.7176570458404075, 0.4227)\n",
      "epoch 172: (0.62795, 0.5935648994515539, 0.8117)\n",
      "epoch 173: (0.6292, 0.7211571379664499, 0.4213)\n",
      "epoch 174: (0.62785, 0.5940557639961745, 0.8075)\n",
      "epoch 175: (0.62905, 0.7170001681520094, 0.4264)\n",
      "epoch 176: (0.6296, 0.5951262477980035, 0.8108)\n",
      "epoch 177: (0.6311, 0.7242559014710913, 0.4234)\n",
      "epoch 178: (0.6271, 0.5932228252897169, 0.8088)\n",
      "epoch 179: (0.6334, 0.7184736324926302, 0.4387)\n",
      "epoch 180: (0.6279, 0.5936996336996337, 0.8104)\n",
      "epoch 181: (0.63165, 0.7233248515691264, 0.4264)\n",
      "epoch 182: (0.6278, 0.5951884403396395, 0.7991)\n",
      "epoch 183: (0.6311, 0.7251803503950532, 0.4222)\n",
      "epoch 184: (0.63005, 0.5984406933615926, 0.7906)\n",
      "epoch 185: (0.6313, 0.723984988058683, 0.4244)\n",
      "epoch 186: (0.62685, 0.5948411214953271, 0.7956)\n",
      "epoch 187: (0.6299, 0.7236570247933884, 0.4203)\n",
      "epoch 188: (0.62955, 0.5970339300426935, 0.7971)\n",
      "epoch 189: (0.6302, 0.7268292682926829, 0.4172)\n",
      "epoch 190: (0.62785, 0.5953748601268184, 0.7981)\n",
      "epoch 191: (0.63235, 0.7239045846726442, 0.4279)\n",
      "epoch 192: (0.62675, 0.5946389905174345, 0.7964)\n",
      "epoch 193: (0.63235, 0.7222502099076407, 0.4301)\n",
      "epoch 194: (0.6275, 0.5952203136669156, 0.797)\n",
      "epoch 195: (0.63355, 0.7229177098981806, 0.4331)\n",
      "epoch 196: (0.62625, 0.59309785414055, 0.8043)\n",
      "epoch 197: (0.6298, 0.7252690038181188, 0.4179)\n",
      "epoch 198: (0.62705, 0.5930837423987105, 0.8095)\n",
      "epoch 199: (0.63125, 0.7209224036357516, 0.4283)\n",
      "epoch 200: (0.626, 0.5920917994445256, 0.8101)\n",
      "epoch 201: (0.6319, 0.7266323024054983, 0.4229)\n",
      "epoch 202: (0.6245, 0.5903221125943122, 0.8137)\n",
      "epoch 203: (0.6322, 0.7201865423051299, 0.4324)\n",
      "epoch 204: (0.6264, 0.5920611798980335, 0.8129)\n",
      "epoch 205: (0.6297, 0.7272249474421864, 0.4151)\n",
      "epoch 206: (0.6281, 0.5943576900412493, 0.8069)\n",
      "epoch 207: (0.631, 0.7229407760381211, 0.4248)\n",
      "epoch 208: (0.62755, 0.5937109690691352, 0.8081)\n",
      "epoch 209: (0.63265, 0.723957453992909, 0.4288)\n",
      "epoch 210: (0.6309, 0.596264156493602, 0.8108)\n",
      "epoch 211: (0.63125, 0.7263321262286602, 0.4212)\n",
      "epoch 212: (0.62805, 0.5936106440529278, 0.812)\n",
      "epoch 213: (0.63115, 0.730128092647833, 0.4161)\n",
      "epoch 214: (0.62835, 0.5933522437995491, 0.8158)\n",
      "epoch 215: (0.6313, 0.7280305661688086, 0.4192)\n",
      "epoch 216: (0.6277, 0.5934983160052716, 0.8106)\n",
      "epoch 217: (0.63125, 0.7257093723129837, 0.422)\n",
      "epoch 218: (0.6274, 0.5920520231213873, 0.8194)\n",
      "epoch 219: (0.6287, 0.7303974221267454, 0.408)\n",
      "epoch 220: (0.6266, 0.5918589464518937, 0.8157)\n",
      "epoch 221: (0.63025, 0.724762726488352, 0.42)\n",
      "epoch 222: (0.62715, 0.5919311691128624, 0.8187)\n",
      "epoch 223: (0.63025, 0.7249179761699188, 0.4198)\n",
      "epoch 224: (0.6271, 0.5927466433158202, 0.8123)\n",
      "epoch 225: (0.6315, 0.7257898351648352, 0.4227)\n",
      "epoch 226: (0.62635, 0.5916177217025597, 0.8159)\n",
      "epoch 227: (0.632, 0.7241847826086957, 0.4264)\n",
      "epoch 228: (0.62875, 0.5950816040174286, 0.8058)\n",
      "epoch 229: (0.6291, 0.728333922886452, 0.4118)\n",
      "epoch 230: (0.62895, 0.5945173348970167, 0.8111)\n",
      "epoch 231: (0.6304, 0.7201958797703478, 0.4265)\n",
      "epoch 232: (0.62875, 0.5941499085923218, 0.8125)\n",
      "epoch 233: (0.63095, 0.7206402695871946, 0.4277)\n",
      "epoch 234: (0.62885, 0.594638266617701, 0.8096)\n",
      "epoch 235: (0.63025, 0.720949957591179, 0.425)\n",
      "epoch 236: (0.6299, 0.5955147058823529, 0.8099)\n",
      "epoch 237: (0.63135, 0.7248758774182503, 0.4234)\n",
      "epoch 238: (0.6273, 0.5924742118262386, 0.8156)\n",
      "epoch 239: (0.63265, 0.7232037691401649, 0.4298)\n",
      "epoch 240: (0.6281, 0.5942050301514928, 0.808)\n",
      "epoch 241: (0.63135, 0.729272124279979, 0.4178)\n",
      "epoch 242: (0.62845, 0.5953105290494918, 0.8023)\n",
      "epoch 243: (0.6314, 0.728125, 0.4194)\n",
      "epoch 244: (0.62985, 0.5958090459676825, 0.8075)\n",
      "epoch 245: (0.63095, 0.7303430079155673, 0.4152)\n",
      "epoch 246: (0.6326, 0.5994599459945995, 0.7992)\n",
      "epoch 247: (0.6314, 0.7252314021254713, 0.4231)\n",
      "epoch 248: (0.63185, 0.5985647006055169, 0.8007)\n",
      "epoch 249: (0.6301, 0.7261821974965229, 0.4177)\n",
      "epoch 250: (0.6319, 0.5980669144981413, 0.8044)\n",
      "epoch 251: (0.6318, 0.7286606523247745, 0.42)\n",
      "epoch 252: (0.6316, 0.598355754857997, 0.8006)\n",
      "epoch 253: (0.63115, 0.7273357600970706, 0.4196)\n",
      "epoch 254: (0.6317, 0.5996670198274557, 0.7924)\n",
      "epoch 255: (0.63055, 0.7315126795531123, 0.4125)\n",
      "epoch 256: (0.6295, 0.5970182798921186, 0.7969)\n",
      "epoch 257: (0.6337, 0.73227936066713, 0.4215)\n",
      "epoch 258: (0.63185, 0.5990385337639901, 0.7975)\n",
      "epoch 259: (0.63225, 0.7391933441852053, 0.4087)\n",
      "epoch 260: (0.6314, 0.5990502035278155, 0.7947)\n",
      "epoch 261: (0.6301, 0.7296152488528063, 0.4134)\n",
      "epoch 262: (0.6293, 0.5944623027469316, 0.8137)\n",
      "epoch 263: (0.63055, 0.7249698431845597, 0.4207)\n",
      "epoch 264: (0.63055, 0.5957883923985619, 0.812)\n",
      "epoch 265: (0.6308, 0.7307692307692307, 0.4142)\n",
      "epoch 266: (0.6317, 0.5970809376382131, 0.81)\n",
      "epoch 267: (0.6315, 0.7307827307827308, 0.4164)\n",
      "epoch 268: (0.6314, 0.5966176470588235, 0.8114)\n",
      "epoch 269: (0.633, 0.7291523087525844, 0.4232)\n",
      "epoch 270: (0.63095, 0.5960818842174774, 0.8124)\n",
      "epoch 271: (0.6322, 0.7297532151546751, 0.4199)\n",
      "epoch 272: (0.6322, 0.5991153096416254, 0.7991)\n",
      "epoch 273: (0.6324, 0.7329345531315975, 0.4166)\n",
      "epoch 274: (0.63015, 0.5963289171785953, 0.8057)\n",
      "epoch 275: (0.63315, 0.7279575415168635, 0.4252)\n",
      "epoch 276: (0.63155, 0.5980911192304824, 0.8021)\n",
      "epoch 277: (0.63175, 0.7315872736860608, 0.4162)\n",
      "epoch 278: (0.6332, 0.5991809381980641, 0.8047)\n",
      "epoch 279: (0.6317, 0.729282729805014, 0.4189)\n",
      "epoch 280: (0.63395, 0.6002844950213371, 0.8018)\n",
      "epoch 281: (0.63115, 0.7315092674315975, 0.4144)\n",
      "epoch 282: (0.63485, 0.6006568634768978, 0.8047)\n",
      "epoch 283: (0.6308, 0.7266897746967071, 0.4193)\n",
      "epoch 284: (0.63285, 0.5988393720705305, 0.8049)\n",
      "epoch 285: (0.63185, 0.7287870900572618, 0.42)\n",
      "epoch 286: (0.6327, 0.5980638486550399, 0.8093)\n",
      "epoch 287: (0.63165, 0.7225697379543533, 0.4274)\n",
      "epoch 288: (0.63215, 0.5980996214089526, 0.8057)\n",
      "epoch 289: (0.6313, 0.723679727427598, 0.4248)\n",
      "epoch 290: (0.6315, 0.5969049373618276, 0.81)\n",
      "epoch 291: (0.6309, 0.7246053534660261, 0.4223)\n",
      "epoch 292: (0.632, 0.5972877358490566, 0.8104)\n",
      "epoch 293: (0.6299, 0.7238111647139903, 0.4201)\n",
      "epoch 294: (0.63365, 0.5993015825841445, 0.8066)\n",
      "epoch 295: (0.62995, 0.7264331765115873, 0.4169)\n",
      "epoch 296: (0.63175, 0.5975853640471076, 0.8068)\n",
      "epoch 297: (0.62955, 0.7282819383259912, 0.4133)\n",
      "epoch 298: (0.6363, 0.6025583145221971, 0.8008)\n",
      "epoch 299: (0.6295, 0.7316636851520573, 0.409)\n",
      "epoch 300: (0.6341, 0.5993333333333334, 0.8091)\n",
      "epoch 301: (0.63085, 0.7286388257906692, 0.417)\n",
      "epoch 302: (0.6336, 0.5985832349468713, 0.8112)\n",
      "epoch 303: (0.63015, 0.724822940058732, 0.4196)\n",
      "epoch 304: (0.6338, 0.5990230905861457, 0.8094)\n",
      "epoch 305: (0.62955, 0.7299023957409051, 0.4113)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 306: (0.6341, 0.5988500663423264, 0.8124)\n",
      "epoch 307: (0.6314, 0.7316643159379408, 0.415)\n",
      "epoch 308: (0.63585, 0.6011014363325147, 0.8077)\n",
      "epoch 309: (0.63215, 0.7300261096605745, 0.4194)\n",
      "epoch 310: (0.63515, 0.6005056890012642, 0.8075)\n",
      "epoch 311: (0.6325, 0.7269612881123673, 0.4244)\n",
      "epoch 312: (0.63505, 0.6006708907938875, 0.8058)\n",
      "epoch 313: (0.6332, 0.7259158751696065, 0.428)\n",
      "epoch 314: (0.63425, 0.5999702137165835, 0.8057)\n",
      "epoch 315: (0.6333, 0.7272417320150018, 0.4266)\n",
      "epoch 316: (0.6343, 0.599777117384844, 0.8073)\n",
      "epoch 317: (0.63515, 0.7282553622698869, 0.4312)\n",
      "epoch 318: (0.63215, 0.5973050585376629, 0.8112)\n",
      "epoch 319: (0.63435, 0.723284028585674, 0.4352)\n",
      "epoch 320: (0.63495, 0.6001187031678908, 0.8089)\n",
      "epoch 321: (0.6324, 0.7203728362183754, 0.4328)\n",
      "epoch 322: (0.63505, 0.6005659393849132, 0.8065)\n",
      "epoch 323: (0.63165, 0.7244671781756181, 0.4249)\n",
      "epoch 324: (0.6315, 0.597364134458759, 0.8068)\n",
      "epoch 325: (0.63275, 0.7301890064158141, 0.4211)\n",
      "epoch 326: (0.6331, 0.5985925925925926, 0.8081)\n",
      "epoch 327: (0.6332, 0.7388809182209469, 0.412)\n",
      "epoch 328: (0.63175, 0.5965130759651308, 0.8143)\n",
      "epoch 329: (0.63275, 0.7313120752744381, 0.4197)\n",
      "epoch 330: (0.6325, 0.5978292971057295, 0.8097)\n",
      "epoch 331: (0.6319, 0.7342806394316164, 0.4134)\n",
      "epoch 332: (0.6328, 0.5988830975428145, 0.8043)\n",
      "epoch 333: (0.63225, 0.7363717605004468, 0.412)\n",
      "epoch 334: (0.63225, 0.5981738549476654, 0.8058)\n",
      "epoch 335: (0.63375, 0.7339513730977786, 0.4196)\n",
      "epoch 336: (0.6322, 0.5978824226269805, 0.8075)\n",
      "epoch 337: (0.6332, 0.7355021216407355, 0.416)\n",
      "epoch 338: (0.63205, 0.597662894756305, 0.8081)\n",
      "epoch 339: (0.6341, 0.7322480083131279, 0.4228)\n",
      "epoch 340: (0.63255, 0.5991621156579636, 0.8009)\n",
      "epoch 341: (0.6332, 0.7276144907723855, 0.4258)\n",
      "epoch 342: (0.63445, 0.6001788242306832, 0.8055)\n",
      "epoch 343: (0.6334, 0.7303176795580111, 0.423)\n",
      "epoch 344: (0.63425, 0.5990263332595707, 0.8121)\n",
      "epoch 345: (0.63355, 0.7333566311375153, 0.4197)\n",
      "epoch 346: (0.63545, 0.6011953679491968, 0.8047)\n",
      "epoch 347: (0.6326, 0.7313328681088626, 0.4192)\n",
      "epoch 348: (0.6354, 0.6015601560156015, 0.802)\n",
      "epoch 349: (0.6346, 0.7319889693209238, 0.4247)\n",
      "epoch 350: (0.63665, 0.6030154542027893, 0.7999)\n",
      "epoch 351: (0.6333, 0.733041958041958, 0.4193)\n",
      "epoch 352: (0.63455, 0.5999702801099636, 0.8075)\n",
      "epoch 353: (0.634, 0.731994459833795, 0.4228)\n",
      "epoch 354: (0.63435, 0.5992025400575943, 0.8115)\n",
      "epoch 355: (0.63385, 0.7316946512030466, 0.4227)\n",
      "epoch 356: (0.63335, 0.5983769826632239, 0.8111)\n",
      "epoch 357: (0.63445, 0.7275342697579963, 0.4299)\n",
      "epoch 358: (0.63285, 0.5986925191293366, 0.8059)\n",
      "epoch 359: (0.636, 0.732796987333105, 0.4281)\n",
      "epoch 360: (0.6327, 0.5982817360391053, 0.8078)\n",
      "epoch 361: (0.6338, 0.7328576400974591, 0.4211)\n",
      "epoch 362: (0.63525, 0.6005351966104214, 0.8079)\n",
      "epoch 363: (0.63435, 0.7316778754957751, 0.4243)\n",
      "epoch 364: (0.63415, 0.5986905024645038, 0.8138)\n",
      "epoch 365: (0.63515, 0.7345132743362832, 0.4233)\n",
      "epoch 366: (0.6338, 0.5985853227232537, 0.8124)\n",
      "epoch 367: (0.633, 0.7353149327671621, 0.4156)\n",
      "epoch 368: (0.6342, 0.5986619614762535, 0.8143)\n",
      "epoch 369: (0.6334, 0.7353563867325336, 0.4168)\n",
      "epoch 370: (0.63255, 0.5974704022354584, 0.8125)\n",
      "epoch 371: (0.6321, 0.7373338124326266, 0.4104)\n",
      "epoch 372: (0.6307, 0.5957789828521178, 0.813)\n",
      "epoch 373: (0.6346, 0.7370553011623812, 0.4185)\n",
      "epoch 374: (0.6302, 0.5958762886597938, 0.8092)\n",
      "epoch 375: (0.6353, 0.7326341127922971, 0.4261)\n",
      "epoch 376: (0.62895, 0.5931921659319217, 0.8208)\n",
      "epoch 377: (0.6333, 0.7299068644360124, 0.4232)\n",
      "epoch 378: (0.63095, 0.5959270383122116, 0.8135)\n",
      "epoch 379: (0.63315, 0.7347082672307421, 0.4168)\n",
      "epoch 380: (0.6306, 0.5961566779561184, 0.8097)\n",
      "epoch 381: (0.6345, 0.7310996563573883, 0.4255)\n",
      "epoch 382: (0.6304, 0.5954472258820085, 0.8135)\n",
      "epoch 383: (0.63415, 0.7326973113616653, 0.4224)\n",
      "epoch 384: (0.6353, 0.6024534302589732, 0.7956)\n",
      "epoch 385: (0.63345, 0.7337537221930286, 0.4189)\n",
      "epoch 386: (0.6333, 0.6000750750750751, 0.7993)\n",
      "epoch 387: (0.63335, 0.7317115551694179, 0.4211)\n",
      "epoch 388: (0.63635, 0.6021884134002848, 0.8035)\n",
      "epoch 389: (0.6351, 0.724269588313413, 0.4363)\n",
      "epoch 390: (0.63385, 0.5986876059868761, 0.812)\n",
      "epoch 391: (0.6335, 0.7256592292089249, 0.4293)\n",
      "epoch 392: (0.6338, 0.5989644970414201, 0.8098)\n",
      "epoch 393: (0.63335, 0.7265930331350892, 0.4276)\n",
      "epoch 394: (0.634, 0.5984570168993387, 0.8145)\n",
      "epoch 395: (0.6327, 0.7288720248361504, 0.4226)\n",
      "epoch 396: (0.6343, 0.5992462311557789, 0.8109)\n",
      "epoch 397: (0.63365, 0.7284224918817296, 0.4262)\n",
      "epoch 398: (0.63335, 0.5983479607640682, 0.8113)\n",
      "epoch 399: (0.6333, 0.7303836847563083, 0.4226)\n",
      "epoch 0: (0.51205, 0.5681175805539853, 0.1005)\n",
      "epoch 1: (0.5585, 0.5701943844492441, 0.4752)\n",
      "epoch 2: (0.55825, 0.5507890836167059, 0.6317)\n",
      "epoch 3: (0.5585, 0.5609756097560976, 0.5382)\n",
      "epoch 4: (0.55445, 0.5463207145895363, 0.6422)\n",
      "epoch 5: (0.5589, 0.5648392778511668, 0.5131)\n",
      "epoch 6: (0.5572, 0.5474688796680498, 0.6597)\n",
      "epoch 7: (0.56795, 0.5755755755755756, 0.5175)\n",
      "epoch 8: (0.56135, 0.5499877780493767, 0.675)\n",
      "epoch 9: (0.5734, 0.5852695167286245, 0.5038)\n",
      "epoch 10: (0.5677, 0.5530314898950337, 0.706)\n",
      "epoch 11: (0.5773, 0.5935382381413359, 0.4905)\n",
      "epoch 12: (0.57085, 0.5546386982339786, 0.7192)\n",
      "epoch 13: (0.5823, 0.6036262906069, 0.4794)\n",
      "epoch 14: (0.5735, 0.5564516129032258, 0.7245)\n",
      "epoch 15: (0.58555, 0.6129372937293729, 0.4643)\n",
      "epoch 16: (0.5767, 0.5586660547651828, 0.7304)\n",
      "epoch 17: (0.58585, 0.617009676979692, 0.4527)\n",
      "epoch 18: (0.579, 0.5602042371589697, 0.7351)\n",
      "epoch 19: (0.5872, 0.6236879432624114, 0.4397)\n",
      "epoch 20: (0.57945, 0.5605056735968319, 0.736)\n",
      "epoch 21: (0.58745, 0.6272, 0.4312)\n",
      "epoch 22: (0.58085, 0.561496919449304, 0.7382)\n",
      "epoch 23: (0.5881, 0.6305185185185185, 0.4256)\n",
      "epoch 24: (0.58185, 0.5621913228478079, 0.7399)\n",
      "epoch 25: (0.58865, 0.6330082520630158, 0.4219)\n",
      "epoch 26: (0.5828, 0.5627938722887912, 0.7421)\n",
      "epoch 27: (0.58855, 0.6349230534816395, 0.4167)\n",
      "epoch 28: (0.58365, 0.5632992811199394, 0.7444)\n",
      "epoch 29: (0.58835, 0.6358186010760953, 0.4136)\n",
      "epoch 30: (0.58465, 0.5638434271061166, 0.7476)\n",
      "epoch 31: (0.58905, 0.6379123431934335, 0.4119)\n",
      "epoch 32: (0.58425, 0.5632840081123713, 0.7499)\n",
      "epoch 33: (0.58965, 0.6388415672913118, 0.4125)\n",
      "epoch 34: (0.58485, 0.563581865867366, 0.7521)\n",
      "epoch 35: (0.5897, 0.63950233281493, 0.4112)\n",
      "epoch 36: (0.5856, 0.5640430944186743, 0.7539)\n",
      "epoch 37: (0.58985, 0.6402372405181832, 0.4102)\n",
      "epoch 38: (0.58615, 0.5641235578712318, 0.7579)\n",
      "epoch 39: (0.58955, 0.6405146712694179, 0.4082)\n",
      "epoch 40: (0.5867, 0.5644035061655029, 0.7598)\n",
      "epoch 41: (0.59025, 0.6419248309482624, 0.4082)\n",
      "epoch 42: (0.5874, 0.5648367952522255, 0.7614)\n",
      "epoch 43: (0.59015, 0.6421251773608703, 0.4073)\n",
      "epoch 44: (0.5886, 0.5656880189798339, 0.763)\n",
      "epoch 45: (0.59005, 0.6426873712565362, 0.4056)\n",
      "epoch 46: (0.5883, 0.5652334515366431, 0.7651)\n",
      "epoch 47: (0.5899, 0.6428344455036543, 0.4046)\n",
      "epoch 48: (0.5893, 0.566040526549327, 0.7654)\n",
      "epoch 49: (0.58975, 0.6435311050695666, 0.4024)\n",
      "epoch 50: (0.5898, 0.5662144226515263, 0.7679)\n",
      "epoch 51: (0.59005, 0.6445193387899214, 0.4016)\n",
      "epoch 52: (0.5901, 0.5663671184443135, 0.7689)\n",
      "epoch 53: (0.5901, 0.64494851994852, 0.4009)\n",
      "epoch 54: (0.59065, 0.5666691181878355, 0.7705)\n",
      "epoch 55: (0.59025, 0.6452131938857603, 0.401)\n",
      "epoch 56: (0.5905, 0.5665441176470588, 0.7705)\n",
      "epoch 57: (0.59015, 0.6454736162659351, 0.4)\n",
      "epoch 58: (0.5912, 0.5669898633759365, 0.7719)\n",
      "epoch 59: (0.5904, 0.645712443584784, 0.4006)\n",
      "epoch 60: (0.59145, 0.5671685640837312, 0.7722)\n",
      "epoch 61: (0.5908, 0.6461687057308435, 0.4014)\n",
      "epoch 62: (0.5914, 0.5670481220657277, 0.773)\n",
      "epoch 63: (0.59125, 0.6469640843936222, 0.4017)\n",
      "epoch 64: (0.59255, 0.5678071653600997, 0.775)\n",
      "epoch 65: (0.5913, 0.6475436328377505, 0.4007)\n",
      "epoch 66: (0.59265, 0.5679202404515798, 0.7747)\n",
      "epoch 67: (0.5913, 0.6478781988986071, 0.4)\n",
      "epoch 68: (0.593, 0.5682218309859155, 0.7746)\n",
      "epoch 69: (0.59075, 0.6476329917032699, 0.3981)\n",
      "epoch 70: (0.59325, 0.5683901723505684, 0.775)\n",
      "epoch 71: (0.59075, 0.6481632653061224, 0.397)\n",
      "epoch 72: (0.59385, 0.5687696929728145, 0.7762)\n",
      "epoch 73: (0.59155, 0.6497138184791497, 0.3973)\n",
      "epoch 74: (0.59405, 0.568906146970474, 0.7765)\n",
      "epoch 75: (0.59165, 0.6499754540991655, 0.3972)\n",
      "epoch 76: (0.594, 0.5688241323766291, 0.7769)\n",
      "epoch 77: (0.5917, 0.6501309757694826, 0.3971)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 78: (0.59435, 0.5691462074019787, 0.7766)\n",
      "epoch 79: (0.592, 0.6508691374221056, 0.3969)\n",
      "epoch 80: (0.59445, 0.5692093500403019, 0.7768)\n",
      "epoch 81: (0.59265, 0.6519599803181892, 0.3975)\n",
      "epoch 82: (0.5949, 0.5696053982690333, 0.7766)\n",
      "epoch 83: (0.59265, 0.652359809241901, 0.3967)\n",
      "epoch 84: (0.5952, 0.5698151950718686, 0.777)\n",
      "epoch 85: (0.59265, 0.652812139205014, 0.3958)\n",
      "epoch 86: (0.59555, 0.5701078582434514, 0.777)\n",
      "epoch 87: (0.59235, 0.6524682185900611, 0.3952)\n",
      "epoch 88: (0.59605, 0.5704747230170959, 0.7775)\n",
      "epoch 89: (0.59255, 0.6530510997188689, 0.3949)\n",
      "epoch 90: (0.5966, 0.5708522810620508, 0.7783)\n",
      "epoch 91: (0.59255, 0.6533046215007454, 0.3944)\n",
      "epoch 92: (0.59645, 0.5707474510379227, 0.7781)\n",
      "epoch 93: (0.59305, 0.6542861880285193, 0.3946)\n",
      "epoch 94: (0.5965, 0.5708308866705814, 0.7777)\n",
      "epoch 95: (0.5932, 0.6546118115461181, 0.3946)\n",
      "epoch 96: (0.5964, 0.5707471011301922, 0.7777)\n",
      "epoch 97: (0.5934, 0.655201063476238, 0.3943)\n",
      "epoch 98: (0.5968, 0.5710823909531503, 0.7777)\n",
      "epoch 99: (0.59305, 0.6552644752210913, 0.3927)\n",
      "epoch 100: (0.59675, 0.5710717696319695, 0.7774)\n",
      "epoch 101: (0.59365, 0.6564745196324143, 0.3929)\n",
      "epoch 102: (0.59675, 0.571030027163938, 0.7778)\n",
      "epoch 103: (0.59355, 0.6564119712422671, 0.3926)\n",
      "epoch 104: (0.59655, 0.5708311936028171, 0.7781)\n",
      "epoch 105: (0.594, 0.6570330771800869, 0.3933)\n",
      "epoch 106: (0.5969, 0.5710618949838663, 0.7787)\n",
      "epoch 107: (0.59435, 0.6576441102756893, 0.3936)\n",
      "epoch 108: (0.597, 0.5711352302728073, 0.7788)\n",
      "epoch 109: (0.59435, 0.657907949790795, 0.3931)\n",
      "epoch 110: (0.59705, 0.5711771177117712, 0.7788)\n",
      "epoch 111: (0.59445, 0.6579695601271116, 0.3934)\n",
      "epoch 112: (0.59705, 0.5711666788883185, 0.7789)\n",
      "epoch 113: (0.5944, 0.658018078339471, 0.3931)\n",
      "epoch 114: (0.5974, 0.5714180964950872, 0.7793)\n",
      "epoch 115: (0.59445, 0.6581812091776922, 0.393)\n",
      "epoch 116: (0.59745, 0.5714914533049666, 0.779)\n",
      "epoch 117: (0.59345, 0.6571909167367536, 0.3907)\n",
      "epoch 118: (0.59775, 0.5717115398723498, 0.7793)\n",
      "epoch 119: (0.59355, 0.6574650732199966, 0.3906)\n",
      "epoch 120: (0.598, 0.5719424460431655, 0.7791)\n",
      "epoch 121: (0.5931, 0.6569983136593592, 0.3896)\n",
      "epoch 122: (0.59805, 0.5719950069755488, 0.779)\n",
      "epoch 123: (0.59315, 0.6572682762113794, 0.3893)\n",
      "epoch 124: (0.5982, 0.5720258178084201, 0.7799)\n",
      "epoch 125: (0.5933, 0.6574949358541526, 0.3895)\n",
      "epoch 126: (0.59835, 0.5721305463879721, 0.7801)\n",
      "epoch 127: (0.59345, 0.6577747762957961, 0.3896)\n",
      "epoch 128: (0.5986, 0.5723298122065728, 0.7802)\n",
      "epoch 129: (0.5935, 0.6578858493752111, 0.3896)\n",
      "epoch 130: (0.5988, 0.5724765258215962, 0.7804)\n",
      "epoch 131: (0.59315, 0.6577476714648602, 0.3884)\n",
      "epoch 132: (0.5991, 0.5726965962441315, 0.7807)\n",
      "epoch 133: (0.59285, 0.6575063613231552, 0.3876)\n",
      "epoch 134: (0.5991, 0.5726965962441315, 0.7807)\n",
      "epoch 135: (0.593, 0.657520325203252, 0.3882)\n",
      "epoch 136: (0.599, 0.5726125861816048, 0.7807)\n",
      "epoch 137: (0.593, 0.657520325203252, 0.3882)\n",
      "epoch 138: (0.59895, 0.5725493071339541, 0.7809)\n",
      "epoch 139: (0.593, 0.6576271186440678, 0.388)\n",
      "epoch 140: (0.59895, 0.5725280363556402, 0.7811)\n",
      "epoch 141: (0.59345, 0.6580950769751311, 0.389)\n",
      "epoch 142: (0.5991, 0.5726326590442685, 0.7813)\n",
      "epoch 143: (0.5934, 0.6581978319783198, 0.3886)\n",
      "epoch 144: (0.5992, 0.5726846424384525, 0.7816)\n",
      "epoch 145: (0.5936, 0.6583756345177665, 0.3891)\n",
      "epoch 146: (0.59915, 0.5725895014276301, 0.7821)\n",
      "epoch 147: (0.5935, 0.6580459770114943, 0.3893)\n",
      "epoch 148: (0.5992, 0.5726207906295754, 0.7822)\n",
      "epoch 149: (0.5938, 0.6584994930719837, 0.3897)\n",
      "epoch 150: (0.59905, 0.5724738421014122, 0.7824)\n",
      "epoch 151: (0.5935, 0.6579925650557621, 0.3894)\n",
      "epoch 152: (0.5991, 0.5725157324747548, 0.7824)\n",
      "epoch 153: (0.5939, 0.6585612968591692, 0.39)\n",
      "epoch 154: (0.5988, 0.572264482153306, 0.7824)\n",
      "epoch 155: (0.5939, 0.6581873315363881, 0.3907)\n",
      "epoch 156: (0.59905, 0.5724738421014122, 0.7824)\n",
      "epoch 157: (0.5939, 0.6585612968591692, 0.39)\n",
      "epoch 158: (0.5991, 0.5724839087185488, 0.7827)\n",
      "epoch 159: (0.5941, 0.6586311530681052, 0.3907)\n",
      "epoch 160: (0.5987, 0.5721596724667349, 0.7826)\n",
      "epoch 161: (0.59395, 0.6582982308340354, 0.3907)\n",
      "epoch 162: (0.5989, 0.5723164668031588, 0.7827)\n",
      "epoch 163: (0.594, 0.6584625758597438, 0.3906)\n",
      "epoch 164: (0.59885, 0.5722323712093533, 0.7831)\n",
      "epoch 165: (0.5942, 0.6587462082912032, 0.3909)\n",
      "epoch 166: (0.59865, 0.572075692262731, 0.783)\n",
      "epoch 167: (0.59425, 0.6588572391707399, 0.3909)\n",
      "epoch 168: (0.59855, 0.5720026302330679, 0.7829)\n",
      "epoch 169: (0.5942, 0.6586392724823172, 0.3911)\n",
      "epoch 170: (0.5986, 0.572044424959813, 0.7829)\n",
      "epoch 171: (0.59435, 0.6589186457806974, 0.3912)\n",
      "epoch 172: (0.5986, 0.572044424959813, 0.7829)\n",
      "epoch 173: (0.59435, 0.658972198820556, 0.3911)\n",
      "epoch 174: (0.59865, 0.5720651618087516, 0.7831)\n",
      "epoch 175: (0.5944, 0.6589225589225589, 0.3914)\n",
      "epoch 176: (0.59875, 0.5721592985020095, 0.783)\n",
      "epoch 177: (0.5944, 0.6590296495956873, 0.3912)\n",
      "epoch 178: (0.5989, 0.5723058926743676, 0.7828)\n",
      "epoch 179: (0.59445, 0.6590335073244654, 0.3914)\n",
      "epoch 180: (0.5989, 0.5723058926743676, 0.7828)\n",
      "epoch 181: (0.59435, 0.6588651288095639, 0.3913)\n",
      "epoch 182: (0.5988, 0.5722433460076045, 0.7826)\n",
      "epoch 183: (0.5944, 0.6590296495956873, 0.3912)\n",
      "epoch 184: (0.59885, 0.5722851919561243, 0.7826)\n",
      "epoch 185: (0.59425, 0.6589644122111654, 0.3907)\n",
      "epoch 186: (0.5988, 0.5722433460076045, 0.7826)\n",
      "epoch 187: (0.59415, 0.6586352148272957, 0.3909)\n",
      "epoch 188: (0.5988, 0.5722433460076045, 0.7826)\n",
      "epoch 189: (0.59445, 0.6590870810173488, 0.3913)\n",
      "epoch 190: (0.59885, 0.5722746216275499, 0.7827)\n",
      "epoch 191: (0.5947, 0.6595888102460398, 0.3914)\n",
      "epoch 192: (0.59875, 0.5722015061782555, 0.7826)\n",
      "epoch 193: (0.5944, 0.6591905564924114, 0.3909)\n",
      "epoch 194: (0.5987, 0.5721596724667349, 0.7826)\n",
      "epoch 195: (0.59455, 0.6593091828138163, 0.3913)\n",
      "epoch 196: (0.5987, 0.5721596724667349, 0.7826)\n",
      "epoch 197: (0.5942, 0.6589605129935876, 0.3905)\n",
      "epoch 198: (0.59875, 0.5722015061782555, 0.7826)\n",
      "epoch 199: (0.59455, 0.6599019110434635, 0.3902)\n",
      "epoch 200: (0.5987, 0.5721596724667349, 0.7826)\n",
      "epoch 201: (0.59415, 0.6590103023137983, 0.3902)\n",
      "epoch 202: (0.5988, 0.5722433460076045, 0.7826)\n",
      "epoch 203: (0.59425, 0.6593945543717233, 0.3899)\n",
      "epoch 204: (0.59885, 0.5722851919561243, 0.7826)\n",
      "epoch 205: (0.5941, 0.6591677943166441, 0.3897)\n",
      "epoch 206: (0.59885, 0.5722746216275499, 0.7827)\n",
      "epoch 207: (0.594, 0.6586765698852127, 0.3902)\n",
      "epoch 208: (0.5989, 0.5723164668031588, 0.7827)\n",
      "epoch 209: (0.5943, 0.6592905405405406, 0.3903)\n",
      "epoch 210: (0.59885, 0.5722746216275499, 0.7827)\n",
      "epoch 211: (0.59385, 0.658503631143388, 0.3899)\n",
      "epoch 212: (0.5989, 0.5723058926743676, 0.7828)\n",
      "epoch 213: (0.5942, 0.6592830571525194, 0.3899)\n",
      "epoch 214: (0.59885, 0.5722746216275499, 0.7827)\n",
      "epoch 215: (0.594, 0.6587837837837838, 0.39)\n",
      "epoch 216: (0.5988, 0.5722327825705512, 0.7827)\n",
      "epoch 217: (0.59435, 0.6595636732623034, 0.39)\n",
      "epoch 218: (0.5988, 0.5722327825705512, 0.7827)\n",
      "epoch 219: (0.59415, 0.6590640310863322, 0.3901)\n",
      "epoch 220: (0.5988, 0.5722222222222222, 0.7828)\n",
      "epoch 221: (0.5943, 0.6597222222222222, 0.3895)\n",
      "epoch 222: (0.5988, 0.5722011107863197, 0.783)\n",
      "epoch 223: (0.59405, 0.6587877764646294, 0.3902)\n",
      "epoch 224: (0.5989, 0.5722741888336743, 0.7831)\n",
      "epoch 225: (0.5943, 0.6595600676818951, 0.3898)\n",
      "epoch 226: (0.59875, 0.5721698457940511, 0.7829)\n",
      "epoch 227: (0.59405, 0.6587877764646294, 0.3902)\n",
      "epoch 228: (0.59885, 0.5722534902419414, 0.7829)\n",
      "epoch 229: (0.59425, 0.6594484858737946, 0.3898)\n",
      "epoch 230: (0.59875, 0.5721487542923942, 0.7831)\n",
      "epoch 231: (0.5944, 0.6592442645074224, 0.3908)\n",
      "epoch 232: (0.5988, 0.5722011107863197, 0.783)\n",
      "epoch 233: (0.5944, 0.6596212377409537, 0.3901)\n",
      "epoch 234: (0.5988, 0.5722011107863197, 0.783)\n",
      "epoch 235: (0.5945, 0.6595205941931127, 0.3907)\n",
      "epoch 236: (0.59885, 0.5722323712093533, 0.7831)\n",
      "epoch 237: (0.59455, 0.6597398209156953, 0.3905)\n",
      "epoch 238: (0.5988, 0.5722011107863197, 0.783)\n",
      "epoch 239: (0.59455, 0.6594166245152588, 0.3911)\n",
      "epoch 240: (0.59885, 0.5722429291821969, 0.783)\n",
      "epoch 241: (0.5947, 0.6599662162162162, 0.3907)\n",
      "epoch 242: (0.5988, 0.5722011107863197, 0.783)\n",
      "epoch 243: (0.59485, 0.660084388185654, 0.3911)\n",
      "epoch 244: (0.5989, 0.5722741888336743, 0.7831)\n",
      "epoch 245: (0.5947, 0.659481306837319, 0.3916)\n",
      "epoch 246: (0.59885, 0.5722323712093533, 0.7831)\n",
      "epoch 247: (0.59475, 0.6598077247427897, 0.3912)\n",
      "epoch 248: (0.59885, 0.5722323712093533, 0.7831)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 249: (0.5946, 0.6593128999663186, 0.3915)\n",
      "epoch 250: (0.5989, 0.5722636270641531, 0.7832)\n",
      "epoch 251: (0.59455, 0.6592555162540004, 0.3914)\n",
      "epoch 252: (0.59875, 0.5721382131638542, 0.7832)\n",
      "epoch 253: (0.59445, 0.6590870810173488, 0.3913)\n",
      "epoch 254: (0.59885, 0.5722218163220574, 0.7832)\n",
      "epoch 255: (0.5946, 0.6596893990546928, 0.3908)\n",
      "epoch 256: (0.59895, 0.5723054439166971, 0.7832)\n",
      "epoch 257: (0.5943, 0.6592905405405406, 0.3903)\n",
      "epoch 258: (0.5989, 0.5722530683810637, 0.7833)\n",
      "epoch 259: (0.5944, 0.6598374534371825, 0.3897)\n",
      "epoch 260: (0.5989, 0.5722741888336743, 0.7831)\n",
      "epoch 261: (0.5943, 0.6593982420554428, 0.3901)\n",
      "epoch 262: (0.59885, 0.5722429291821969, 0.783)\n",
      "epoch 263: (0.59455, 0.6602270801559058, 0.3896)\n",
      "epoch 264: (0.59885, 0.5722429291821969, 0.783)\n",
      "epoch 265: (0.59435, 0.659996608444972, 0.3892)\n",
      "epoch 266: (0.59885, 0.5722429291821969, 0.783)\n",
      "epoch 267: (0.5941, 0.6593834688346883, 0.3893)\n",
      "epoch 268: (0.59885, 0.5722218163220574, 0.7832)\n",
      "epoch 269: (0.59445, 0.6602205258693808, 0.3892)\n",
      "epoch 270: (0.59885, 0.5722429291821969, 0.783)\n",
      "epoch 271: (0.594, 0.6591062965470549, 0.3894)\n",
      "epoch 272: (0.5988, 0.572211664961263, 0.7829)\n",
      "epoch 273: (0.5939, 0.6595853161114887, 0.3881)\n",
      "epoch 274: (0.59885, 0.5722429291821969, 0.783)\n",
      "epoch 275: (0.59345, 0.6586318112374809, 0.388)\n",
      "epoch 276: (0.59885, 0.5722534902419414, 0.7829)\n",
      "epoch 277: (0.5939, 0.6596938775510204, 0.3879)\n",
      "epoch 278: (0.59885, 0.5722534902419414, 0.7829)\n",
      "epoch 279: (0.59405, 0.6598130841121496, 0.3883)\n",
      "epoch 280: (0.5988, 0.5722011107863197, 0.783)\n",
      "epoch 281: (0.594, 0.6593760596812479, 0.3889)\n",
      "epoch 282: (0.59875, 0.5721803961698706, 0.7828)\n",
      "epoch 283: (0.5943, 0.6601018675721562, 0.3888)\n",
      "epoch 284: (0.5988, 0.572211664961263, 0.7829)\n",
      "epoch 285: (0.5942, 0.6597693351424695, 0.389)\n",
      "epoch 286: (0.5988, 0.572211664961263, 0.7829)\n",
      "epoch 287: (0.5946, 0.6606657608695652, 0.389)\n",
      "epoch 288: (0.5987, 0.5721385762315451, 0.7828)\n",
      "epoch 289: (0.59445, 0.6603293159056187, 0.389)\n",
      "epoch 290: (0.59885, 0.5722323712093533, 0.7831)\n",
      "epoch 291: (0.59415, 0.6594951719464679, 0.3893)\n",
      "epoch 292: (0.5989, 0.5722636270641531, 0.7832)\n",
      "epoch 293: (0.59445, 0.6603837663440313, 0.3889)\n",
      "epoch 294: (0.5989, 0.5722636270641531, 0.7832)\n",
      "epoch 295: (0.59395, 0.659426438146954, 0.3886)\n",
      "epoch 296: (0.5989, 0.5722636270641531, 0.7832)\n",
      "epoch 297: (0.5943, 0.6603196191771507, 0.3884)\n",
      "epoch 298: (0.5989, 0.5722636270641531, 0.7832)\n",
      "epoch 299: (0.5943, 0.6602106693849813, 0.3886)\n",
      "epoch 300: (0.59885, 0.5722218163220574, 0.7832)\n",
      "epoch 301: (0.59385, 0.6592027141645462, 0.3886)\n",
      "epoch 302: (0.5989, 0.5722636270641531, 0.7832)\n",
      "epoch 303: (0.5943, 0.6602106693849813, 0.3886)\n",
      "epoch 304: (0.59895, 0.5723054439166971, 0.7832)\n",
      "epoch 305: (0.59405, 0.659487875190775, 0.3889)\n",
      "epoch 306: (0.5989, 0.5722847536909809, 0.783)\n",
      "epoch 307: (0.59435, 0.6602139582272033, 0.3888)\n",
      "epoch 308: (0.59895, 0.5723265843140122, 0.783)\n",
      "epoch 309: (0.5943, 0.6602651257647859, 0.3885)\n",
      "epoch 310: (0.599, 0.572347266881029, 0.7832)\n",
      "epoch 311: (0.59405, 0.6595961310028848, 0.3887)\n",
      "epoch 312: (0.599, 0.5723578424206988, 0.7831)\n",
      "epoch 313: (0.59435, 0.6603228547153781, 0.3886)\n",
      "epoch 314: (0.599, 0.5723684210526315, 0.783)\n",
      "epoch 315: (0.59375, 0.659411664682877, 0.3878)\n",
      "epoch 316: (0.59895, 0.5723371591490606, 0.7829)\n",
      "epoch 317: (0.59385, 0.6599079911398875, 0.3873)\n",
      "epoch 318: (0.5991, 0.5724415204678363, 0.7831)\n",
      "epoch 319: (0.5936, 0.6590214067278287, 0.3879)\n",
      "epoch 320: (0.59895, 0.5723265843140122, 0.783)\n",
      "epoch 321: (0.594, 0.6599183395712828, 0.3879)\n",
      "epoch 322: (0.5989, 0.5722847536909809, 0.783)\n",
      "epoch 323: (0.5941, 0.6599795987759266, 0.3882)\n",
      "epoch 324: (0.599, 0.572379002778184, 0.7829)\n",
      "epoch 325: (0.59365, 0.6589173595791618, 0.3883)\n",
      "epoch 326: (0.59895, 0.5723371591490606, 0.7829)\n",
      "epoch 327: (0.5941, 0.6598165760869565, 0.3885)\n",
      "epoch 328: (0.599, 0.5723578424206988, 0.7831)\n",
      "epoch 329: (0.5938, 0.659036961681926, 0.3887)\n",
      "epoch 330: (0.59905, 0.5723996783860829, 0.7831)\n",
      "epoch 331: (0.5942, 0.6599864130434783, 0.3886)\n",
      "epoch 332: (0.599, 0.5723684210526315, 0.783)\n",
      "epoch 333: (0.59385, 0.658986955785194, 0.389)\n",
      "epoch 334: (0.59905, 0.5724208525261387, 0.7829)\n",
      "epoch 335: (0.5944, 0.6602172437202987, 0.389)\n",
      "epoch 336: (0.59895, 0.5723371591490606, 0.7829)\n",
      "epoch 337: (0.59415, 0.6595492289442467, 0.3892)\n",
      "epoch 338: (0.59905, 0.5723996783860829, 0.7831)\n",
      "epoch 339: (0.5943, 0.6602106693849813, 0.3886)\n",
      "epoch 340: (0.599, 0.5723578424206988, 0.7831)\n",
      "epoch 341: (0.59385, 0.659635992515734, 0.3878)\n",
      "epoch 342: (0.59895, 0.5723477370768444, 0.7828)\n",
      "epoch 343: (0.59375, 0.6590870524350925, 0.3884)\n",
      "epoch 344: (0.59895, 0.5723689022160462, 0.7826)\n",
      "epoch 345: (0.594, 0.6599183395712828, 0.3879)\n",
      "epoch 346: (0.59895, 0.5723477370768444, 0.7828)\n",
      "epoch 347: (0.5941, 0.6601974804221995, 0.3878)\n",
      "epoch 348: (0.59905, 0.5724102639081804, 0.783)\n",
      "epoch 349: (0.59375, 0.659303313508921, 0.388)\n",
      "epoch 350: (0.59905, 0.5724208525261387, 0.7829)\n",
      "epoch 351: (0.59385, 0.6597446808510639, 0.3876)\n",
      "epoch 352: (0.599, 0.572379002778184, 0.7829)\n",
      "epoch 353: (0.59415, 0.6600918211188573, 0.3882)\n",
      "epoch 354: (0.59905, 0.5724314442413163, 0.7828)\n",
      "epoch 355: (0.59405, 0.6601396219989784, 0.3877)\n",
      "epoch 356: (0.59895, 0.5723583180987203, 0.7827)\n",
      "epoch 357: (0.59385, 0.6595817037918721, 0.3879)\n",
      "epoch 358: (0.59895, 0.5723477370768444, 0.7828)\n",
      "epoch 359: (0.5937, 0.6592995579734784, 0.3878)\n",
      "epoch 360: (0.599, 0.572379002778184, 0.7829)\n",
      "epoch 361: (0.5937, 0.6595165134490977, 0.3874)\n",
      "epoch 362: (0.59915, 0.5725045703839122, 0.7829)\n",
      "epoch 363: (0.59375, 0.6594658955604694, 0.3877)\n",
      "epoch 364: (0.5991, 0.5724733070059967, 0.7828)\n",
      "epoch 365: (0.59395, 0.659969351268517, 0.3876)\n",
      "epoch 366: (0.59915, 0.5725045703839122, 0.7829)\n",
      "epoch 367: (0.59385, 0.659635992515734, 0.3878)\n",
      "epoch 368: (0.59915, 0.5725045703839122, 0.7829)\n",
      "epoch 369: (0.59365, 0.6595672175839155, 0.3871)\n",
      "epoch 370: (0.5992, 0.5725570509069632, 0.7828)\n",
      "epoch 371: (0.5937, 0.6596252129471891, 0.3872)\n",
      "epoch 372: (0.5993, 0.5726301930953774, 0.7829)\n",
      "epoch 373: (0.5936, 0.6588594704684317, 0.3882)\n",
      "epoch 374: (0.59935, 0.5726720795845219, 0.7829)\n",
      "epoch 375: (0.5939, 0.6598025867937373, 0.3877)\n",
      "epoch 376: (0.5993, 0.5726301930953774, 0.7829)\n",
      "epoch 377: (0.5939, 0.6596395783747024, 0.388)\n",
      "epoch 378: (0.59925, 0.5725883127331237, 0.7829)\n",
      "epoch 379: (0.5939, 0.6599114441416893, 0.3875)\n",
      "epoch 380: (0.5993, 0.5726408193123629, 0.7828)\n",
      "epoch 381: (0.5939, 0.6599659284497444, 0.3874)\n",
      "epoch 382: (0.5994, 0.572713972201902, 0.7829)\n",
      "epoch 383: (0.5936, 0.6592920353982301, 0.3874)\n",
      "epoch 384: (0.59935, 0.5726720795845219, 0.7829)\n",
      "epoch 385: (0.594, 0.6601908657123381, 0.3874)\n",
      "epoch 386: (0.5993, 0.5726408193123629, 0.7828)\n",
      "epoch 387: (0.59375, 0.6595744680851063, 0.3875)\n",
      "epoch 388: (0.5993, 0.5726408193123629, 0.7828)\n",
      "epoch 389: (0.59395, 0.6601875532821825, 0.3872)\n",
      "epoch 390: (0.5995, 0.5727977758267486, 0.7829)\n",
      "epoch 391: (0.594, 0.6605191256830601, 0.3868)\n",
      "epoch 392: (0.59955, 0.5728396868369064, 0.7829)\n",
      "epoch 393: (0.5935, 0.6592302452316077, 0.3871)\n",
      "epoch 394: (0.59945, 0.5727665178898076, 0.7828)\n",
      "epoch 395: (0.59405, 0.6604127579737336, 0.3872)\n",
      "epoch 396: (0.59945, 0.5727558709488624, 0.7829)\n",
      "epoch 397: (0.59385, 0.6597446808510639, 0.3876)\n",
      "epoch 398: (0.5994, 0.5727246122329529, 0.7828)\n",
      "epoch 399: (0.59415, 0.660364503491739, 0.3877)\n",
      "epoch 0: (0.55315, 0.5613387189844201, 0.4864)\n",
      "epoch 1: (0.5561, 0.5992920353982301, 0.3386)\n",
      "epoch 2: (0.5513, 0.5430441349219668, 0.6472)\n",
      "epoch 3: (0.56835, 0.5966350911918563, 0.422)\n",
      "epoch 4: (0.56405, 0.5506604445147513, 0.6962)\n",
      "epoch 5: (0.57105, 0.6193916988741388, 0.3686)\n",
      "epoch 6: (0.5652, 0.5463792858159056, 0.7681)\n",
      "epoch 7: (0.5764, 0.6256578947368421, 0.3804)\n",
      "epoch 8: (0.57025, 0.5514312907240647, 0.7532)\n",
      "epoch 9: (0.58085, 0.620044543429844, 0.4176)\n",
      "epoch 10: (0.57025, 0.5486058257801149, 0.7929)\n",
      "epoch 11: (0.58715, 0.6276548996631024, 0.4285)\n",
      "epoch 12: (0.57075, 0.5499259050172888, 0.7793)\n",
      "epoch 13: (0.588, 0.6430429128738622, 0.3956)\n",
      "epoch 14: (0.57725, 0.555025286701332, 0.7792)\n",
      "epoch 15: (0.58955, 0.6547433903576982, 0.3789)\n",
      "epoch 16: (0.5794, 0.5557897695334457, 0.791)\n",
      "epoch 17: (0.5929, 0.6516487104146261, 0.3992)\n",
      "epoch 18: (0.5803, 0.5563113604488078, 0.7933)\n",
      "epoch 19: (0.5939, 0.6750559284116331, 0.3621)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20: (0.5795, 0.5543106981828119, 0.8114)\n",
      "epoch 21: (0.5965, 0.6704344754503709, 0.3796)\n",
      "epoch 22: (0.57645, 0.551415697087901, 0.8199)\n",
      "epoch 23: (0.599, 0.6781857451403888, 0.3768)\n",
      "epoch 24: (0.57645, 0.5509089698341879, 0.8273)\n",
      "epoch 25: (0.59795, 0.6816917084028937, 0.3675)\n",
      "epoch 26: (0.58065, 0.5541166208146011, 0.8258)\n",
      "epoch 27: (0.5982, 0.6775768535262207, 0.3747)\n",
      "epoch 28: (0.58115, 0.5544813695871098, 0.8259)\n",
      "epoch 29: (0.6022, 0.6846098265895953, 0.379)\n",
      "epoch 30: (0.58075, 0.5542565343008802, 0.8249)\n",
      "epoch 31: (0.6046, 0.6858564321250888, 0.386)\n",
      "epoch 32: (0.58345, 0.555637042469498, 0.8334)\n",
      "epoch 33: (0.60245, 0.6856314549737271, 0.3784)\n",
      "epoch 34: (0.5824, 0.5550213675213675, 0.8312)\n",
      "epoch 35: (0.60215, 0.6834920064666786, 0.3805)\n",
      "epoch 36: (0.5831, 0.555488782051282, 0.8319)\n",
      "epoch 37: (0.6072, 0.693571686529433, 0.3841)\n",
      "epoch 38: (0.585, 0.5571083042192959, 0.8292)\n",
      "epoch 39: (0.6101, 0.6976660682226212, 0.3886)\n",
      "epoch 40: (0.5828, 0.5548489666136724, 0.8376)\n",
      "epoch 41: (0.60685, 0.6939553457977854, 0.3823)\n",
      "epoch 42: (0.58655, 0.557420553307238, 0.8402)\n",
      "epoch 43: (0.60995, 0.6955361906455628, 0.3911)\n",
      "epoch 44: (0.5859, 0.5564463135760284, 0.8468)\n",
      "epoch 45: (0.60885, 0.6994685724757193, 0.3817)\n",
      "epoch 46: (0.58885, 0.5604134085809479, 0.8242)\n",
      "epoch 47: (0.6107, 0.6970452118191527, 0.3916)\n",
      "epoch 48: (0.59095, 0.5616902936987045, 0.8281)\n",
      "epoch 49: (0.61035, 0.7021432496794284, 0.3833)\n",
      "epoch 50: (0.5923, 0.5617721857850355, 0.8394)\n",
      "epoch 51: (0.6145, 0.6997557571528262, 0.4011)\n",
      "epoch 52: (0.59275, 0.56216904618272, 0.8387)\n",
      "epoch 53: (0.6144, 0.7001399580125962, 0.4002)\n",
      "epoch 54: (0.59085, 0.5599630387433173, 0.8484)\n",
      "epoch 55: (0.6158, 0.6975435005117707, 0.4089)\n",
      "epoch 56: (0.5922, 0.5615898463593855, 0.8407)\n",
      "epoch 57: (0.614, 0.7004924375659515, 0.3983)\n",
      "epoch 58: (0.59365, 0.5622879946790822, 0.8454)\n",
      "epoch 59: (0.61255, 0.7086190917516219, 0.3823)\n",
      "epoch 60: (0.59355, 0.5625961860153897, 0.8408)\n",
      "epoch 61: (0.6131, 0.7045947901591896, 0.3895)\n",
      "epoch 62: (0.59435, 0.5631568378070821, 0.8413)\n",
      "epoch 63: (0.6127, 0.7024793388429752, 0.391)\n",
      "epoch 64: (0.5928, 0.5613837809234026, 0.8487)\n",
      "epoch 65: (0.6141, 0.6938498131158681, 0.4084)\n",
      "epoch 66: (0.59135, 0.5605889765868541, 0.8452)\n",
      "epoch 67: (0.615, 0.7197172334734429, 0.3767)\n",
      "epoch 68: (0.59325, 0.5618327697102314, 0.8473)\n",
      "epoch 69: (0.61745, 0.7172184205659331, 0.3878)\n",
      "epoch 70: (0.5943, 0.5631275940554291, 0.8412)\n",
      "epoch 71: (0.6163, 0.7143383708072245, 0.3876)\n",
      "epoch 72: (0.5957, 0.5644010767160161, 0.8387)\n",
      "epoch 73: (0.61485, 0.7189704480457578, 0.3771)\n",
      "epoch 74: (0.5956, 0.5641352475513216, 0.8409)\n",
      "epoch 75: (0.6136, 0.7197292069632495, 0.3721)\n",
      "epoch 76: (0.59565, 0.563762415838944, 0.8457)\n",
      "epoch 77: (0.61115, 0.7201426024955436, 0.3636)\n",
      "epoch 78: (0.59485, 0.5637389960352127, 0.8389)\n",
      "epoch 79: (0.6112, 0.7145889617908143, 0.3703)\n",
      "epoch 80: (0.59725, 0.5661069947658215, 0.8328)\n",
      "epoch 81: (0.60965, 0.7167424392172366, 0.3626)\n",
      "epoch 82: (0.5972, 0.5655516590234692, 0.8386)\n",
      "epoch 83: (0.61075, 0.7185711466350898, 0.3641)\n",
      "epoch 84: (0.59565, 0.5642161799261497, 0.8404)\n",
      "epoch 85: (0.612, 0.7145593869731801, 0.373)\n",
      "epoch 86: (0.59675, 0.5644613232060763, 0.8472)\n",
      "epoch 87: (0.6134, 0.7203653322969297, 0.3707)\n",
      "epoch 88: (0.59675, 0.5640855799165397, 0.8516)\n",
      "epoch 89: (0.61215, 0.7159637974196034, 0.3718)\n",
      "epoch 90: (0.59565, 0.563847540217609, 0.8447)\n",
      "epoch 91: (0.61525, 0.715622076707203, 0.3825)\n",
      "epoch 92: (0.5935, 0.5617650944642621, 0.8504)\n",
      "epoch 93: (0.6168, 0.7184811073699963, 0.3841)\n",
      "epoch 94: (0.5954, 0.5635576282478347, 0.8459)\n",
      "epoch 95: (0.61525, 0.716188332395423, 0.3818)\n",
      "epoch 96: (0.6, 0.5671591672263264, 0.8445)\n",
      "epoch 97: (0.61545, 0.7197791738054445, 0.3781)\n",
      "epoch 98: (0.59835, 0.5653618661527214, 0.8507)\n",
      "epoch 99: (0.61615, 0.7138648499355551, 0.3877)\n",
      "epoch 100: (0.5984, 0.5659605845287572, 0.8443)\n",
      "epoch 101: (0.61595, 0.7153203342618384, 0.3852)\n",
      "epoch 102: (0.5995, 0.5674027909497358, 0.8376)\n",
      "epoch 103: (0.61945, 0.7269618088542656, 0.3826)\n",
      "epoch 104: (0.59905, 0.5668850023634276, 0.8395)\n",
      "epoch 105: (0.6202, 0.7177536231884057, 0.3962)\n",
      "epoch 106: (0.6011, 0.5689537580139136, 0.8342)\n",
      "epoch 107: (0.6183, 0.7186691312384473, 0.3888)\n",
      "epoch 108: (0.601, 0.5686141304347826, 0.837)\n",
      "epoch 109: (0.6164, 0.7269890795631825, 0.3728)\n",
      "epoch 110: (0.60145, 0.56811925065467, 0.8461)\n",
      "epoch 111: (0.6137, 0.721810378462739, 0.37)\n",
      "epoch 112: (0.60215, 0.5683140506921688, 0.8498)\n",
      "epoch 113: (0.61515, 0.7345691586881239, 0.3606)\n",
      "epoch 114: (0.6018, 0.5687187795328743, 0.8425)\n",
      "epoch 115: (0.616, 0.7344381568310429, 0.3634)\n",
      "epoch 116: (0.60195, 0.5682076670903861, 0.8493)\n",
      "epoch 117: (0.6169, 0.7340808970764918, 0.3666)\n",
      "epoch 118: (0.60125, 0.567441550656098, 0.8519)\n",
      "epoch 119: (0.6151, 0.7314032971451548, 0.3638)\n",
      "epoch 120: (0.60395, 0.57001414427157, 0.8463)\n",
      "epoch 121: (0.61605, 0.7354432947859606, 0.3625)\n",
      "epoch 122: (0.6031, 0.5687608376684007, 0.8528)\n",
      "epoch 123: (0.61665, 0.7294904583907141, 0.3708)\n",
      "epoch 124: (0.6042, 0.5696710350361059, 0.852)\n",
      "epoch 125: (0.617, 0.7315914489311164, 0.3696)\n",
      "epoch 126: (0.6045, 0.5705794947994056, 0.8448)\n",
      "epoch 127: (0.6142, 0.7401177460050462, 0.352)\n",
      "epoch 128: (0.60405, 0.5703373217062124, 0.8437)\n",
      "epoch 129: (0.61545, 0.7321536295998391, 0.3641)\n",
      "epoch 130: (0.60405, 0.5703183077650875, 0.8439)\n",
      "epoch 131: (0.61725, 0.7308525300255956, 0.3712)\n",
      "epoch 132: (0.6046, 0.570475677132462, 0.8467)\n",
      "epoch 133: (0.61675, 0.7376348463260737, 0.3624)\n",
      "epoch 134: (0.6049, 0.5714188453159041, 0.8393)\n",
      "epoch 135: (0.61645, 0.7365427584806012, 0.3626)\n",
      "epoch 136: (0.60575, 0.5713129678332997, 0.8472)\n",
      "epoch 137: (0.6163, 0.7352346278317152, 0.3635)\n",
      "epoch 138: (0.60465, 0.5705521472392638, 0.8463)\n",
      "epoch 139: (0.61805, 0.7312438785504407, 0.3733)\n",
      "epoch 140: (0.6051, 0.5701789529914529, 0.8539)\n",
      "epoch 141: (0.61735, 0.7339047239386087, 0.3682)\n",
      "epoch 142: (0.60475, 0.5702595747535046, 0.8502)\n",
      "epoch 143: (0.61845, 0.7253186227886628, 0.3813)\n",
      "epoch 144: (0.6053, 0.5713414634146341, 0.8433)\n",
      "epoch 145: (0.6185, 0.727972297037322, 0.3784)\n",
      "epoch 146: (0.60575, 0.5709493458570949, 0.851)\n",
      "epoch 147: (0.6186, 0.7267686424474188, 0.3801)\n",
      "epoch 148: (0.60555, 0.5713031142336013, 0.8457)\n",
      "epoch 149: (0.6192, 0.7329034779210629, 0.3751)\n",
      "epoch 150: (0.60375, 0.5700871444977369, 0.8439)\n",
      "epoch 151: (0.62015, 0.7342561902905049, 0.3766)\n",
      "epoch 152: (0.605, 0.5716136952666757, 0.8381)\n",
      "epoch 153: (0.6189, 0.7368525896414343, 0.3699)\n",
      "epoch 154: (0.60395, 0.5702602230483271, 0.8437)\n",
      "epoch 155: (0.6166, 0.733573717948718, 0.3662)\n",
      "epoch 156: (0.6055, 0.5715642382309049, 0.8426)\n",
      "epoch 157: (0.6185, 0.7360557768924303, 0.3695)\n",
      "epoch 158: (0.60495, 0.5710225350206402, 0.8438)\n",
      "epoch 159: (0.6184, 0.7395791177660866, 0.3655)\n",
      "epoch 160: (0.60695, 0.5722000945115777, 0.8476)\n",
      "epoch 161: (0.6191, 0.7381047580967613, 0.3692)\n",
      "epoch 162: (0.6072, 0.5728260869565217, 0.8432)\n",
      "epoch 163: (0.61835, 0.7294049234347741, 0.3763)\n",
      "epoch 164: (0.6074, 0.5730811105062602, 0.8422)\n",
      "epoch 165: (0.6177, 0.7291666666666666, 0.3745)\n",
      "epoch 166: (0.60695, 0.5727402570903897, 0.8421)\n",
      "epoch 167: (0.6172, 0.7321711568938193, 0.3696)\n",
      "epoch 168: (0.6071, 0.5726692902700502, 0.844)\n",
      "epoch 169: (0.6177, 0.7308748528834837, 0.3726)\n",
      "epoch 170: (0.6082, 0.5737459105779716, 0.8418)\n",
      "epoch 171: (0.6187, 0.7300387596899225, 0.3767)\n",
      "epoch 172: (0.6074, 0.5722356739305892, 0.8508)\n",
      "epoch 173: (0.61795, 0.7303261081819957, 0.374)\n",
      "epoch 174: (0.6063, 0.5711798580420517, 0.853)\n",
      "epoch 175: (0.6173, 0.7365873336022589, 0.3652)\n",
      "epoch 176: (0.60865, 0.5735065286516474, 0.8477)\n",
      "epoch 177: (0.61745, 0.7361753468731148, 0.3661)\n",
      "epoch 178: (0.60825, 0.5732656514382403, 0.847)\n",
      "epoch 179: (0.6185, 0.7312646370023419, 0.3747)\n",
      "epoch 180: (0.60815, 0.5733966745843231, 0.8449)\n",
      "epoch 181: (0.6185, 0.729918509895227, 0.3762)\n",
      "epoch 182: (0.6084, 0.573721436343852, 0.8436)\n",
      "epoch 183: (0.6199, 0.7293420045906657, 0.3813)\n",
      "epoch 184: (0.6063, 0.5715728521411257, 0.8489)\n",
      "epoch 185: (0.62095, 0.7321942791322711, 0.3814)\n",
      "epoch 186: (0.60725, 0.5727858839497795, 0.844)\n",
      "epoch 187: (0.62085, 0.7322698443205843, 0.381)\n",
      "epoch 188: (0.60715, 0.5728762837516154, 0.8423)\n",
      "epoch 189: (0.6222, 0.7379283489096573, 0.379)\n",
      "epoch 190: (0.6076, 0.5726928793406296, 0.8477)\n",
      "epoch 191: (0.62145, 0.7322623828647925, 0.3829)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 192: (0.60775, 0.5733342407949363, 0.8424)\n",
      "epoch 193: (0.6242, 0.7366615853658537, 0.3866)\n",
      "epoch 194: (0.60855, 0.5738184291057463, 0.8438)\n",
      "epoch 195: (0.62325, 0.7314553990610329, 0.3895)\n",
      "epoch 196: (0.60795, 0.5730033137215121, 0.8473)\n",
      "epoch 197: (0.6228, 0.7343511450381679, 0.3848)\n",
      "epoch 198: (0.60705, 0.572179893466388, 0.8486)\n",
      "epoch 199: (0.6248, 0.7421420256111758, 0.3825)\n",
      "epoch 200: (0.6083, 0.5721903746167177, 0.8584)\n",
      "epoch 201: (0.624, 0.738003838771593, 0.3845)\n",
      "epoch 202: (0.6073, 0.5713810537519958, 0.8589)\n",
      "epoch 203: (0.62155, 0.7416981507257904, 0.373)\n",
      "epoch 204: (0.60935, 0.5736016692468197, 0.8522)\n",
      "epoch 205: (0.62265, 0.7388510223953262, 0.3794)\n",
      "epoch 206: (0.60795, 0.5728456710979148, 0.8489)\n",
      "epoch 207: (0.62235, 0.7351527964635787, 0.3825)\n",
      "epoch 208: (0.6086, 0.5731805929919137, 0.8506)\n",
      "epoch 209: (0.61995, 0.7319667375749371, 0.3785)\n",
      "epoch 210: (0.60915, 0.5737749239607975, 0.8489)\n",
      "epoch 211: (0.61875, 0.7372627372627373, 0.369)\n",
      "epoch 212: (0.60915, 0.5737948752619836, 0.8487)\n",
      "epoch 213: (0.62095, 0.7364613880742913, 0.3767)\n",
      "epoch 214: (0.6083, 0.5727333781061115, 0.8528)\n",
      "epoch 215: (0.61965, 0.744034264735876, 0.3648)\n",
      "epoch 216: (0.6082, 0.5730291576673866, 0.849)\n",
      "epoch 217: (0.6196, 0.7366442421844084, 0.3723)\n",
      "epoch 218: (0.60715, 0.5722765598650927, 0.8484)\n",
      "epoch 219: (0.6209, 0.7343931756494766, 0.3788)\n",
      "epoch 220: (0.6079, 0.5730139396400055, 0.8468)\n",
      "epoch 221: (0.62145, 0.7345047306429813, 0.3804)\n",
      "epoch 222: (0.60865, 0.5735164760809256, 0.8476)\n",
      "epoch 223: (0.6204, 0.7461161079313164, 0.365)\n",
      "epoch 224: (0.60755, 0.5723706345468004, 0.8506)\n",
      "epoch 225: (0.6202, 0.7432213678672602, 0.3673)\n",
      "epoch 226: (0.6074, 0.5720998925886144, 0.8522)\n",
      "epoch 227: (0.62025, 0.7445596908684157, 0.3661)\n",
      "epoch 228: (0.6071, 0.571917808219178, 0.8517)\n",
      "epoch 229: (0.6217, 0.7411811335711455, 0.374)\n",
      "epoch 230: (0.6073, 0.5720811500738949, 0.8516)\n",
      "epoch 231: (0.621, 0.7384706346078045, 0.3747)\n",
      "epoch 232: (0.60865, 0.5734369719499831, 0.8484)\n",
      "epoch 233: (0.62105, 0.7397504456327986, 0.3735)\n",
      "epoch 234: (0.60795, 0.5726887078311225, 0.8505)\n",
      "epoch 235: (0.623, 0.7367205542725174, 0.3828)\n",
      "epoch 236: (0.6103, 0.5750953159041394, 0.8447)\n",
      "epoch 237: (0.62095, 0.7391734229780502, 0.3738)\n",
      "epoch 238: (0.60895, 0.5733719442386692, 0.8514)\n",
      "epoch 239: (0.62265, 0.740537360266719, 0.3776)\n",
      "epoch 240: (0.6091, 0.5739962018448183, 0.8463)\n",
      "epoch 241: (0.622, 0.7360681114551083, 0.3804)\n",
      "epoch 242: (0.6094, 0.5738191632928475, 0.8504)\n",
      "epoch 243: (0.62155, 0.7327206586253111, 0.3827)\n",
      "epoch 244: (0.61015, 0.5748454168648501, 0.846)\n",
      "epoch 245: (0.6211, 0.7368009385999218, 0.3768)\n",
      "epoch 246: (0.6097, 0.5746055495103374, 0.8449)\n",
      "epoch 247: (0.62265, 0.7350067062655681, 0.3836)\n",
      "epoch 248: (0.61055, 0.5753938484621155, 0.8437)\n",
      "epoch 249: (0.6239, 0.7366310160427807, 0.3857)\n",
      "epoch 250: (0.6107, 0.5761348005502063, 0.8377)\n",
      "epoch 251: (0.6233, 0.7386759581881533, 0.3816)\n",
      "epoch 252: (0.61045, 0.575018678258507, 0.8466)\n",
      "epoch 253: (0.62435, 0.743108504398827, 0.3801)\n",
      "epoch 254: (0.60775, 0.5719148368150571, 0.8569)\n",
      "epoch 255: (0.6261, 0.7431546471268801, 0.3854)\n",
      "epoch 256: (0.60835, 0.5727132407220992, 0.8534)\n",
      "epoch 257: (0.62575, 0.7411313518696069, 0.3865)\n",
      "epoch 258: (0.60745, 0.5722644428004573, 0.8509)\n",
      "epoch 259: (0.62655, 0.7411854392986469, 0.3889)\n",
      "epoch 260: (0.608, 0.5728057165970069, 0.8497)\n",
      "epoch 261: (0.6242, 0.7414463452566097, 0.3814)\n",
      "epoch 262: (0.6067, 0.5714764201500536, 0.8531)\n",
      "epoch 263: (0.6257, 0.7427578215527231, 0.3846)\n",
      "epoch 264: (0.60515, 0.5700392992739626, 0.8558)\n",
      "epoch 265: (0.62435, 0.7421616358325219, 0.3811)\n",
      "epoch 266: (0.60885, 0.5740224413464808, 0.8441)\n",
      "epoch 267: (0.62545, 0.736030103480715, 0.3912)\n",
      "epoch 268: (0.6073, 0.57156195811658, 0.857)\n",
      "epoch 269: (0.6243, 0.729844674556213, 0.3947)\n",
      "epoch 270: (0.60465, 0.569752716123442, 0.8548)\n",
      "epoch 271: (0.62485, 0.7365927610384688, 0.3887)\n",
      "epoch 272: (0.60505, 0.569982013190327, 0.8556)\n",
      "epoch 273: (0.625, 0.7310536044362292, 0.3955)\n",
      "epoch 274: (0.6071, 0.5720532831001076, 0.8503)\n",
      "epoch 275: (0.6244, 0.73941493456505, 0.3842)\n",
      "epoch 276: (0.60745, 0.5718584899351301, 0.8551)\n",
      "epoch 277: (0.62485, 0.7307336906301978, 0.3954)\n",
      "epoch 278: (0.6084, 0.5725568942436412, 0.8554)\n",
      "epoch 279: (0.6259, 0.7328032544378699, 0.3963)\n",
      "epoch 280: (0.60675, 0.5712283979448856, 0.8561)\n",
      "epoch 281: (0.62615, 0.7383336482146231, 0.3908)\n",
      "epoch 282: (0.60755, 0.5725268055836537, 0.849)\n",
      "epoch 283: (0.6269, 0.7443203696572969, 0.3866)\n",
      "epoch 284: (0.6062, 0.5714093598708984, 0.8498)\n",
      "epoch 285: (0.62845, 0.7510259917920656, 0.3843)\n",
      "epoch 286: (0.60685, 0.5722398756000271, 0.8464)\n",
      "epoch 287: (0.6279, 0.7525671406003159, 0.3811)\n",
      "epoch 288: (0.6064, 0.5717658168083097, 0.8477)\n",
      "epoch 289: (0.6287, 0.7434733257661748, 0.393)\n",
      "epoch 290: (0.60765, 0.572379479593895, 0.8513)\n",
      "epoch 291: (0.62795, 0.7501466275659824, 0.3837)\n",
      "epoch 292: (0.6062, 0.5706680862390205, 0.8576)\n",
      "epoch 293: (0.6287, 0.7439347990902199, 0.3925)\n",
      "epoch 294: (0.6075, 0.572244623655914, 0.8515)\n",
      "epoch 295: (0.62835, 0.7435021817491937, 0.3919)\n",
      "epoch 296: (0.608, 0.572337575351641, 0.8545)\n",
      "epoch 297: (0.62875, 0.7434297598789942, 0.3932)\n",
      "epoch 298: (0.6077, 0.5723304231027535, 0.8522)\n",
      "epoch 299: (0.62915, 0.7396548524772685, 0.3986)\n",
      "epoch 300: (0.6071, 0.5715048738149285, 0.856)\n",
      "epoch 301: (0.628, 0.741145440844009, 0.3934)\n",
      "epoch 302: (0.60735, 0.571801217309879, 0.8549)\n",
      "epoch 303: (0.62765, 0.74235807860262, 0.391)\n",
      "epoch 304: (0.6075, 0.5720895922746781, 0.8531)\n",
      "epoch 305: (0.6265, 0.7432692307692308, 0.3865)\n",
      "epoch 306: (0.6067, 0.5713330659179034, 0.8546)\n",
      "epoch 307: (0.62545, 0.7416682720092468, 0.385)\n",
      "epoch 308: (0.60695, 0.5715815541128438, 0.854)\n",
      "epoch 309: (0.62565, 0.7453622339386838, 0.3817)\n",
      "epoch 310: (0.6083, 0.5736233854520734, 0.8438)\n",
      "epoch 311: (0.62515, 0.7446725317693059, 0.3809)\n",
      "epoch 312: (0.6082, 0.57315753887762, 0.8477)\n",
      "epoch 313: (0.6247, 0.7376143292682927, 0.3871)\n",
      "epoch 314: (0.60745, 0.5721867651998657, 0.8517)\n",
      "epoch 315: (0.62665, 0.738737040527804, 0.3919)\n",
      "epoch 316: (0.60725, 0.5718881962598029, 0.8532)\n",
      "epoch 317: (0.6252, 0.7431067961165049, 0.3827)\n",
      "epoch 318: (0.6088, 0.5730888082762327, 0.8531)\n",
      "epoch 319: (0.62565, 0.741774100442563, 0.3855)\n",
      "epoch 320: (0.6109, 0.5746499730748519, 0.8537)\n",
      "epoch 321: (0.62645, 0.7403535449534309, 0.3895)\n",
      "epoch 322: (0.61, 0.5741639697950378, 0.8516)\n",
      "epoch 323: (0.62465, 0.7395733230828369, 0.3848)\n",
      "epoch 324: (0.61075, 0.5741944128090039, 0.8571)\n",
      "epoch 325: (0.62455, 0.7429295884532865, 0.3809)\n",
      "epoch 326: (0.6094, 0.574119241192412, 0.8474)\n",
      "epoch 327: (0.62605, 0.7452811831095544, 0.383)\n",
      "epoch 328: (0.60965, 0.574414658975229, 0.8464)\n",
      "epoch 329: (0.6276, 0.7418498862774829, 0.3914)\n",
      "epoch 330: (0.60915, 0.5729758641438791, 0.857)\n",
      "epoch 331: (0.62735, 0.7405099150141643, 0.3921)\n",
      "epoch 332: (0.6106, 0.5740889603429796, 0.857)\n",
      "epoch 333: (0.62785, 0.7390166386240419, 0.3953)\n",
      "epoch 334: (0.61035, 0.5736698043928166, 0.8593)\n",
      "epoch 335: (0.6294, 0.7380426784400295, 0.4012)\n",
      "epoch 336: (0.6086, 0.5721978460311129, 0.8607)\n",
      "epoch 337: (0.6279, 0.7431558935361217, 0.3909)\n",
      "epoch 338: (0.6079, 0.5717515627078069, 0.8598)\n",
      "epoch 339: (0.6286, 0.7373569582871908, 0.3995)\n",
      "epoch 340: (0.6066, 0.5708023379383634, 0.8594)\n",
      "epoch 341: (0.62885, 0.7364654064966049, 0.4013)\n",
      "epoch 342: (0.608, 0.5716180371352785, 0.862)\n",
      "epoch 343: (0.6277, 0.7425911854103343, 0.3909)\n",
      "epoch 344: (0.60845, 0.5717594124263878, 0.8641)\n",
      "epoch 345: (0.6278, 0.745674740484429, 0.3879)\n",
      "epoch 346: (0.6085, 0.5721601489757915, 0.8603)\n",
      "epoch 347: (0.6293, 0.7382092851879145, 0.4007)\n",
      "epoch 348: (0.608, 0.571193144363876, 0.8665)\n",
      "epoch 349: (0.62855, 0.7381878821567538, 0.3984)\n",
      "epoch 350: (0.6078, 0.5713718220338984, 0.863)\n",
      "epoch 351: (0.6251, 0.7413194444444444, 0.3843)\n",
      "epoch 352: (0.6077, 0.5719919786096257, 0.8557)\n",
      "epoch 353: (0.62475, 0.7465902352243526, 0.3777)\n",
      "epoch 354: (0.6096, 0.5736361193227627, 0.8538)\n",
      "epoch 355: (0.6241, 0.7422881686841077, 0.3802)\n",
      "epoch 356: (0.60785, 0.5720970653118524, 0.8558)\n",
      "epoch 357: (0.62415, 0.7410211609396233, 0.3817)\n",
      "epoch 358: (0.60795, 0.5723670979419454, 0.8538)\n",
      "epoch 359: (0.6256, 0.7397861779305078, 0.3875)\n",
      "epoch 360: (0.60865, 0.5729341478149963, 0.8535)\n",
      "epoch 361: (0.62575, 0.7270265390864777, 0.4027)\n",
      "epoch 362: (0.60945, 0.5743899952423027, 0.8451)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 363: (0.6258, 0.7368222891566265, 0.3914)\n",
      "epoch 364: (0.6095, 0.5734702093397746, 0.8547)\n",
      "epoch 365: (0.62445, 0.7404830917874397, 0.3832)\n",
      "epoch 366: (0.60895, 0.5734213895815082, 0.8509)\n",
      "epoch 367: (0.6256, 0.7370705926764817, 0.3905)\n",
      "epoch 368: (0.6095, 0.5741769407939303, 0.8476)\n",
      "epoch 369: (0.6261, 0.7389162561576355, 0.39)\n",
      "epoch 370: (0.61065, 0.5752056004893632, 0.8463)\n",
      "epoch 371: (0.6267, 0.7400530503978779, 0.3906)\n",
      "epoch 372: (0.6103, 0.5747188727814659, 0.8484)\n",
      "epoch 373: (0.6266, 0.7369011976047904, 0.3938)\n",
      "epoch 374: (0.60955, 0.5740252719778364, 0.8495)\n",
      "epoch 375: (0.6273, 0.7480514419329696, 0.3839)\n",
      "epoch 376: (0.608, 0.5728057165970069, 0.8497)\n",
      "epoch 377: (0.6273, 0.7475690392843252, 0.3844)\n",
      "epoch 378: (0.60835, 0.5726547307718098, 0.854)\n",
      "epoch 379: (0.62675, 0.7433288539066999, 0.3872)\n",
      "epoch 380: (0.60755, 0.5718484868728706, 0.856)\n",
      "epoch 381: (0.6254, 0.743495145631068, 0.3829)\n",
      "epoch 382: (0.6081, 0.5725016767270288, 0.8536)\n",
      "epoch 383: (0.6258, 0.7437039907012786, 0.3839)\n",
      "epoch 384: (0.6084, 0.5726541554959785, 0.8544)\n",
      "epoch 385: (0.62575, 0.7427137618220421, 0.3848)\n",
      "epoch 386: (0.60785, 0.5719431658995398, 0.8574)\n",
      "epoch 387: (0.6259, 0.733754177497215, 0.3952)\n",
      "epoch 388: (0.60965, 0.5738533036977167, 0.852)\n",
      "epoch 389: (0.6284, 0.7319364161849711, 0.4052)\n",
      "epoch 390: (0.6074, 0.5718490767995719, 0.8548)\n",
      "epoch 391: (0.6288, 0.7388724035608308, 0.3984)\n",
      "epoch 392: (0.60925, 0.5737527847161277, 0.8499)\n",
      "epoch 393: (0.6257, 0.735481453727988, 0.3926)\n",
      "epoch 394: (0.6082, 0.5724618269488347, 0.8548)\n",
      "epoch 395: (0.6256, 0.7504986039090547, 0.3763)\n",
      "epoch 396: (0.6082, 0.5729012262498315, 0.8503)\n",
      "epoch 397: (0.62485, 0.7461068401340429, 0.3785)\n",
      "epoch 398: (0.60875, 0.5729914759379824, 0.8537)\n",
      "epoch 399: (0.62615, 0.7424562752258312, 0.3863)\n",
      "epoch 0: (0.5363, 0.6485270049099836, 0.1585)\n",
      "epoch 1: (0.55295, 0.5399592483586144, 0.7155)\n",
      "epoch 2: (0.5512, 0.572934472934473, 0.4022)\n",
      "epoch 3: (0.55875, 0.5470489308881237, 0.6831)\n",
      "epoch 4: (0.55165, 0.5763262893453525, 0.39)\n",
      "epoch 5: (0.5519, 0.5381337252020573, 0.7324)\n",
      "epoch 6: (0.5589, 0.5880418535127055, 0.3934)\n",
      "epoch 7: (0.55295, 0.5376359371668207, 0.7564)\n",
      "epoch 8: (0.5661, 0.5985978520286396, 0.4013)\n",
      "epoch 9: (0.55625, 0.5393990334103803, 0.7701)\n",
      "epoch 10: (0.56965, 0.6043133143627377, 0.4035)\n",
      "epoch 11: (0.55865, 0.5404454865181711, 0.7837)\n",
      "epoch 12: (0.57435, 0.6127369219105383, 0.4041)\n",
      "epoch 13: (0.5603, 0.5412279502256256, 0.7916)\n",
      "epoch 14: (0.57585, 0.6162808523685421, 0.402)\n",
      "epoch 15: (0.5614, 0.541723294373471, 0.7972)\n",
      "epoch 16: (0.5785, 0.6221599751011516, 0.3998)\n",
      "epoch 17: (0.5623, 0.5420604914933838, 0.8029)\n",
      "epoch 18: (0.58125, 0.6276913405626277, 0.3994)\n",
      "epoch 19: (0.56315, 0.5424480742085098, 0.807)\n",
      "epoch 20: (0.58405, 0.6338162712943799, 0.3981)\n",
      "epoch 21: (0.56415, 0.5429125694026357, 0.8116)\n",
      "epoch 22: (0.58465, 0.6365542829488627, 0.3946)\n",
      "epoch 23: (0.56395, 0.5426361757450496, 0.8139)\n",
      "epoch 24: (0.5852, 0.6392611964694345, 0.3911)\n",
      "epoch 25: (0.56395, 0.5424268559676242, 0.8176)\n",
      "epoch 26: (0.5856, 0.6409749670619236, 0.3892)\n",
      "epoch 27: (0.564, 0.5424009540214655, 0.8187)\n",
      "epoch 28: (0.5859, 0.6418428005284016, 0.3887)\n",
      "epoch 29: (0.56465, 0.5427212053128924, 0.8213)\n",
      "epoch 30: (0.5867, 0.643828798938288, 0.3881)\n",
      "epoch 31: (0.56505, 0.5428722072101759, 0.8237)\n",
      "epoch 32: (0.5881, 0.6458609271523179, 0.3901)\n",
      "epoch 33: (0.56535, 0.5429397463696695, 0.8263)\n",
      "epoch 34: (0.5883, 0.6466290269013617, 0.3894)\n",
      "epoch 35: (0.56545, 0.5429377419143213, 0.8276)\n",
      "epoch 36: (0.5899, 0.6491373589913736, 0.3913)\n",
      "epoch 37: (0.5659, 0.5431734800838575, 0.8291)\n",
      "epoch 38: (0.59005, 0.6497090606816293, 0.3908)\n",
      "epoch 39: (0.5662, 0.5432962720732505, 0.8307)\n",
      "epoch 40: (0.5913, 0.6519640479360852, 0.3917)\n",
      "epoch 41: (0.56575, 0.5429485923313084, 0.8312)\n",
      "epoch 42: (0.5916, 0.6524633821571239, 0.392)\n",
      "epoch 43: (0.56575, 0.5428534184970345, 0.8329)\n",
      "epoch 44: (0.5926, 0.653667441088616, 0.3939)\n",
      "epoch 45: (0.56605, 0.5429985027016471, 0.8341)\n",
      "epoch 46: (0.59375, 0.6552409339294585, 0.3957)\n",
      "epoch 47: (0.5663, 0.5430128454651615, 0.837)\n",
      "epoch 48: (0.5936, 0.6561561561561562, 0.3933)\n",
      "epoch 49: (0.56605, 0.5427868109088554, 0.8379)\n",
      "epoch 50: (0.59385, 0.6567039572549674, 0.3933)\n",
      "epoch 51: (0.56635, 0.5429366466058371, 0.839)\n",
      "epoch 52: (0.5945, 0.6580267558528428, 0.3935)\n",
      "epoch 53: (0.5664, 0.5429106888975055, 0.8401)\n",
      "epoch 54: (0.595, 0.6597712748065927, 0.3923)\n",
      "epoch 55: (0.56665, 0.5429916790298652, 0.8418)\n",
      "epoch 56: (0.59535, 0.6607654695666835, 0.3919)\n",
      "epoch 57: (0.5667, 0.542910447761194, 0.8439)\n",
      "epoch 58: (0.59505, 0.6608563208664748, 0.3905)\n",
      "epoch 59: (0.5671, 0.5431067711679302, 0.8454)\n",
      "epoch 60: (0.59565, 0.662697737710495, 0.3896)\n",
      "epoch 61: (0.5671, 0.5430790960451978, 0.8459)\n",
      "epoch 62: (0.59585, 0.6634271099744246, 0.3891)\n",
      "epoch 63: (0.5669, 0.5428571428571428, 0.8474)\n",
      "epoch 64: (0.596, 0.6641025641025641, 0.3885)\n",
      "epoch 65: (0.56685, 0.5427785243488833, 0.8482)\n",
      "epoch 66: (0.5966, 0.6653543307086615, 0.3887)\n",
      "epoch 67: (0.56755, 0.5432209354405272, 0.849)\n",
      "epoch 68: (0.59645, 0.665238992633202, 0.3883)\n",
      "epoch 69: (0.5679, 0.5434254284983372, 0.8497)\n",
      "epoch 70: (0.5975, 0.6671810699588477, 0.3891)\n",
      "epoch 71: (0.568, 0.5434727017005498, 0.8501)\n",
      "epoch 72: (0.59795, 0.6685596282911719, 0.3885)\n",
      "epoch 73: (0.5684, 0.5437396086456069, 0.8503)\n",
      "epoch 74: (0.5983, 0.6699515905947441, 0.3875)\n",
      "epoch 75: (0.56815, 0.5435491085692377, 0.8506)\n",
      "epoch 76: (0.5988, 0.6709934233298719, 0.3877)\n",
      "epoch 77: (0.5683, 0.5436421725239616, 0.8508)\n",
      "epoch 78: (0.59875, 0.6715899218071243, 0.3865)\n",
      "epoch 79: (0.56805, 0.5434241592750941, 0.8516)\n",
      "epoch 80: (0.59885, 0.671763683753258, 0.3866)\n",
      "epoch 81: (0.5683, 0.5435920347204494, 0.8517)\n",
      "epoch 82: (0.59905, 0.67331583552056, 0.3848)\n",
      "epoch 83: (0.5682, 0.5435115477861426, 0.8519)\n",
      "epoch 84: (0.59945, 0.6743207712532866, 0.3847)\n",
      "epoch 85: (0.5679, 0.543281489036206, 0.8523)\n",
      "epoch 86: (0.5993, 0.6746394653534998, 0.3836)\n",
      "epoch 87: (0.56805, 0.5433688101459435, 0.8526)\n",
      "epoch 88: (0.5989, 0.6740584301302358, 0.383)\n",
      "epoch 89: (0.56785, 0.5432193133320594, 0.8528)\n",
      "epoch 90: (0.5993, 0.6754416961130743, 0.3823)\n",
      "epoch 91: (0.5681, 0.5433868501529052, 0.8529)\n",
      "epoch 92: (0.599, 0.6751592356687898, 0.3816)\n",
      "epoch 93: (0.568, 0.5433286606346375, 0.8527)\n",
      "epoch 94: (0.5988, 0.6749291784702549, 0.3812)\n",
      "epoch 95: (0.5679, 0.5432484076433121, 0.8529)\n",
      "epoch 96: (0.59835, 0.6750311443317316, 0.3793)\n",
      "epoch 97: (0.5681, 0.5433813224614601, 0.853)\n",
      "epoch 98: (0.5984, 0.6759656652360515, 0.378)\n",
      "epoch 99: (0.5683, 0.5435031847133758, 0.8533)\n",
      "epoch 100: (0.59815, 0.6762434907523792, 0.3766)\n",
      "epoch 101: (0.5682, 0.5434394904458598, 0.8532)\n",
      "epoch 102: (0.59865, 0.6768872153487538, 0.3775)\n",
      "epoch 103: (0.56815, 0.5433827742058692, 0.8536)\n",
      "epoch 104: (0.59855, 0.6768982229402262, 0.3771)\n",
      "epoch 105: (0.56845, 0.5435848455905763, 0.8537)\n",
      "epoch 106: (0.5984, 0.6768511861969806, 0.3766)\n",
      "epoch 107: (0.5688, 0.5438272391387438, 0.8537)\n",
      "epoch 108: (0.5984, 0.6769147788565264, 0.3765)\n",
      "epoch 109: (0.5689, 0.5438853503184713, 0.8539)\n",
      "epoch 110: (0.59845, 0.6771639373762822, 0.3763)\n",
      "epoch 111: (0.5693, 0.5441626306398165, 0.8539)\n",
      "epoch 112: (0.59835, 0.6772391421877816, 0.3758)\n",
      "epoch 113: (0.5697, 0.544445861497258, 0.8538)\n",
      "epoch 114: (0.59875, 0.6784101174345076, 0.3755)\n",
      "epoch 115: (0.5699, 0.5445904567491707, 0.8537)\n",
      "epoch 116: (0.59905, 0.6788228922188121, 0.376)\n",
      "epoch 117: (0.57015, 0.5447699278830812, 0.8536)\n",
      "epoch 118: (0.59905, 0.679081540408606, 0.3756)\n",
      "epoch 119: (0.57055, 0.5450424567451957, 0.8537)\n",
      "epoch 120: (0.59905, 0.679470918644682, 0.375)\n",
      "epoch 121: (0.57115, 0.5454603539709922, 0.8537)\n",
      "epoch 122: (0.5996, 0.6795241528478732, 0.377)\n",
      "epoch 123: (0.57115, 0.5454371288077144, 0.8541)\n",
      "epoch 124: (0.5998, 0.6799495131626397, 0.3771)\n",
      "epoch 125: (0.5713, 0.5455125750031916, 0.8546)\n",
      "epoch 126: (0.5993, 0.6790479624954923, 0.3766)\n",
      "epoch 127: (0.57145, 0.5456170593117539, 0.8546)\n",
      "epoch 128: (0.59955, 0.679920477137177, 0.3762)\n",
      "epoch 129: (0.5717, 0.545814696485623, 0.8542)\n",
      "epoch 130: (0.5997, 0.6800939306358381, 0.3765)\n",
      "epoch 131: (0.57195, 0.5459832555761488, 0.8543)\n",
      "epoch 132: (0.5995, 0.6799927641099855, 0.3759)\n",
      "epoch 133: (0.5722, 0.5461873080859775, 0.8538)\n",
      "epoch 134: (0.5994, 0.6805303305484925, 0.3747)\n",
      "epoch 135: (0.5724, 0.5463389656938044, 0.8536)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 136: (0.59955, 0.6805731906403047, 0.3752)\n",
      "epoch 137: (0.57245, 0.5463798732475513, 0.8535)\n",
      "epoch 138: (0.59945, 0.6807196074868254, 0.3746)\n",
      "epoch 139: (0.57245, 0.5464095829863558, 0.853)\n",
      "epoch 140: (0.59965, 0.6810830456114847, 0.3748)\n",
      "epoch 141: (0.5725, 0.5464267418032787, 0.8533)\n",
      "epoch 142: (0.59945, 0.6810486073184052, 0.3741)\n",
      "epoch 143: (0.57225, 0.546263687007748, 0.8531)\n",
      "epoch 144: (0.5997, 0.6816029143897996, 0.3742)\n",
      "epoch 145: (0.5725, 0.546462445526788, 0.8527)\n",
      "epoch 146: (0.5996, 0.6816192560175055, 0.3738)\n",
      "epoch 147: (0.5726, 0.5465444287729196, 0.8525)\n",
      "epoch 148: (0.59925, 0.6809480401093893, 0.3735)\n",
      "epoch 149: (0.57265, 0.5465854440525809, 0.8524)\n",
      "epoch 150: (0.59945, 0.6812465828321487, 0.3738)\n",
      "epoch 151: (0.5727, 0.5466204950622034, 0.8524)\n",
      "epoch 152: (0.5993, 0.6814692982456141, 0.3729)\n",
      "epoch 153: (0.57265, 0.5466093539488035, 0.852)\n",
      "epoch 154: (0.5992, 0.6810218978102189, 0.3732)\n",
      "epoch 155: (0.5724, 0.5464459840903259, 0.8518)\n",
      "epoch 156: (0.59925, 0.6811461945610513, 0.3732)\n",
      "epoch 157: (0.57245, 0.5464750785810507, 0.8519)\n",
      "epoch 158: (0.59895, 0.6807966380412936, 0.3726)\n",
      "epoch 159: (0.57245, 0.5464810418938859, 0.8518)\n",
      "epoch 160: (0.599, 0.6812522885389967, 0.3721)\n",
      "epoch 161: (0.57265, 0.546621318103061, 0.8518)\n",
      "epoch 162: (0.59905, 0.6813106351821343, 0.3722)\n",
      "epoch 163: (0.5727, 0.5466683784824753, 0.8516)\n",
      "epoch 164: (0.59905, 0.6811117206070579, 0.3725)\n",
      "epoch 165: (0.5726, 0.5465982028241335, 0.8516)\n",
      "epoch 166: (0.59895, 0.6808627307622007, 0.3725)\n",
      "epoch 167: (0.57275, 0.546709470304976, 0.8515)\n",
      "epoch 168: (0.5989, 0.6808705193855157, 0.3723)\n",
      "epoch 169: (0.5727, 0.5466683784824753, 0.8516)\n",
      "epoch 170: (0.5991, 0.6809054399415845, 0.373)\n",
      "epoch 171: (0.57285, 0.5467736757624398, 0.8516)\n",
      "epoch 172: (0.59905, 0.6811779769526248, 0.3724)\n",
      "epoch 173: (0.5729, 0.5468027734976888, 0.8517)\n",
      "epoch 174: (0.59905, 0.6814434878182818, 0.372)\n",
      "epoch 175: (0.57275, 0.5467034730692688, 0.8516)\n",
      "epoch 176: (0.5988, 0.6810850439882697, 0.3716)\n",
      "epoch 177: (0.5731, 0.5469552929085303, 0.8515)\n",
      "epoch 178: (0.59855, 0.6806599450045829, 0.3713)\n",
      "epoch 179: (0.57315, 0.5469783572024918, 0.8517)\n",
      "epoch 180: (0.59875, 0.6810929763432972, 0.3714)\n",
      "epoch 181: (0.57305, 0.546914135251429, 0.8516)\n",
      "epoch 182: (0.5985, 0.6807339449541284, 0.371)\n",
      "epoch 183: (0.573, 0.5468729934506228, 0.8517)\n",
      "epoch 184: (0.59875, 0.6813590449954087, 0.371)\n",
      "epoch 185: (0.5733, 0.5470595788392398, 0.8521)\n",
      "epoch 186: (0.599, 0.6814516129032258, 0.3718)\n",
      "epoch 187: (0.5731, 0.5469070841889117, 0.8523)\n",
      "epoch 188: (0.5989, 0.6812019054598755, 0.3718)\n",
      "epoch 189: (0.57325, 0.5470244591384734, 0.8521)\n",
      "epoch 190: (0.5986, 0.6807184750733137, 0.3714)\n",
      "epoch 191: (0.573, 0.5468489282505455, 0.8521)\n",
      "epoch 192: (0.5987, 0.680968096809681, 0.3714)\n",
      "epoch 193: (0.57315, 0.5469602619246324, 0.852)\n",
      "epoch 194: (0.59855, 0.6807262057582982, 0.3712)\n",
      "epoch 195: (0.5732, 0.5469953775038521, 0.852)\n",
      "epoch 196: (0.59865, 0.6813085829810697, 0.3707)\n",
      "epoch 197: (0.5731, 0.5469492614001285, 0.8516)\n",
      "epoch 198: (0.59855, 0.681592039800995, 0.3699)\n",
      "epoch 199: (0.5731, 0.5469492614001285, 0.8516)\n",
      "epoch 200: (0.5986, 0.6815837937384899, 0.3701)\n",
      "epoch 201: (0.5732, 0.5470255685468328, 0.8515)\n",
      "epoch 202: (0.59845, 0.6811407543698252, 0.3702)\n",
      "epoch 203: (0.5733, 0.5470837615621789, 0.8517)\n",
      "epoch 204: (0.59885, 0.6822119815668203, 0.3701)\n",
      "epoch 205: (0.57335, 0.5471128524632282, 0.8518)\n",
      "epoch 206: (0.5986, 0.6809838472834068, 0.371)\n",
      "epoch 207: (0.57355, 0.5472352450067433, 0.8521)\n",
      "epoch 208: (0.59895, 0.6820607175712972, 0.3707)\n",
      "epoch 209: (0.5738, 0.5474049331963001, 0.8522)\n",
      "epoch 210: (0.5989, 0.6820692194403535, 0.3705)\n",
      "epoch 211: (0.5736, 0.5472886147519918, 0.8518)\n",
      "epoch 212: (0.5988, 0.6816176470588236, 0.3708)\n",
      "epoch 213: (0.57355, 0.5472595257983679, 0.8517)\n",
      "epoch 214: (0.59875, 0.6819605675327068, 0.3701)\n",
      "epoch 215: (0.5736, 0.5473068517804345, 0.8515)\n",
      "epoch 216: (0.5988, 0.6824224519940916, 0.3696)\n",
      "epoch 217: (0.5736, 0.5472946921989461, 0.8517)\n",
      "epoch 218: (0.5986, 0.6819188191881919, 0.3696)\n",
      "epoch 219: (0.57345, 0.547195270834672, 0.8516)\n",
      "epoch 220: (0.5987, 0.6817679558011049, 0.3702)\n",
      "epoch 221: (0.5736, 0.5472946921989461, 0.8517)\n",
      "epoch 222: (0.59855, 0.6821289964886342, 0.3691)\n",
      "epoch 223: (0.5734, 0.5471540537067968, 0.8517)\n",
      "epoch 224: (0.5983, 0.6818349981502034, 0.3686)\n",
      "epoch 225: (0.57365, 0.5473176999678766, 0.8519)\n",
      "epoch 226: (0.5985, 0.6819357222016993, 0.3692)\n",
      "epoch 227: (0.5735, 0.5472365038560412, 0.8515)\n",
      "epoch 228: (0.59845, 0.6818097876269621, 0.3692)\n",
      "epoch 229: (0.57365, 0.5473237807620639, 0.8518)\n",
      "epoch 230: (0.5985, 0.6820702402957486, 0.369)\n",
      "epoch 231: (0.57375, 0.5473880357257598, 0.8519)\n",
      "epoch 232: (0.5984, 0.6814828476576908, 0.3695)\n",
      "epoch 233: (0.57355, 0.5472534532605204, 0.8518)\n",
      "epoch 234: (0.59835, 0.6813571823713812, 0.3695)\n",
      "epoch 235: (0.5736, 0.5472886147519918, 0.8518)\n",
      "epoch 236: (0.59835, 0.6812903225806451, 0.3696)\n",
      "epoch 237: (0.5738, 0.5474354030080987, 0.8517)\n",
      "epoch 238: (0.59845, 0.6818769628671716, 0.3691)\n",
      "epoch 239: (0.57325, 0.5470425791535547, 0.8518)\n",
      "epoch 240: (0.59845, 0.6817426619900314, 0.3693)\n",
      "epoch 241: (0.57385, 0.5474644900057845, 0.8518)\n",
      "epoch 242: (0.5983, 0.6814992614475628, 0.3691)\n",
      "epoch 243: (0.57385, 0.5474766955962713, 0.8516)\n",
      "epoch 244: (0.5981, 0.6812638580931264, 0.3687)\n",
      "epoch 245: (0.5738, 0.5474232103842693, 0.8519)\n",
      "epoch 246: (0.59835, 0.6818265853207617, 0.3688)\n",
      "epoch 247: (0.5738, 0.5474415016713808, 0.8516)\n",
      "epoch 248: (0.59825, 0.6816417082640044, 0.3687)\n",
      "epoch 249: (0.57365, 0.5473359470402982, 0.8516)\n",
      "epoch 250: (0.5985, 0.6820702402957486, 0.369)\n",
      "epoch 251: (0.57365, 0.5473481195756992, 0.8514)\n",
      "epoch 252: (0.59835, 0.6817593790426908, 0.3689)\n",
      "epoch 253: (0.5737, 0.5473772177937773, 0.8515)\n",
      "epoch 254: (0.59835, 0.6816922224274894, 0.369)\n",
      "epoch 255: (0.57375, 0.5474063122710034, 0.8516)\n",
      "epoch 256: (0.59825, 0.6815074819878071, 0.3689)\n",
      "epoch 257: (0.57405, 0.5476297678008619, 0.8514)\n",
      "epoch 258: (0.5983, 0.6817005545286506, 0.3688)\n",
      "epoch 259: (0.57365, 0.5473420325255512, 0.8515)\n",
      "epoch 260: (0.59865, 0.6823812164910334, 0.3691)\n",
      "epoch 261: (0.57385, 0.5474828007458368, 0.8515)\n",
      "epoch 262: (0.5986, 0.6823899371069182, 0.3689)\n",
      "epoch 263: (0.57375, 0.5474124075859852, 0.8515)\n",
      "epoch 264: (0.59845, 0.6824161571243283, 0.3683)\n",
      "epoch 265: (0.57355, 0.547283831565413, 0.8513)\n",
      "epoch 266: (0.5984, 0.6824249165739711, 0.3681)\n",
      "epoch 267: (0.57375, 0.5474124075859852, 0.8515)\n",
      "epoch 268: (0.59835, 0.6821633635858493, 0.3683)\n",
      "epoch 269: (0.5739, 0.5475180041152263, 0.8515)\n",
      "epoch 270: (0.5987, 0.6831168831168831, 0.3682)\n",
      "epoch 271: (0.5737, 0.5473772177937773, 0.8515)\n",
      "epoch 272: (0.59875, 0.683243644460939, 0.3682)\n",
      "epoch 273: (0.57365, 0.5473359470402982, 0.8516)\n",
      "epoch 274: (0.5988, 0.6827598964113948, 0.3691)\n",
      "epoch 275: (0.5737, 0.5473833097595474, 0.8514)\n",
      "epoch 276: (0.5988, 0.6828952239911144, 0.3689)\n",
      "epoch 277: (0.5736, 0.5473129339161739, 0.8514)\n",
      "epoch 278: (0.59885, 0.6828862164662349, 0.3691)\n",
      "epoch 279: (0.57345, 0.5472013366750209, 0.8515)\n",
      "epoch 280: (0.5986, 0.6824574389341229, 0.3688)\n",
      "epoch 281: (0.5735, 0.5472182962867789, 0.8518)\n",
      "epoch 282: (0.5986, 0.6823899371069182, 0.3689)\n",
      "epoch 283: (0.57345, 0.5471770826642688, 0.8519)\n",
      "epoch 284: (0.5987, 0.6823725055432373, 0.3693)\n",
      "epoch 285: (0.5736, 0.5472643205753918, 0.8522)\n",
      "epoch 286: (0.59915, 0.6831024930747922, 0.3699)\n",
      "epoch 287: (0.5735, 0.5471879815100154, 0.8523)\n",
      "epoch 288: (0.59895, 0.6828682313805211, 0.3695)\n",
      "epoch 289: (0.57385, 0.5474096424215189, 0.8527)\n",
      "epoch 290: (0.59905, 0.6829178208679594, 0.3698)\n",
      "epoch 291: (0.57405, 0.5475502472227574, 0.8527)\n",
      "epoch 292: (0.59905, 0.6829178208679594, 0.3698)\n",
      "epoch 293: (0.57395, 0.5474677450414018, 0.8529)\n",
      "epoch 294: (0.5989, 0.6825396825396826, 0.3698)\n",
      "epoch 295: (0.57365, 0.5472387916105446, 0.8532)\n",
      "epoch 296: (0.5988, 0.6824224519940916, 0.3696)\n",
      "epoch 297: (0.57355, 0.5471746520428452, 0.8531)\n",
      "epoch 298: (0.59905, 0.6829178208679594, 0.3698)\n",
      "epoch 299: (0.5735, 0.5471335128895729, 0.8532)\n",
      "epoch 300: (0.59905, 0.6825806451612904, 0.3703)\n",
      "epoch 301: (0.5735, 0.547139558748076, 0.8531)\n",
      "epoch 302: (0.59885, 0.6825484764542936, 0.3696)\n",
      "epoch 303: (0.57335, 0.5470282746682055, 0.8532)\n",
      "epoch 304: (0.5986, 0.6821877309682187, 0.3692)\n",
      "epoch 305: (0.57395, 0.5474312103136425, 0.8535)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 306: (0.5987, 0.6826424870466321, 0.3689)\n",
      "epoch 307: (0.5739, 0.5474082627662304, 0.8533)\n",
      "epoch 308: (0.5983, 0.682239525398591, 0.368)\n",
      "epoch 309: (0.5738, 0.5473501860644168, 0.8531)\n",
      "epoch 310: (0.59845, 0.6826191801150064, 0.368)\n",
      "epoch 311: (0.574, 0.547490694390964, 0.8531)\n",
      "epoch 312: (0.5986, 0.6827279466271312, 0.3684)\n",
      "epoch 313: (0.57385, 0.5473913880510813, 0.853)\n",
      "epoch 314: (0.59845, 0.6832991994042078, 0.367)\n",
      "epoch 315: (0.57405, 0.5475380368492008, 0.8529)\n",
      "epoch 316: (0.59865, 0.6836715695401229, 0.3672)\n",
      "epoch 317: (0.57385, 0.5474035560690673, 0.8528)\n",
      "epoch 318: (0.59865, 0.6836032011911409, 0.3673)\n",
      "epoch 319: (0.5739, 0.5474386955963538, 0.8528)\n",
      "epoch 320: (0.5986, 0.6835443037974683, 0.3672)\n",
      "epoch 321: (0.5738, 0.5473623411628803, 0.8529)\n",
      "epoch 322: (0.59865, 0.6838084591019191, 0.367)\n",
      "epoch 323: (0.5739, 0.5474326059050064, 0.8529)\n",
      "epoch 324: (0.5989, 0.6839657738095238, 0.3677)\n",
      "epoch 325: (0.57395, 0.5474738396353598, 0.8528)\n",
      "epoch 326: (0.59865, 0.6838769804287046, 0.3669)\n",
      "epoch 327: (0.57385, 0.5474096424215189, 0.8527)\n",
      "epoch 328: (0.59895, 0.6842987520953623, 0.3674)\n",
      "epoch 329: (0.57395, 0.5474799357945426, 0.8527)\n",
      "epoch 330: (0.59855, 0.6836221352711012, 0.3669)\n",
      "epoch 331: (0.57385, 0.5474157303370787, 0.8526)\n",
      "epoch 332: (0.59855, 0.683553734401192, 0.367)\n",
      "epoch 333: (0.57385, 0.5474096424215189, 0.8527)\n",
      "epoch 334: (0.59865, 0.6840141764596157, 0.3667)\n",
      "epoch 335: (0.5738, 0.5473805855161787, 0.8526)\n",
      "epoch 336: (0.59845, 0.6837096473222616, 0.3664)\n",
      "epoch 337: (0.57405, 0.5475502472227574, 0.8527)\n",
      "epoch 338: (0.5982, 0.6839640314724615, 0.3651)\n",
      "epoch 339: (0.574, 0.5475211918828666, 0.8526)\n",
      "epoch 340: (0.5984, 0.6841317365269461, 0.3656)\n",
      "epoch 341: (0.5741, 0.5475915221579961, 0.8526)\n",
      "epoch 342: (0.59875, 0.6846829998129792, 0.3661)\n",
      "epoch 343: (0.57415, 0.5476266940715524, 0.8526)\n",
      "epoch 344: (0.59835, 0.6842795578040097, 0.3652)\n",
      "epoch 345: (0.57415, 0.5476144609259616, 0.8528)\n",
      "epoch 346: (0.59855, 0.6842400448681997, 0.366)\n",
      "epoch 347: (0.57425, 0.547690924272593, 0.8527)\n",
      "epoch 348: (0.59855, 0.6844469399213925, 0.3657)\n",
      "epoch 349: (0.57405, 0.5475502472227574, 0.8527)\n",
      "epoch 350: (0.5985, 0.6844569288389513, 0.3655)\n",
      "epoch 351: (0.57415, 0.5476144609259616, 0.8528)\n",
      "epoch 352: (0.5985, 0.6844569288389513, 0.3655)\n",
      "epoch 353: (0.5742, 0.5476557482337829, 0.8527)\n",
      "epoch 354: (0.59855, 0.684654300168634, 0.3654)\n",
      "epoch 355: (0.574, 0.5475211918828666, 0.8526)\n",
      "epoch 356: (0.5986, 0.6847133757961783, 0.3655)\n",
      "epoch 357: (0.57415, 0.547632813001863, 0.8525)\n",
      "epoch 358: (0.59845, 0.6842597791502901, 0.3656)\n",
      "epoch 359: (0.574, 0.5475211918828666, 0.8526)\n",
      "epoch 360: (0.59845, 0.6844669289863219, 0.3653)\n",
      "epoch 361: (0.5743, 0.5477506426735218, 0.8523)\n",
      "epoch 362: (0.5982, 0.6841710427606902, 0.3648)\n",
      "epoch 363: (0.57455, 0.5479082321187584, 0.8526)\n",
      "epoch 364: (0.59835, 0.684417776111007, 0.365)\n",
      "epoch 365: (0.5743, 0.547732236926635, 0.8526)\n",
      "epoch 366: (0.59805, 0.6839242168448696, 0.3646)\n",
      "epoch 367: (0.5743, 0.547732236926635, 0.8526)\n",
      "epoch 368: (0.5983, 0.6842894638170228, 0.365)\n",
      "epoch 369: (0.57415, 0.547632813001863, 0.8525)\n",
      "epoch 370: (0.59845, 0.6846052878304894, 0.3651)\n",
      "epoch 371: (0.57435, 0.5477858474195, 0.8523)\n",
      "epoch 372: (0.5984, 0.6844769403824522, 0.3651)\n",
      "epoch 373: (0.5741, 0.5475976361767728, 0.8525)\n",
      "epoch 374: (0.5988, 0.6848802395209581, 0.366)\n",
      "epoch 375: (0.5742, 0.547674119763557, 0.8524)\n",
      "epoch 376: (0.59855, 0.6845160082381576, 0.3656)\n",
      "epoch 377: (0.5743, 0.5477199743095696, 0.8528)\n",
      "epoch 378: (0.5986, 0.6845059880239521, 0.3658)\n",
      "epoch 379: (0.57435, 0.5477735655079354, 0.8525)\n",
      "epoch 380: (0.5985, 0.6843878697117185, 0.3656)\n",
      "epoch 381: (0.57425, 0.5476970514550009, 0.8526)\n",
      "epoch 382: (0.59855, 0.6845160082381576, 0.3656)\n",
      "epoch 383: (0.57415, 0.5476450555805435, 0.8523)\n",
      "epoch 384: (0.59845, 0.6842597791502901, 0.3656)\n",
      "epoch 385: (0.57445, 0.5478439688966005, 0.8525)\n",
      "epoch 386: (0.59815, 0.6839048154393854, 0.365)\n",
      "epoch 387: (0.5743, 0.5477383705988178, 0.8525)\n",
      "epoch 388: (0.5986, 0.6846441947565544, 0.3656)\n",
      "epoch 389: (0.57445, 0.5478624236579878, 0.8522)\n",
      "epoch 390: (0.59805, 0.6838552409525596, 0.3647)\n",
      "epoch 391: (0.57445, 0.5478439688966005, 0.8525)\n",
      "epoch 392: (0.5985, 0.6845260397152492, 0.3654)\n",
      "epoch 393: (0.5745, 0.5478914888146053, 0.8523)\n",
      "epoch 394: (0.5986, 0.6847133757961783, 0.3655)\n",
      "epoch 395: (0.57445, 0.5478501189022431, 0.8524)\n",
      "epoch 396: (0.5984, 0.6845461365341335, 0.365)\n",
      "epoch 397: (0.5745, 0.5479099678456592, 0.852)\n",
      "epoch 398: (0.5983, 0.6843585896474118, 0.3649)\n",
      "epoch 399: (0.5741, 0.547603751766671, 0.8524)\n",
      "epoch 0: (0.5147, 0.6366171003717472, 0.0685)\n",
      "epoch 1: (0.52475, 0.5143920451241496, 0.8846)\n",
      "epoch 2: (0.55035, 0.6065608465608465, 0.2866)\n",
      "epoch 3: (0.55535, 0.5403513887876358, 0.7412)\n",
      "epoch 4: (0.57085, 0.6159384716085747, 0.3764)\n",
      "epoch 5: (0.55445, 0.5386691286130246, 0.7585)\n",
      "epoch 6: (0.564, 0.6361122926414292, 0.2991)\n",
      "epoch 7: (0.5554, 0.5385686438318017, 0.7736)\n",
      "epoch 8: (0.5639, 0.6324626865671642, 0.3051)\n",
      "epoch 9: (0.5578, 0.5395024603608529, 0.7894)\n",
      "epoch 10: (0.56775, 0.6311713455953534, 0.326)\n",
      "epoch 11: (0.56055, 0.5397075218047085, 0.823)\n",
      "epoch 12: (0.57185, 0.6455927051671733, 0.3186)\n",
      "epoch 13: (0.5593, 0.5381497683993824, 0.8365)\n",
      "epoch 14: (0.57445, 0.6545567780776417, 0.3153)\n",
      "epoch 15: (0.56225, 0.5399422521655438, 0.8415)\n",
      "epoch 16: (0.57235, 0.658003930989299, 0.3013)\n",
      "epoch 17: (0.5652, 0.5421733505821474, 0.8382)\n",
      "epoch 18: (0.5819, 0.6833855799373041, 0.3052)\n",
      "epoch 19: (0.5642, 0.5410485933503836, 0.8462)\n",
      "epoch 20: (0.58405, 0.6866533422163003, 0.3092)\n",
      "epoch 21: (0.5643, 0.5403640929064658, 0.8608)\n",
      "epoch 22: (0.5848, 0.6866197183098591, 0.312)\n",
      "epoch 23: (0.56325, 0.5391180654338549, 0.8717)\n",
      "epoch 24: (0.58745, 0.6848446417247939, 0.324)\n",
      "epoch 25: (0.5686, 0.542875, 0.8686)\n",
      "epoch 26: (0.5868, 0.6893542757417103, 0.316)\n",
      "epoch 27: (0.56755, 0.5417826436568318, 0.8759)\n",
      "epoch 28: (0.58665, 0.6877573131094258, 0.3174)\n",
      "epoch 29: (0.57255, 0.5449198192062411, 0.8801)\n",
      "epoch 30: (0.5877, 0.6814983443708609, 0.3293)\n",
      "epoch 31: (0.57285, 0.5451279192219538, 0.88)\n",
      "epoch 32: (0.5886, 0.6813344248874335, 0.3329)\n",
      "epoch 33: (0.5745, 0.5466850482516606, 0.8724)\n",
      "epoch 34: (0.5895, 0.680589184826473, 0.3373)\n",
      "epoch 35: (0.57315, 0.5452464897630976, 0.8815)\n",
      "epoch 36: (0.59405, 0.6864222001982161, 0.3463)\n",
      "epoch 37: (0.5734, 0.545387088795449, 0.882)\n",
      "epoch 38: (0.5954, 0.6962962962962963, 0.3384)\n",
      "epoch 39: (0.57515, 0.5465757669662225, 0.8819)\n",
      "epoch 40: (0.5964, 0.7017580577647551, 0.3353)\n",
      "epoch 41: (0.5761, 0.547056641108088, 0.8847)\n",
      "epoch 42: (0.59665, 0.7013122266194542, 0.3367)\n",
      "epoch 43: (0.5742, 0.5453545232273839, 0.8922)\n",
      "epoch 44: (0.5988, 0.7011400651465798, 0.3444)\n",
      "epoch 45: (0.57415, 0.5454656937887056, 0.8896)\n",
      "epoch 46: (0.59745, 0.6984320912237834, 0.343)\n",
      "epoch 47: (0.5762, 0.5468461822205828, 0.8895)\n",
      "epoch 48: (0.59745, 0.7006382540662961, 0.3403)\n",
      "epoch 49: (0.5762, 0.5465713237990466, 0.8943)\n",
      "epoch 50: (0.59905, 0.6998184385717168, 0.3469)\n",
      "epoch 51: (0.5724, 0.5439587128111718, 0.8959)\n",
      "epoch 52: (0.6007, 0.7035988677719369, 0.348)\n",
      "epoch 53: (0.5737, 0.5448405938184473, 0.8955)\n",
      "epoch 54: (0.60015, 0.6958732642284373, 0.3558)\n",
      "epoch 55: (0.57355, 0.5446596636104196, 0.897)\n",
      "epoch 56: (0.60395, 0.7036238981390793, 0.3592)\n",
      "epoch 57: (0.57835, 0.5483134981809212, 0.8892)\n",
      "epoch 58: (0.60255, 0.7029487433207995, 0.3552)\n",
      "epoch 59: (0.5782, 0.5479107952456806, 0.8943)\n",
      "epoch 60: (0.60525, 0.700897117770567, 0.3672)\n",
      "epoch 61: (0.57715, 0.5473283847616711, 0.8922)\n",
      "epoch 62: (0.60345, 0.6982180494347576, 0.3644)\n",
      "epoch 63: (0.57755, 0.5476673427991886, 0.891)\n",
      "epoch 64: (0.6024, 0.7043912175648702, 0.3529)\n",
      "epoch 65: (0.57795, 0.5480490661406645, 0.8891)\n",
      "epoch 66: (0.6044, 0.7066508313539193, 0.357)\n",
      "epoch 67: (0.57775, 0.5476263399693722, 0.894)\n",
      "epoch 68: (0.6045, 0.7063586097946287, 0.3577)\n",
      "epoch 69: (0.57865, 0.5481186907311104, 0.8959)\n",
      "epoch 70: (0.60605, 0.7179856115107913, 0.3493)\n",
      "epoch 71: (0.58205, 0.550027437351381, 0.9021)\n",
      "epoch 72: (0.60585, 0.7148366145727624, 0.3522)\n",
      "epoch 73: (0.5823, 0.5505963359154064, 0.8956)\n",
      "epoch 74: (0.60545, 0.728890818319948, 0.3358)\n",
      "epoch 75: (0.58435, 0.5518981111179475, 0.897)\n",
      "epoch 76: (0.6041, 0.7282894736842105, 0.3321)\n",
      "epoch 77: (0.58285, 0.5516617821288271, 0.8847)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 78: (0.6074, 0.7329718004338395, 0.3379)\n",
      "epoch 79: (0.584, 0.5517815312538528, 0.8951)\n",
      "epoch 80: (0.60645, 0.723775488753416, 0.3443)\n",
      "epoch 81: (0.5856, 0.5530885636318531, 0.8918)\n",
      "epoch 82: (0.6112, 0.7222222222222222, 0.3614)\n",
      "epoch 83: (0.58175, 0.5502798450089181, 0.8947)\n",
      "epoch 84: (0.61105, 0.7248430856448674, 0.358)\n",
      "epoch 85: (0.5805, 0.5489718943910451, 0.9024)\n",
      "epoch 86: (0.6103, 0.7215749296906389, 0.3592)\n",
      "epoch 87: (0.57975, 0.5483773127085229, 0.904)\n",
      "epoch 88: (0.61225, 0.7344892416962607, 0.3516)\n",
      "epoch 89: (0.57865, 0.547537020247809, 0.9059)\n",
      "epoch 90: (0.6115, 0.736228813559322, 0.3475)\n",
      "epoch 91: (0.5804, 0.548804176277771, 0.9041)\n",
      "epoch 92: (0.6123, 0.7350355797404772, 0.3512)\n",
      "epoch 93: (0.58265, 0.5506713260989516, 0.8982)\n",
      "epoch 94: (0.61225, 0.7294093603106478, 0.3569)\n",
      "epoch 95: (0.58195, 0.5504525026165117, 0.8941)\n",
      "epoch 96: (0.6144, 0.7292585170340682, 0.3639)\n",
      "epoch 97: (0.5791, 0.5483673718967836, 0.8968)\n",
      "epoch 98: (0.61595, 0.7185673892554194, 0.3812)\n",
      "epoch 99: (0.58085, 0.5496347228190803, 0.8953)\n",
      "epoch 100: (0.6156, 0.7180309317238778, 0.3807)\n",
      "epoch 101: (0.58165, 0.5499541144080758, 0.8989)\n",
      "epoch 102: (0.6156, 0.7200228397411496, 0.3783)\n",
      "epoch 103: (0.58115, 0.5498740089730195, 0.8947)\n",
      "epoch 104: (0.61315, 0.7290022262699858, 0.3602)\n",
      "epoch 105: (0.57875, 0.5478229185644016, 0.9021)\n",
      "epoch 106: (0.6142, 0.7324918566775245, 0.3598)\n",
      "epoch 107: (0.57915, 0.5481946051269561, 0.9003)\n",
      "epoch 108: (0.61365, 0.7294568948112256, 0.3613)\n",
      "epoch 109: (0.5789, 0.5480687218228342, 0.8996)\n",
      "epoch 110: (0.61415, 0.7210923881464265, 0.3723)\n",
      "epoch 111: (0.5816, 0.549792531120332, 0.901)\n",
      "epoch 112: (0.61305, 0.7195571955719557, 0.3705)\n",
      "epoch 113: (0.5808, 0.5493404982901807, 0.8996)\n",
      "epoch 114: (0.6132, 0.7241584158415841, 0.3657)\n",
      "epoch 115: (0.585, 0.5524756142733671, 0.8949)\n",
      "epoch 116: (0.6112, 0.7202852614896988, 0.3636)\n",
      "epoch 117: (0.5853, 0.5528042590070571, 0.893)\n",
      "epoch 118: (0.6115, 0.7330685618729097, 0.3507)\n",
      "epoch 119: (0.58505, 0.5527180313642844, 0.8917)\n",
      "epoch 120: (0.6112, 0.7342038753159225, 0.3486)\n",
      "epoch 121: (0.58285, 0.5509313333743161, 0.8962)\n",
      "epoch 122: (0.6136, 0.7365680966264057, 0.3537)\n",
      "epoch 123: (0.5836, 0.5512694713602355, 0.8989)\n",
      "epoch 124: (0.6151, 0.7272906793048973, 0.3683)\n",
      "epoch 125: (0.58285, 0.551025435733202, 0.8947)\n",
      "epoch 126: (0.614, 0.7230046948356808, 0.3696)\n",
      "epoch 127: (0.5828, 0.5509915014164306, 0.8947)\n",
      "epoch 128: (0.615, 0.7338348922326149, 0.3609)\n",
      "epoch 129: (0.5837, 0.5517369266905674, 0.8926)\n",
      "epoch 130: (0.6137, 0.7255952380952381, 0.3657)\n",
      "epoch 131: (0.58705, 0.5537843682421996, 0.8963)\n",
      "epoch 132: (0.6134, 0.7267093162734906, 0.3635)\n",
      "epoch 133: (0.58665, 0.5538901672989613, 0.8906)\n",
      "epoch 134: (0.614, 0.7418328383538396, 0.3497)\n",
      "epoch 135: (0.5904, 0.5568267538345486, 0.8858)\n",
      "epoch 136: (0.61565, 0.7346317711503347, 0.3621)\n",
      "epoch 137: (0.59085, 0.5571132205947067, 0.8862)\n",
      "epoch 138: (0.61075, 0.734689552871371, 0.3467)\n",
      "epoch 139: (0.59075, 0.5567435753141999, 0.8904)\n",
      "epoch 140: (0.6124, 0.7351464435146443, 0.3514)\n",
      "epoch 141: (0.59165, 0.5576886762762007, 0.886)\n",
      "epoch 142: (0.6097, 0.7404647084612013, 0.3378)\n",
      "epoch 143: (0.59245, 0.5583907029621676, 0.8841)\n",
      "epoch 144: (0.61195, 0.7354363827549948, 0.3497)\n",
      "epoch 145: (0.59265, 0.5584284543103992, 0.8855)\n",
      "epoch 146: (0.6124, 0.7385398981324278, 0.348)\n",
      "epoch 147: (0.5924, 0.5578657314629258, 0.8908)\n",
      "epoch 148: (0.61125, 0.7379679144385026, 0.345)\n",
      "epoch 149: (0.5919, 0.5575237856785178, 0.8907)\n",
      "epoch 150: (0.6135, 0.7346980976013234, 0.3553)\n",
      "epoch 151: (0.58895, 0.5551764778859872, 0.895)\n",
      "epoch 152: (0.6124, 0.7374313476975074, 0.3491)\n",
      "epoch 153: (0.59085, 0.5568986033694495, 0.8892)\n",
      "epoch 154: (0.61365, 0.7375130616509927, 0.3529)\n",
      "epoch 155: (0.59045, 0.5565701419726061, 0.8899)\n",
      "epoch 156: (0.61415, 0.735215330723264, 0.3568)\n",
      "epoch 157: (0.593, 0.5586232980332829, 0.8862)\n",
      "epoch 158: (0.61525, 0.7385634444214448, 0.3568)\n",
      "epoch 159: (0.5925, 0.5581687838007797, 0.8876)\n",
      "epoch 160: (0.6163, 0.7385151763740772, 0.3601)\n",
      "epoch 161: (0.59075, 0.557389489660406, 0.8814)\n",
      "epoch 162: (0.6136, 0.7307067424857839, 0.3598)\n",
      "epoch 163: (0.5892, 0.5558617234468938, 0.8876)\n",
      "epoch 164: (0.6129, 0.7347193347193347, 0.3534)\n",
      "epoch 165: (0.5874, 0.5543262058677275, 0.8918)\n",
      "epoch 166: (0.61425, 0.7346477716163483, 0.3577)\n",
      "epoch 167: (0.59005, 0.5563552162212905, 0.889)\n",
      "epoch 168: (0.6138, 0.7416135881104033, 0.3493)\n",
      "epoch 169: (0.5903, 0.5564586720020007, 0.89)\n",
      "epoch 170: (0.61435, 0.7381795459279317, 0.3544)\n",
      "epoch 171: (0.59065, 0.5564340409637054, 0.8938)\n",
      "epoch 172: (0.6148, 0.7354388843314192, 0.3586)\n",
      "epoch 173: (0.59045, 0.5564289724873667, 0.8919)\n",
      "epoch 174: (0.61585, 0.7370574994884387, 0.3602)\n",
      "epoch 175: (0.5937, 0.5590571032396319, 0.887)\n",
      "epoch 176: (0.6146, 0.7417721518987341, 0.3516)\n",
      "epoch 177: (0.5909, 0.5572851020922611, 0.8843)\n",
      "epoch 178: (0.61515, 0.7321104616004838, 0.3632)\n",
      "epoch 179: (0.59125, 0.5573430528498712, 0.8869)\n",
      "epoch 180: (0.61735, 0.7392456676860346, 0.3626)\n",
      "epoch 181: (0.59, 0.5559910414333706, 0.8937)\n",
      "epoch 182: (0.6162, 0.7451476793248946, 0.3532)\n",
      "epoch 183: (0.58925, 0.555417572182552, 0.8945)\n",
      "epoch 184: (0.6169, 0.7390593047034765, 0.3614)\n",
      "epoch 185: (0.58915, 0.555218333849489, 0.8964)\n",
      "epoch 186: (0.6157, 0.7376746096959738, 0.3591)\n",
      "epoch 187: (0.5884, 0.5547639697683063, 0.8955)\n",
      "epoch 188: (0.6174, 0.7328441094803649, 0.3695)\n",
      "epoch 189: (0.5884, 0.5550367326609389, 0.8915)\n",
      "epoch 190: (0.61845, 0.7359091814379606, 0.3695)\n",
      "epoch 191: (0.58995, 0.5560191816653173, 0.8928)\n",
      "epoch 192: (0.61855, 0.7356390379646194, 0.3701)\n",
      "epoch 193: (0.59145, 0.5568612820991109, 0.8956)\n",
      "epoch 194: (0.61835, 0.7371268282909237, 0.3679)\n",
      "epoch 195: (0.5935, 0.5585399449035813, 0.8921)\n",
      "epoch 196: (0.61855, 0.7268031375550029, 0.3799)\n",
      "epoch 197: (0.5936, 0.5583104909045602, 0.8962)\n",
      "epoch 198: (0.6192, 0.7234720659917511, 0.3859)\n",
      "epoch 199: (0.59115, 0.5569225004683694, 0.8918)\n",
      "epoch 200: (0.6184, 0.7211430706014195, 0.3861)\n",
      "epoch 201: (0.59255, 0.5579342723004694, 0.8913)\n",
      "epoch 202: (0.6187, 0.7268730886850153, 0.3803)\n",
      "epoch 203: (0.59185, 0.5574385591895441, 0.8914)\n",
      "epoch 204: (0.6193, 0.7301311728395061, 0.3785)\n",
      "epoch 205: (0.5908, 0.5566508609932618, 0.8922)\n",
      "epoch 206: (0.6189, 0.7438474159146842, 0.3627)\n",
      "epoch 207: (0.5905, 0.5562810945273632, 0.8945)\n",
      "epoch 208: (0.619, 0.7435530085959885, 0.3633)\n",
      "epoch 209: (0.59055, 0.5564913594110674, 0.892)\n",
      "epoch 210: (0.61855, 0.7426816786079836, 0.3628)\n",
      "epoch 211: (0.5904, 0.5565919619381495, 0.8891)\n",
      "epoch 212: (0.6181, 0.7435051546391752, 0.3606)\n",
      "epoch 213: (0.5906, 0.5563012677106637, 0.8952)\n",
      "epoch 214: (0.6192, 0.7406136455389584, 0.3669)\n",
      "epoch 215: (0.5917, 0.5574417439238286, 0.8899)\n",
      "epoch 216: (0.61875, 0.7399474641341686, 0.3662)\n",
      "epoch 217: (0.59105, 0.5568600512083932, 0.8917)\n",
      "epoch 218: (0.61975, 0.7389742566354021, 0.3703)\n",
      "epoch 219: (0.59135, 0.5568698250638112, 0.8945)\n",
      "epoch 220: (0.61975, 0.7466529351184346, 0.3625)\n",
      "epoch 221: (0.5925, 0.557848655409631, 0.892)\n",
      "epoch 222: (0.62085, 0.7413620930697025, 0.3712)\n",
      "epoch 223: (0.5909, 0.5563406470806992, 0.8976)\n",
      "epoch 224: (0.62225, 0.7382576495809784, 0.3788)\n",
      "epoch 225: (0.5907, 0.5559393117059331, 0.9014)\n",
      "epoch 226: (0.6192, 0.7411003236245954, 0.3664)\n",
      "epoch 227: (0.59185, 0.5567992084595882, 0.9004)\n",
      "epoch 228: (0.619, 0.7440525020508614, 0.3628)\n",
      "epoch 229: (0.59205, 0.5570640381873412, 0.8986)\n",
      "epoch 230: (0.6192, 0.7411978955888304, 0.3663)\n",
      "epoch 231: (0.5927, 0.5580827067669173, 0.8907)\n",
      "epoch 232: (0.61845, 0.749211024616032, 0.3561)\n",
      "epoch 233: (0.59105, 0.5567891224349779, 0.8927)\n",
      "epoch 234: (0.6181, 0.7408238172920065, 0.3633)\n",
      "epoch 235: (0.59225, 0.5573801082291472, 0.8961)\n",
      "epoch 236: (0.61875, 0.7404332860903017, 0.3657)\n",
      "epoch 237: (0.59245, 0.5575402999937761, 0.8958)\n",
      "epoch 238: (0.6184, 0.7342698852394143, 0.3711)\n",
      "epoch 239: (0.59225, 0.5576526467095807, 0.8923)\n",
      "epoch 240: (0.6191, 0.7417783191230207, 0.3654)\n",
      "epoch 241: (0.5916, 0.5571072319201995, 0.8936)\n",
      "epoch 242: (0.6194, 0.7445718967636215, 0.3635)\n",
      "epoch 243: (0.5908, 0.5566084788029925, 0.8928)\n",
      "epoch 244: (0.61945, 0.7495299770210988, 0.3588)\n",
      "epoch 245: (0.59155, 0.5572366364488903, 0.8913)\n",
      "epoch 246: (0.61915, 0.7520626189972498, 0.3555)\n",
      "epoch 247: (0.5903, 0.5561497326203209, 0.8944)\n",
      "epoch 248: (0.61865, 0.7487942964982176, 0.3571)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 249: (0.59095, 0.556592620247651, 0.8945)\n",
      "epoch 250: (0.61865, 0.7467248908296943, 0.3591)\n",
      "epoch 251: (0.59085, 0.5567706055114666, 0.891)\n",
      "epoch 252: (0.61885, 0.7457101509199917, 0.3607)\n",
      "epoch 253: (0.59115, 0.5565061062550369, 0.8977)\n",
      "epoch 254: (0.6193, 0.7340133385641427, 0.3742)\n",
      "epoch 255: (0.5935, 0.5585913021681915, 0.8914)\n",
      "epoch 256: (0.6194, 0.7366230677764566, 0.3717)\n",
      "epoch 257: (0.59235, 0.5580051504302493, 0.8884)\n",
      "epoch 258: (0.6207, 0.743052758759565, 0.369)\n",
      "epoch 259: (0.59275, 0.5583663709017683, 0.8873)\n",
      "epoch 260: (0.61815, 0.743056984159638, 0.3612)\n",
      "epoch 261: (0.59375, 0.5594822663536577, 0.8818)\n",
      "epoch 262: (0.6189, 0.7429505516959543, 0.3636)\n",
      "epoch 263: (0.59165, 0.5576668973762033, 0.8863)\n",
      "epoch 264: (0.6194, 0.7424857839155159, 0.3656)\n",
      "epoch 265: (0.5916, 0.557523235367998, 0.8878)\n",
      "epoch 266: (0.62085, 0.7326275264677574, 0.3806)\n",
      "epoch 267: (0.59245, 0.5581775847964257, 0.887)\n",
      "epoch 268: (0.62195, 0.7336654531519449, 0.3829)\n",
      "epoch 269: (0.59155, 0.5574017179760486, 0.889)\n",
      "epoch 270: (0.62275, 0.7322611163670766, 0.387)\n",
      "epoch 271: (0.59175, 0.5572471454420665, 0.8931)\n",
      "epoch 272: (0.62295, 0.7361244478586518, 0.3833)\n",
      "epoch 273: (0.5904, 0.5557267907779558, 0.9015)\n",
      "epoch 274: (0.62235, 0.7373423860329776, 0.3801)\n",
      "epoch 275: (0.5909, 0.5562569624953584, 0.8988)\n",
      "epoch 276: (0.6226, 0.7367709540363074, 0.3815)\n",
      "epoch 277: (0.59375, 0.5588770960246184, 0.8899)\n",
      "epoch 278: (0.6219, 0.73715953307393, 0.3789)\n",
      "epoch 279: (0.591, 0.5564236111111112, 0.8974)\n",
      "epoch 280: (0.62215, 0.7405000984445756, 0.3761)\n",
      "epoch 281: (0.5899, 0.5559706138712489, 0.893)\n",
      "epoch 282: (0.62265, 0.7397849462365591, 0.3784)\n",
      "epoch 283: (0.59015, 0.5561367457500467, 0.8931)\n",
      "epoch 284: (0.62165, 0.7393271689946882, 0.3758)\n",
      "epoch 285: (0.5903, 0.5565718581631375, 0.8884)\n",
      "epoch 286: (0.6227, 0.7376065065840434, 0.3809)\n",
      "epoch 287: (0.58835, 0.5547771095542191, 0.8948)\n",
      "epoch 288: (0.62285, 0.7388683647676454, 0.38)\n",
      "epoch 289: (0.58895, 0.5554862453995384, 0.8905)\n",
      "epoch 290: (0.62325, 0.7390882638215325, 0.381)\n",
      "epoch 291: (0.5887, 0.5551411164988188, 0.893)\n",
      "epoch 292: (0.6252, 0.7441497659906396, 0.3816)\n",
      "epoch 293: (0.59, 0.555942317255097, 0.8944)\n",
      "epoch 294: (0.62445, 0.7333583348959309, 0.3911)\n",
      "epoch 295: (0.59005, 0.5557826921885647, 0.8972)\n",
      "epoch 296: (0.62425, 0.7311627906976744, 0.393)\n",
      "epoch 297: (0.5929, 0.55806975871984, 0.8928)\n",
      "epoch 298: (0.6205, 0.7485561056105611, 0.3629)\n",
      "epoch 299: (0.59265, 0.5578809270943962, 0.893)\n",
      "epoch 300: (0.62145, 0.7518142235123367, 0.3626)\n",
      "epoch 301: (0.5912, 0.5568153501121356, 0.8938)\n",
      "epoch 302: (0.623, 0.7455089820359282, 0.3735)\n",
      "epoch 303: (0.5916, 0.5573001376204179, 0.8909)\n",
      "epoch 304: (0.6225, 0.7509217533797624, 0.3666)\n",
      "epoch 305: (0.58975, 0.5558737471207122, 0.8929)\n",
      "epoch 306: (0.62095, 0.7463841922998574, 0.3664)\n",
      "epoch 307: (0.59235, 0.5576863014554313, 0.8928)\n",
      "epoch 308: (0.62085, 0.750674133997096, 0.3619)\n",
      "epoch 309: (0.59175, 0.5572471454420665, 0.8931)\n",
      "epoch 310: (0.62065, 0.751616266944734, 0.3604)\n",
      "epoch 311: (0.5908, 0.5564255530698484, 0.8954)\n",
      "epoch 312: (0.6198, 0.7473162675474814, 0.362)\n",
      "epoch 313: (0.592, 0.5576730190571715, 0.8896)\n",
      "epoch 314: (0.62175, 0.7535930014580295, 0.3618)\n",
      "epoch 315: (0.5929, 0.5578023892483823, 0.8965)\n",
      "epoch 316: (0.6233, 0.7522504091653028, 0.3677)\n",
      "epoch 317: (0.591, 0.5563397721644379, 0.8986)\n",
      "epoch 318: (0.62345, 0.7575631128729398, 0.3631)\n",
      "epoch 319: (0.5909, 0.5563616071428571, 0.8973)\n",
      "epoch 320: (0.62235, 0.7653437432227282, 0.3529)\n",
      "epoch 321: (0.5915, 0.5567829216830086, 0.8972)\n",
      "epoch 322: (0.623, 0.7704485488126649, 0.3504)\n",
      "epoch 323: (0.592, 0.557299451918286, 0.8948)\n",
      "epoch 324: (0.62265, 0.7464335945348604, 0.3715)\n",
      "epoch 325: (0.59205, 0.5577007459412023, 0.8897)\n",
      "epoch 326: (0.62215, 0.747417459995949, 0.369)\n",
      "epoch 327: (0.5916, 0.5571999500437117, 0.8923)\n",
      "epoch 328: (0.6223, 0.7476711219117051, 0.3692)\n",
      "epoch 329: (0.59235, 0.5577946054196132, 0.8913)\n",
      "epoch 330: (0.6223, 0.7483753046303818, 0.3685)\n",
      "epoch 331: (0.5923, 0.5572864945382324, 0.8979)\n",
      "epoch 332: (0.62075, 0.7431044896315684, 0.3691)\n",
      "epoch 333: (0.59455, 0.559245566764835, 0.8925)\n",
      "epoch 334: (0.6183, 0.7492625368731564, 0.3556)\n",
      "epoch 335: (0.59495, 0.5596307228537336, 0.8911)\n",
      "epoch 336: (0.62015, 0.7497401787570152, 0.3607)\n",
      "epoch 337: (0.5976, 0.5618975139523085, 0.886)\n",
      "epoch 338: (0.6193, 0.7460808580858086, 0.3617)\n",
      "epoch 339: (0.5971, 0.5616429659725749, 0.8847)\n",
      "epoch 340: (0.61975, 0.7516284933809624, 0.3577)\n",
      "epoch 341: (0.5954, 0.5602653190145294, 0.8869)\n",
      "epoch 342: (0.61945, 0.75131495897328, 0.3571)\n",
      "epoch 343: (0.5965, 0.5607606094950258, 0.8906)\n",
      "epoch 344: (0.621, 0.7608883139284174, 0.3529)\n",
      "epoch 345: (0.59245, 0.5577704180466163, 0.8926)\n",
      "epoch 346: (0.6194, 0.7588898525585429, 0.35)\n",
      "epoch 347: (0.5938, 0.5587645658438792, 0.8919)\n",
      "epoch 348: (0.619, 0.7566867989646247, 0.3508)\n",
      "epoch 349: (0.5949, 0.5597531797002896, 0.889)\n",
      "epoch 350: (0.61995, 0.7624152264274776, 0.3485)\n",
      "epoch 351: (0.5963, 0.5606270460841098, 0.8905)\n",
      "epoch 352: (0.61885, 0.7638179800221976, 0.3441)\n",
      "epoch 353: (0.596, 0.5603621730382293, 0.8912)\n",
      "epoch 354: (0.62005, 0.7663634346571999, 0.3454)\n",
      "epoch 355: (0.59545, 0.5597122302158274, 0.8947)\n",
      "epoch 356: (0.6187, 0.7622624834290764, 0.345)\n",
      "epoch 357: (0.5958, 0.5603654694391934, 0.8893)\n",
      "epoch 358: (0.6179, 0.7702888583218707, 0.336)\n",
      "epoch 359: (0.59825, 0.5623057898408269, 0.8867)\n",
      "epoch 360: (0.6179, 0.7666214382632293, 0.339)\n",
      "epoch 361: (0.59865, 0.5626070952592499, 0.8865)\n",
      "epoch 362: (0.619, 0.7597119161938019, 0.3481)\n",
      "epoch 363: (0.598, 0.5619704059693942, 0.8887)\n",
      "epoch 364: (0.6194, 0.758777633289987, 0.3501)\n",
      "epoch 365: (0.5979, 0.5622377622377622, 0.8844)\n",
      "epoch 366: (0.6194, 0.7512626262626263, 0.357)\n",
      "epoch 367: (0.5991, 0.5631290610268824, 0.884)\n",
      "epoch 368: (0.6189, 0.7575823223570191, 0.3497)\n",
      "epoch 369: (0.5981, 0.5623094512195121, 0.8853)\n",
      "epoch 370: (0.62015, 0.7610254182055182, 0.3503)\n",
      "epoch 371: (0.59695, 0.5612483416513994, 0.8884)\n",
      "epoch 372: (0.62155, 0.7598888176181313, 0.3554)\n",
      "epoch 373: (0.59695, 0.561567282657014, 0.8843)\n",
      "epoch 374: (0.6212, 0.7605331040412726, 0.3538)\n",
      "epoch 375: (0.5979, 0.562024835276229, 0.8871)\n",
      "epoch 376: (0.62285, 0.7475317348377997, 0.371)\n",
      "epoch 377: (0.59835, 0.5621327942384231, 0.8898)\n",
      "epoch 378: (0.6233, 0.7465013994402239, 0.3734)\n",
      "epoch 379: (0.5998, 0.5631725534877833, 0.8897)\n",
      "epoch 380: (0.62305, 0.7450707030472018, 0.3741)\n",
      "epoch 381: (0.5981, 0.5620336410775263, 0.8888)\n",
      "epoch 382: (0.62335, 0.7508643481797844, 0.3692)\n",
      "epoch 383: (0.59705, 0.5611184583412053, 0.891)\n",
      "epoch 384: (0.62305, 0.7504579686545899, 0.3687)\n",
      "epoch 385: (0.59715, 0.5610814209368123, 0.8924)\n",
      "epoch 386: (0.62135, 0.7547764014276717, 0.3595)\n",
      "epoch 387: (0.59765, 0.5614344133375275, 0.8924)\n",
      "epoch 388: (0.62175, 0.7555089192025184, 0.36)\n",
      "epoch 389: (0.5982, 0.562175509687223, 0.8879)\n",
      "epoch 390: (0.62265, 0.7556806337294142, 0.3625)\n",
      "epoch 391: (0.5959, 0.5602462620932278, 0.8918)\n",
      "epoch 392: (0.62225, 0.7529484792054625, 0.3639)\n",
      "epoch 393: (0.59795, 0.5619270405260163, 0.8888)\n",
      "epoch 394: (0.62075, 0.75696956799319, 0.3557)\n",
      "epoch 395: (0.59815, 0.5620927437211362, 0.8885)\n",
      "epoch 396: (0.6221, 0.750615763546798, 0.3657)\n",
      "epoch 397: (0.598, 0.5621985275450622, 0.8858)\n",
      "epoch 398: (0.6225, 0.7603059923501913, 0.3578)\n",
      "epoch 399: (0.598, 0.5619077700568541, 0.8895)\n"
     ]
    }
   ],
   "source": [
    "# k=100\n",
    "attack_params = model_params('attack_model')\n",
    "attack_params.learning_rate = 0.001\n",
    "attack_params.weight_decay = 1e-5\n",
    "attack_params.epoch = 400\n",
    "attack_params.h_neurons=64\n",
    "attack_params.do=0\n",
    "\n",
    "for attack_params.learning_rate in [0.001, 0.01]:\n",
    "    for attack_params.h_neurons in [32,64,128]:\n",
    "        for attack_params.do in [0, 0.5]:\n",
    "            # attack_train_data = torch.tensor(np.array(df.drop(['a_target'], axis=1)), dtype=torch.float, requires_grad=True)   \n",
    "            # attack_train_target = torch.tensor(np.array(df['a_target']), dtype=torch.float)\n",
    "            attack_train_args = Train_args(attack_params.learning_rate, attack_params.weight_decay, attack_params.epoch)\n",
    "            attack_model = Net_attack(attack_params.h_neurons, attack_params.do, input_size=attack_train_data.shape[1])\n",
    "            for epoch in range(attack_train_args.epoch):\n",
    "                attack_model = attack.train_attack_model(attack_model, attack_train_data, attack_train_target, attack_train_args)\n",
    "                print(f'epoch {epoch}: {attack_evaluation(attack_model, attack_train_data, attack_train_target)}' )        \n",
    "                \n",
    "                train_res = attack_evaluation(attack_model, attack_train_data, attack_train_target)\n",
    "                test_res = attack.mi_attack_test(model, attack_model, x_target_train, y_target_train, x_target_test, y_target_test)\n",
    "\n",
    "                attack_params.number_of_sms = number_of_sms\n",
    "                attack_params.shadow_size = shadow_size\n",
    "\n",
    "                attack_params.train_acc, attack_params.train_pre, attack_params.train_rec = train_res\n",
    "                attack_params.test_acc, attack_params.test_pre, attack_params.test_rec = test_res\n",
    "\n",
    "                a_param = dict(shadow_model.__dict__)\n",
    "                a_param.pop('theta')\n",
    "                a_param.pop('pred_func')\n",
    "                a_param.pop('accuracy')\n",
    "                a_param.update(dict(attack_params.__dict__))\n",
    "                a_param\n",
    "\n",
    "                k+=1\n",
    "                at_path = 'mia/texas/attack_model'+str(k)\n",
    "                torch.save(attack_model, at_path)\n",
    "                with open(at_path+'_params.json', 'w') as file:\n",
    "                    json.dump(a_param, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199458b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f24523c4",
   "metadata": {},
   "source": [
    "# Attack models texas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "b3593172",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = 'mia/texas/best_mia/'\n",
    "aparams = {}\n",
    "ams = {}\n",
    "for r,d,f in os.walk(path):\n",
    "    for file in f:\n",
    "        if \".json\" in file:\n",
    "            with open(r+'/'+file) as json_file:\n",
    "                aparams[r+file.replace('.json', '')] = json.load(json_file)\n",
    "            \n",
    "for r,d,f in os.walk(path):\n",
    "    for file in f:\n",
    "        if \".json\" not in file and '.DS_Store' not in file:\n",
    "            ams[r+file] = Net_attack(h_neurons=aparams[r+file]['h_neurons'], do=aparams[r+file]['do'], input_size=14)\n",
    "            ams[r+file] = torch.load(r+'/'+file)      \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "f8b19a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attack_acc_mean': 0.5413636363636365,\n",
       " 'attack_acc_std': 0.007413412013772774,\n",
       " 'attack_pre_mean': 0.9583333333333333,\n",
       " 'attack_pre_std': 0.05892556509887896,\n",
       " 'attack_rec_mean': 0.08727272727272727,\n",
       " 'attack_rec_std': 0.016564424689353267}"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attack_dict = attack.test_mi_attack(ams, model, x_target_train, y_target_train, x_target_test, y_target_test)\n",
    "attack_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "b7791fe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attack_acc_mean': 0.6455909090909091,\n",
       " 'attack_acc_std': 0.0034299362690751855,\n",
       " 'attack_pre_mean': 0.700552255210943,\n",
       " 'attack_pre_std': 0.007573150520431135,\n",
       " 'attack_rec_mean': 0.5088181818181818,\n",
       " 'attack_rec_std': 0.008277221556429125}"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attack_dict = attack.test_mi_attack(ams, model, x_target_train[:1000], y_target_train[:1000], x_target_test[:1000], y_target_test[:1000])\n",
    "attack_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "5632dcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attack_dict = attack.test_mi_attack(ams, target_model, x_target_train, y_target_train, x_target_test, y_target_test)\n",
    "a_10k = {}\n",
    "a_1k = {}\n",
    "for m in ams:\n",
    "    model = ams[m]\n",
    "    test_acc, test_pre, test_rec = attack.mi_attack_test(model10k, model, x_target_train, y_target_train, x_target_test, y_target_test)\n",
    "    a_10k[m] = test_acc, test_pre, test_rec\n",
    "    test_acc, test_pre, test_rec = attack.mi_attack_test(target_model, model, x_target_train[:1000], y_target_train[:1000], x_target_test[:1000], y_target_test[:1000])\n",
    "    a_1k[m] = test_acc, test_pre, test_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "cd59fc7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mia/texas/attack_model9699\n",
      "mia/texas/attack_model9697\n",
      "mia/texas/attack_model9665\n",
      "mia/texas/attack_model9691\n",
      "mia/texas/attack_model9683\n",
      "mia/texas/attack_model9669\n",
      "mia/texas/attack_model9693\n",
      "mia/texas/attack_model9695\n",
      "mia/texas/attack_model9657\n",
      "mia/texas/attack_model9681\n",
      "mia/texas/attack_model9689\n"
     ]
    }
   ],
   "source": [
    "for i,m in enumerate(best_models):\n",
    "    print(m)\n",
    "    torch.save(ams[m], 'mia/texas/best_mia/attack_model_'+str(i))\n",
    "    with open('mia/texas/best_mia/attack_model_'+str(i)+'.json', 'w') as file:\n",
    "                    json.dump(aparams[m], file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "b4dc845b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mia/texas/attack_model9699'"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "2309bc34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "4dffbf00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1K:  (0.6405, 0.6937931034482758, 0.503) 0.6085054252712635\n",
      "10K: (0.5549, 0.5423807318202871, 0.7026) 0.6085054252712635\n",
      "1K:  (0.6495, 0.7151079136690648, 0.497) 0.6085054252712635\n",
      "10K: (0.5539, 0.5420240137221269, 0.6952) 0.6085054252712635\n",
      "1K:  (0.6425, 0.6949384404924761, 0.508) 0.6085054252712635\n",
      "10K: (0.5537, 0.5421440904096688, 0.6908) 0.6085054252712635\n",
      "1K:  (0.649, 0.6991978609625669, 0.523) 0.6085054252712635\n",
      "10K: (0.5537, 0.54156346749226, 0.6997) 0.6085054252712635\n",
      "1K:  (0.6455, 0.6958277254374159, 0.517) 0.6085054252712635\n",
      "10K: (0.55295, 0.5413123195755637, 0.6938) 0.6085054252712635\n",
      "1K:  (0.642, 0.7005649717514124, 0.496) 0.6085054252712635\n",
      "10K: (0.5529, 0.5416469847268147, 0.688) 0.6085054252712635\n",
      "1K:  (0.648, 0.7, 0.518) 0.6085054252712635\n",
      "10K: (0.55365, 0.5415472779369628, 0.6993) 0.6085054252712635\n",
      "1K:  (0.651, 0.7138810198300283, 0.504) 0.6085054252712635\n",
      "10K: (0.5533, 0.5416341196688017, 0.6934) 0.6085054252712635\n",
      "1K:  (0.642, 0.6908602150537635, 0.514) 0.6085054252712635\n",
      "10K: (0.55235, 0.541269215608987, 0.6866) 0.6085054252712635\n",
      "1K:  (0.644, 0.6961852861035422, 0.511) 0.6085054252712635\n",
      "10K: (0.55325, 0.5413849382140359, 0.6966) 0.6085054252712635\n",
      "1K:  (0.6475, 0.705718270571827, 0.506) 0.6085054252712635\n",
      "10K: (0.5526, 0.540914747977598, 0.6954) 0.6085054252712635\n"
     ]
    }
   ],
   "source": [
    "best_res1k = {}\n",
    "best_res10k = {}\n",
    "best_res10k['acc'] = []\n",
    "best_res10k['pre'] = []\n",
    "best_res10k['rec'] = []\n",
    "best_res10k['f1'] = []\n",
    "\n",
    "best_res1k['acc'] = []\n",
    "best_res1k['pre'] = []\n",
    "best_res1k['rec'] = []\n",
    "best_res1k['f1'] = []\n",
    "best_models = []\n",
    "for i in a_1k:\n",
    "    if a_10k[i][0]>0.55 and a_1k[i][0]>0.64:\n",
    "        best_models.append(i)\n",
    "        f1_1 = 2*a_1k[i][1]*a_1k[i][2]/(a_1k[i][1]+a_1k[i][2])\n",
    "        print('1K: ',a_1k[i], f1)\n",
    "        f1_10 = 2*a_10k[i][1]*a_10k[i][2]/(a_10k[i][1]+a_10k[i][2])\n",
    "        print('10K:', a_10k[i], f1)\n",
    "        best_res10k['acc'].append(a_10k[i][0])\n",
    "        best_res10k['pre'].append(a_10k[i][1])\n",
    "        best_res10k['rec'].append(a_10k[i][2])\n",
    "        best_res10k['f1'].append(f1_10)\n",
    "        \n",
    "        best_res1k['acc'].append(a_1k[i][0])\n",
    "        best_res1k['pre'].append(a_1k[i][1])\n",
    "        best_res1k['rec'].append(a_1k[i][2])\n",
    "        best_res1k['f1'].append(f1_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "23642a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6455909090909091 0.700552255210943 0.508818181818182 0.5894076353621919\n",
      "0.5533818181818181 0.5416201733775552 0.6946727272727272 0.608666034689381\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(best_res1k['acc']), np.mean(best_res1k['pre']), np.mean(best_res1k['rec']), np.mean(best_res1k['f1']))\n",
    "print(np.mean(best_res10k['acc']), np.mean(best_res10k['pre']), np.mean(best_res10k['rec']), np.mean(best_res10k['f1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "4e0db568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attack_acc_mean': 0.5129863636363635, 'attack_acc_std': 0.0010101959551337707, 'attack_pre_mean': 0.5281946482817765, 'attack_pre_std': 0.00191616621491754, 'attack_rec_mean': 0.24327272727272728, 'attack_rec_std': 0.008797839704784038}\n",
      "{'attack_acc_mean': 0.5533818181818182, 'attack_acc_std': 0.0006719282724411607, 'attack_pre_mean': 0.5416201733775551, 'attack_pre_std': 0.0004041122448942372, 'attack_rec_mean': 0.6946727272727272, 'attack_rec_std': 0.004681897616272309}\n"
     ]
    }
   ],
   "source": [
    "attack_dict = attack.test_mi_attack(ams, target_model, x_target_train, y_target_train, x_target_test, y_target_test)\n",
    "print(attack_dict)\n",
    "attack_dict = attack.test_mi_attack(ams, model10k, x_target_train, y_target_train, x_target_test, y_target_test)\n",
    "print(attack_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "248864db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6932, 'train_pre': 0.724808005585292, 'train_rec': 0.6229, 'test_acc': 0.5522, 'test_pre': 0.543471019320453, 'test_rec': 0.6526}\n",
      "train: 0.6932\n",
      "test:  0.5522\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.69055, 'train_pre': 0.71985692857967, 'train_rec': 0.6239, 'test_acc': 0.55115, 'test_pre': 0.5413667610190053, 'test_rec': 0.6694}\n",
      "train: 0.69055\n",
      "test:  0.55115\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6934, 'train_pre': 0.7235838150289018, 'train_rec': 0.6259, 'test_acc': 0.55325, 'test_pre': 0.5438741039795666, 'test_rec': 0.6601}\n",
      "train: 0.6934\n",
      "test:  0.55325\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6943, 'train_pre': 0.7012637248808784, 'train_rec': 0.677, 'test_acc': 0.55045, 'test_pre': 0.5389244657048067, 'test_rec': 0.6985}\n",
      "train: 0.6943\n",
      "test:  0.55045\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6898, 'train_pre': 0.7221441947565543, 'train_rec': 0.617, 'test_acc': 0.5529, 'test_pre': 0.5444164567590261, 'test_rec': 0.6484}\n",
      "train: 0.6898\n",
      "test:  0.5529\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 64, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.69315, 'train_pre': 0.7179776548922243, 'train_rec': 0.6362, 'test_acc': 0.5531, 'test_pre': 0.543044747081712, 'test_rec': 0.6699}\n",
      "train: 0.69315\n",
      "test:  0.5531\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.69665, 'train_pre': 0.7326392996569265, 'train_rec': 0.6193, 'test_acc': 0.553, 'test_pre': 0.5436573311367381, 'test_rec': 0.66}\n",
      "train: 0.69665\n",
      "test:  0.553\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.70265, 'train_pre': 0.7137883743010867, 'train_rec': 0.6766, 'test_acc': 0.5533, 'test_pre': 0.5416341196688017, 'test_rec': 0.6934}\n",
      "train: 0.70265\n",
      "test:  0.5533\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 64, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6905, 'train_pre': 0.7063921993499458, 'train_rec': 0.652, 'test_acc': 0.55135, 'test_pre': 0.5412416673359569, 'test_rec': 0.6739}\n",
      "train: 0.6905\n",
      "test:  0.55135\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6867, 'train_pre': 0.7153899400092294, 'train_rec': 0.6201, 'test_acc': 0.5511, 'test_pre': 0.5415920559986978, 'test_rec': 0.6654}\n",
      "train: 0.6867\n",
      "test:  0.5511\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.70185, 'train_pre': 0.7097142857142857, 'train_rec': 0.6831, 'test_acc': 0.5526, 'test_pre': 0.540914747977598, 'test_rec': 0.6954}\n",
      "train: 0.70185\n",
      "test:  0.5526\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.698, 'train_pre': 0.7299651567944251, 'train_rec': 0.6285, 'test_acc': 0.5542, 'test_pre': 0.5443535188216039, 'test_rec': 0.6652}\n",
      "train: 0.698\n",
      "test:  0.5542\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6849, 'train_pre': 0.71316578279917, 'train_rec': 0.6186, 'test_acc': 0.5501, 'test_pre': 0.5409246855089038, 'test_rec': 0.6622}\n",
      "train: 0.6849\n",
      "test:  0.5501\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6866, 'train_pre': 0.7183477650362743, 'train_rec': 0.6139, 'test_acc': 0.5511, 'test_pre': 0.5430207105573329, 'test_rec': 0.645}\n",
      "train: 0.6866\n",
      "test:  0.5511\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.69465, 'train_pre': 0.7013551256853212, 'train_rec': 0.678, 'test_acc': 0.55055, 'test_pre': 0.5389175456155209, 'test_rec': 0.7}\n",
      "train: 0.69465\n",
      "test:  0.55055\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6897, 'train_pre': 0.7186995619091537, 'train_rec': 0.6234, 'test_acc': 0.5511, 'test_pre': 0.5414100486223663, 'test_rec': 0.6681}\n",
      "train: 0.6897\n",
      "test:  0.5511\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.69155, 'train_pre': 0.7209087763810402, 'train_rec': 0.6251, 'test_acc': 0.5514, 'test_pre': 0.5415252867991598, 'test_rec': 0.6703}\n",
      "train: 0.69155\n",
      "test:  0.5514\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 64, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6851, 'train_pre': 0.6952531645569621, 'train_rec': 0.6591, 'test_acc': 0.55025, 'test_pre': 0.5403517224765116, 'test_rec': 0.6729}\n",
      "train: 0.6851\n",
      "test:  0.55025\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 64, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.68755, 'train_pre': 0.713100784001818, 'train_rec': 0.6276, 'test_acc': 0.5509, 'test_pre': 0.541941331575478, 'test_rec': 0.6577}\n",
      "train: 0.68755\n",
      "test:  0.5509\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6988, 'train_pre': 0.7082111436950147, 'train_rec': 0.6762, 'test_acc': 0.55295, 'test_pre': 0.5415979259957577, 'test_rec': 0.6894}\n",
      "train: 0.6988\n",
      "test:  0.55295\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6925, 'train_pre': 0.7016129032258065, 'train_rec': 0.6699, 'test_acc': 0.55075, 'test_pre': 0.5408648039294629, 'test_rec': 0.6717}\n",
      "train: 0.6925\n",
      "test:  0.55075\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 64, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6918, 'train_pre': 0.717411017909771, 'train_rec': 0.6329, 'test_acc': 0.55355, 'test_pre': 0.5436821926747696, 'test_rec': 0.6665}\n",
      "train: 0.6918\n",
      "test:  0.55355\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6995, 'train_pre': 0.7320307048150733, 'train_rec': 0.6294, 'test_acc': 0.55445, 'test_pre': 0.5444018592514067, 'test_rec': 0.6676}\n",
      "train: 0.6995\n",
      "test:  0.55445\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.69285, 'train_pre': 0.7019583202429573, 'train_rec': 0.6703, 'test_acc': 0.5512, 'test_pre': 0.5410453743787077, 'test_rec': 0.6749}\n",
      "train: 0.69285\n",
      "test:  0.5512\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 64, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.68745, 'train_pre': 0.703949515830704, 'train_rec': 0.647, 'test_acc': 0.55005, 'test_pre': 0.5406217027838649, 'test_rec': 0.6661}\n",
      "train: 0.68745\n",
      "test:  0.55005\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6917, 'train_pre': 0.699438202247191, 'train_rec': 0.6723, 'test_acc': 0.55015, 'test_pre': 0.5389877944491953, 'test_rec': 0.6933}\n",
      "train: 0.6917\n",
      "test:  0.55015\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.69785, 'train_pre': 0.7069777173344493, 'train_rec': 0.6758, 'test_acc': 0.55125, 'test_pre': 0.5404786351788958, 'test_rec': 0.6843}\n",
      "train: 0.69785\n",
      "test:  0.55125\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.69035, 'train_pre': 0.7225014611338398, 'train_rec': 0.6181, 'test_acc': 0.55255, 'test_pre': 0.5441337028638616, 'test_rec': 0.6479}\n",
      "train: 0.69035\n",
      "test:  0.55255\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.69765, 'train_pre': 0.7325567713848689, 'train_rec': 0.6226, 'test_acc': 0.55395, 'test_pre': 0.5443339633494946, 'test_rec': 0.6624}\n",
      "train: 0.69765\n",
      "test:  0.55395\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 64, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6953, 'train_pre': 0.7148987676056338, 'train_rec': 0.6497, 'test_acc': 0.5524, 'test_pre': 0.5419737263697533, 'test_rec': 0.6766}\n",
      "train: 0.6953\n",
      "test:  0.5524\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 64, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6873, 'train_pre': 0.708018658374056, 'train_rec': 0.6375, 'test_acc': 0.55075, 'test_pre': 0.5414997137950772, 'test_rec': 0.6622}\n",
      "train: 0.6873\n",
      "test:  0.55075\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.70395, 'train_pre': 0.7125143273939772, 'train_rec': 0.6838, 'test_acc': 0.5549, 'test_pre': 0.5423807318202871, 'test_rec': 0.7026}\n",
      "train: 0.70395\n",
      "test:  0.5549\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.68885, 'train_pre': 0.7178451955242819, 'train_rec': 0.6223, 'test_acc': 0.55135, 'test_pre': 0.5417581523948931, 'test_rec': 0.6662}\n",
      "train: 0.68885\n",
      "test:  0.55135\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6912, 'train_pre': 0.7205814490078449, 'train_rec': 0.6246, 'test_acc': 0.55145, 'test_pre': 0.5415690393471763, 'test_rec': 0.6703}\n",
      "train: 0.6912\n",
      "test:  0.55145\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6936, 'train_pre': 0.7004555808656037, 'train_rec': 0.6765, 'test_acc': 0.5505, 'test_pre': 0.538996138996139, 'test_rec': 0.698}\n",
      "train: 0.6936\n",
      "test:  0.5505\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6949, 'train_pre': 0.7017180707927966, 'train_rec': 0.678, 'test_acc': 0.55065, 'test_pre': 0.5389285988778726, 'test_rec': 0.7012}\n",
      "train: 0.6949\n",
      "test:  0.55065\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6938, 'train_pre': 0.7229636447307869, 'train_rec': 0.6284, 'test_acc': 0.553, 'test_pre': 0.5434853954709551, 'test_rec': 0.6624}\n",
      "train: 0.6938\n",
      "test:  0.553\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.68925, 'train_pre': 0.718609217973894, 'train_rec': 0.6221, 'test_acc': 0.5514, 'test_pre': 0.5417072379097696, 'test_rec': 0.6676}\n",
      "train: 0.68925\n",
      "test:  0.5514\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.69125, 'train_pre': 0.7207155222158107, 'train_rec': 0.6245, 'test_acc': 0.55165, 'test_pre': 0.542952182952183, 'test_rec': 0.6529}\n",
      "train: 0.69125\n",
      "test:  0.55165\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.70195, 'train_pre': 0.7162437091765713, 'train_rec': 0.6689, 'test_acc': 0.5537, 'test_pre': 0.5422768068020785, 'test_rec': 0.6888}\n",
      "train: 0.70195\n",
      "test:  0.5537\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 64, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.69055, 'train_pre': 0.71889718552556, 'train_rec': 0.6258, 'test_acc': 0.55195, 'test_pre': 0.5426694045174538, 'test_rec': 0.6607}\n",
      "train: 0.69055\n",
      "test:  0.55195\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.69925, 'train_pre': 0.7331772966647162, 'train_rec': 0.6265, 'test_acc': 0.5545, 'test_pre': 0.5445990180032734, 'test_rec': 0.6655}\n",
      "train: 0.69925\n",
      "test:  0.5545\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.68755, 'train_pre': 0.7179546775130738, 'train_rec': 0.6178, 'test_acc': 0.5513, 'test_pre': 0.5428714691626274, 'test_rec': 0.6496}\n",
      "train: 0.68755\n",
      "test:  0.5513\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6981, 'train_pre': 0.7297077922077922, 'train_rec': 0.6293, 'test_acc': 0.55425, 'test_pre': 0.5440877691995124, 'test_rec': 0.6695}\n",
      "train: 0.6981\n",
      "test:  0.55425\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 64, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.69625, 'train_pre': 0.7128755830350363, 'train_rec': 0.6572, 'test_acc': 0.55095, 'test_pre': 0.5405297907883223, 'test_rec': 0.6795}\n",
      "train: 0.69625\n",
      "test:  0.55095\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6957, 'train_pre': 0.7043224055126331, 'train_rec': 0.6746, 'test_acc': 0.55245, 'test_pre': 0.5415379741823078, 'test_rec': 0.6838}\n",
      "train: 0.6957\n",
      "test:  0.55245\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6957, 'train_pre': 0.7026299440878029, 'train_rec': 0.6786, 'test_acc': 0.5521, 'test_pre': 0.541421529654953, 'test_rec': 0.681}\n",
      "train: 0.6957\n",
      "test:  0.5521\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 64, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6818, 'train_pre': 0.7033557046979866, 'train_rec': 0.6288, 'test_acc': 0.5507, 'test_pre': 0.5422148209825146, 'test_rec': 0.6512}\n",
      "train: 0.6818\n",
      "test:  0.5507\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 64, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.68765, 'train_pre': 0.7070049641478213, 'train_rec': 0.6409, 'test_acc': 0.5501, 'test_pre': 0.5408846091072302, 'test_rec': 0.6628}\n",
      "train: 0.68765\n",
      "test:  0.5501\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.69225, 'train_pre': 0.7215627521032615, 'train_rec': 0.6261, 'test_acc': 0.55195, 'test_pre': 0.541918825143226, 'test_rec': 0.6716}\n",
      "train: 0.69225\n",
      "test:  0.55195\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.68985, 'train_pre': 0.705532099166396, 'train_rec': 0.6517, 'test_acc': 0.55035, 'test_pre': 0.5409582689335394, 'test_rec': 0.665}\n",
      "train: 0.68985\n",
      "test:  0.55035\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.7002, 'train_pre': 0.7113597972972973, 'train_rec': 0.6738, 'test_acc': 0.55235, 'test_pre': 0.5412172269900007, 'test_rec': 0.6874}\n",
      "train: 0.7002\n",
      "test:  0.55235\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 64, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6904, 'train_pre': 0.7152385258874068, 'train_rec': 0.6327, 'test_acc': 0.5511, 'test_pre': 0.5417483660130719, 'test_rec': 0.6631}\n",
      "train: 0.6904\n",
      "test:  0.5511\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6876, 'train_pre': 0.71548357454629, 'train_rec': 0.6229, 'test_acc': 0.5513, 'test_pre': 0.5428285189514109, 'test_rec': 0.6502}\n",
      "train: 0.6876\n",
      "test:  0.5513\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6857, 'train_pre': 0.713841547673883, 'train_rec': 0.6199, 'test_acc': 0.5507, 'test_pre': 0.5413405088062623, 'test_rec': 0.6639}\n",
      "train: 0.6857\n",
      "test:  0.5507\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 64, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6897, 'train_pre': 0.7043300301594141, 'train_rec': 0.6539, 'test_acc': 0.55095, 'test_pre': 0.5408285920346182, 'test_rec': 0.6749}\n",
      "train: 0.6897\n",
      "test:  0.55095\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 64, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.69255, 'train_pre': 0.7184840576421196, 'train_rec': 0.6332, 'test_acc': 0.55325, 'test_pre': 0.5433667236745663, 'test_rec': 0.6672}\n",
      "train: 0.69255\n",
      "test:  0.55325\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.69785, 'train_pre': 0.7288606130711394, 'train_rec': 0.6301, 'test_acc': 0.55355, 'test_pre': 0.5436964504283965, 'test_rec': 0.6663}\n",
      "train: 0.69785\n",
      "test:  0.55355\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.69435, 'train_pre': 0.701128014074304, 'train_rec': 0.6775, 'test_acc': 0.5505, 'test_pre': 0.5389180024660912, 'test_rec': 0.6993}\n",
      "train: 0.69435\n",
      "test:  0.5505\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.69025, 'train_pre': 0.7194601453454839, 'train_rec': 0.6237, 'test_acc': 0.5512, 'test_pre': 0.5414172464002589, 'test_rec': 0.6693}\n",
      "train: 0.69025\n",
      "test:  0.5512\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6849, 'train_pre': 0.7158029878618114, 'train_rec': 0.6133, 'test_acc': 0.5511, 'test_pre': 0.5430787388298769, 'test_rec': 0.6442}\n",
      "train: 0.6849\n",
      "test:  0.5511\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6931, 'train_pre': 0.7207866453235765, 'train_rec': 0.6304, 'test_acc': 0.55295, 'test_pre': 0.543591010125957, 'test_rec': 0.6603}\n",
      "train: 0.6931\n",
      "test:  0.55295\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6914, 'train_pre': 0.7226099092812281, 'train_rec': 0.6213, 'test_acc': 0.552, 'test_pre': 0.5432900432900433, 'test_rec': 0.6526}\n",
      "train: 0.6914\n",
      "test:  0.552\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 64, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.69375, 'train_pre': 0.7229830820577742, 'train_rec': 0.6282, 'test_acc': 0.55215, 'test_pre': 0.5425610054680486, 'test_rec': 0.6648}\n",
      "train: 0.69375\n",
      "test:  0.55215\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 64, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.68815, 'train_pre': 0.704089380626966, 'train_rec': 0.6491, 'test_acc': 0.55015, 'test_pre': 0.5404011922983969, 'test_rec': 0.6708}\n",
      "train: 0.68815\n",
      "test:  0.55015\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.70315, 'train_pre': 0.70980068160694, 'train_rec': 0.6873, 'test_acc': 0.55365, 'test_pre': 0.5415472779369628, 'test_rec': 0.6993}\n",
      "train: 0.70315\n",
      "test:  0.55365\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 64, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6909, 'train_pre': 0.716784010901658, 'train_rec': 0.6312, 'test_acc': 0.55235, 'test_pre': 0.5427940815826044, 'test_rec': 0.664}\n",
      "train: 0.6909\n",
      "test:  0.55235\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6988, 'train_pre': 0.7357685009487666, 'train_rec': 0.6204, 'test_acc': 0.5544, 'test_pre': 0.5445682451253482, 'test_rec': 0.6647}\n",
      "train: 0.6988\n",
      "test:  0.5544\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 64, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.68745, 'train_pre': 0.7014941416747286, 'train_rec': 0.6526, 'test_acc': 0.55115, 'test_pre': 0.5412400225751834, 'test_rec': 0.6713}\n",
      "train: 0.68745\n",
      "test:  0.55115\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.69905, 'train_pre': 0.7082330787739304, 'train_rec': 0.677, 'test_acc': 0.55115, 'test_pre': 0.5403295750216826, 'test_rec': 0.6853}\n",
      "train: 0.69905\n",
      "test:  0.55115\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6935, 'train_pre': 0.7013527575442248, 'train_rec': 0.674, 'test_acc': 0.5507, 'test_pre': 0.5404048453936883, 'test_rec': 0.6781}\n",
      "train: 0.6935\n",
      "test:  0.5507\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.695, 'train_pre': 0.708377858516777, 'train_rec': 0.6629, 'test_acc': 0.55145, 'test_pre': 0.5411962527023781, 'test_rec': 0.6759}\n",
      "train: 0.695\n",
      "test:  0.55145\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.69185, 'train_pre': 0.7212037357315808, 'train_rec': 0.6255, 'test_acc': 0.5515, 'test_pre': 0.5415590703679793, 'test_rec': 0.6711}\n",
      "train: 0.69185\n",
      "test:  0.5515\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6978, 'train_pre': 0.7059987502603624, 'train_rec': 0.6779, 'test_acc': 0.55185, 'test_pre': 0.5407914404846196, 'test_rec': 0.6874}\n",
      "train: 0.6978\n",
      "test:  0.55185\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6949, 'train_pre': 0.7042548731922029, 'train_rec': 0.672, 'test_acc': 0.55085, 'test_pre': 0.5409453257106047, 'test_rec': 0.6718}\n",
      "train: 0.6949\n",
      "test:  0.55085\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 64, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6872, 'train_pre': 0.7090685727049364, 'train_rec': 0.6349, 'test_acc': 0.55085, 'test_pre': 0.5416974169741697, 'test_rec': 0.6606}\n",
      "train: 0.6872\n",
      "test:  0.55085\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6998, 'train_pre': 0.7125531914893617, 'train_rec': 0.6698, 'test_acc': 0.55285, 'test_pre': 0.5417621493480838, 'test_rec': 0.6856}\n",
      "train: 0.6998\n",
      "test:  0.55285\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.69135, 'train_pre': 0.719463241197385, 'train_rec': 0.6273, 'test_acc': 0.5513, 'test_pre': 0.5426504822081809, 'test_rec': 0.6527}\n",
      "train: 0.69135\n",
      "test:  0.5513\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6929, 'train_pre': 0.7223887479824763, 'train_rec': 0.6266, 'test_acc': 0.55195, 'test_pre': 0.5418445428916633, 'test_rec': 0.6727}\n",
      "train: 0.6929\n",
      "test:  0.55195\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.69415, 'train_pre': 0.7260449412038654, 'train_rec': 0.6236, 'test_acc': 0.55235, 'test_pre': 0.5431895058163518, 'test_rec': 0.6584}\n",
      "train: 0.69415\n",
      "test:  0.55235\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6889, 'train_pre': 0.7182805639010862, 'train_rec': 0.6216, 'test_acc': 0.55145, 'test_pre': 0.5417511969487949, 'test_rec': 0.6676}\n",
      "train: 0.6889\n",
      "test:  0.55145\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 64, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6897, 'train_pre': 0.7190025398291388, 'train_rec': 0.6228, 'test_acc': 0.5519, 'test_pre': 0.5427582797825012, 'test_rec': 0.6588}\n",
      "train: 0.6897\n",
      "test:  0.5519\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.7012, 'train_pre': 0.7096270056261721, 'train_rec': 0.6811, 'test_acc': 0.55295, 'test_pre': 0.5413123195755637, 'test_rec': 0.6938}\n",
      "train: 0.7012\n",
      "test:  0.55295\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 64, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.69265, 'train_pre': 0.7094249374932058, 'train_rec': 0.6526, 'test_acc': 0.55275, 'test_pre': 0.5423320760773613, 'test_rec': 0.6758}\n",
      "train: 0.69265\n",
      "test:  0.55275\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 64, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6942, 'train_pre': 0.7209831588529814, 'train_rec': 0.6336, 'test_acc': 0.5533, 'test_pre': 0.5431998703193386, 'test_rec': 0.6702}\n",
      "train: 0.6942\n",
      "test:  0.5533\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.69675, 'train_pre': 0.72891215823153, 'train_rec': 0.6265, 'test_acc': 0.5528, 'test_pre': 0.5432786885245902, 'test_rec': 0.6628}\n",
      "train: 0.69675\n",
      "test:  0.5528\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.68735, 'train_pre': 0.7162146566647433, 'train_rec': 0.6206, 'test_acc': 0.55125, 'test_pre': 0.5417311293868577, 'test_rec': 0.6653}\n",
      "train: 0.68735\n",
      "test:  0.55125\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6988, 'train_pre': 0.7308943089430894, 'train_rec': 0.6293, 'test_acc': 0.55475, 'test_pre': 0.5442997006230278, 'test_rec': 0.6727}\n",
      "train: 0.6988\n",
      "test:  0.55475\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 64, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6889, 'train_pre': 0.7018593716606112, 'train_rec': 0.6568, 'test_acc': 0.55095, 'test_pre': 0.5408220495152632, 'test_rec': 0.675}\n",
      "train: 0.6889\n",
      "test:  0.55095\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6899, 'train_pre': 0.7208139534883721, 'train_rec': 0.6199, 'test_acc': 0.55165, 'test_pre': 0.543210909395131, 'test_rec': 0.6493}\n",
      "train: 0.6899\n",
      "test:  0.55165\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.69335, 'train_pre': 0.7001760016564862, 'train_rec': 0.6763, 'test_acc': 0.5503, 'test_pre': 0.5388897479511365, 'test_rec': 0.697}\n",
      "train: 0.69335\n",
      "test:  0.5503\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.69785, 'train_pre': 0.7085925144965736, 'train_rec': 0.6721, 'test_acc': 0.5529, 'test_pre': 0.5418446448346781, 'test_rec': 0.685}\n",
      "train: 0.69785\n",
      "test:  0.5529\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6927, 'train_pre': 0.7220557732196359, 'train_rec': 0.6266, 'test_acc': 0.55205, 'test_pre': 0.5419656534709345, 'test_rec': 0.6722}\n",
      "train: 0.6927\n",
      "test:  0.55205\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6948, 'train_pre': 0.7041500733598827, 'train_rec': 0.6719, 'test_acc': 0.5502, 'test_pre': 0.5400255142720459, 'test_rec': 0.6773}\n",
      "train: 0.6948\n",
      "test:  0.5502\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.7006, 'train_pre': 0.7099644128113879, 'train_rec': 0.6783, 'test_acc': 0.5525, 'test_pre': 0.5410284463894968, 'test_rec': 0.6923}\n",
      "train: 0.7006\n",
      "test:  0.5525\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 64, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6895, 'train_pre': 0.7148526077097506, 'train_rec': 0.6305, 'test_acc': 0.5512, 'test_pre': 0.5419465836473866, 'test_rec': 0.6615}\n",
      "train: 0.6895\n",
      "test:  0.5512\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.69145, 'train_pre': 0.6994063118425164, 'train_rec': 0.6715, 'test_acc': 0.55015, 'test_pre': 0.538993857398336, 'test_rec': 0.6932}\n",
      "train: 0.69145\n",
      "test:  0.55015\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.69905, 'train_pre': 0.7368233194527067, 'train_rec': 0.6193, 'test_acc': 0.5539, 'test_pre': 0.5440287534716549, 'test_rec': 0.666}\n",
      "train: 0.69905\n",
      "test:  0.5539\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 64, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6943, 'train_pre': 0.7074081981212639, 'train_rec': 0.6627, 'test_acc': 0.55185, 'test_pre': 0.5411344704482348, 'test_rec': 0.6821}\n",
      "train: 0.6943\n",
      "test:  0.55185\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.69535, 'train_pre': 0.7044479330193616, 'train_rec': 0.6731, 'test_acc': 0.55245, 'test_pre': 0.5418028213915677, 'test_rec': 0.6798}\n",
      "train: 0.69535\n",
      "test:  0.55245\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.69695, 'train_pre': 0.7066414856783129, 'train_rec': 0.6735, 'test_acc': 0.5516, 'test_pre': 0.5409004438807863, 'test_rec': 0.6824}\n",
      "train: 0.69695\n",
      "test:  0.5516\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6944, 'train_pre': 0.7013256006628004, 'train_rec': 0.6772, 'test_acc': 0.5506, 'test_pre': 0.5390191239975324, 'test_rec': 0.699}\n",
      "train: 0.6944\n",
      "test:  0.5506\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.685, 'train_pre': 0.7161720028043935, 'train_rec': 0.6129, 'test_acc': 0.55085, 'test_pre': 0.5429948423099688, 'test_rec': 0.6422}\n",
      "train: 0.685\n",
      "test:  0.55085\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 64, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.68825, 'train_pre': 0.7014877448357059, 'train_rec': 0.6554, 'test_acc': 0.5501, 'test_pre': 0.5403511597938144, 'test_rec': 0.6709}\n",
      "train: 0.68825\n",
      "test:  0.5501\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6863, 'train_pre': 0.7147798017062486, 'train_rec': 0.62, 'test_acc': 0.55035, 'test_pre': 0.5410250142589424, 'test_rec': 0.664}\n",
      "train: 0.6863\n",
      "test:  0.55035\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 64, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6902, 'train_pre': 0.7039459575380657, 'train_rec': 0.6565, 'test_acc': 0.5505, 'test_pre': 0.5403097062579821, 'test_rec': 0.6769}\n",
      "train: 0.6902\n",
      "test:  0.5505\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6957, 'train_pre': 0.7295331925873798, 'train_rec': 0.622, 'test_acc': 0.55325, 'test_pre': 0.5437443522549905, 'test_rec': 0.6619}\n",
      "train: 0.6957\n",
      "test:  0.55325\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.68615, 'train_pre': 0.7153267784846732, 'train_rec': 0.6184, 'test_acc': 0.5522, 'test_pre': 0.5436527847466132, 'test_rec': 0.6501}\n",
      "train: 0.68615\n",
      "test:  0.5522\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 64, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6943, 'train_pre': 0.7209460996133727, 'train_rec': 0.634, 'test_acc': 0.5531, 'test_pre': 0.5431496830814238, 'test_rec': 0.6684}\n",
      "train: 0.6943\n",
      "test:  0.5531\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.70235, 'train_pre': 0.707389566465102, 'train_rec': 0.6902, 'test_acc': 0.5537, 'test_pre': 0.54156346749226, 'test_rec': 0.6997}\n",
      "train: 0.70235\n",
      "test:  0.5537\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 64, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6825, 'train_pre': 0.6983695652173914, 'train_rec': 0.6425, 'test_acc': 0.5502, 'test_pre': 0.5411677874364441, 'test_rec': 0.6599}\n",
      "train: 0.6825\n",
      "test:  0.5502\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6926, 'train_pre': 0.7202149554081866, 'train_rec': 0.6299, 'test_acc': 0.55145, 'test_pre': 0.5425875341445244, 'test_rec': 0.6555}\n",
      "train: 0.6926\n",
      "test:  0.55145\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6901, 'train_pre': 0.7192112546125461, 'train_rec': 0.6237, 'test_acc': 0.55125, 'test_pre': 0.5414878976766777, 'test_rec': 0.6689}\n",
      "train: 0.6901\n",
      "test:  0.55125\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6851, 'train_pre': 0.7132979949297074, 'train_rec': 0.619, 'test_acc': 0.55015, 'test_pre': 0.5420686184044963, 'test_rec': 0.6462}\n",
      "train: 0.6851\n",
      "test:  0.55015\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.69385, 'train_pre': 0.7142225660293955, 'train_rec': 0.6463, 'test_acc': 0.55195, 'test_pre': 0.5421843280552172, 'test_rec': 0.6677}\n",
      "train: 0.69385\n",
      "test:  0.55195\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 64, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6863, 'train_pre': 0.6977707006369427, 'train_rec': 0.6573, 'test_acc': 0.55045, 'test_pre': 0.5405644448018011, 'test_rec': 0.6723}\n",
      "train: 0.6863\n",
      "test:  0.55045\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6998, 'train_pre': 0.7084724540901502, 'train_rec': 0.679, 'test_acc': 0.55235, 'test_pre': 0.541269215608987, 'test_rec': 0.6866}\n",
      "train: 0.6998\n",
      "test:  0.55235\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6929, 'train_pre': 0.7223374827109267, 'train_rec': 0.6267, 'test_acc': 0.55205, 'test_pre': 0.5419250906161901, 'test_rec': 0.6728}\n",
      "train: 0.6929\n",
      "test:  0.55205\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6912, 'train_pre': 0.6999163529903806, 'train_rec': 0.6694, 'test_acc': 0.55055, 'test_pre': 0.5405470441966792, 'test_rec': 0.6739}\n",
      "train: 0.6912\n",
      "test:  0.55055\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.70025, 'train_pre': 0.7107672876539312, 'train_rec': 0.6753, 'test_acc': 0.5533, 'test_pre': 0.541640625, 'test_rec': 0.6933}\n",
      "train: 0.70025\n",
      "test:  0.5533\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 64, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6915, 'train_pre': 0.7149270482603816, 'train_rec': 0.637, 'test_acc': 0.5525, 'test_pre': 0.5426343998700666, 'test_rec': 0.6682}\n",
      "train: 0.6915\n",
      "test:  0.5525\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6988, 'train_pre': 0.7298265895953757, 'train_rec': 0.6313, 'test_acc': 0.5541, 'test_pre': 0.5441056579161911, 'test_rec': 0.6674}\n",
      "train: 0.6988\n",
      "test:  0.5541\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.69115, 'train_pre': 0.6992183428869203, 'train_rec': 0.6709, 'test_acc': 0.5501, 'test_pre': 0.5389640690620625, 'test_rec': 0.693}\n",
      "train: 0.69115\n",
      "test:  0.5501\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.69895, 'train_pre': 0.7301862779127618, 'train_rec': 0.6311, 'test_acc': 0.55425, 'test_pre': 0.5437394178827702, 'test_rec': 0.6744}\n",
      "train: 0.69895\n",
      "test:  0.55425\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 64, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.68645, 'train_pre': 0.7097064447193792, 'train_rec': 0.631, 'test_acc': 0.55075, 'test_pre': 0.5415949512335054, 'test_rec': 0.6608}\n",
      "train: 0.68645\n",
      "test:  0.55075\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.7006, 'train_pre': 0.71173738653156, 'train_rec': 0.6743, 'test_acc': 0.5537, 'test_pre': 0.5421440904096688, 'test_rec': 0.6908}\n",
      "train: 0.7006\n",
      "test:  0.5537\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6937, 'train_pre': 0.7035947025436199, 'train_rec': 0.6694, 'test_acc': 0.55105, 'test_pre': 0.5411527609834744, 'test_rec': 0.6713}\n",
      "train: 0.6937\n",
      "test:  0.55105\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.69155, 'train_pre': 0.7209087763810402, 'train_rec': 0.6251, 'test_acc': 0.5513, 'test_pre': 0.5414110429447853, 'test_rec': 0.6707}\n",
      "train: 0.69155\n",
      "test:  0.5513\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.70135, 'train_pre': 0.7089776855215361, 'train_rec': 0.6831, 'test_acc': 0.55325, 'test_pre': 0.5413849382140359, 'test_rec': 0.6966}\n",
      "train: 0.70135\n",
      "test:  0.55325\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 64, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.693, 'train_pre': 0.7126018946904604, 'train_rec': 0.6469, 'test_acc': 0.5536, 'test_pre': 0.5432258064516129, 'test_rec': 0.6736}\n",
      "train: 0.693\n",
      "test:  0.5536\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6945, 'train_pre': 0.7259526022304833, 'train_rec': 0.6249, 'test_acc': 0.55235, 'test_pre': 0.5431254633824862, 'test_rec': 0.6593}\n",
      "train: 0.6945\n",
      "test:  0.55235\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.68875, 'train_pre': 0.7179812911421642, 'train_rec': 0.6217, 'test_acc': 0.5514, 'test_pre': 0.5417207792207792, 'test_rec': 0.6674}\n",
      "train: 0.68875\n",
      "test:  0.5514\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 64, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6858, 'train_pre': 0.7089518668466037, 'train_rec': 0.6304, 'test_acc': 0.55025, 'test_pre': 0.5413478153542335, 'test_rec': 0.6579}\n",
      "train: 0.6858\n",
      "test:  0.55025\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6904, 'train_pre': 0.7203703703703703, 'train_rec': 0.6224, 'test_acc': 0.5526, 'test_pre': 0.5439725798361478, 'test_rec': 0.6507}\n",
      "train: 0.6904\n",
      "test:  0.5526\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6937, 'train_pre': 0.7006837961044343, 'train_rec': 0.6763, 'test_acc': 0.55015, 'test_pre': 0.5387707769617317, 'test_rec': 0.6969}\n",
      "train: 0.6937\n",
      "test:  0.55015\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.686, 'train_pre': 0.7174929840972872, 'train_rec': 0.6136, 'test_acc': 0.5517, 'test_pre': 0.5435845557241612, 'test_rec': 0.6448}\n",
      "train: 0.686\n",
      "test:  0.5517\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6878, 'train_pre': 0.7184737087017218, 'train_rec': 0.6176, 'test_acc': 0.55145, 'test_pre': 0.5429932313863124, 'test_rec': 0.6498}\n",
      "train: 0.6878\n",
      "test:  0.55145\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6959, 'train_pre': 0.7267361111111111, 'train_rec': 0.6279, 'test_acc': 0.5522, 'test_pre': 0.54286418131056, 'test_rec': 0.6611}\n",
      "train: 0.6959\n",
      "test:  0.5522\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6881, 'train_pre': 0.7171052631578947, 'train_rec': 0.6213, 'test_acc': 0.5514, 'test_pre': 0.5418498615860609, 'test_rec': 0.6655}\n",
      "train: 0.6881\n",
      "test:  0.5514\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 64, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6877, 'train_pre': 0.7022629310344828, 'train_rec': 0.6517, 'test_acc': 0.55045, 'test_pre': 0.5406036217303823, 'test_rec': 0.6717}\n",
      "train: 0.6877\n",
      "test:  0.55045\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6982, 'train_pre': 0.7109408258833546, 'train_rec': 0.668, 'test_acc': 0.55295, 'test_pre': 0.5417224804979907, 'test_rec': 0.6875}\n",
      "train: 0.6982\n",
      "test:  0.55295\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.69815, 'train_pre': 0.7297924156326104, 'train_rec': 0.6293, 'test_acc': 0.5541, 'test_pre': 0.5439765891724923, 'test_rec': 0.6692}\n",
      "train: 0.69815\n",
      "test:  0.5541\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 64, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.68875, 'train_pre': 0.71500170862285, 'train_rec': 0.6277, 'test_acc': 0.551, 'test_pre': 0.5418169891767792, 'test_rec': 0.6608}\n",
      "train: 0.68875\n",
      "test:  0.551\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6925, 'train_pre': 0.721927599723311, 'train_rec': 0.6262, 'test_acc': 0.55205, 'test_pre': 0.5419724215789049, 'test_rec': 0.6721}\n",
      "train: 0.6925\n",
      "test:  0.55205\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.69215, 'train_pre': 0.7214475048980062, 'train_rec': 0.626, 'test_acc': 0.5518, 'test_pre': 0.5417944166532193, 'test_rec': 0.6715}\n",
      "train: 0.69215\n",
      "test:  0.5518\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.69685, 'train_pre': 0.7087265401336019, 'train_rec': 0.6684, 'test_acc': 0.5523, 'test_pre': 0.5414947635671216, 'test_rec': 0.6825}\n",
      "train: 0.69685\n",
      "test:  0.5523\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6961, 'train_pre': 0.7069875448596158, 'train_rec': 0.6698, 'test_acc': 0.5531, 'test_pre': 0.5423782920989625, 'test_rec': 0.6796}\n",
      "train: 0.6961\n",
      "test:  0.5531\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.69945, 'train_pre': 0.731568559154766, 'train_rec': 0.6301, 'test_acc': 0.5542, 'test_pre': 0.5439293240395526, 'test_rec': 0.6711}\n",
      "train: 0.69945\n",
      "test:  0.5542\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.7007, 'train_pre': 0.7120667793744717, 'train_rec': 0.6739, 'test_acc': 0.5529, 'test_pre': 0.5416469847268147, 'test_rec': 0.688}\n",
      "train: 0.7007\n",
      "test:  0.5529\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 64, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.69375, 'train_pre': 0.7080872086779079, 'train_rec': 0.6593, 'test_acc': 0.5526, 'test_pre': 0.5417659202794982, 'test_rec': 0.6823}\n",
      "train: 0.69375\n",
      "test:  0.5526\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.69355, 'train_pre': 0.702648937284054, 'train_rec': 0.6711, 'test_acc': 0.55105, 'test_pre': 0.5410007228335073, 'test_rec': 0.6736}\n",
      "train: 0.69355\n",
      "test:  0.55105\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 64, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.69215, 'train_pre': 0.7159716758457907, 'train_rec': 0.637, 'test_acc': 0.5526, 'test_pre': 0.54257041113629, 'test_rec': 0.6704}\n",
      "train: 0.69215\n",
      "test:  0.5526\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.70095, 'train_pre': 0.7127580730545262, 'train_rec': 0.6732, 'test_acc': 0.5539, 'test_pre': 0.5420240137221269, 'test_rec': 0.6952}\n",
      "train: 0.70095\n",
      "test:  0.5539\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.68885, 'train_pre': 0.7179457587997692, 'train_rec': 0.6221, 'test_acc': 0.55105, 'test_pre': 0.5414669807489237, 'test_rec': 0.6666}\n",
      "train: 0.68885\n",
      "test:  0.55105\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.69075, 'train_pre': 0.7201384881708021, 'train_rec': 0.624, 'test_acc': 0.5515, 'test_pre': 0.5416329830234439, 'test_rec': 0.67}\n",
      "train: 0.69075\n",
      "test:  0.5515\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.69235, 'train_pre': 0.7258954785672342, 'train_rec': 0.6181, 'test_acc': 0.5523, 'test_pre': 0.543388086942094, 'test_rec': 0.655}\n",
      "train: 0.69235\n",
      "test:  0.5523\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.68395, 'train_pre': 0.7155243116578793, 'train_rec': 0.6107, 'test_acc': 0.55105, 'test_pre': 0.5431712473572938, 'test_rec': 0.6423}\n",
      "train: 0.68395\n",
      "test:  0.55105\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.69095, 'train_pre': 0.7230463730872562, 'train_rec': 0.619, 'test_acc': 0.5518, 'test_pre': 0.5430948419301165, 'test_rec': 0.6528}\n",
      "train: 0.69095\n",
      "test:  0.5518\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6903, 'train_pre': 0.7221055088702147, 'train_rec': 0.6187, 'test_acc': 0.55155, 'test_pre': 0.5430480167014614, 'test_rec': 0.6503}\n",
      "train: 0.6903\n",
      "test:  0.55155\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6948, 'train_pre': 0.7015311400786262, 'train_rec': 0.6781, 'test_acc': 0.5503, 'test_pre': 0.5386863559452392, 'test_rec': 0.7004}\n",
      "train: 0.6948\n",
      "test:  0.5503\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.69615, 'train_pre': 0.7276314262504352, 'train_rec': 0.627, 'test_acc': 0.55245, 'test_pre': 0.5431438677305256, 'test_rec': 0.6603}\n",
      "train: 0.69615\n",
      "test:  0.55245\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6879, 'train_pre': 0.7174768518518518, 'train_rec': 0.6199, 'test_acc': 0.5504, 'test_pre': 0.5421898543445505, 'test_rec': 0.6477}\n",
      "train: 0.6879\n",
      "test:  0.5504\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.68685, 'train_pre': 0.7153890489913545, 'train_rec': 0.6206, 'test_acc': 0.5506, 'test_pre': 0.5412052117263844, 'test_rec': 0.6646}\n",
      "train: 0.68685\n",
      "test:  0.5506\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6973, 'train_pre': 0.729578775890156, 'train_rec': 0.627, 'test_acc': 0.55485, 'test_pre': 0.5448157529209903, 'test_rec': 0.6668}\n",
      "train: 0.6973\n",
      "test:  0.55485\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.69215, 'train_pre': 0.7034840622683469, 'train_rec': 0.6643, 'test_acc': 0.55105, 'test_pre': 0.5411262386208008, 'test_rec': 0.6717}\n",
      "train: 0.69215\n",
      "test:  0.55105\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 64, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.68835, 'train_pre': 0.7151342090234152, 'train_rec': 0.6261, 'test_acc': 0.5508, 'test_pre': 0.5419072760270582, 'test_rec': 0.6569}\n",
      "train: 0.68835\n",
      "test:  0.5508\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.7008, 'train_pre': 0.7095595908996034, 'train_rec': 0.6799, 'test_acc': 0.55285, 'test_pre': 0.5413763407187036, 'test_rec': 0.6915}\n",
      "train: 0.7008\n",
      "test:  0.55285\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 64, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.69625, 'train_pre': 0.7109534558744491, 'train_rec': 0.6614, 'test_acc': 0.5524, 'test_pre': 0.5414950902755781, 'test_rec': 0.6838}\n",
      "train: 0.69625\n",
      "test:  0.5524\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6916, 'train_pre': 0.7209409594095941, 'train_rec': 0.6252, 'test_acc': 0.5513, 'test_pre': 0.5414244186046512, 'test_rec': 0.6705}\n",
      "train: 0.6916\n",
      "test:  0.5513\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.69805, 'train_pre': 0.7091120261851969, 'train_rec': 0.6716, 'test_acc': 0.5518, 'test_pre': 0.540929203539823, 'test_rec': 0.6846}\n",
      "train: 0.69805\n",
      "test:  0.5518\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 64, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.68145, 'train_pre': 0.7000330724286187, 'train_rec': 0.635, 'test_acc': 0.55025, 'test_pre': 0.5415873541339071, 'test_rec': 0.6544}\n",
      "train: 0.68145\n",
      "test:  0.55025\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6923, 'train_pre': 0.6994813278008298, 'train_rec': 0.6743, 'test_acc': 0.55085, 'test_pre': 0.5406182602444285, 'test_rec': 0.6768}\n",
      "train: 0.6923\n",
      "test:  0.55085\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 64, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6918, 'train_pre': 0.7209168394379175, 'train_rec': 0.6259, 'test_acc': 0.55235, 'test_pre': 0.5429838246161426, 'test_rec': 0.6613}\n",
      "train: 0.6918\n",
      "test:  0.55235\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.69875, 'train_pre': 0.7284220204574187, 'train_rec': 0.6338, 'test_acc': 0.5553, 'test_pre': 0.5449739752765127, 'test_rec': 0.6701}\n",
      "train: 0.69875\n",
      "test:  0.5553\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 64, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.69145, 'train_pre': 0.7086648501362398, 'train_rec': 0.6502, 'test_acc': 0.5525, 'test_pre': 0.5422501207146306, 'test_rec': 0.6738}\n",
      "train: 0.69145\n",
      "test:  0.5525\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.69445, 'train_pre': 0.719941183124081, 'train_rec': 0.6365, 'test_acc': 0.5529, 'test_pre': 0.5431414124938836, 'test_rec': 0.666}\n",
      "train: 0.69445\n",
      "test:  0.5529\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6939, 'train_pre': 0.700807787903894, 'train_rec': 0.6767, 'test_acc': 0.55035, 'test_pre': 0.5388653029718256, 'test_rec': 0.6981}\n",
      "train: 0.6939\n",
      "test:  0.55035\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.692, 'train_pre': 0.7226861517049409, 'train_rec': 0.6231, 'test_acc': 0.5533, 'test_pre': 0.5442397078353254, 'test_rec': 0.6557}\n",
      "train: 0.692\n",
      "test:  0.5533\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.69685, 'train_pre': 0.7326557144545562, 'train_rec': 0.6199, 'test_acc': 0.55385, 'test_pre': 0.5443757725587145, 'test_rec': 0.6606}\n",
      "train: 0.69685\n",
      "test:  0.55385\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 64, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.68805, 'train_pre': 0.7023130715438408, 'train_rec': 0.6528, 'test_acc': 0.55005, 'test_pre': 0.5403466344216042, 'test_rec': 0.6703}\n",
      "train: 0.68805\n",
      "test:  0.55005\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6886, 'train_pre': 0.7176321255481191, 'train_rec': 0.6219, 'test_acc': 0.5515, 'test_pre': 0.5419039869812856, 'test_rec': 0.666}\n",
      "train: 0.6886\n",
      "test:  0.5515\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6889, 'train_pre': 0.7193960511033681, 'train_rec': 0.6194, 'test_acc': 0.5523, 'test_pre': 0.5437730164044191, 'test_rec': 0.6497}\n",
      "train: 0.6889\n",
      "test:  0.5523\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6854, 'train_pre': 0.7136929460580913, 'train_rec': 0.6192, 'test_acc': 0.5501, 'test_pre': 0.5408979591836734, 'test_rec': 0.6626}\n",
      "train: 0.6854\n",
      "test:  0.5501\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6871, 'train_pre': 0.7159012231710131, 'train_rec': 0.6204, 'test_acc': 0.5511, 'test_pre': 0.5415920559986978, 'test_rec': 0.6654}\n",
      "train: 0.6871\n",
      "test:  0.5511\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.703, 'train_pre': 0.7166488794023479, 'train_rec': 0.6715, 'test_acc': 0.55265, 'test_pre': 0.5414860925065007, 'test_rec': 0.6872}\n",
      "train: 0.703\n",
      "test:  0.55265\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 64, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6917, 'train_pre': 0.7057308435286542, 'train_rec': 0.6576, 'test_acc': 0.55275, 'test_pre': 0.5421831267493002, 'test_rec': 0.678}\n",
      "train: 0.6917\n",
      "test:  0.55275\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6897, 'train_pre': 0.7210440456769984, 'train_rec': 0.6188, 'test_acc': 0.5521, 'test_pre': 0.5435691587221944, 'test_rec': 0.65}\n",
      "train: 0.6897\n",
      "test:  0.5521\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.69385, 'train_pre': 0.7274433884782353, 'train_rec': 0.62, 'test_acc': 0.5528, 'test_pre': 0.5436724565756824, 'test_rec': 0.6573}\n",
      "train: 0.69385\n",
      "test:  0.5528\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 64, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6864, 'train_pre': 0.7098626435487503, 'train_rec': 0.6305, 'test_acc': 0.55085, 'test_pre': 0.5418759779296715, 'test_rec': 0.658}\n",
      "train: 0.6864\n",
      "test:  0.55085\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.68955, 'train_pre': 0.7187031268028152, 'train_rec': 0.6229, 'test_acc': 0.55145, 'test_pre': 0.5417173437119922, 'test_rec': 0.6681}\n",
      "train: 0.68955\n",
      "test:  0.55145\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6955, 'train_pre': 0.7082002129925452, 'train_rec': 0.665, 'test_acc': 0.5512, 'test_pre': 0.5411046885035324, 'test_rec': 0.674}\n",
      "train: 0.6955\n",
      "test:  0.5512\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6938, 'train_pre': 0.7132951793968743, 'train_rec': 0.6481, 'test_acc': 0.5525, 'test_pre': 0.5424482535575679, 'test_rec': 0.6709}\n",
      "train: 0.6938\n",
      "test:  0.5525\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 64, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.68495, 'train_pre': 0.6956107879428873, 'train_rec': 0.6577, 'test_acc': 0.5504, 'test_pre': 0.5404884318766067, 'test_rec': 0.6728}\n",
      "train: 0.68495\n",
      "test:  0.5504\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6929, 'train_pre': 0.7000622277535781, 'train_rec': 0.675, 'test_acc': 0.55005, 'test_pre': 0.5387774076082745, 'test_rec': 0.6954}\n",
      "train: 0.6929\n",
      "test:  0.55005\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.69905, 'train_pre': 0.7298233460339453, 'train_rec': 0.6321, 'test_acc': 0.55465, 'test_pre': 0.5444200601479314, 'test_rec': 0.6698}\n",
      "train: 0.69905\n",
      "test:  0.55465\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 64, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.68835, 'train_pre': 0.7059595407326408, 'train_rec': 0.6456, 'test_acc': 0.55035, 'test_pre': 0.5407066052227343, 'test_rec': 0.6688}\n",
      "train: 0.68835\n",
      "test:  0.55035\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 64, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6946, 'train_pre': 0.7130968024529128, 'train_rec': 0.6512, 'test_acc': 0.55105, 'test_pre': 0.5408825178185312, 'test_rec': 0.6754}\n",
      "train: 0.6946\n",
      "test:  0.55105\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.69965, 'train_pre': 0.7073854783421627, 'train_rec': 0.681, 'test_acc': 0.55205, 'test_pre': 0.5406608858682915, 'test_rec': 0.6921}\n",
      "train: 0.69965\n",
      "test:  0.55205\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 64, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6937, 'train_pre': 0.7155575339416871, 'train_rec': 0.643, 'test_acc': 0.55235, 'test_pre': 0.5422961945544155, 'test_rec': 0.6712}\n",
      "train: 0.6937\n",
      "test:  0.55235\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 64, 'do': 0.5, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.68935, 'train_pre': 0.716721986952043, 'train_rec': 0.6262, 'test_acc': 0.5514, 'test_pre': 0.5421657095980311, 'test_rec': 0.6609}\n",
      "train: 0.68935\n",
      "test:  0.5514\n",
      "{'n_classes': 100, 'alpha': 0.001, 'max_iter': 100, 'lambda_': 1e-05, 'tolerance': 1e-05, 'sgdDP': False, 'L': 1, 'C': 1, 'epsilon': 1, 'delta': 1e-05, 'sigma': 0, 'DP': False, 'model_name': 'attack_model', 'learning_rate': 0.001, 'weight_decay': 1e-05, 'epoch': 400, 'h_neurons': 128, 'do': 0, 'number_of_sms': 5, 'shadow_size': 10000, 'train_acc': 0.6925, 'train_pre': 0.721927599723311, 'train_rec': 0.6262, 'test_acc': 0.55205, 'test_pre': 0.5419724215789049, 'test_rec': 0.6721}\n",
      "train: 0.6925\n",
      "test:  0.55205\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in aparams:\n",
    "    if aparams[i]['test_acc']>0.55:\n",
    "        print(aparams[i])\n",
    "        print('train:', aparams[i]['train_acc'])\n",
    "        print('test: ', aparams[i]['test_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "35e597cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LogisticRegression_DPSGD' object has no attribute 'theta'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [73]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m train_res \u001b[38;5;241m=\u001b[39m attack_evaluation(attack_model, attack_train_data, attack_train_target)\n\u001b[0;32m----> 2\u001b[0m test_res \u001b[38;5;241m=\u001b[39m \u001b[43mattack\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmi_attack_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattack_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_target_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_target_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_target_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_target_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m attack_params\u001b[38;5;241m.\u001b[39mnumber_of_sms \u001b[38;5;241m=\u001b[39m number_of_sms\n\u001b[1;32m      5\u001b[0m attack_params\u001b[38;5;241m.\u001b[39mshadow_size \u001b[38;5;241m=\u001b[39m shadow_size\n",
      "File \u001b[0;32m~/Documents/Projects/dp_fl/attack.py:123\u001b[0m, in \u001b[0;36mmi_attack_test\u001b[0;34m(model, a_model, x_target_train, y_target_train, x_target_test, y_target_test)\u001b[0m\n\u001b[1;32m    120\u001b[0m x_target_train, y_target_train \u001b[38;5;241m=\u001b[39m  x_target_train[:set_size], y_target_train[:set_size]\n\u001b[1;32m    121\u001b[0m x_target_test, y_target_test \u001b[38;5;241m=\u001b[39m x_target_test[:set_size], y_target_test[:set_size]\n\u001b[0;32m--> 123\u001b[0m train_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_target_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_target_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m test_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(x_target_test, y_target_test)\n\u001b[1;32m    126\u001b[0m y_train \u001b[38;5;241m=\u001b[39m y_ohe(model, y_target_train)\n",
      "File \u001b[0;32m~/Documents/Projects/dp_fl/algo.py:86\u001b[0m, in \u001b[0;36mLogisticRegression_DPSGD.predict\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;124;03m    Predict class labels for samples in X\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;124;03m        Predicted class labels\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtheta\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     87\u001b[0m         X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mones([X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],\u001b[38;5;241m1\u001b[39m]), X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m#add column to the data for bias\u001b[39;00m\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtheta\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LogisticRegression_DPSGD' object has no attribute 'theta'"
     ]
    }
   ],
   "source": [
    "train_res = attack_evaluation(attack_model, attack_train_data, attack_train_target)\n",
    "test_res = attack.mi_attack_test(model, attack_model, x_target_train, y_target_train, x_target_test, y_target_test)\n",
    "\n",
    "attack_params.number_of_sms = number_of_sms\n",
    "attack_params.shadow_size = shadow_size\n",
    "\n",
    "attack_params.train_acc, attack_params.train_pre, attack_params.train_rec = train_res\n",
    "attack_params.test_acc, attack_params.test_pre, attack_params.test_rec = test_res\n",
    "\n",
    "a_param = dict(shadow_model.__dict__)\n",
    "a_param.pop('theta')\n",
    "a_param.pop('pred_func')\n",
    "a_param.pop('accuracy')\n",
    "a_param.update(dict(attack_params.__dict__))\n",
    "a_param\n",
    "\n",
    "k+=1\n",
    "at_path = 'mia/loan/attack_model'+str(k)\n",
    "torch.save(attack_model, at_path)\n",
    "with open(at_path+'_params.json', 'w') as file:\n",
    "    json.dump(a_param, file)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cd5e8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d1108d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sh_path = f'mia/shms{number_of_sms}_shtrsize{shadow_size}_shlr{shadow_model.alpha}_shiter{int(shadow_model.max_iter/shadow_batch_size)}_shreg{shadow_model.lambda_}/'      \n",
    "os.mkdir(sh_path)\n",
    "\n",
    "torch.save(attack_train_data, sh_path+'attack_train_data.pt')\n",
    "torch.save(attack_train_target, sh_path+'attack_train_target.pt')\n",
    "\n",
    "at_path = sh_path+f'attack_model_aneur{attack_model.h_neurons}_ado{attack_model.do}_alr{attack_train_args.learning_rate}_alreg{attack_train_args.weight_decay}_aepoch{attack_train_args.epoch}'\n",
    "torch.save(attack_model, at_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2e82b131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6107, 0.5711531045121481, 0.8886)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_acc, train_pre, train_rec = attack_evaluation(attack_model, attack_train_data, attack_train_target)\n",
    "train_acc, train_pre, train_rec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "655d2c37",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'attack_test_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [82]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test_acc, test_pre, test_rec \u001b[38;5;241m=\u001b[39m attack_evaluation(attack_model, \u001b[43mattack_test_data\u001b[49m, attack_test_target)\n\u001b[1;32m      2\u001b[0m test_acc, test_pre, test_rec\n",
      "\u001b[0;31mNameError\u001b[0m: name 'attack_test_data' is not defined"
     ]
    }
   ],
   "source": [
    "test_acc, test_pre, test_rec = attack.mi_attack_test(model, attack_model, x_target_train, y_target_train, x_target_test, y_target_test)\n",
    "test_acc, test_pre, test_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1193a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MI optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f833cccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2178b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_seed=42\n",
    "np.random.seed(rand_seed)\n",
    "# random.seed(rand_seed)\n",
    "torch.manual_seed(rand_seed)\n",
    "\n",
    "epo = [200]\n",
    "wd = [1e-5, 1e-6]\n",
    "ams = {}\n",
    "for ep in epo:\n",
    "    for w_d in wd:\n",
    "        attack_train_args = Train_args(learning_rate=l_r, weight_decay=w_d, epoch=ep)\n",
    "        attack_model = Net_attack(h_neurons=64, do=0, input_size=attack_train_data.shape[1])\n",
    "        for epoch in range(attack_train_args.epoch):\n",
    "\n",
    "            attack_model = train_model(attack_model, attack_train_data, attack_train_target, attack_train_args)\n",
    "            ams[(l_r,w_d)] = attack_model\n",
    "        at_path = sh_path+f'attack_model_aneur{attack_model.h_neurons}_ado{attack_model.do}_alr{attack_train_args.learning_rate}_alreg{attack_train_args.weight_decay}_aepoch{attack_train_args.epoch}'\n",
    "        torch.save(attack_model, at_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3371d8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "epo = [200,500]\n",
    "wd = [1e-5, 1e-6]\n",
    "\n",
    "for ep in epo:\n",
    "    for w_d in wd:\n",
    "        print(ep, w_d)\n",
    "        attack_train_args = Train_args(learning_rate=l_r, weight_decay=w_d, epoch=500)\n",
    "        attack_model = Net_attack(h_neurons=64, do=0, input_size=attack_train_data.shape[1])\n",
    "        at_path = sh_path+f'attack_model_aneur{attack_model.h_neurons}_ado{attack_model.do}_alr{attack_train_args.learning_rate}_alreg{attack_train_args.weight_decay}_aepoch{attack_train_args.epoch}'\n",
    "        attack_model = torch.load(at_path)\n",
    "        \n",
    "        train_acc, train_pre, train_rec = attack_evaluation(attack_model, attack_train_data, attack_train_target)\n",
    "        print('Train: ', train_acc, train_pre, train_rec)\n",
    "        test_acc, test_pre, test_rec = attack_evaluation(attack_model, attack_test_data, attack_test_target)\n",
    "        print('Test: ' , test_acc, test_pre, test_rec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f715562f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for l_r in lr:\n",
    "    for w_d in wd:\n",
    "        ams[(l_r,w_d)]\n",
    "        train_acc, train_pre, train_rec = attack_evaluation(attack_model, attack_train_data, attack_train_target)\n",
    "        print(\"Train acc pre rec: \", train_acc, train_pre, train_rec)\n",
    "        test_acc, test_pre, test_rec = attack_evaluation(attack_model, attack_test_data, attack_test_target)\n",
    "        print(\"Test acc pre rec: \", test_acc, test_pre, test_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325080ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba7ecbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "shadow_size = 20000\n",
    "shadow_clf = LogisticRegression(random_state=1).fit(x_shadow[:shadow_size], y_shadow[:shadow_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ead4496",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(shadow_clf.score(x_shadow[:shadow_size], y_shadow[:shadow_size]))\n",
    "print(shadow_clf.score(x_shadow[shadow_size:shadow_size*2], y_shadow[shadow_size:shadow_size*2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988f7ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "shadow_train_pred = shadow_clf.predict_proba(x_shadow[:shadow_size])\n",
    "shadow_test_pred = shadow_clf.predict_proba(x_shadow[shadow_size:shadow_size*2])\n",
    "y_shadow_train = y_shadow[:shadow_size]\n",
    "y_shadow_test = y_shadow[shadow_size:shadow_size*2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258d38bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# members\n",
    "labels = np.ones(shadow_train_pred.shape[0])\n",
    "# non-members\n",
    "test_labels = np.zeros(shadow_test_pred.shape[0])\n",
    "\n",
    "x_1 = np.concatenate((shadow_train_pred, shadow_test_pred))\n",
    "x_2 = np.concatenate((y_shadow_train, y_shadow_test)).reshape((-1, 1))\n",
    "y_new = np.concatenate((labels, test_labels))\n",
    "\n",
    "attack_train_data = np.concatenate((x_1,x_2),axis=1)\n",
    "attack_train_target = y_new\n",
    "df = pd.DataFrame(attack_train_data)\n",
    "df['a_target'] = attack_train_target\n",
    "df = df.sample(frac = 1)\n",
    "\n",
    "attack_train_data = np.array(df.drop(['a_target'], axis=1))\n",
    "attack_train_target = np.array(df['a_target'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e799369",
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_train_data = torch.tensor(np.array(df.drop(['a_target'], axis=1)), dtype=torch.float, requires_grad=True)   \n",
    "attack_train_target = torch.tensor(np.array(df['a_target']), dtype=torch.float)\n",
    "attack_train_args = Train_args(learning_rate=0.001, weight_decay=1e-3, epoch=200)\n",
    "attack_model = Net_attack(h_neurons=64, do=0, input_size=attack_train_data.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91bbc86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4930a1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_train_data = torch.tensor(np.array(df.drop(['a_target'], axis=1)), dtype=torch.float, requires_grad=True)   \n",
    "attack_train_target = torch.tensor(np.array(df['a_target']), dtype=torch.float)\n",
    "attack_train_args = Train_args(learning_rate=0.001, weight_decay=1e-3, epoch=500)\n",
    "attack_model = Net_attack(h_neurons=64, do=0, input_size=attack_train_data.shape[1])\n",
    "for epoch in range(attack_train_args.epoch):\n",
    "            \n",
    "    attack_model = train_model(attack_model, attack_train_data, attack_train_target, attack_train_args)\n",
    "    train_acc, train_pre, train_rec = attack_evaluation(attack_model, attack_train_data, attack_train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046e9287",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc, train_pre, train_rec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bbe8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = model.predict(x_target_train, y_target_train)\n",
    "test_pred = model.predict(x_target_test, y_target_test)\n",
    "\n",
    "y_target_train_ohe = OneHotEncoder(sparse=False).fit_transform(y_target_train.reshape(-1,1)) #encoode the target values\n",
    "y_target_test_ohe = OneHotEncoder(sparse=False).fit_transform(y_target_test.reshape(-1,1)) #encoode the target values\n",
    "    \n",
    "# members\n",
    "labels = np.ones(train_pred.shape[0])\n",
    "# non-members\n",
    "test_labels = np.zeros(test_pred.shape[0])\n",
    "\n",
    "x_1 = np.concatenate((train_pred, test_pred))\n",
    "x_2 = np.concatenate((y_target_train_ohe, y_target_test_ohe))#.reshape((-1, 1))\n",
    "y_new = np.concatenate((labels, test_labels))\n",
    "\n",
    "attack_test_data = np.concatenate((x_1,x_2),axis=1)\n",
    "attack_test_target = y_new\n",
    "df = pd.DataFrame(attack_test_data)\n",
    "df['a_target'] = attack_test_target\n",
    "df = df.sample(frac = 1)\n",
    "\n",
    "attack_test_data = torch.tensor(np.array(df.drop(['a_target'], axis=1)), dtype=torch.float, requires_grad=True)\n",
    "attack_test_target = torch.tensor(np.array(df['a_target']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af443ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc, test_pre, test_rec = attack_evaluation(a_model, attack_test_data, attack_test_target)\n",
    "test_acc, test_pre, test_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f32a7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_model = Net_attack(h_neurons=64, do=0, input_size=100)\n",
    "a_model = torch.load('attack_model') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891b5b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rand_seed=42\n",
    "np.random.seed(rand_seed)\n",
    "# random.seed(rand_seed)\n",
    "torch.manual_seed(rand_seed)\n",
    "\n",
    "lr = [0.001]\n",
    "wd = [1e-4, 1e-6]\n",
    "tms = {}\n",
    "for l_r in lr:\n",
    "    for w_d in wd:\n",
    "        model = algo.LogisticRegression_DPSGD()\n",
    "\n",
    "        model.n_classes      = 100\n",
    "        model.alpha          = 0.001\n",
    "        model.max_iter       = 100*X_train_size \n",
    "        model.lambda_        = 1e-3\n",
    "        model.tolerance      = 10e-5\n",
    "        model.DP             = True\n",
    "        model.epsilon\n",
    "\n",
    "        X,y = model.init_theta(x_target_train, y_target_train)\n",
    "        model.SGD(X,y)\n",
    "        model.evaluate(x_target_train, y_target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3e39e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import algo\n",
    "# import attack\n",
    "\n",
    "# from torch import nn,optim\n",
    "import torch\n",
    "\n",
    "rand_seed=42\n",
    "np.random.seed(rand_seed)\n",
    "torch.manual_seed(rand_seed)\n",
    "        \n",
    "\n",
    "raw_data_path = '../datasets/dataset_purchase'\n",
    "raw_data = pd.read_csv(raw_data_path)\n",
    "y=raw_data['63']\n",
    "X=raw_data.drop('63', axis=1)\n",
    "y =  y.replace(100, 0)\n",
    "print('Dataset: ', raw_data_path)\n",
    "print('Classes in classification task: ', y.nunique())\n",
    "n_classes = y.nunique()\n",
    "\n",
    "X_train, x_shadow, y_train, y_shadow = train_test_split(X, y, train_size=0.2, random_state=rand_seed)\n",
    "print(X_train.shape, x_shadow.shape)\n",
    "\n",
    "#Target model\n",
    "X_train_size = 10000\n",
    "X_test_size = 10000\n",
    "x_target_train = np.array(X_train[:X_train_size])\n",
    "y_target_train = np.array(y_train[:X_train_size])\n",
    "x_target_test = np.array(X_train[X_train_size:X_train_size+X_test_size])\n",
    "y_target_test = np.array(y_train[X_train_size:X_train_size+X_test_size])\n",
    "if y_target_test.shape[0]<X_test_size or y_target_train.shape[0]<X_train_size:\n",
    "    raise ValueError(\n",
    "            \"Not enough traning or test data for the target model\")\n",
    "\n",
    "for L in [1,10,100]:\n",
    "    for epsilon in np.arange(0,1,0.1):\n",
    "        model = algo.LogisticRegression_DPSGD()\n",
    "\n",
    "        model.n_classes      = n_classes\n",
    "        model.alpha          = 0.001\n",
    "        model.max_iter       = 100*X_train_size\n",
    "        model.lambda_        = 1e-3\n",
    "        model.tolerance      = 10e-5\n",
    "        model.DP             = True\n",
    "        model.L              = L\n",
    "        model.epsilon        = epsilon\n",
    "\n",
    "\n",
    "        X,y = model.init_theta(x_target_train, y_target_train)\n",
    "        model.train(X,y)\n",
    "        model.evaluate(x_target_train, y_target_train, acc=True)\n",
    "        model.evaluate(x_target_test, y_target_test, acc=True)\n",
    "\n",
    "        tm_path = f'tm/lr{model.alpha}_iter{int(model.max_iter/X_train_size)}_reg{model.lambda_}_DP{model.DP}'\n",
    "        if model.DP:\n",
    "            tm_path += f'_eps{model.epsilon}_L{model.L}'\n",
    "        np.save(tm_path+'_target_model', model.theta)\n",
    "\n",
    "        print(tm_path)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e9f215",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shadow models\n",
    "# s_ms = {}\n",
    "# number_of_sms = 10\n",
    "# shadow_size = 50000\n",
    "# shadow_batch_size = int(shadow_size/number_of_sms)\n",
    "\n",
    "# x_shadow_train = np.array(x_shadow[:shadow_size])\n",
    "# y_shadow_train = np.array(y_shadow[:shadow_size])\n",
    "# x_shadow_test = np.array(x_shadow[shadow_size:2*shadow_size])\n",
    "# y_shadow_test = np.array(y_shadow[shadow_size:2*shadow_size])\n",
    "\n",
    "# attack.train_shadow_models(number_of_sms,)\n",
    "\n",
    "# for i in range(number_of_sms):  \n",
    "#     batch_start = i*shadow_batch_size\n",
    "#     batch_end = (i+1)*shadow_batch_size\n",
    "    \n",
    "#     shadow_model = algo.LogisticRegression_DPSGD()\n",
    "\n",
    "#     shadow_model.n_classes      = n_classes\n",
    "#     shadow_model.alpha          = 0.001\n",
    "#     shadow_model.max_iter       = 100*shadow_batch_size\n",
    "#     shadow_model.lambda_        = 10e-3\n",
    "#     shadow_model.tolerance      = 10e-5\n",
    "#     shadow_model.DP             = False\n",
    "\n",
    "#     X,y = shadow_model.init_theta(x_shadow_train[batch_start:batch_end], y_shadow_train[batch_start:batch_end] )\n",
    "#     shadow_model.SGD(X,y)\n",
    "#     print('Shadow model: ', i)\n",
    "#     shadow_model.evaluate(x_shadow_train[batch_start:batch_end], y_shadow_train[batch_start:batch_end])\n",
    "#     shadow_model.evaluate(x_shadow_test[batch_start:batch_end], y_shadow_test[batch_start:batch_end])\n",
    "#     s_ms[i] = shadow_model\n",
    "\n",
    "# #Attack model\n",
    "\n",
    "# shadow_train_pred = []\n",
    "# shadow_test_pred = []\n",
    "\n",
    "# for i in range(number_of_sms): \n",
    "#     batch_start = i*shadow_batch_size\n",
    "#     batch_end = (i+1)*shadow_batch_size\n",
    "    \n",
    "#     train_prediciton = s_ms[i].predict(x_shadow_train[batch_start:batch_end], y_shadow_train[batch_start:batch_end])\n",
    "#     test_prediciton = s_ms[i].predict(x_shadow_test[batch_start:batch_end], y_shadow_test[batch_start:batch_end])\n",
    "    \n",
    "#     shadow_train_pred.append(train_prediciton)\n",
    "#     shadow_test_pred.append(test_prediciton)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "3bdfc1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attack models\n",
    "from torch import nn\n",
    "\n",
    "class Net_attack(nn.Module):\n",
    "\n",
    "    def __init__(self, h_neurons, do, input_size):\n",
    "        super(Net_attack, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.h_neurons = h_neurons\n",
    "        self.do = do\n",
    "        self.fc1 = nn.Linear(input_size, h_neurons)\n",
    "        self.fc2 = nn.Linear(h_neurons, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.drop = nn.Dropout(do)\n",
    "        self.softmax = nn.Softmax(dim=1)   \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.input_size)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "path = 'mia'\n",
    "ams = {}\n",
    "for r,d,f in os.walk(path):\n",
    "    for file in f:\n",
    "        if \"best_mi_model\" in file:\n",
    "            ams[file] = Net_attack(h_neurons=64, do=0, input_size=200)\n",
    "            ams[file] = torch.load(r+'/'+file)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "4a3ca102",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8851e49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_dict = attack.test_mi_attack(ams, target_model, x_target_train, y_target_train, x_target_test, y_target_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "0cd702ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attack_acc_mean': 0.5811666666666667,\n",
       " 'attack_acc_std': 0.005857094463601882,\n",
       " 'attack_pre_mean': 0.6439540525080872,\n",
       " 'attack_pre_std': 0.014326959721099111,\n",
       " 'attack_rec_mean': 0.36600000000000005,\n",
       " 'attack_rec_std': 0.04052982440952177}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10 K target \n",
    "attack_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "81c5cfff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<algo.LogisticRegression_DPSGD at 0x199813820>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8409ef07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
