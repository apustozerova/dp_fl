{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "718a424e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "from torch import nn,optim\n",
    "import torch\n",
    "\n",
    "import algo\n",
    "import json\n",
    "\n",
    "rand_seed=42\n",
    "np.random.seed(rand_seed)\n",
    "torch.manual_seed(rand_seed)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import attack\n",
    "import random\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "545f33a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_attack(nn.Module):\n",
    "\n",
    "    def __init__(self, h_neurons, do, input_size):\n",
    "        super(Net_attack, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.h_neurons = h_neurons\n",
    "        self.do = do\n",
    "        self.fc1 = nn.Linear(input_size, h_neurons)\n",
    "        self.fc2 = nn.Linear(h_neurons, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.drop = nn.Dropout(do)\n",
    "        self.softmax = nn.Softmax(dim=1)   \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.input_size)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "class Train_args():\n",
    "\n",
    "    def __init__(self, learning_rate, weight_decay, epoch):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weight_decay = weight_decay\n",
    "        self.epoch = epoch\n",
    "         \n",
    "def train_attack_model(model, train_data, train_target, train_args):\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=train_args.learning_rate, weight_decay=train_args.weight_decay)\n",
    "    \n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(train_data)\n",
    "    loss = nn.CrossEntropyLoss()(output, train_target.to(torch.long))\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "\n",
    "    return model\n",
    "\n",
    "def attack_evaluation(model, x, y, dev=\"cpu\", extended=False):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output =  model(x)\n",
    "        out_target = output.argmax(1, keepdim=True)\n",
    "        correct = out_target.to(dev).eq(y.to(dev).view_as(out_target.to(dev))).sum().item()\n",
    "        acc = correct/y.shape[0]\n",
    "\n",
    "        predicted_positive = output.argmax(1, keepdim=True) == 1\n",
    "        labeled_positive = y == 1\n",
    "        tp = predicted_positive.to(dev) * labeled_positive.to(dev).view_as(out_target)\n",
    "        tp_count = tp.to(dev).sum().item()\n",
    "        \n",
    "        if predicted_positive.to(dev).sum().item() != 0:\n",
    "            pre = tp_count / predicted_positive.to(dev).sum().item()\n",
    "        else:\n",
    "            pre = 0\n",
    "        if labeled_positive.to(dev).sum().item() !=0:\n",
    "            rec = tp_count / labeled_positive.to(dev).sum().item()\n",
    "        else:\n",
    "            rec = 0\n",
    "    if extended:\n",
    "        predicted_negative = output.argmax(1, keepdim=True) == 0\n",
    "        labeled_negative = y == 0\n",
    "        tn = predicted_negative.to(dev) * labeled_negative.to(dev).view_as(out_target)\n",
    "        tn_count = tn.to(dev).sum().item()\n",
    "\n",
    "        fp_count = predicted_positive.to(dev).sum().item() - tp.to(dev).sum().item()\n",
    "        fn_count = labeled_positive.to(dev).sum().item() - tp.to(dev).sum().item()\n",
    "        \n",
    "        return acc, pre, rec, tp_count, tn_count, fp_count, fn_count\n",
    "    else:\n",
    "        return acc, pre, rec\n",
    "\n",
    "class model_params(object):\n",
    "\n",
    "    def __init__(self, model_name):\n",
    "        self.model_name      = model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b97d5cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_data = pd.read_csv('../datasets/dataset_purchase', )\n",
    "# y=raw_data['63']\n",
    "# X=raw_data.drop('63', axis=1)\n",
    "# y =  y.replace(100, 0)\n",
    "# print(y.nunique())\n",
    "\n",
    "# X_train, x_shadow, y_train, y_shadow = train_test_split(X, y, train_size=0.1, random_state=42)\n",
    "# print(X_train.shape, x_shadow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc381c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../DP-UTIL.nosync/loan_preprocessed.csv', index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22e21b4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(661283, 167)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e444fe6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loan\n",
    "y = data['grade']\n",
    "X = data.drop('grade', axis=1)\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "tr_size = 1000\n",
    "X_train, X_test, y_train, y_test = train_test_split(X[0:100000], y[0:100000], train_size=0.5, random_state=0)\n",
    "x_target_train = np.array(X_train)[:tr_size]\n",
    "y_target_train = np.array(y_train)[:tr_size]\n",
    "x_target_test = np.array(X_test)[:tr_size]\n",
    "y_target_test = np.array(y_test)[:tr_size]\n",
    "\n",
    "x_shadow = X[100000:]\n",
    "y_shadow = y[100000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "602ac2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = algo.LogisticRegression_DPSGD()\n",
    "\n",
    "model.n_classes      = len(np.unique(y_target_test))\n",
    "model.alpha          = 0.001\n",
    "model.max_iter       = 100\n",
    "model.lambda_        = 1e-5\n",
    "model.tolerance      = 1e-5\n",
    "model.DP             = False\n",
    "model.L              = 1\n",
    "model.epsilon        = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f2b256ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model : 84.39999999999999 %\n",
      "The accuracy of the model : 57.99999999999999 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.58"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_seed=42\n",
    "np.random.seed(rand_seed)\n",
    "torch.manual_seed(rand_seed)\n",
    "random.seed(rand_seed)\n",
    "\n",
    "X,y = model.init_theta(x_target_train, y_target_train)\n",
    "model.train(X,y)\n",
    "model.evaluate(x_target_train, y_target_train, acc=True)\n",
    "model.evaluate(x_target_test, y_target_test, acc=True)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2b54ef05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model : 88.0 %\n",
      "The accuracy of the model : 83.7 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8371"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_target_train, y_target_train, acc=True)\n",
    "model.evaluate(x_target_test, y_target_test, acc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "c2f620cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/66/0p0lnj8d6zj532q0yvm1zt580000gn/T/ipykernel_4428/3992013641.py:7: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  y_shadow_train = np.array(y_shadow[:shadow_size])\n",
      "/var/folders/66/0p0lnj8d6zj532q0yvm1zt580000gn/T/ipykernel_4428/3992013641.py:9: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  y_shadow_test = np.array(y_shadow[shadow_size:2*shadow_size])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shadow model:  0\n",
      "The accuracy of the model : 86.2 %\n",
      "The accuracy of the model : 78.4 %\n",
      "Shadow model:  1\n",
      "The accuracy of the model : 87.0 %\n",
      "The accuracy of the model : 78.3 %\n",
      "Shadow model:  2\n",
      "The accuracy of the model : 86.7 %\n",
      "The accuracy of the model : 78.9 %\n",
      "Shadow model:  3\n",
      "The accuracy of the model : 87.1 %\n",
      "The accuracy of the model : 80.30000000000001 %\n",
      "Shadow model:  4\n",
      "The accuracy of the model : 86.3 %\n",
      "The accuracy of the model : 79.3 %\n",
      "Shadow model:  5\n",
      "The accuracy of the model : 87.0 %\n",
      "The accuracy of the model : 79.7 %\n",
      "Shadow model:  6\n",
      "The accuracy of the model : 85.6 %\n",
      "The accuracy of the model : 78.8 %\n",
      "Shadow model:  7\n",
      "The accuracy of the model : 86.6 %\n",
      "The accuracy of the model : 78.8 %\n",
      "Shadow model:  8\n",
      "The accuracy of the model : 86.3 %\n",
      "The accuracy of the model : 78.4 %\n",
      "Shadow model:  9\n",
      "The accuracy of the model : 86.4 %\n",
      "The accuracy of the model : 78.2 %\n"
     ]
    }
   ],
   "source": [
    "s_ms = {}\n",
    "number_of_sms = 10\n",
    "shadow_size = 40000\n",
    "shadow_batch_size = int(shadow_size/number_of_sms)\n",
    "\n",
    "x_shadow_train = np.array(x_shadow[:shadow_size])\n",
    "y_shadow_train = np.array(y_shadow[:shadow_size])\n",
    "x_shadow_test = np.array(x_shadow[shadow_size:2*shadow_size])\n",
    "y_shadow_test = np.array(y_shadow[shadow_size:2*shadow_size])\n",
    "\n",
    "for i in range(number_of_sms):\n",
    "    batch_start = i*shadow_batch_size\n",
    "    batch_end = (i+1)*shadow_batch_size\n",
    "    \n",
    "    shadow_model = algo.LogisticRegression_DPSGD()\n",
    "\n",
    "    shadow_model.n_classes      = len(np.unique(y_target_test))\n",
    "    shadow_model.alpha          = 0.001\n",
    "    shadow_model.max_iter       = 100\n",
    "    shadow_model.lambda_        = 1e-5\n",
    "    shadow_model.tolerance      = 1e-5\n",
    "    shadow_model.DP             = False\n",
    "\n",
    "    X,y = shadow_model.init_theta(x_shadow_train[batch_start:batch_end], y_shadow_train[batch_start:batch_end] )\n",
    "    shadow_model.SGD(X,y)\n",
    "    print('Shadow model: ', i)\n",
    "    shadow_model.evaluate(x_shadow_train[batch_start:batch_end], y_shadow_train[batch_start:batch_end], acc=True)\n",
    "    shadow_model.evaluate(x_shadow_test[batch_start:batch_end], y_shadow_test[batch_start:batch_end], acc=True)\n",
    "    s_ms[i] = shadow_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "04dd133b",
   "metadata": {},
   "outputs": [],
   "source": [
    "shadow_train_pred = []\n",
    "shadow_test_pred = []\n",
    "\n",
    "for i in range(number_of_sms): \n",
    "    batch_start = i*shadow_batch_size\n",
    "    batch_end = (i+1)*shadow_batch_size\n",
    "    \n",
    "    train_prediciton = s_ms[i].predict(x_shadow_train[batch_start:batch_end], y_shadow_train[batch_start:batch_end])\n",
    "    test_prediciton = s_ms[i].predict(x_shadow_test[batch_start:batch_end], y_shadow_test[batch_start:batch_end])\n",
    "    \n",
    "    shadow_train_pred.append(train_prediciton)\n",
    "    shadow_test_pred.append(test_prediciton)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "608b26f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_shadow_train_ohe = OneHotEncoder(sparse=False).fit_transform(y_shadow_train.reshape(-1,1)) #encoode the target values\n",
    "y_shadow_test_ohe = OneHotEncoder(sparse=False).fit_transform(y_shadow_test.reshape(-1,1)) #encoode the target values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "7aa36459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 7)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shadow_train_pred[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "e0522fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sh_train_pred = np.concatenate(shadow_train_pred)\n",
    "sh_test_pred = np.concatenate(shadow_test_pred)\n",
    "\n",
    "# members\n",
    "labels = np.ones(sh_train_pred.shape[0])\n",
    "# non-members\n",
    "test_labels = np.zeros(sh_test_pred.shape[0])\n",
    "\n",
    "x_1 = np.concatenate((sh_train_pred, sh_test_pred))\n",
    "x_2 = np.concatenate((y_shadow_train_ohe, y_shadow_test_ohe))#.reshape((-1, 1))\n",
    "y_new = np.concatenate((labels, test_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "62f9fd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_train_data = np.concatenate((x_1,x_2),axis=1)\n",
    "attack_train_target = y_new\n",
    "df = pd.DataFrame(attack_train_data)\n",
    "df['a_target'] = attack_train_target\n",
    "df = df.sample(frac = 1)\n",
    "\n",
    "attack_train_data = torch.tensor(np.array(df.drop(['a_target'], axis=1)), dtype=torch.float, requires_grad=True)\n",
    "attack_train_target = torch.tensor(np.array(df['a_target']), dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "d4abfc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "f70dc25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: (0.491625, 0.4947346913114548, 0.786925)\n",
      "epoch 1: (0.4910625, 0.4940220390281424, 0.7386)\n",
      "epoch 2: (0.4902875, 0.49315165083114454, 0.6994)\n",
      "epoch 3: (0.4905875, 0.493071784774488, 0.669875)\n",
      "epoch 4: (0.4907625, 0.4930218503899832, 0.65265)\n",
      "epoch 5: (0.4914625, 0.4933772907980219, 0.636025)\n",
      "epoch 6: (0.4928, 0.4942602040816326, 0.62)\n",
      "epoch 7: (0.4937875, 0.49488798831540187, 0.601425)\n",
      "epoch 8: (0.4942125, 0.4951407401188052, 0.589725)\n",
      "epoch 9: (0.4956, 0.4962322315464977, 0.5795)\n",
      "epoch 10: (0.497325, 0.49766528474798166, 0.5702)\n",
      "epoch 11: (0.4990625, 0.4991692328141962, 0.5633)\n",
      "epoch 12: (0.5003, 0.5002689256420599, 0.558075)\n",
      "epoch 13: (0.5011375, 0.5010283647869815, 0.5542)\n",
      "epoch 14: (0.501825, 0.5016619615699845, 0.550875)\n",
      "epoch 15: (0.5025625, 0.5023502166785133, 0.547725)\n",
      "epoch 16: (0.503075, 0.5028378939596696, 0.54485)\n",
      "epoch 17: (0.5035625, 0.5033034286111691, 0.542775)\n",
      "epoch 18: (0.50425, 0.5039597503028045, 0.5409)\n",
      "epoch 19: (0.5049, 0.5045852243484771, 0.539225)\n",
      "epoch 20: (0.5055, 0.505166744950681, 0.53775)\n",
      "epoch 21: (0.505675, 0.5053479715403101, 0.53625)\n",
      "epoch 22: (0.50665, 0.5063045127038301, 0.53405)\n",
      "epoch 23: (0.5081125, 0.507778603447036, 0.529575)\n",
      "epoch 24: (0.5096875, 0.5094206598108575, 0.52385)\n",
      "epoch 25: (0.5106625, 0.5104644600927448, 0.520125)\n",
      "epoch 26: (0.5125375, 0.5123720241766375, 0.519225)\n",
      "epoch 27: (0.5154375, 0.514824862554918, 0.5361)\n",
      "epoch 28: (0.5218375, 0.5191075139450946, 0.593275)\n",
      "epoch 29: (0.5274125, 0.5225603357817419, 0.63495)\n",
      "epoch 30: (0.5308125, 0.5244441800043632, 0.661075)\n",
      "epoch 31: (0.5323125, 0.5253944240328506, 0.668525)\n",
      "epoch 32: (0.532275, 0.525102080497764, 0.67515)\n",
      "epoch 33: (0.5318, 0.525054165845972, 0.666425)\n",
      "epoch 34: (0.5318375, 0.5255985044925526, 0.6537)\n",
      "epoch 35: (0.5322125, 0.5256954830990128, 0.659025)\n",
      "epoch 36: (0.5324625, 0.5261504380223543, 0.65315)\n",
      "epoch 37: (0.5326, 0.5261752780119635, 0.655325)\n",
      "epoch 38: (0.5316375, 0.5257346212506355, 0.646325)\n",
      "epoch 39: (0.5305375, 0.5251146246684623, 0.6385)\n",
      "epoch 40: (0.53025, 0.5248858541401011, 0.638025)\n",
      "epoch 41: (0.5293875, 0.5245207451135818, 0.628625)\n",
      "epoch 42: (0.52925, 0.5245622874417433, 0.624675)\n",
      "epoch 43: (0.5282375, 0.5240262917189594, 0.615875)\n",
      "epoch 44: (0.52775, 0.5238894628099173, 0.60855)\n",
      "epoch 45: (0.527275, 0.523666970367478, 0.6035)\n",
      "epoch 46: (0.5268125, 0.5236843848684937, 0.59285)\n",
      "epoch 47: (0.5275, 0.5229673863114378, 0.626175)\n",
      "epoch 48: (0.527775, 0.5239666925532833, 0.607225)\n",
      "epoch 49: (0.5278875, 0.524230510241762, 0.60335)\n",
      "epoch 50: (0.528625, 0.5247631817985207, 0.6066)\n",
      "epoch 51: (0.5288625, 0.5249670206094159, 0.606875)\n",
      "epoch 52: (0.5294625, 0.5251843145635218, 0.6144)\n",
      "epoch 53: (0.529475, 0.5254720649872532, 0.60805)\n",
      "epoch 54: (0.530875, 0.5251619738396969, 0.6444)\n",
      "epoch 55: (0.5299875, 0.525364234209469, 0.621125)\n",
      "epoch 56: (0.5308125, 0.5261438601701207, 0.6201)\n",
      "epoch 57: (0.5309375, 0.5261125530163955, 0.623325)\n",
      "epoch 58: (0.5316625, 0.5267233557698394, 0.624075)\n",
      "epoch 59: (0.5328625, 0.5265036191705144, 0.652825)\n",
      "epoch 60: (0.532575, 0.5270848923256007, 0.633925)\n",
      "epoch 61: (0.5334375, 0.5279350028196078, 0.631925)\n",
      "epoch 62: (0.533525, 0.528125, 0.629525)\n",
      "epoch 63: (0.5342375, 0.5274135756750805, 0.6587)\n",
      "epoch 64: (0.534975, 0.5289984246745709, 0.638025)\n",
      "epoch 65: (0.5356875, 0.5297278160728045, 0.635925)\n",
      "epoch 66: (0.5362, 0.528799872707745, 0.664675)\n",
      "epoch 67: (0.53615, 0.5296798029556651, 0.64515)\n",
      "epoch 68: (0.536175, 0.5299610733808183, 0.639875)\n",
      "epoch 69: (0.5367875, 0.5303370786516854, 0.6431)\n",
      "epoch 70: (0.537075, 0.5307293825113966, 0.640325)\n",
      "epoch 71: (0.5374875, 0.5299355173584077, 0.663625)\n",
      "epoch 72: (0.53765, 0.5311337137186802, 0.6423)\n",
      "epoch 73: (0.5379625, 0.5313163810348739, 0.644075)\n",
      "epoch 74: (0.53795, 0.5313299760587799, 0.6436)\n",
      "epoch 75: (0.53795, 0.5314116624591317, 0.642025)\n",
      "epoch 76: (0.5384875, 0.5307193455053377, 0.664925)\n",
      "epoch 77: (0.538275, 0.5315644070592116, 0.644575)\n",
      "epoch 78: (0.538675, 0.5308228730822873, 0.66605)\n",
      "epoch 79: (0.5385, 0.5317342565117046, 0.6451)\n",
      "epoch 80: (0.5386625, 0.5318203329149606, 0.646175)\n",
      "epoch 81: (0.5386875, 0.5321104724752558, 0.6411)\n",
      "epoch 82: (0.540075, 0.5322120408327304, 0.662125)\n",
      "epoch 83: (0.5392, 0.532548677709968, 0.641375)\n",
      "epoch 84: (0.540825, 0.5326247652535262, 0.6665)\n",
      "epoch 85: (0.539325, 0.5324570815450643, 0.645125)\n",
      "epoch 86: (0.539125, 0.5324796612983563, 0.641425)\n",
      "epoch 87: (0.5400125, 0.5331538063179699, 0.64345)\n",
      "epoch 88: (0.539325, 0.5327367325702393, 0.63995)\n",
      "epoch 89: (0.5403125, 0.5334120718592652, 0.643575)\n",
      "epoch 90: (0.5402875, 0.5335066015178292, 0.641475)\n",
      "epoch 91: (0.54155, 0.533495908742795, 0.661775)\n",
      "epoch 92: (0.540425, 0.5336931155192532, 0.640325)\n",
      "epoch 93: (0.541875, 0.5335389051299507, 0.66615)\n",
      "epoch 94: (0.5407875, 0.5336954501332122, 0.646025)\n",
      "epoch 95: (0.5408, 0.5337106502520036, 0.64595)\n",
      "epoch 96: (0.5406, 0.5337756332931243, 0.641625)\n",
      "epoch 97: (0.541075, 0.5339504897301318, 0.646)\n",
      "epoch 98: (0.5411875, 0.5343852399140108, 0.6401)\n",
      "epoch 99: (0.542275, 0.5340611529629778, 0.66285)\n",
      "epoch 100: (0.541975, 0.5348803390393884, 0.643675)\n",
      "epoch 101: (0.5423625, 0.5349951467338552, 0.647625)\n",
      "epoch 102: (0.5418375, 0.5348740283826869, 0.641675)\n",
      "epoch 103: (0.542375, 0.5350931677018633, 0.646125)\n",
      "epoch 104: (0.5421875, 0.5351643084873617, 0.64205)\n",
      "epoch 105: (0.5431875, 0.5350157089287524, 0.659875)\n",
      "epoch 106: (0.5428, 0.5357381429525718, 0.6416)\n",
      "epoch 107: (0.543175, 0.5349566836693385, 0.660725)\n",
      "epoch 108: (0.5429, 0.5357276702061212, 0.643275)\n",
      "epoch 109: (0.5434, 0.5351388551534288, 0.66095)\n",
      "epoch 110: (0.5431375, 0.5359351896203428, 0.64335)\n",
      "epoch 111: (0.5434, 0.5349619366012809, 0.664075)\n",
      "epoch 112: (0.5434875, 0.535975017062023, 0.6479)\n",
      "epoch 113: (0.54325, 0.5353465184700883, 0.65505)\n",
      "epoch 114: (0.5433375, 0.5360028245654115, 0.6452)\n",
      "epoch 115: (0.5438125, 0.5353376484584518, 0.663725)\n",
      "epoch 116: (0.5438, 0.5362898214507643, 0.647275)\n",
      "epoch 117: (0.5435, 0.5349566055930569, 0.6657)\n",
      "epoch 118: (0.5437875, 0.5361394821004849, 0.6496)\n",
      "epoch 119: (0.5437125, 0.5351351351351351, 0.665775)\n",
      "epoch 120: (0.54405, 0.5363373891524026, 0.650175)\n",
      "epoch 121: (0.5435875, 0.5349056037157901, 0.66795)\n",
      "epoch 122: (0.544075, 0.536232479756669, 0.6523)\n",
      "epoch 123: (0.544, 0.5355383248525967, 0.66305)\n",
      "epoch 124: (0.544075, 0.536436159219609, 0.6489)\n",
      "epoch 125: (0.5441, 0.5352503896726749, 0.669625)\n",
      "epoch 126: (0.5442375, 0.5361794352777607, 0.6556)\n",
      "epoch 127: (0.544225, 0.535924617196702, 0.65975)\n",
      "epoch 128: (0.5443625, 0.5363604696432597, 0.6544)\n",
      "epoch 129: (0.5446875, 0.5357492850142997, 0.6697)\n",
      "epoch 130: (0.5442875, 0.5362826420890937, 0.6546)\n",
      "epoch 131: (0.5447125, 0.5355037220843673, 0.6744)\n",
      "epoch 132: (0.5443875, 0.5361675256156933, 0.658025)\n",
      "epoch 133: (0.54455, 0.5353992848629321, 0.6738)\n",
      "epoch 134: (0.5442875, 0.5360801645654698, 0.658025)\n",
      "epoch 135: (0.5447875, 0.5355830536079608, 0.674125)\n",
      "epoch 136: (0.5440875, 0.5358850701015404, 0.658375)\n",
      "epoch 137: (0.5446625, 0.5360334012384276, 0.6644)\n",
      "epoch 138: (0.5443125, 0.5363746434361468, 0.653425)\n",
      "epoch 139: (0.5450625, 0.5357589223718928, 0.67515)\n",
      "epoch 140: (0.5444, 0.5361578240156358, 0.658375)\n",
      "epoch 141: (0.544775, 0.5362052235788792, 0.663125)\n",
      "epoch 142: (0.5446, 0.5365020256168924, 0.655525)\n",
      "epoch 143: (0.5455125, 0.536117448665807, 0.675575)\n",
      "epoch 144: (0.5446375, 0.5363150080338438, 0.659225)\n",
      "epoch 145: (0.5447375, 0.5360997357325856, 0.664375)\n",
      "epoch 146: (0.544875, 0.5366640794150088, 0.65685)\n",
      "epoch 147: (0.5451375, 0.5359539598144055, 0.67285)\n",
      "epoch 148: (0.544825, 0.5365948240672708, 0.657275)\n",
      "epoch 149: (0.5448375, 0.5361352326073379, 0.66525)\n",
      "epoch 150: (0.5447375, 0.5367340654829108, 0.653675)\n",
      "epoch 151: (0.54495, 0.5358210144638802, 0.672375)\n",
      "epoch 152: (0.544825, 0.5366471814577116, 0.6564)\n",
      "epoch 153: (0.544975, 0.5363684146686613, 0.6633)\n",
      "epoch 154: (0.544925, 0.5368222613827303, 0.65495)\n",
      "epoch 155: (0.5453375, 0.5361305361305362, 0.67275)\n",
      "epoch 156: (0.5450125, 0.536843397654955, 0.655875)\n",
      "epoch 157: (0.5451875, 0.5365055641952619, 0.6641)\n",
      "epoch 158: (0.5451125, 0.5370937570662117, 0.6532)\n",
      "epoch 159: (0.5451125, 0.5360330677529503, 0.6711)\n",
      "epoch 160: (0.5451875, 0.5369790707665869, 0.656175)\n",
      "epoch 161: (0.5454375, 0.5367149465688948, 0.664225)\n",
      "epoch 162: (0.545325, 0.5372937836837125, 0.653)\n",
      "epoch 163: (0.5452375, 0.5361415702958037, 0.671075)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 164: (0.545425, 0.5372687369241498, 0.65485)\n",
      "epoch 165: (0.54525, 0.5360902855319828, 0.67215)\n",
      "epoch 166: (0.54545, 0.5372403621614978, 0.655675)\n",
      "epoch 167: (0.545525, 0.5363255535607421, 0.67215)\n",
      "epoch 168: (0.5454875, 0.5372657450076805, 0.6558)\n",
      "epoch 169: (0.5456, 0.5364042790994731, 0.6719)\n",
      "epoch 170: (0.5456, 0.537337263571604, 0.65625)\n",
      "epoch 171: (0.545775, 0.5364799171182658, 0.673175)\n",
      "epoch 172: (0.545725, 0.5374365482233503, 0.656425)\n",
      "epoch 173: (0.5457875, 0.5364339851598401, 0.67415)\n",
      "epoch 174: (0.545925, 0.5375112309074573, 0.658075)\n",
      "epoch 175: (0.5458125, 0.5365454799274076, 0.6726)\n",
      "epoch 176: (0.5457875, 0.5374271993460713, 0.657475)\n",
      "epoch 177: (0.545775, 0.5363842301883793, 0.674825)\n",
      "epoch 178: (0.5455875, 0.537142275180772, 0.659275)\n",
      "epoch 179: (0.5458, 0.5365420672597438, 0.672475)\n",
      "epoch 180: (0.54575, 0.5373759241861035, 0.657775)\n",
      "epoch 181: (0.5460125, 0.5365824571167339, 0.6749)\n",
      "epoch 182: (0.54565, 0.5371909242739011, 0.659375)\n",
      "epoch 183: (0.5456875, 0.5364704943223773, 0.67205)\n",
      "epoch 184: (0.5456, 0.5372184133202742, 0.6582)\n",
      "epoch 185: (0.5459375, 0.5365460729131446, 0.674425)\n",
      "epoch 186: (0.545475, 0.5370800717547293, 0.658675)\n",
      "epoch 187: (0.5461875, 0.5367391174657467, 0.674775)\n",
      "epoch 188: (0.5452875, 0.5369128884360672, 0.658725)\n",
      "epoch 189: (0.5462625, 0.5368809167912307, 0.67345)\n",
      "epoch 190: (0.5453125, 0.5369784759767419, 0.658)\n",
      "epoch 191: (0.546225, 0.5368121366568448, 0.674075)\n",
      "epoch 192: (0.5452875, 0.536944506760753, 0.6582)\n",
      "epoch 193: (0.5461125, 0.5367466879171232, 0.67355)\n",
      "epoch 194: (0.5453625, 0.5370192798123024, 0.65805)\n",
      "epoch 195: (0.546225, 0.5367652907022986, 0.674875)\n",
      "epoch 196: (0.5452125, 0.5369043975104582, 0.657775)\n",
      "epoch 197: (0.5464, 0.5370252154484519, 0.673)\n",
      "epoch 198: (0.545125, 0.5368307215148547, 0.657725)\n",
      "epoch 199: (0.5460625, 0.53662512175244, 0.6749)\n",
      "epoch 0: (0.5, 0, 0.0)\n",
      "epoch 1: (0.5, 0, 0.0)\n",
      "epoch 2: (0.5, 0, 0.0)\n",
      "epoch 3: (0.5, 0, 0.0)\n",
      "epoch 4: (0.5, 0, 0.0)\n",
      "epoch 5: (0.4992, 0.25757575757575757, 0.00085)\n",
      "epoch 6: (0.4979125, 0.32712215320910976, 0.00395)\n",
      "epoch 7: (0.49695, 0.37448559670781895, 0.0091)\n",
      "epoch 8: (0.496125, 0.40606060606060607, 0.01675)\n",
      "epoch 9: (0.4947625, 0.43684051854085015, 0.036225)\n",
      "epoch 10: (0.4937875, 0.4614070507842833, 0.074275)\n",
      "epoch 11: (0.5002625, 0.5005287275290801, 0.2485)\n",
      "epoch 12: (0.502775, 0.5047894373489817, 0.292475)\n",
      "epoch 13: (0.5024125, 0.5041350644898659, 0.294125)\n",
      "epoch 14: (0.502425, 0.5036764705882353, 0.332225)\n",
      "epoch 15: (0.5027875, 0.5036036327203387, 0.38955)\n",
      "epoch 16: (0.5039, 0.5048100641341885, 0.4093)\n",
      "epoch 17: (0.50615, 0.5070649052268811, 0.4414)\n",
      "epoch 18: (0.50825, 0.5090065502183406, 0.46625)\n",
      "epoch 19: (0.5107125, 0.5107095548724101, 0.51085)\n",
      "epoch 20: (0.5118875, 0.511115266836532, 0.546625)\n",
      "epoch 21: (0.511575, 0.5116179865502358, 0.509725)\n",
      "epoch 22: (0.5134625, 0.5126941844840999, 0.543725)\n",
      "epoch 23: (0.5152375, 0.5137339732756484, 0.569975)\n",
      "epoch 24: (0.517, 0.5151353276353277, 0.5786)\n",
      "epoch 25: (0.5196625, 0.5146344640232217, 0.69145)\n",
      "epoch 26: (0.5202625, 0.5148663768594435, 0.70175)\n",
      "epoch 27: (0.5205625, 0.5171536424117291, 0.619925)\n",
      "epoch 28: (0.52085, 0.5177916204454305, 0.6068)\n",
      "epoch 29: (0.5193875, 0.5179542981501633, 0.5593)\n",
      "epoch 30: (0.524075, 0.5190504451038576, 0.65595)\n",
      "epoch 31: (0.524825, 0.5194973493029649, 0.66145)\n",
      "epoch 32: (0.5227625, 0.5202616997129315, 0.584475)\n",
      "epoch 33: (0.5235875, 0.5205838078408273, 0.59655)\n",
      "epoch 34: (0.5234625, 0.5198695827070057, 0.613875)\n",
      "epoch 35: (0.52355, 0.5209538215143696, 0.5855)\n",
      "epoch 36: (0.5275375, 0.5211181195958512, 0.679525)\n",
      "epoch 37: (0.5260125, 0.5211341986066257, 0.641425)\n",
      "epoch 38: (0.52655, 0.5224078997341436, 0.618975)\n",
      "epoch 39: (0.5286875, 0.521727604945752, 0.68885)\n",
      "epoch 40: (0.52895, 0.521784934908571, 0.6934)\n",
      "epoch 41: (0.5294125, 0.5221592300303242, 0.693075)\n",
      "epoch 42: (0.5275, 0.5225169900925244, 0.63815)\n",
      "epoch 43: (0.52815, 0.5221863177805801, 0.66255)\n",
      "epoch 44: (0.5306625, 0.5221866464065411, 0.721675)\n",
      "epoch 45: (0.5287875, 0.5224739934032047, 0.66925)\n",
      "epoch 46: (0.53055, 0.522635498092098, 0.705375)\n",
      "epoch 47: (0.528875, 0.5234546340670945, 0.644425)\n",
      "epoch 48: (0.5297375, 0.5229018656500896, 0.678975)\n",
      "epoch 49: (0.5286375, 0.5233999959144485, 0.64055)\n",
      "epoch 50: (0.5270375, 0.5235996246754097, 0.599875)\n",
      "epoch 51: (0.5288, 0.5239780201481975, 0.62935)\n",
      "epoch 52: (0.530675, 0.5242739574266044, 0.662525)\n",
      "epoch 53: (0.5304, 0.5242018947536025, 0.65845)\n",
      "epoch 54: (0.531275, 0.5279590559628107, 0.590575)\n",
      "epoch 55: (0.531575, 0.5245901639344263, 0.6736)\n",
      "epoch 56: (0.5336875, 0.5243455166308334, 0.72555)\n",
      "epoch 57: (0.5337125, 0.5245150617194175, 0.7213)\n",
      "epoch 58: (0.5334375, 0.5259855064016631, 0.676825)\n",
      "epoch 59: (0.533625, 0.5273596419853539, 0.648125)\n",
      "epoch 60: (0.5342125, 0.5271038402883682, 0.66535)\n",
      "epoch 61: (0.535275, 0.5273132017034456, 0.681025)\n",
      "epoch 62: (0.5348875, 0.5260865501448734, 0.703575)\n",
      "epoch 63: (0.536225, 0.5266428860368477, 0.71605)\n",
      "epoch 64: (0.5350875, 0.5274566191286656, 0.67405)\n",
      "epoch 65: (0.5358375, 0.5286751615290752, 0.660725)\n",
      "epoch 66: (0.5359, 0.5290605901161615, 0.653575)\n",
      "epoch 67: (0.536375, 0.5288187292029789, 0.667475)\n",
      "epoch 68: (0.536825, 0.5285886188960485, 0.680875)\n",
      "epoch 69: (0.537, 0.5298351005926702, 0.657075)\n",
      "epoch 70: (0.537525, 0.5289790717429917, 0.684975)\n",
      "epoch 71: (0.53775, 0.5316045041650969, 0.634975)\n",
      "epoch 72: (0.5372125, 0.5305176832393644, 0.6469)\n",
      "epoch 73: (0.536825, 0.5311614131584514, 0.6277)\n",
      "epoch 74: (0.5372125, 0.5290910156937089, 0.6768)\n",
      "epoch 75: (0.5369, 0.5311918850380389, 0.6284)\n",
      "epoch 76: (0.5375125, 0.5291330938743811, 0.681325)\n",
      "epoch 77: (0.5384625, 0.5314293885722458, 0.65035)\n",
      "epoch 78: (0.5393125, 0.531059274328942, 0.672175)\n",
      "epoch 79: (0.5392625, 0.5303425491218918, 0.68625)\n",
      "epoch 80: (0.5395375, 0.5295944909148749, 0.707525)\n",
      "epoch 81: (0.540225, 0.531754489836195, 0.6736)\n",
      "epoch 82: (0.538125, 0.5316600232519515, 0.640225)\n",
      "epoch 83: (0.5409375, 0.5316982519986837, 0.686675)\n",
      "epoch 84: (0.5395125, 0.5320036448314266, 0.656825)\n",
      "epoch 85: (0.54045, 0.532319923295114, 0.666225)\n",
      "epoch 86: (0.538275, 0.532035990793053, 0.63565)\n",
      "epoch 87: (0.538525, 0.5315468391745823, 0.649125)\n",
      "epoch 88: (0.5404, 0.5308161708619374, 0.6959)\n",
      "epoch 89: (0.5385625, 0.5316819684926161, 0.64715)\n",
      "epoch 90: (0.540425, 0.5317332600675092, 0.677375)\n",
      "epoch 91: (0.5399, 0.5315427487252461, 0.672375)\n",
      "epoch 92: (0.539175, 0.5329201680672269, 0.634175)\n",
      "epoch 93: (0.5409625, 0.5320714830981229, 0.679575)\n",
      "epoch 94: (0.5393875, 0.533195676450138, 0.63265)\n",
      "epoch 95: (0.5407375, 0.5322590224298696, 0.67215)\n",
      "epoch 96: (0.540775, 0.5329109326445781, 0.66025)\n",
      "epoch 97: (0.5414625, 0.5318262938726949, 0.69285)\n",
      "epoch 98: (0.54195, 0.5317526397456761, 0.702525)\n",
      "epoch 99: (0.5416, 0.5331434489901605, 0.669175)\n",
      "epoch 100: (0.540275, 0.5340923519702035, 0.63095)\n",
      "epoch 101: (0.5410375, 0.5335637025374691, 0.652375)\n",
      "epoch 102: (0.5398625, 0.5338355437665783, 0.628925)\n",
      "epoch 103: (0.539175, 0.5342963449332457, 0.6103)\n",
      "epoch 104: (0.5410125, 0.5329239167519618, 0.66385)\n",
      "epoch 105: (0.53995, 0.53420523138833, 0.623925)\n",
      "epoch 106: (0.541425, 0.5329593825834428, 0.66985)\n",
      "epoch 107: (0.5405625, 0.5328182204332612, 0.65855)\n",
      "epoch 108: (0.5416, 0.5327597747765485, 0.676525)\n",
      "epoch 109: (0.5411125, 0.5341970097111606, 0.642225)\n",
      "epoch 110: (0.5419, 0.5335804448006412, 0.665775)\n",
      "epoch 111: (0.5420125, 0.5318137932340079, 0.7023)\n",
      "epoch 112: (0.5422875, 0.5341213967280576, 0.66195)\n",
      "epoch 113: (0.5425875, 0.534152649411576, 0.666075)\n",
      "epoch 114: (0.5419, 0.5336397575368311, 0.664675)\n",
      "epoch 115: (0.540975, 0.5343174204355109, 0.637975)\n",
      "epoch 116: (0.5413625, 0.5328501935868163, 0.670925)\n",
      "epoch 117: (0.54205, 0.5342538286086673, 0.65585)\n",
      "epoch 118: (0.54195, 0.5334516167616922, 0.668975)\n",
      "epoch 119: (0.543025, 0.5343143119192886, 0.66995)\n",
      "epoch 120: (0.5427125, 0.5339722813227019, 0.67135)\n",
      "epoch 121: (0.54145, 0.5346311304202523, 0.6399)\n",
      "epoch 122: (0.5422, 0.5343774184350943, 0.655975)\n",
      "epoch 123: (0.54185, 0.5332353875476493, 0.67145)\n",
      "epoch 124: (0.5421, 0.5340270761770055, 0.660725)\n",
      "epoch 125: (0.5411125, 0.5348005502063273, 0.6318)\n",
      "epoch 126: (0.542675, 0.5339633903700756, 0.670925)\n",
      "epoch 127: (0.5419625, 0.5350424852293367, 0.6407)\n",
      "epoch 128: (0.541625, 0.5345335379765214, 0.6443)\n",
      "epoch 129: (0.5427, 0.5343427031809225, 0.664375)\n",
      "epoch 130: (0.540975, 0.5350348424607755, 0.62575)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 131: (0.5426875, 0.5343499165141121, 0.66405)\n",
      "epoch 132: (0.5417, 0.5355332111967961, 0.628475)\n",
      "epoch 133: (0.5423125, 0.5346192395017284, 0.653425)\n",
      "epoch 134: (0.542625, 0.5347859795160567, 0.6553)\n",
      "epoch 135: (0.5426125, 0.5349032456230163, 0.65305)\n",
      "epoch 136: (0.5412875, 0.5356272246791068, 0.620725)\n",
      "epoch 137: (0.5423875, 0.5352487474272885, 0.64365)\n",
      "epoch 138: (0.5424125, 0.5351467815782386, 0.645775)\n",
      "epoch 139: (0.5415625, 0.5355592154514148, 0.625975)\n",
      "epoch 140: (0.5426875, 0.5345291298457059, 0.660825)\n",
      "epoch 141: (0.5430625, 0.53423024184734, 0.672075)\n",
      "epoch 142: (0.542275, 0.5354968722448465, 0.63775)\n",
      "epoch 143: (0.5431125, 0.534432841483138, 0.66915)\n",
      "epoch 144: (0.5427875, 0.5346128177644751, 0.660875)\n",
      "epoch 145: (0.543225, 0.5343628269337786, 0.672175)\n",
      "epoch 146: (0.542225, 0.5355130361648444, 0.636725)\n",
      "epoch 147: (0.5427625, 0.534301241301863, 0.6661)\n",
      "epoch 148: (0.54395, 0.5341332712022367, 0.68775)\n",
      "epoch 149: (0.5424875, 0.5347965848365103, 0.653)\n",
      "epoch 150: (0.543275, 0.5347032878909382, 0.666775)\n",
      "epoch 151: (0.5424875, 0.5345013094053879, 0.658225)\n",
      "epoch 152: (0.5429875, 0.5347408829174665, 0.661675)\n",
      "epoch 153: (0.543075, 0.5345221398517331, 0.66695)\n",
      "epoch 154: (0.5430125, 0.5346784109003688, 0.663175)\n",
      "epoch 155: (0.5420375, 0.5351095149604327, 0.6407)\n",
      "epoch 156: (0.5414625, 0.5353391148707677, 0.6281)\n",
      "epoch 157: (0.542925, 0.5347149211484028, 0.661175)\n",
      "epoch 158: (0.5431375, 0.5346423337147905, 0.66575)\n",
      "epoch 159: (0.54405, 0.5348125024696724, 0.676725)\n",
      "epoch 160: (0.5429, 0.5351668169522092, 0.65285)\n",
      "epoch 161: (0.5415125, 0.5353335461219279, 0.62895)\n",
      "epoch 162: (0.543275, 0.5353077958634194, 0.6561)\n",
      "epoch 163: (0.54255, 0.534734693877551, 0.65505)\n",
      "epoch 164: (0.54375, 0.5343743861716755, 0.680125)\n",
      "epoch 165: (0.54335, 0.5342796141072276, 0.67565)\n",
      "epoch 166: (0.5419375, 0.5352393756696007, 0.636975)\n",
      "epoch 167: (0.5431625, 0.5354714112546998, 0.651575)\n",
      "epoch 168: (0.544025, 0.5345551587457321, 0.68105)\n",
      "epoch 169: (0.5425875, 0.5346190582640681, 0.657675)\n",
      "epoch 170: (0.5424125, 0.535020539603245, 0.64795)\n",
      "epoch 171: (0.5437875, 0.534585233892147, 0.676825)\n",
      "epoch 172: (0.5428125, 0.5344629812239641, 0.66395)\n",
      "epoch 173: (0.5423375, 0.5346382769834939, 0.653475)\n",
      "epoch 174: (0.54315, 0.5346433302557103, 0.665925)\n",
      "epoch 175: (0.5426125, 0.5357915293030678, 0.6379)\n",
      "epoch 176: (0.5429625, 0.5352418842154912, 0.6525)\n",
      "epoch 177: (0.5430125, 0.5345641561363682, 0.665225)\n",
      "epoch 178: (0.5430875, 0.5350582779032159, 0.6576)\n",
      "epoch 179: (0.542875, 0.5359207439678284, 0.639675)\n",
      "epoch 180: (0.543425, 0.5345067344749493, 0.67265)\n",
      "epoch 181: (0.54305, 0.5353913186451825, 0.65125)\n",
      "epoch 182: (0.5421375, 0.5354640520125402, 0.636225)\n",
      "epoch 183: (0.5432625, 0.5345913206868291, 0.6686)\n",
      "epoch 184: (0.5430625, 0.5350094510274181, 0.658075)\n",
      "epoch 185: (0.5437125, 0.5350155201762291, 0.6679)\n",
      "epoch 186: (0.5433125, 0.5352084053081878, 0.6584)\n",
      "epoch 187: (0.5433375, 0.5350081790092291, 0.6623)\n",
      "epoch 188: (0.5449375, 0.5351658026019759, 0.683875)\n",
      "epoch 189: (0.5434125, 0.535543956606284, 0.6541)\n",
      "epoch 190: (0.54355, 0.5349546512561201, 0.6665)\n",
      "epoch 191: (0.5432375, 0.5361827653298186, 0.640725)\n",
      "epoch 192: (0.544225, 0.5350546924540266, 0.675025)\n",
      "epoch 193: (0.5440625, 0.5355235311901643, 0.66425)\n",
      "epoch 194: (0.543975, 0.53519266936097, 0.66875)\n",
      "epoch 195: (0.5447, 0.5355057786250447, 0.674175)\n",
      "epoch 196: (0.5442625, 0.5349493673384789, 0.6775)\n",
      "epoch 197: (0.544025, 0.5365322379885487, 0.646575)\n",
      "epoch 198: (0.5436875, 0.5351249221121184, 0.665575)\n",
      "epoch 199: (0.5439, 0.536307997684228, 0.64845)\n",
      "epoch 0: (0.4849, 0.48495941032919965, 0.486875)\n",
      "epoch 1: (0.4883, 0.4883680469254859, 0.491225)\n",
      "epoch 2: (0.4924875, 0.49251090342679127, 0.49405)\n",
      "epoch 3: (0.4970125, 0.49716145276609897, 0.52325)\n",
      "epoch 4: (0.50215, 0.5017912188619512, 0.6023)\n",
      "epoch 5: (0.5049, 0.5041511352084039, 0.5951)\n",
      "epoch 6: (0.5063125, 0.5052557084278667, 0.60685)\n",
      "epoch 7: (0.5062, 0.5054560654727857, 0.574375)\n",
      "epoch 8: (0.5059625, 0.5054041193664605, 0.557625)\n",
      "epoch 9: (0.5058625, 0.5054581849498405, 0.5429)\n",
      "epoch 10: (0.5062375, 0.5060781017807986, 0.51935)\n",
      "epoch 11: (0.506575, 0.5063640323283163, 0.52315)\n",
      "epoch 12: (0.5082625, 0.508376207010163, 0.501475)\n",
      "epoch 13: (0.5108375, 0.5095022029328599, 0.5811)\n",
      "epoch 14: (0.511175, 0.5111873060366403, 0.510625)\n",
      "epoch 15: (0.5114625, 0.5095510884282887, 0.611525)\n",
      "epoch 16: (0.5114875, 0.5106269802724392, 0.551975)\n",
      "epoch 17: (0.51235, 0.5107559658596064, 0.58645)\n",
      "epoch 18: (0.5126875, 0.5116119437135339, 0.559)\n",
      "epoch 19: (0.51375, 0.5116961551548146, 0.60155)\n",
      "epoch 20: (0.5143625, 0.512256, 0.6003)\n",
      "epoch 21: (0.5159, 0.5133562938384645, 0.611125)\n",
      "epoch 22: (0.5166875, 0.5139711576700086, 0.6139)\n",
      "epoch 23: (0.517025, 0.5140158063719437, 0.624375)\n",
      "epoch 24: (0.5178, 0.5147369292544604, 0.621725)\n",
      "epoch 25: (0.5190375, 0.5152841057342994, 0.641825)\n",
      "epoch 26: (0.519525, 0.5158122772918692, 0.636925)\n",
      "epoch 27: (0.5206, 0.5164497324922144, 0.64675)\n",
      "epoch 28: (0.521575, 0.5171926049884453, 0.649025)\n",
      "epoch 29: (0.52245, 0.5177814740010297, 0.653725)\n",
      "epoch 30: (0.5232, 0.5183631470634795, 0.6549)\n",
      "epoch 31: (0.5238875, 0.518579011841568, 0.66675)\n",
      "epoch 32: (0.523875, 0.519064920546195, 0.650025)\n",
      "epoch 33: (0.526775, 0.5196766489068528, 0.70715)\n",
      "epoch 34: (0.52485, 0.5196047493195535, 0.658625)\n",
      "epoch 35: (0.5261375, 0.5201588801264871, 0.674425)\n",
      "epoch 36: (0.52845, 0.5234243135317608, 0.635725)\n",
      "epoch 37: (0.528325, 0.5206842412735505, 0.713025)\n",
      "epoch 38: (0.53175, 0.526544603294039, 0.6298)\n",
      "epoch 39: (0.5331625, 0.526570919215592, 0.6572)\n",
      "epoch 40: (0.533625, 0.528169899049135, 0.63045)\n",
      "epoch 41: (0.535075, 0.5284780578898226, 0.6509)\n",
      "epoch 42: (0.534575, 0.5292921591053501, 0.62475)\n",
      "epoch 43: (0.5362, 0.527844011999077, 0.68625)\n",
      "epoch 44: (0.5353, 0.5296676051603143, 0.630225)\n",
      "epoch 45: (0.5357375, 0.5292468850379524, 0.6467)\n",
      "epoch 46: (0.53535, 0.529823673331646, 0.628)\n",
      "epoch 47: (0.5366625, 0.5286700162264667, 0.67605)\n",
      "epoch 48: (0.5358375, 0.5302534664331089, 0.628125)\n",
      "epoch 49: (0.5370625, 0.5288127028550328, 0.680225)\n",
      "epoch 50: (0.535925, 0.5302297206327836, 0.630125)\n",
      "epoch 51: (0.5370125, 0.5299738829388779, 0.654425)\n",
      "epoch 52: (0.536525, 0.531196617697301, 0.621925)\n",
      "epoch 53: (0.537275, 0.5290586630286493, 0.67865)\n",
      "epoch 54: (0.537625, 0.5316176470588235, 0.632625)\n",
      "epoch 55: (0.537425, 0.5304478704795997, 0.652)\n",
      "epoch 56: (0.5369, 0.5316643068605998, 0.619575)\n",
      "epoch 57: (0.5373875, 0.5292873509194524, 0.675675)\n",
      "epoch 58: (0.53765, 0.5316506241856164, 0.632425)\n",
      "epoch 59: (0.53785, 0.5307386202135868, 0.653525)\n",
      "epoch 60: (0.5377625, 0.5324009524013814, 0.6205)\n",
      "epoch 61: (0.53815, 0.5299568119356105, 0.6749)\n",
      "epoch 62: (0.53815, 0.5321317274488335, 0.6318)\n",
      "epoch 63: (0.538475, 0.5305187594193702, 0.668825)\n",
      "epoch 64: (0.5384875, 0.5324645199384239, 0.63125)\n",
      "epoch 65: (0.53865, 0.5301929536754941, 0.6787)\n",
      "epoch 66: (0.5385625, 0.5322813552937237, 0.63585)\n",
      "epoch 67: (0.5387625, 0.5307145262574038, 0.669775)\n",
      "epoch 68: (0.5384125, 0.5322828028154218, 0.63335)\n",
      "epoch 69: (0.5390625, 0.5305277142801321, 0.67885)\n",
      "epoch 70: (0.5382, 0.5318359863321943, 0.63815)\n",
      "epoch 71: (0.539, 0.530823947836396, 0.671625)\n",
      "epoch 72: (0.538475, 0.532204737591027, 0.635825)\n",
      "epoch 73: (0.539175, 0.5305065607600358, 0.68125)\n",
      "epoch 74: (0.5389875, 0.5323850067490395, 0.640925)\n",
      "epoch 75: (0.5398375, 0.5312199996081581, 0.67785)\n",
      "epoch 76: (0.5395875, 0.5329189447643599, 0.640875)\n",
      "epoch 77: (0.5407875, 0.531782673913467, 0.68245)\n",
      "epoch 78: (0.54045, 0.5334823276218856, 0.6445)\n",
      "epoch 79: (0.541175, 0.5322132686590518, 0.680275)\n",
      "epoch 80: (0.5405625, 0.5335886554186937, 0.644375)\n",
      "epoch 81: (0.54205, 0.5327939169428738, 0.683175)\n",
      "epoch 82: (0.5416375, 0.5345489244300621, 0.644225)\n",
      "epoch 83: (0.5424, 0.5331690526480481, 0.68155)\n",
      "epoch 84: (0.541825, 0.5346176129779838, 0.645925)\n",
      "epoch 85: (0.5427125, 0.5333255310433612, 0.68355)\n",
      "epoch 86: (0.5418875, 0.5346714950853595, 0.64595)\n",
      "epoch 87: (0.542625, 0.533239755137053, 0.6838)\n",
      "epoch 88: (0.5418875, 0.5347578052069287, 0.64445)\n",
      "epoch 89: (0.54305, 0.5335437120149603, 0.68475)\n",
      "epoch 90: (0.5419125, 0.5346993687260685, 0.64585)\n",
      "epoch 91: (0.5432, 0.5338412126434531, 0.681475)\n",
      "epoch 92: (0.5421, 0.5349653253602425, 0.644125)\n",
      "epoch 93: (0.543425, 0.5339509792424064, 0.68295)\n",
      "epoch 94: (0.54255, 0.5352585349685117, 0.64595)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 95: (0.5435375, 0.5340369393139842, 0.6831)\n",
      "epoch 96: (0.5427625, 0.5354382911720222, 0.6461)\n",
      "epoch 97: (0.543475, 0.5340140046160466, 0.68255)\n",
      "epoch 98: (0.5427875, 0.5354443224884544, 0.646375)\n",
      "epoch 99: (0.5436375, 0.5341524976031619, 0.6825)\n",
      "epoch 100: (0.5427875, 0.5354369836635816, 0.6465)\n",
      "epoch 101: (0.54375, 0.5342559605371334, 0.682325)\n",
      "epoch 102: (0.542975, 0.5355871149387215, 0.646775)\n",
      "epoch 103: (0.5439, 0.5343989970224102, 0.682)\n",
      "epoch 104: (0.543325, 0.5358710051333002, 0.647225)\n",
      "epoch 105: (0.544075, 0.5345821890937622, 0.681325)\n",
      "epoch 106: (0.5434125, 0.5359620601818295, 0.647)\n",
      "epoch 107: (0.5441875, 0.5347092669324274, 0.680725)\n",
      "epoch 108: (0.5431625, 0.5358024179333513, 0.64595)\n",
      "epoch 109: (0.544375, 0.5349946768660542, 0.6784)\n",
      "epoch 110: (0.543125, 0.5358032378580324, 0.645375)\n",
      "epoch 111: (0.544525, 0.5350742447516641, 0.67925)\n",
      "epoch 112: (0.543325, 0.5360365980453317, 0.64445)\n",
      "epoch 113: (0.544675, 0.5351329034287512, 0.680475)\n",
      "epoch 114: (0.5434625, 0.5360916772197887, 0.645575)\n",
      "epoch 115: (0.5448625, 0.5354693337022909, 0.677275)\n",
      "epoch 116: (0.5436125, 0.5362900709367394, 0.6445)\n",
      "epoch 117: (0.5446875, 0.5352306994895244, 0.6789)\n",
      "epoch 118: (0.543625, 0.5362982069309814, 0.64455)\n",
      "epoch 119: (0.544925, 0.5354326050950391, 0.678875)\n",
      "epoch 120: (0.543575, 0.536267166042447, 0.644325)\n",
      "epoch 121: (0.545225, 0.5356945540647198, 0.678725)\n",
      "epoch 122: (0.5436375, 0.5363274990114258, 0.64425)\n",
      "epoch 123: (0.545075, 0.535543902535189, 0.67915)\n",
      "epoch 124: (0.5436375, 0.5363971891486123, 0.6431)\n",
      "epoch 125: (0.5450375, 0.5355094317308261, 0.6792)\n",
      "epoch 126: (0.5435875, 0.5363418447107868, 0.643275)\n",
      "epoch 127: (0.5451625, 0.5356290554799519, 0.67895)\n",
      "epoch 128: (0.543475, 0.536309349814173, 0.64215)\n",
      "epoch 129: (0.545025, 0.535543714229327, 0.6784)\n",
      "epoch 130: (0.54365, 0.5364372469635628, 0.642625)\n",
      "epoch 131: (0.545, 0.5355674992096111, 0.6776)\n",
      "epoch 132: (0.5437875, 0.5366062658055887, 0.641875)\n",
      "epoch 133: (0.5449875, 0.5355330450407756, 0.678025)\n",
      "epoch 134: (0.54375, 0.5365329213811532, 0.642525)\n",
      "epoch 135: (0.5453625, 0.5358306510534943, 0.678375)\n",
      "epoch 136: (0.5438, 0.5366098294884654, 0.642)\n",
      "epoch 137: (0.5453, 0.5358046158710086, 0.6779)\n",
      "epoch 138: (0.5438375, 0.5366649242028227, 0.64165)\n",
      "epoch 139: (0.5455875, 0.535919002501625, 0.680175)\n",
      "epoch 140: (0.5438875, 0.5366209817051547, 0.6431)\n",
      "epoch 141: (0.5456, 0.5360146902025826, 0.678675)\n",
      "epoch 142: (0.5439875, 0.5367427485538873, 0.642575)\n",
      "epoch 143: (0.5455875, 0.5359714358984475, 0.67925)\n",
      "epoch 144: (0.5439125, 0.5366678496127592, 0.6427)\n",
      "epoch 145: (0.5457875, 0.5360709010339734, 0.680475)\n",
      "epoch 146: (0.544025, 0.5367119746497665, 0.643625)\n",
      "epoch 147: (0.5458375, 0.5360449800460023, 0.681675)\n",
      "epoch 148: (0.5441125, 0.5367903087925606, 0.643625)\n",
      "epoch 149: (0.545925, 0.536125860373648, 0.68155)\n",
      "epoch 150: (0.544025, 0.5366005736376107, 0.64545)\n",
      "epoch 151: (0.54595, 0.5361341564109622, 0.681775)\n",
      "epoch 152: (0.5441625, 0.5366821022904251, 0.646125)\n",
      "epoch 153: (0.5459125, 0.5360600051051464, 0.682525)\n",
      "epoch 154: (0.544225, 0.5367241021382603, 0.64635)\n",
      "epoch 155: (0.545875, 0.5359550121482874, 0.683825)\n",
      "epoch 156: (0.5441375, 0.5366659051733089, 0.646025)\n",
      "epoch 157: (0.54585, 0.5359495060373216, 0.68355)\n",
      "epoch 158: (0.5441375, 0.5366522036994748, 0.64625)\n",
      "epoch 159: (0.5459375, 0.5360145822308461, 0.6837)\n",
      "epoch 160: (0.54415, 0.5366298846760142, 0.6468)\n",
      "epoch 161: (0.5459125, 0.5359217603911981, 0.684975)\n",
      "epoch 162: (0.5444625, 0.5368074670419504, 0.64845)\n",
      "epoch 163: (0.5459625, 0.5359721379796122, 0.684825)\n",
      "epoch 164: (0.5443, 0.5367116930471534, 0.64765)\n",
      "epoch 165: (0.54605, 0.5360004690614861, 0.685625)\n",
      "epoch 166: (0.5444125, 0.5367691193211218, 0.64835)\n",
      "epoch 167: (0.545875, 0.53583984375, 0.685875)\n",
      "epoch 168: (0.5446, 0.5369037276074635, 0.648875)\n",
      "epoch 169: (0.5459625, 0.5358906783796974, 0.686275)\n",
      "epoch 170: (0.544575, 0.536922758335059, 0.6482)\n",
      "epoch 171: (0.5458875, 0.5358643193497333, 0.685625)\n",
      "epoch 172: (0.5447375, 0.5370243932716777, 0.6489)\n",
      "epoch 173: (0.5458, 0.5358008285781287, 0.68545)\n",
      "epoch 174: (0.5448, 0.5370584829183556, 0.64925)\n",
      "epoch 175: (0.545875, 0.5358552503028645, 0.6856)\n",
      "epoch 176: (0.54505, 0.5372776168804303, 0.6493)\n",
      "epoch 177: (0.5458875, 0.535867122618466, 0.685575)\n",
      "epoch 178: (0.5451125, 0.5373501955995281, 0.649025)\n",
      "epoch 179: (0.5459125, 0.5358726438128724, 0.68585)\n",
      "epoch 180: (0.5451875, 0.537413839498251, 0.649075)\n",
      "epoch 181: (0.546, 0.535978256618826, 0.685275)\n",
      "epoch 182: (0.545325, 0.537536231884058, 0.649075)\n",
      "epoch 183: (0.54615, 0.5360885204879574, 0.68555)\n",
      "epoch 184: (0.5451375, 0.5373894675806085, 0.64875)\n",
      "epoch 185: (0.5464, 0.5363237826835761, 0.6851)\n",
      "epoch 186: (0.545375, 0.5376041105540131, 0.6487)\n",
      "epoch 187: (0.5464625, 0.536356344998924, 0.68545)\n",
      "epoch 188: (0.5454125, 0.5376453277516424, 0.648575)\n",
      "epoch 189: (0.5465875, 0.5364784183224038, 0.68515)\n",
      "epoch 190: (0.545525, 0.5377362400530504, 0.648725)\n",
      "epoch 191: (0.546625, 0.5364956361786232, 0.6854)\n",
      "epoch 192: (0.5457125, 0.5379113018597997, 0.6486)\n",
      "epoch 193: (0.5468875, 0.5367147583344752, 0.685425)\n",
      "epoch 194: (0.545925, 0.5380599179546679, 0.64925)\n",
      "epoch 195: (0.5469125, 0.5367156469506349, 0.685775)\n",
      "epoch 196: (0.5459875, 0.5381805350879013, 0.648225)\n",
      "epoch 197: (0.547175, 0.5369767988712965, 0.685075)\n",
      "epoch 198: (0.5460125, 0.5381458683081515, 0.649125)\n",
      "epoch 199: (0.547225, 0.5369681787936905, 0.68595)\n",
      "epoch 0: (0.4971625, 0.48589536473219835, 0.09775)\n",
      "epoch 1: (0.4963125, 0.4848950332821301, 0.118375)\n",
      "epoch 2: (0.50925, 0.5146083385975995, 0.32585)\n",
      "epoch 3: (0.5081875, 0.5104796646507311, 0.398825)\n",
      "epoch 4: (0.5053125, 0.5059006469885875, 0.455475)\n",
      "epoch 5: (0.504225, 0.5039699318769086, 0.53635)\n",
      "epoch 6: (0.5068125, 0.5058180498323974, 0.592275)\n",
      "epoch 7: (0.5043625, 0.5048211078878299, 0.4568)\n",
      "epoch 8: (0.5055625, 0.5065197644094119, 0.43215)\n",
      "epoch 9: (0.50665, 0.5060099412562132, 0.5599)\n",
      "epoch 10: (0.5100125, 0.5106694727868503, 0.479225)\n",
      "epoch 11: (0.513875, 0.5128169599556602, 0.55515)\n",
      "epoch 12: (0.5161875, 0.5137786478837274, 0.6036)\n",
      "epoch 13: (0.517775, 0.5117075580438004, 0.7769)\n",
      "epoch 14: (0.5168125, 0.5141772952461263, 0.60975)\n",
      "epoch 15: (0.523075, 0.5219104590988938, 0.54965)\n",
      "epoch 16: (0.5256625, 0.5224937000109565, 0.5961)\n",
      "epoch 17: (0.5211, 0.5221790087770011, 0.496775)\n",
      "epoch 18: (0.5201625, 0.5226043330810841, 0.46615)\n",
      "epoch 19: (0.5253125, 0.5216027651539397, 0.611175)\n",
      "epoch 20: (0.524075, 0.5222001936465489, 0.5663)\n",
      "epoch 21: (0.5231125, 0.5255436134059073, 0.475525)\n",
      "epoch 22: (0.52365, 0.5236393622869708, 0.523875)\n",
      "epoch 23: (0.5271125, 0.5226963564447606, 0.6244)\n",
      "epoch 24: (0.5269875, 0.5229940145270199, 0.613825)\n",
      "epoch 25: (0.5266875, 0.5242630179330409, 0.57665)\n",
      "epoch 26: (0.5295125, 0.5241692770714329, 0.64005)\n",
      "epoch 27: (0.524425, 0.5235921954988892, 0.542075)\n",
      "epoch 28: (0.5301625, 0.5251968339494184, 0.6287)\n",
      "epoch 29: (0.5315375, 0.5239869939723527, 0.688925)\n",
      "epoch 30: (0.529625, 0.5254291845493563, 0.612125)\n",
      "epoch 31: (0.52675, 0.5265944226276283, 0.529675)\n",
      "epoch 32: (0.5257375, 0.5299055918663762, 0.45605)\n",
      "epoch 33: (0.52585, 0.5301933072475618, 0.453925)\n",
      "epoch 34: (0.531275, 0.527945315641335, 0.59085)\n",
      "epoch 35: (0.532475, 0.5268977512734501, 0.63615)\n",
      "epoch 36: (0.5295125, 0.5284752876474419, 0.547725)\n",
      "epoch 37: (0.5282375, 0.5308278064357652, 0.486225)\n",
      "epoch 38: (0.5350375, 0.5282737194617604, 0.65465)\n",
      "epoch 39: (0.5339125, 0.5297654312860685, 0.603575)\n",
      "epoch 40: (0.535625, 0.5283176344342435, 0.66465)\n",
      "epoch 41: (0.5328375, 0.5303047781648709, 0.574625)\n",
      "epoch 42: (0.53465, 0.5300872660964703, 0.610475)\n",
      "epoch 43: (0.537225, 0.5294839808324423, 0.6685)\n",
      "epoch 44: (0.5353625, 0.5295642177866026, 0.633425)\n",
      "epoch 45: (0.53475, 0.5308600861418232, 0.597775)\n",
      "epoch 46: (0.534425, 0.5298400728123781, 0.61125)\n",
      "epoch 47: (0.5364375, 0.5303462491411439, 0.6368)\n",
      "epoch 48: (0.5371375, 0.5307092799702313, 0.6418)\n",
      "epoch 49: (0.5343625, 0.532490249379506, 0.563175)\n",
      "epoch 50: (0.5352, 0.5320058192398618, 0.5851)\n",
      "epoch 51: (0.539, 0.5319567354965585, 0.6492)\n",
      "epoch 52: (0.5385375, 0.527256652815843, 0.745475)\n",
      "epoch 53: (0.5396, 0.5320868614025848, 0.656675)\n",
      "epoch 54: (0.5392375, 0.5315471045808124, 0.661125)\n",
      "epoch 55: (0.53535, 0.5321422076741226, 0.58525)\n",
      "epoch 56: (0.535675, 0.5332123074058558, 0.57275)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 57: (0.5375875, 0.5333244674956225, 0.60155)\n",
      "epoch 58: (0.5386, 0.5330408731007917, 0.622725)\n",
      "epoch 59: (0.5385125, 0.5341778892019613, 0.601925)\n",
      "epoch 60: (0.5373125, 0.5337036786125601, 0.59085)\n",
      "epoch 61: (0.5408625, 0.5335550491675392, 0.64975)\n",
      "epoch 62: (0.5381875, 0.5349374442487592, 0.5847)\n",
      "epoch 63: (0.5384375, 0.534100738572094, 0.602025)\n",
      "epoch 64: (0.5399625, 0.5352053738575047, 0.607525)\n",
      "epoch 65: (0.5417375, 0.534192147787085, 0.652075)\n",
      "epoch 66: (0.5408875, 0.5356232711114983, 0.614775)\n",
      "epoch 67: (0.540825, 0.5353907502925751, 0.6176)\n",
      "epoch 68: (0.5413625, 0.5355752897413293, 0.6227)\n",
      "epoch 69: (0.539025, 0.5360808062130178, 0.579825)\n",
      "epoch 70: (0.5423125, 0.5336568099111102, 0.6709)\n",
      "epoch 71: (0.5423375, 0.5348005671660193, 0.650625)\n",
      "epoch 72: (0.5411625, 0.5357011210130315, 0.61765)\n",
      "epoch 73: (0.5419375, 0.5342675627642841, 0.65385)\n",
      "epoch 74: (0.5432875, 0.5341162098792189, 0.6777)\n",
      "epoch 75: (0.541575, 0.5351942774908999, 0.632225)\n",
      "epoch 76: (0.5422125, 0.5349058359001923, 0.646875)\n",
      "epoch 77: (0.5436, 0.5344936708860759, 0.6756)\n",
      "epoch 78: (0.5435625, 0.5349541634069527, 0.6667)\n",
      "epoch 79: (0.542375, 0.5364751452550033, 0.62325)\n",
      "epoch 80: (0.5427125, 0.5349794238683128, 0.65325)\n",
      "epoch 81: (0.541575, 0.536985143670492, 0.603625)\n",
      "epoch 82: (0.5418875, 0.5360749273334051, 0.62245)\n",
      "epoch 83: (0.543375, 0.537343951786483, 0.624125)\n",
      "epoch 84: (0.5432625, 0.5373282426281843, 0.62275)\n",
      "epoch 85: (0.544625, 0.537635995614405, 0.637475)\n",
      "epoch 86: (0.544325, 0.5335681017834829, 0.70455)\n",
      "epoch 87: (0.5443875, 0.5372996365622571, 0.6394)\n",
      "epoch 88: (0.54425, 0.5353915060385508, 0.6694)\n",
      "epoch 89: (0.54345, 0.536868901145524, 0.6327)\n",
      "epoch 90: (0.54425, 0.535805316179148, 0.662175)\n",
      "epoch 91: (0.5428875, 0.5369409332672969, 0.623375)\n",
      "epoch 92: (0.5451125, 0.5351350298876536, 0.6871)\n",
      "epoch 93: (0.5435625, 0.5370342819493741, 0.6317)\n",
      "epoch 94: (0.54455, 0.5355518314579842, 0.6711)\n",
      "epoch 95: (0.5440375, 0.535777394130192, 0.659475)\n",
      "epoch 96: (0.544075, 0.5365373456022549, 0.647225)\n",
      "epoch 97: (0.5453125, 0.5347521809989455, 0.69725)\n",
      "epoch 98: (0.5443875, 0.5369134493440612, 0.645625)\n",
      "epoch 99: (0.5448375, 0.5355071172615866, 0.676225)\n",
      "epoch 100: (0.5432375, 0.5364681075382183, 0.63605)\n",
      "epoch 101: (0.5448125, 0.5352002042299158, 0.68135)\n",
      "epoch 102: (0.54405, 0.5364591954974341, 0.64815)\n",
      "epoch 103: (0.54485, 0.5355839416058394, 0.67505)\n",
      "epoch 104: (0.5439625, 0.5366422870954971, 0.64385)\n",
      "epoch 105: (0.5438375, 0.5375634626507573, 0.62735)\n",
      "epoch 106: (0.5456125, 0.5359372845634147, 0.680225)\n",
      "epoch 107: (0.5446, 0.5376371308016877, 0.6371)\n",
      "epoch 108: (0.544975, 0.535848079069026, 0.672275)\n",
      "epoch 109: (0.544775, 0.5360594346460498, 0.665625)\n",
      "epoch 110: (0.544225, 0.5369959846076627, 0.641925)\n",
      "epoch 111: (0.5431, 0.538236337828247, 0.6067)\n",
      "epoch 112: (0.5444375, 0.5370659993744135, 0.643875)\n",
      "epoch 113: (0.5439375, 0.538065019167876, 0.621075)\n",
      "epoch 114: (0.54385, 0.5370589478132263, 0.635475)\n",
      "epoch 115: (0.54535, 0.535634306368601, 0.681675)\n",
      "epoch 116: (0.54425, 0.537852865697177, 0.62875)\n",
      "epoch 117: (0.545325, 0.5356637028877174, 0.680775)\n",
      "epoch 118: (0.5446625, 0.5376097345319046, 0.638425)\n",
      "epoch 119: (0.5446625, 0.536339781534143, 0.659175)\n",
      "epoch 120: (0.545425, 0.5360716270944176, 0.675075)\n",
      "epoch 121: (0.544575, 0.5379992327692766, 0.6311)\n",
      "epoch 122: (0.5451625, 0.536379563807721, 0.665875)\n",
      "epoch 123: (0.5442125, 0.5376284601800039, 0.6317)\n",
      "epoch 124: (0.5446625, 0.5372365925339225, 0.644375)\n",
      "epoch 125: (0.54485, 0.5380924069984712, 0.63355)\n",
      "epoch 126: (0.5460125, 0.5364766038408942, 0.676725)\n",
      "epoch 127: (0.5449, 0.5380363420729383, 0.635125)\n",
      "epoch 128: (0.545075, 0.5365201539396395, 0.6622)\n",
      "epoch 129: (0.544525, 0.5368752329288997, 0.64825)\n",
      "epoch 130: (0.546925, 0.5362187403519605, 0.694725)\n",
      "epoch 131: (0.544575, 0.5371303623490212, 0.644825)\n",
      "epoch 132: (0.5461375, 0.5363494908510764, 0.680775)\n",
      "epoch 133: (0.544725, 0.5378608312875646, 0.635375)\n",
      "epoch 134: (0.5435625, 0.5383076483390858, 0.61215)\n",
      "epoch 135: (0.5452375, 0.5370837175940157, 0.655175)\n",
      "epoch 136: (0.5451125, 0.5367358156389325, 0.659125)\n",
      "epoch 137: (0.5445375, 0.5371029886493804, 0.644725)\n",
      "epoch 138: (0.544225, 0.537678381256656, 0.6311)\n",
      "epoch 139: (0.545975, 0.5361879648943287, 0.6812)\n",
      "epoch 140: (0.545525, 0.5373385277834735, 0.65515)\n",
      "epoch 141: (0.5455625, 0.5372143834357708, 0.657725)\n",
      "epoch 142: (0.545025, 0.5374724314427198, 0.6458)\n",
      "epoch 143: (0.5458125, 0.5362318840579711, 0.678025)\n",
      "epoch 144: (0.5450375, 0.5377285388175669, 0.6419)\n",
      "epoch 145: (0.546775, 0.5363230440691128, 0.69065)\n",
      "epoch 146: (0.5450875, 0.5376050376363144, 0.644575)\n",
      "epoch 147: (0.5445875, 0.5381130462656266, 0.629525)\n",
      "epoch 148: (0.5453875, 0.5370291052234392, 0.65825)\n",
      "epoch 149: (0.546, 0.5372303832301404, 0.663775)\n",
      "epoch 150: (0.5447125, 0.5385112293016946, 0.625225)\n",
      "epoch 151: (0.54555, 0.5367146253979769, 0.665875)\n",
      "epoch 152: (0.5449, 0.5373171542553191, 0.6465)\n",
      "epoch 153: (0.54675, 0.5369433798253586, 0.679475)\n",
      "epoch 154: (0.5451375, 0.5378837155626429, 0.640875)\n",
      "epoch 155: (0.5472, 0.5368879684263999, 0.686975)\n",
      "epoch 156: (0.545425, 0.5379426996324758, 0.644025)\n",
      "epoch 157: (0.5458875, 0.5372970556560258, 0.66105)\n",
      "epoch 158: (0.546125, 0.5364422849016355, 0.678975)\n",
      "epoch 159: (0.5455875, 0.5382662161878581, 0.64125)\n",
      "epoch 160: (0.5469625, 0.5368890285332757, 0.6835)\n",
      "epoch 161: (0.5456, 0.5380047505938242, 0.645525)\n",
      "epoch 162: (0.5458625, 0.5375945242535402, 0.655825)\n",
      "epoch 163: (0.5466625, 0.5362885194906192, 0.6896)\n",
      "epoch 164: (0.5457125, 0.5371035490351251, 0.661725)\n",
      "epoch 165: (0.547, 0.5372188786822933, 0.6784)\n",
      "epoch 166: (0.5462875, 0.5375550191679682, 0.66255)\n",
      "epoch 167: (0.5479625, 0.5368821731357056, 0.698175)\n",
      "epoch 168: (0.54635, 0.537745836556863, 0.660325)\n",
      "epoch 169: (0.547125, 0.5369506410005097, 0.6848)\n",
      "epoch 170: (0.5461, 0.5384038653782073, 0.6463)\n",
      "epoch 171: (0.5470125, 0.5367292329928319, 0.687)\n",
      "epoch 172: (0.5467, 0.5391860709041326, 0.642575)\n",
      "epoch 173: (0.547075, 0.5371972660108253, 0.67985)\n",
      "epoch 174: (0.54615, 0.5390605162928481, 0.6369)\n",
      "epoch 175: (0.5468125, 0.536837756487183, 0.6822)\n",
      "epoch 176: (0.54675, 0.5368124729320052, 0.681725)\n",
      "epoch 177: (0.5472625, 0.5378926058808202, 0.6709)\n",
      "epoch 178: (0.545975, 0.5374480736336239, 0.659825)\n",
      "epoch 179: (0.5474375, 0.5373119653918003, 0.683125)\n",
      "epoch 180: (0.5461625, 0.5378885811018775, 0.65535)\n",
      "epoch 181: (0.5467, 0.5374754243068651, 0.669775)\n",
      "epoch 182: (0.5467375, 0.5361109501458345, 0.693875)\n",
      "epoch 183: (0.5460125, 0.538331771321462, 0.6462)\n",
      "epoch 184: (0.54685, 0.5376139055035928, 0.669625)\n",
      "epoch 185: (0.5464375, 0.5361374292328943, 0.68895)\n",
      "epoch 186: (0.547025, 0.538104691678146, 0.664075)\n",
      "epoch 187: (0.5466375, 0.5362648471063938, 0.68965)\n",
      "epoch 188: (0.5471125, 0.5372806583710855, 0.678975)\n",
      "epoch 189: (0.5463625, 0.5387751688376858, 0.6442)\n",
      "epoch 190: (0.547775, 0.5372064950741794, 0.6898)\n",
      "epoch 191: (0.5466375, 0.5389091667535718, 0.64595)\n",
      "epoch 192: (0.547425, 0.5372165110256611, 0.684575)\n",
      "epoch 193: (0.546875, 0.5383702369745835, 0.6577)\n",
      "epoch 194: (0.5468375, 0.5369606818047308, 0.68045)\n",
      "epoch 195: (0.54705, 0.5386717626268853, 0.655375)\n",
      "epoch 196: (0.54695, 0.5366811203562639, 0.686925)\n",
      "epoch 197: (0.547675, 0.5375748738965952, 0.682075)\n",
      "epoch 198: (0.5466125, 0.5383618295166965, 0.65415)\n",
      "epoch 199: (0.5479625, 0.5370302457102047, 0.695575)\n",
      "epoch 0: (0.5027375, 0.5013916955808899, 0.98625)\n",
      "epoch 1: (0.5037, 0.5019136776229021, 0.970425)\n",
      "epoch 2: (0.5021, 0.5013464559356265, 0.781925)\n",
      "epoch 3: (0.50275, 0.5020115573110965, 0.6863)\n",
      "epoch 4: (0.5066875, 0.5053563204581406, 0.63095)\n",
      "epoch 5: (0.5115375, 0.5100328268005826, 0.586525)\n",
      "epoch 6: (0.5110875, 0.5100674187910017, 0.56175)\n",
      "epoch 7: (0.5158125, 0.5123614829870815, 0.6554)\n",
      "epoch 8: (0.5169, 0.5133528226602931, 0.649725)\n",
      "epoch 9: (0.5178375, 0.5145277217844563, 0.63175)\n",
      "epoch 10: (0.5211, 0.5154003357419167, 0.70615)\n",
      "epoch 11: (0.52285, 0.5194220144496388, 0.6111)\n",
      "epoch 12: (0.52245, 0.5161702740663378, 0.716625)\n",
      "epoch 13: (0.5259625, 0.5225785411457767, 0.6009)\n",
      "epoch 14: (0.5261375, 0.519069071807686, 0.711475)\n",
      "epoch 15: (0.5270125, 0.5242139703740224, 0.5848)\n",
      "epoch 16: (0.52755, 0.5200043566656986, 0.71615)\n",
      "epoch 17: (0.5275125, 0.5247932953342195, 0.58235)\n",
      "epoch 18: (0.5285875, 0.5209382381484262, 0.71125)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19: (0.5286, 0.5255516840882695, 0.58825)\n",
      "epoch 20: (0.5293625, 0.521800464037123, 0.7028)\n",
      "epoch 21: (0.5278875, 0.5248679135920815, 0.5886)\n",
      "epoch 22: (0.5324, 0.5240579172080936, 0.705775)\n",
      "epoch 23: (0.5283375, 0.5253052932377827, 0.58825)\n",
      "epoch 24: (0.5349, 0.525679702733527, 0.714425)\n",
      "epoch 25: (0.5288375, 0.525438306318227, 0.59565)\n",
      "epoch 26: (0.536025, 0.5265778892618688, 0.71375)\n",
      "epoch 27: (0.531, 0.5269459776609153, 0.606225)\n",
      "epoch 28: (0.5361625, 0.5267479058414541, 0.71215)\n",
      "epoch 29: (0.5330625, 0.5284573838572935, 0.613975)\n",
      "epoch 30: (0.53685, 0.5274948703600074, 0.706975)\n",
      "epoch 31: (0.534475, 0.529639341443494, 0.61605)\n",
      "epoch 32: (0.5378, 0.5281973816717019, 0.708075)\n",
      "epoch 33: (0.534925, 0.5298478762498932, 0.619975)\n",
      "epoch 34: (0.5380875, 0.5285979764608714, 0.704)\n",
      "epoch 35: (0.535825, 0.5304867670836525, 0.623375)\n",
      "epoch 36: (0.5389, 0.5291287580965218, 0.706625)\n",
      "epoch 37: (0.5362125, 0.5308001445916349, 0.624075)\n",
      "epoch 38: (0.5393375, 0.5295665082019579, 0.704575)\n",
      "epoch 39: (0.5373125, 0.5316415442345608, 0.626925)\n",
      "epoch 40: (0.539925, 0.5300425147672975, 0.7044)\n",
      "epoch 41: (0.5381875, 0.5323000148019708, 0.629325)\n",
      "epoch 42: (0.5404875, 0.5305583334905749, 0.70295)\n",
      "epoch 43: (0.5389, 0.5328866720209663, 0.630325)\n",
      "epoch 44: (0.5409375, 0.5309411786935737, 0.702475)\n",
      "epoch 45: (0.539075, 0.5329454913367901, 0.6321)\n",
      "epoch 46: (0.541725, 0.5316710311586778, 0.70045)\n",
      "epoch 47: (0.539225, 0.5330496692926655, 0.63265)\n",
      "epoch 48: (0.54255, 0.5323488045007032, 0.700225)\n",
      "epoch 49: (0.539875, 0.5334620064616288, 0.6357)\n",
      "epoch 50: (0.5430125, 0.5328120530180223, 0.69845)\n",
      "epoch 51: (0.540175, 0.5337519952953037, 0.635325)\n",
      "epoch 52: (0.5433125, 0.533008173452474, 0.6994)\n",
      "epoch 53: (0.5405125, 0.5339962657603793, 0.63635)\n",
      "epoch 54: (0.5435375, 0.5331644798232751, 0.699925)\n",
      "epoch 55: (0.5409875, 0.5343372358472783, 0.637825)\n",
      "epoch 56: (0.5437, 0.5332812916492137, 0.700225)\n",
      "epoch 57: (0.5412125, 0.5345271756204838, 0.638025)\n",
      "epoch 58: (0.5441875, 0.5337315597625909, 0.699175)\n",
      "epoch 59: (0.5414875, 0.5347823353105154, 0.637875)\n",
      "epoch 60: (0.5445, 0.5340682896952993, 0.6976)\n",
      "epoch 61: (0.5414875, 0.534815902653939, 0.6373)\n",
      "epoch 62: (0.5449125, 0.5343282441289435, 0.699075)\n",
      "epoch 63: (0.541875, 0.5350462401138218, 0.6393)\n",
      "epoch 64: (0.5448125, 0.5344188636494557, 0.6958)\n",
      "epoch 65: (0.542375, 0.5355405518745282, 0.638525)\n",
      "epoch 66: (0.5449875, 0.5345360330102678, 0.6963)\n",
      "epoch 67: (0.542475, 0.5356274115081362, 0.638575)\n",
      "epoch 68: (0.5450875, 0.5347234255569033, 0.694325)\n",
      "epoch 69: (0.5427625, 0.5358572836089973, 0.63905)\n",
      "epoch 70: (0.5455875, 0.5350639361599846, 0.69565)\n",
      "epoch 71: (0.5428375, 0.5359488093989301, 0.63865)\n",
      "epoch 72: (0.5455375, 0.535109192189819, 0.69405)\n",
      "epoch 73: (0.543, 0.536090477989005, 0.638725)\n",
      "epoch 74: (0.5455375, 0.5351511993670275, 0.693275)\n",
      "epoch 75: (0.5432, 0.5362964207696186, 0.6383)\n",
      "epoch 76: (0.545525, 0.5351979279418587, 0.692225)\n",
      "epoch 77: (0.5431625, 0.5362702464233945, 0.638175)\n",
      "epoch 78: (0.545725, 0.5354169087177104, 0.69125)\n",
      "epoch 79: (0.5432375, 0.5363668860525265, 0.6377)\n",
      "epoch 80: (0.5458625, 0.5355158461270401, 0.691525)\n",
      "epoch 81: (0.5432625, 0.536426210874187, 0.6371)\n",
      "epoch 82: (0.545875, 0.5355468598659486, 0.69115)\n",
      "epoch 83: (0.5432375, 0.5363974998421618, 0.6372)\n",
      "epoch 84: (0.5459625, 0.5355919078501598, 0.69165)\n",
      "epoch 85: (0.5432125, 0.5363565614286014, 0.6375)\n",
      "epoch 86: (0.5461625, 0.5357661688651287, 0.6915)\n",
      "epoch 87: (0.5431, 0.5363207348417814, 0.636425)\n",
      "epoch 88: (0.5464125, 0.5359028408981028, 0.692775)\n",
      "epoch 89: (0.5431375, 0.5363822295317013, 0.635975)\n",
      "epoch 90: (0.546525, 0.5360212139981418, 0.692325)\n",
      "epoch 91: (0.54335, 0.5365606814539934, 0.6362)\n",
      "epoch 92: (0.5468125, 0.5362796194757135, 0.691975)\n",
      "epoch 93: (0.5435, 0.5366701791359325, 0.636625)\n",
      "epoch 94: (0.54665, 0.5362161322878658, 0.6907)\n",
      "epoch 95: (0.543525, 0.5367082735936578, 0.636375)\n",
      "epoch 96: (0.5468625, 0.536411491618267, 0.690375)\n",
      "epoch 97: (0.5435125, 0.5367294827695359, 0.63585)\n",
      "epoch 98: (0.5468125, 0.5363881925416351, 0.69005)\n",
      "epoch 99: (0.5437125, 0.5369247988511816, 0.635625)\n",
      "epoch 100: (0.5467125, 0.5363118720485065, 0.689925)\n",
      "epoch 101: (0.5437875, 0.5369662945062367, 0.63605)\n",
      "epoch 102: (0.5467625, 0.5363747739338428, 0.68955)\n",
      "epoch 103: (0.5438375, 0.5370663960936014, 0.635175)\n",
      "epoch 104: (0.5468625, 0.5364667431861954, 0.6894)\n",
      "epoch 105: (0.5437125, 0.5370154751571861, 0.634175)\n",
      "epoch 106: (0.5469625, 0.5365516704609578, 0.689375)\n",
      "epoch 107: (0.543925, 0.5371962062833432, 0.634375)\n",
      "epoch 108: (0.54695, 0.5365696927211123, 0.688875)\n",
      "epoch 109: (0.54365, 0.5369962283341103, 0.633575)\n",
      "epoch 110: (0.5472375, 0.5368086805758479, 0.6889)\n",
      "epoch 111: (0.5437375, 0.5370774610575395, 0.63355)\n",
      "epoch 112: (0.5472375, 0.5368575051204526, 0.68805)\n",
      "epoch 113: (0.5440125, 0.5373359065170827, 0.633425)\n",
      "epoch 114: (0.5472, 0.5368462138953942, 0.6877)\n",
      "epoch 115: (0.5442625, 0.5375447971669105, 0.633725)\n",
      "epoch 116: (0.5472875, 0.5369253294289897, 0.6876)\n",
      "epoch 117: (0.5443, 0.5375805904309467, 0.6337)\n",
      "epoch 118: (0.5470625, 0.5367740423121252, 0.68695)\n",
      "epoch 119: (0.54445, 0.5377174374204498, 0.6337)\n",
      "epoch 120: (0.547025, 0.5367569468870911, 0.6867)\n",
      "epoch 121: (0.5448375, 0.5380357559434182, 0.63425)\n",
      "epoch 122: (0.5472375, 0.5369671120849882, 0.68615)\n",
      "epoch 123: (0.5448125, 0.5380129360619235, 0.63425)\n",
      "epoch 124: (0.5471375, 0.5368758678688076, 0.686275)\n",
      "epoch 125: (0.54505, 0.5382362926498048, 0.63415)\n",
      "epoch 126: (0.5473625, 0.5370692860077876, 0.6862)\n",
      "epoch 127: (0.545525, 0.5386001356622011, 0.635225)\n",
      "epoch 128: (0.5474625, 0.5371664611107848, 0.685975)\n",
      "epoch 129: (0.5456, 0.538676844783715, 0.6351)\n",
      "epoch 130: (0.5475125, 0.5372231035901052, 0.685725)\n",
      "epoch 131: (0.5455875, 0.538662143538641, 0.63515)\n",
      "epoch 132: (0.547625, 0.5373105096165145, 0.68585)\n",
      "epoch 133: (0.545525, 0.5385984993005214, 0.63525)\n",
      "epoch 134: (0.5478125, 0.5374625374625375, 0.68595)\n",
      "epoch 135: (0.54555, 0.5386246078181972, 0.6352)\n",
      "epoch 136: (0.5480375, 0.5376653925316084, 0.685725)\n",
      "epoch 137: (0.5456, 0.5386784850926672, 0.635075)\n",
      "epoch 138: (0.5479375, 0.537604675334863, 0.685325)\n",
      "epoch 139: (0.5456375, 0.5387242527735941, 0.6349)\n",
      "epoch 140: (0.5480625, 0.5376938611454228, 0.6856)\n",
      "epoch 141: (0.545675, 0.5387470308788599, 0.635075)\n",
      "epoch 142: (0.5481375, 0.5377674911244925, 0.685425)\n",
      "epoch 143: (0.545875, 0.5389199966064309, 0.635225)\n",
      "epoch 144: (0.5479875, 0.5376542362241795, 0.6852)\n",
      "epoch 145: (0.5459, 0.5389643463497453, 0.6349)\n",
      "epoch 146: (0.5480125, 0.5376856812071976, 0.685025)\n",
      "epoch 147: (0.546025, 0.5390588534815632, 0.6352)\n",
      "epoch 148: (0.5479875, 0.53764832793959, 0.6853)\n",
      "epoch 149: (0.5460625, 0.5390666412229926, 0.6356)\n",
      "epoch 150: (0.54795, 0.5376122681099738, 0.685375)\n",
      "epoch 151: (0.546075, 0.5390913333050524, 0.6354)\n",
      "epoch 152: (0.5481, 0.5377284492901404, 0.68555)\n",
      "epoch 153: (0.546025, 0.5390455991516437, 0.6354)\n",
      "epoch 154: (0.5481, 0.5377402903099254, 0.68535)\n",
      "epoch 155: (0.546125, 0.5391437179106378, 0.6353)\n",
      "epoch 156: (0.5478375, 0.5375409546604932, 0.684975)\n",
      "epoch 157: (0.54625, 0.5392314869793876, 0.6357)\n",
      "epoch 158: (0.5478875, 0.5375580870963315, 0.6854)\n",
      "epoch 159: (0.5462875, 0.539254139546717, 0.635875)\n",
      "epoch 160: (0.54795, 0.5376063683777107, 0.685475)\n",
      "epoch 161: (0.5463, 0.5392672377236876, 0.63585)\n",
      "epoch 162: (0.548075, 0.5377132771131594, 0.68545)\n",
      "epoch 163: (0.546475, 0.5393889312653615, 0.636425)\n",
      "epoch 164: (0.5481875, 0.5377933766004588, 0.6857)\n",
      "epoch 165: (0.5464375, 0.5393413110240389, 0.636625)\n",
      "epoch 166: (0.5481, 0.537700356624995, 0.686025)\n",
      "epoch 167: (0.546625, 0.53950434230036, 0.63675)\n",
      "epoch 168: (0.548275, 0.5378375200846495, 0.6862)\n",
      "epoch 169: (0.5467875, 0.5396193661748205, 0.63725)\n",
      "epoch 170: (0.54815, 0.5377277179236043, 0.686275)\n",
      "epoch 171: (0.5467125, 0.5395458104933438, 0.637325)\n",
      "epoch 172: (0.548175, 0.5377354795754514, 0.6865)\n",
      "epoch 173: (0.5467875, 0.5395875198307774, 0.637725)\n",
      "epoch 174: (0.5479625, 0.537569764026241, 0.686275)\n",
      "epoch 175: (0.5468125, 0.5396069970598811, 0.637775)\n",
      "epoch 176: (0.548, 0.5375925128245291, 0.686425)\n",
      "epoch 177: (0.546775, 0.539566063271866, 0.637875)\n",
      "epoch 178: (0.548, 0.5375586854460094, 0.687)\n",
      "epoch 179: (0.5465625, 0.5393521942149634, 0.638175)\n",
      "epoch 180: (0.54795, 0.5374916924039251, 0.687425)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 181: (0.54655, 0.5393225206960636, 0.63845)\n",
      "epoch 182: (0.5479375, 0.5374665390101409, 0.687675)\n",
      "epoch 183: (0.5466, 0.5393381732230289, 0.6389)\n",
      "epoch 184: (0.54805, 0.5375317320835774, 0.688175)\n",
      "epoch 185: (0.54665, 0.5393737339635382, 0.63905)\n",
      "epoch 186: (0.548175, 0.5376205536683456, 0.68845)\n",
      "epoch 187: (0.546625, 0.5393725722006418, 0.638725)\n",
      "epoch 188: (0.5482125, 0.5376593958093304, 0.688325)\n",
      "epoch 189: (0.5466375, 0.5393889487130762, 0.63865)\n",
      "epoch 190: (0.5482625, 0.5377058145666908, 0.68825)\n",
      "epoch 191: (0.546725, 0.5394753516664554, 0.63855)\n",
      "epoch 192: (0.548275, 0.5377163170436345, 0.68825)\n",
      "epoch 193: (0.5466375, 0.5394122493820379, 0.6383)\n",
      "epoch 194: (0.5482125, 0.5376755816906637, 0.68805)\n",
      "epoch 195: (0.54675, 0.5394764618957146, 0.638875)\n",
      "epoch 196: (0.5483125, 0.5377404550336882, 0.688375)\n",
      "epoch 197: (0.546725, 0.5394486892650597, 0.63895)\n",
      "epoch 198: (0.548075, 0.5375483266294373, 0.68825)\n",
      "epoch 199: (0.546875, 0.5395636394328157, 0.639275)\n",
      "epoch 0: (0.5036875, 0.5155475914409191, 0.122275)\n",
      "epoch 1: (0.50925, 0.5086456678194223, 0.5442)\n",
      "epoch 2: (0.5018375, 0.5015836762836396, 0.581975)\n",
      "epoch 3: (0.5049125, 0.5037702181546078, 0.6564)\n",
      "epoch 4: (0.50735, 0.5065937023414372, 0.5647)\n",
      "epoch 5: (0.511175, 0.5066265417457305, 0.854375)\n",
      "epoch 6: (0.5117875, 0.5116809116809117, 0.51635)\n",
      "epoch 7: (0.5149375, 0.5176968871249593, 0.436975)\n",
      "epoch 8: (0.513925, 0.5081133834411233, 0.872075)\n",
      "epoch 9: (0.519075, 0.5248307732361365, 0.403175)\n",
      "epoch 10: (0.5191375, 0.5138354208462108, 0.71075)\n",
      "epoch 11: (0.5166875, 0.5354958787556501, 0.25175)\n",
      "epoch 12: (0.5279875, 0.526323214747584, 0.5596)\n",
      "epoch 13: (0.528, 0.5201598387212902, 0.72245)\n",
      "epoch 14: (0.51615, 0.5303571428571429, 0.28215)\n",
      "epoch 15: (0.5281625, 0.5191904737568355, 0.761925)\n",
      "epoch 16: (0.5196375, 0.5300324985662397, 0.346575)\n",
      "epoch 17: (0.5326625, 0.5216304365821758, 0.787675)\n",
      "epoch 18: (0.5264, 0.5323153191749801, 0.434875)\n",
      "epoch 19: (0.5377875, 0.5292784503631961, 0.6831)\n",
      "epoch 20: (0.5327125, 0.5315811068471991, 0.550625)\n",
      "epoch 21: (0.5323875, 0.5349087871520574, 0.496275)\n",
      "epoch 22: (0.5426, 0.5297164382128283, 0.759375)\n",
      "epoch 23: (0.535175, 0.5337863797906061, 0.555725)\n",
      "epoch 24: (0.539725, 0.5352156376047161, 0.60375)\n",
      "epoch 25: (0.5428375, 0.53190102954592, 0.71425)\n",
      "epoch 26: (0.5353625, 0.5379639818567326, 0.5011)\n",
      "epoch 27: (0.543275, 0.5327977566410247, 0.703)\n",
      "epoch 28: (0.541775, 0.5342600565875262, 0.65145)\n",
      "epoch 29: (0.5301625, 0.5437121843411471, 0.375175)\n",
      "epoch 30: (0.5425125, 0.5336326417594589, 0.674525)\n",
      "epoch 31: (0.5395, 0.5359777757537116, 0.58845)\n",
      "epoch 32: (0.543175, 0.5330159822589279, 0.697025)\n",
      "epoch 33: (0.5351875, 0.5413326285496138, 0.46085)\n",
      "epoch 34: (0.5438, 0.5318881729824179, 0.730575)\n",
      "epoch 35: (0.5386375, 0.5390169397389614, 0.533775)\n",
      "epoch 36: (0.5440125, 0.5312317053699729, 0.748625)\n",
      "epoch 37: (0.5391625, 0.5361736520032329, 0.580475)\n",
      "epoch 38: (0.5437375, 0.5314992528042347, 0.738)\n",
      "epoch 39: (0.5383875, 0.5377319080968178, 0.547075)\n",
      "epoch 40: (0.5439125, 0.5323331799355729, 0.722975)\n",
      "epoch 41: (0.538525, 0.5382647993643226, 0.541925)\n",
      "epoch 42: (0.54395, 0.5333421841216857, 0.703025)\n",
      "epoch 43: (0.5385375, 0.5393249827801729, 0.528525)\n",
      "epoch 44: (0.544475, 0.5338058680449985, 0.702275)\n",
      "epoch 45: (0.5396, 0.5379583033788641, 0.561225)\n",
      "epoch 46: (0.5431125, 0.534532129197621, 0.66735)\n",
      "epoch 47: (0.540225, 0.5364043621883343, 0.5927)\n",
      "epoch 48: (0.541425, 0.5354499165632621, 0.6257)\n",
      "epoch 49: (0.5423375, 0.5355754889397727, 0.637375)\n",
      "epoch 50: (0.543675, 0.5347302294143375, 0.67245)\n",
      "epoch 51: (0.53925, 0.5386585245740175, 0.5469)\n",
      "epoch 52: (0.5437375, 0.534138583721974, 0.684325)\n",
      "epoch 53: (0.5412125, 0.5372483448945929, 0.594425)\n",
      "epoch 54: (0.5460625, 0.5341830392757092, 0.719825)\n",
      "epoch 55: (0.5411, 0.5379975038136181, 0.581925)\n",
      "epoch 56: (0.5456125, 0.5349527768731202, 0.6981)\n",
      "epoch 57: (0.540275, 0.5369800752915251, 0.584825)\n",
      "epoch 58: (0.54155, 0.5365146322172423, 0.6105)\n",
      "epoch 59: (0.5435125, 0.534880458526223, 0.66725)\n",
      "epoch 60: (0.540125, 0.5370721116089989, 0.5813)\n",
      "epoch 61: (0.5447375, 0.5346191793542396, 0.690875)\n",
      "epoch 62: (0.5408125, 0.5375037331434216, 0.584925)\n",
      "epoch 63: (0.5442875, 0.5350771241312398, 0.675575)\n",
      "epoch 64: (0.5420125, 0.5364905652183354, 0.617675)\n",
      "epoch 65: (0.5444, 0.5355997434252726, 0.668)\n",
      "epoch 66: (0.5436625, 0.5356697914751956, 0.6557)\n",
      "epoch 67: (0.5434375, 0.5370745759095273, 0.62925)\n",
      "epoch 68: (0.5451375, 0.5352547204811279, 0.6853)\n",
      "epoch 69: (0.5410625, 0.5374649300882736, 0.589075)\n",
      "epoch 70: (0.5454625, 0.5348578657823612, 0.697575)\n",
      "epoch 71: (0.5408, 0.537596756358275, 0.5834)\n",
      "epoch 72: (0.545025, 0.5353040341866938, 0.6827)\n",
      "epoch 73: (0.5407, 0.5379699598843176, 0.57665)\n",
      "epoch 74: (0.5453, 0.5355810391548521, 0.681875)\n",
      "epoch 75: (0.5416375, 0.5376682121451996, 0.594325)\n",
      "epoch 76: (0.5456, 0.5355098703422497, 0.687675)\n",
      "epoch 77: (0.543075, 0.5367565491936171, 0.629025)\n",
      "epoch 78: (0.5414, 0.5368032714019024, 0.60385)\n",
      "epoch 79: (0.545875, 0.5349550441938433, 0.702075)\n",
      "epoch 80: (0.543, 0.5372391097254698, 0.62035)\n",
      "epoch 81: (0.5443875, 0.5373121782074183, 0.6392)\n",
      "epoch 82: (0.543275, 0.5382254217825281, 0.609325)\n",
      "epoch 83: (0.5454375, 0.5355529038946812, 0.68445)\n",
      "epoch 84: (0.5431875, 0.5376714569204265, 0.6164)\n",
      "epoch 85: (0.54575, 0.535195015001154, 0.6957)\n",
      "epoch 86: (0.5422375, 0.5379296410210358, 0.599025)\n",
      "epoch 87: (0.545975, 0.5355582195753896, 0.69245)\n",
      "epoch 88: (0.5423625, 0.5381257734278322, 0.597925)\n",
      "epoch 89: (0.54635, 0.5360714424685785, 0.688825)\n",
      "epoch 90: (0.5445375, 0.5363712459933444, 0.6568)\n",
      "epoch 91: (0.5468375, 0.5354473729022005, 0.7075)\n",
      "epoch 92: (0.54385, 0.5381105510168608, 0.61915)\n",
      "epoch 93: (0.546375, 0.5354793053324153, 0.699925)\n",
      "epoch 94: (0.5441, 0.5380467604175654, 0.62365)\n",
      "epoch 95: (0.545325, 0.5372294550084192, 0.65405)\n",
      "epoch 96: (0.5456875, 0.5380737098689556, 0.645675)\n",
      "epoch 97: (0.54505, 0.5377682763246143, 0.64145)\n",
      "epoch 98: (0.5460625, 0.5366980699902404, 0.67365)\n",
      "epoch 99: (0.5462625, 0.5376692111959287, 0.660325)\n",
      "epoch 100: (0.54615, 0.5362686156626979, 0.682375)\n",
      "epoch 101: (0.5444875, 0.5380064500971786, 0.62975)\n",
      "epoch 102: (0.5470125, 0.5356661925082977, 0.706075)\n",
      "epoch 103: (0.54455, 0.5386148912195545, 0.6214)\n",
      "epoch 104: (0.547125, 0.536259762243681, 0.69695)\n",
      "epoch 105: (0.5445375, 0.5386904115539146, 0.6201)\n",
      "epoch 106: (0.5470125, 0.5364459173982984, 0.691975)\n",
      "epoch 107: (0.5450875, 0.5391920377251885, 0.6203)\n",
      "epoch 108: (0.54665, 0.5361796184271754, 0.69135)\n",
      "epoch 109: (0.544475, 0.5394421780773324, 0.608275)\n",
      "epoch 110: (0.547225, 0.537138251022334, 0.683025)\n",
      "epoch 111: (0.5465375, 0.5388857554678198, 0.644925)\n",
      "epoch 112: (0.54755, 0.53702550126533, 0.689675)\n",
      "epoch 113: (0.5448, 0.5395829651881958, 0.6107)\n",
      "epoch 114: (0.5472125, 0.5367290973802439, 0.689925)\n",
      "epoch 115: (0.5457, 0.5396598108131563, 0.62185)\n",
      "epoch 116: (0.546425, 0.5371980289251231, 0.67045)\n",
      "epoch 117: (0.54565, 0.5392958595162263, 0.6265)\n",
      "epoch 118: (0.5475625, 0.5366633905686921, 0.6962)\n",
      "epoch 119: (0.5454125, 0.5392765248978356, 0.623525)\n",
      "epoch 120: (0.5475875, 0.5367350483432078, 0.6953)\n",
      "epoch 121: (0.5451375, 0.539465343504776, 0.617)\n",
      "epoch 122: (0.54745, 0.5370081503724213, 0.688525)\n",
      "epoch 123: (0.5457625, 0.539577522648159, 0.6239)\n",
      "epoch 124: (0.5478875, 0.5374333118367826, 0.687525)\n",
      "epoch 125: (0.5455625, 0.5399749950648154, 0.61545)\n",
      "epoch 126: (0.548075, 0.5372703310334135, 0.693025)\n",
      "epoch 127: (0.545275, 0.5397428019662921, 0.614875)\n",
      "epoch 128: (0.548, 0.5372873456070846, 0.69165)\n",
      "epoch 129: (0.545525, 0.5387842903390697, 0.632425)\n",
      "epoch 130: (0.5476625, 0.5376786102492144, 0.68015)\n",
      "epoch 131: (0.5460375, 0.5390123509098997, 0.636075)\n",
      "epoch 132: (0.54755, 0.5364647239263803, 0.69955)\n",
      "epoch 133: (0.546175, 0.5396062958356563, 0.6291)\n",
      "epoch 134: (0.547875, 0.5371440763441695, 0.692325)\n",
      "epoch 135: (0.5465125, 0.5405700080682091, 0.61975)\n",
      "epoch 136: (0.547775, 0.5370420624151967, 0.69265)\n",
      "epoch 137: (0.5462375, 0.5402844634183529, 0.620125)\n",
      "epoch 138: (0.547775, 0.5370636152055858, 0.692275)\n",
      "epoch 139: (0.54605, 0.5391931571556237, 0.633525)\n",
      "epoch 140: (0.54805, 0.5367579559363526, 0.70165)\n",
      "epoch 141: (0.546925, 0.5386834837805532, 0.65345)\n",
      "epoch 142: (0.548, 0.53796867584243, 0.6801)\n",
      "epoch 143: (0.546075, 0.5402718293855432, 0.618125)\n",
      "epoch 144: (0.547675, 0.5372141128717508, 0.688225)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 145: (0.547325, 0.5383120825743777, 0.66495)\n",
      "epoch 146: (0.548075, 0.5366565001906214, 0.703825)\n",
      "epoch 147: (0.5459625, 0.5390182304378276, 0.63495)\n",
      "epoch 148: (0.5481, 0.5366993476519284, 0.703425)\n",
      "epoch 149: (0.5464125, 0.5394387440783464, 0.634825)\n",
      "epoch 150: (0.548425, 0.5370023687628944, 0.702775)\n",
      "epoch 151: (0.546575, 0.5394252338426376, 0.63725)\n",
      "epoch 152: (0.548125, 0.5366262034323985, 0.7051)\n",
      "epoch 153: (0.546525, 0.5388064058720494, 0.645975)\n",
      "epoch 154: (0.548375, 0.5367493447791241, 0.70655)\n",
      "epoch 155: (0.546875, 0.5395102832097101, 0.640075)\n",
      "epoch 156: (0.5483125, 0.5368186408062949, 0.7044)\n",
      "epoch 157: (0.546675, 0.5394381073088298, 0.638425)\n",
      "epoch 158: (0.5484, 0.5368874323603384, 0.70445)\n",
      "epoch 159: (0.5465375, 0.5393693293572743, 0.637575)\n",
      "epoch 160: (0.54845, 0.5369706219000382, 0.7037)\n",
      "epoch 161: (0.54645, 0.5390598721829801, 0.64105)\n",
      "epoch 162: (0.548725, 0.5371294673474053, 0.704875)\n",
      "epoch 163: (0.5467625, 0.5394129669820266, 0.64)\n",
      "epoch 164: (0.548575, 0.5369026817594773, 0.706725)\n",
      "epoch 165: (0.5468875, 0.5392980618124673, 0.64345)\n",
      "epoch 166: (0.5486, 0.5368335291219827, 0.708325)\n",
      "epoch 167: (0.546975, 0.5392718304560464, 0.64505)\n",
      "epoch 168: (0.5484375, 0.5367570336362429, 0.707325)\n",
      "epoch 169: (0.5470875, 0.539434290140904, 0.644125)\n",
      "epoch 170: (0.548475, 0.5366319050857704, 0.710125)\n",
      "epoch 171: (0.54725, 0.5394325057375339, 0.646375)\n",
      "epoch 172: (0.5480875, 0.5366415849128489, 0.704275)\n",
      "epoch 173: (0.5471, 0.5397552226208061, 0.639475)\n",
      "epoch 174: (0.5480625, 0.5366085880224698, 0.7045)\n",
      "epoch 175: (0.546975, 0.5396413502109705, 0.639475)\n",
      "epoch 176: (0.5483625, 0.5368118589560618, 0.70525)\n",
      "epoch 177: (0.547125, 0.5396074970583291, 0.642025)\n",
      "epoch 178: (0.5480875, 0.5367606306736742, 0.70215)\n",
      "epoch 179: (0.5472375, 0.539649564578743, 0.642925)\n",
      "epoch 180: (0.548725, 0.5374303821778376, 0.6996)\n",
      "epoch 181: (0.546725, 0.5398371557677552, 0.633175)\n",
      "epoch 182: (0.548425, 0.5373923786726381, 0.69595)\n",
      "epoch 183: (0.546975, 0.5388110877019044, 0.65215)\n",
      "epoch 184: (0.5488375, 0.5365666473241862, 0.716625)\n",
      "epoch 185: (0.5471625, 0.5390409966681153, 0.651175)\n",
      "epoch 186: (0.5492125, 0.5371969539502277, 0.710725)\n",
      "epoch 187: (0.547325, 0.5391763245033112, 0.651325)\n",
      "epoch 188: (0.5488125, 0.5366783761952173, 0.714225)\n",
      "epoch 189: (0.5474875, 0.538726579542906, 0.6606)\n",
      "epoch 190: (0.5487875, 0.5371254637115952, 0.70585)\n",
      "epoch 191: (0.5475125, 0.5395797321781869, 0.647725)\n",
      "epoch 192: (0.5487125, 0.537234144197512, 0.70285)\n",
      "epoch 193: (0.5473125, 0.5399438569830516, 0.63955)\n",
      "epoch 194: (0.54905, 0.5373074729035938, 0.706425)\n",
      "epoch 195: (0.5471625, 0.5390135456519491, 0.6516)\n",
      "epoch 196: (0.54915, 0.5372729685663368, 0.708475)\n",
      "epoch 197: (0.5473625, 0.5395321661832523, 0.6464)\n",
      "epoch 198: (0.5489, 0.5370132081898347, 0.709475)\n",
      "epoch 199: (0.5475, 0.5398306150685506, 0.643775)\n",
      "epoch 0: (0.49545, 0.25405405405405407, 0.0047)\n",
      "epoch 1: (0.5043, 0.5031959567430971, 0.677025)\n",
      "epoch 2: (0.5056875, 0.5153872167737572, 0.1905)\n",
      "epoch 3: (0.5095375, 0.5050215208034433, 0.9592)\n",
      "epoch 4: (0.5084625, 0.5502002076227198, 0.09275)\n",
      "epoch 5: (0.5133625, 0.5070066199121714, 0.966925)\n",
      "epoch 6: (0.5067375, 0.6049863654070899, 0.038825)\n",
      "epoch 7: (0.5167125, 0.508808454007616, 0.965375)\n",
      "epoch 8: (0.5133375, 0.5711807871914609, 0.107025)\n",
      "epoch 9: (0.5232, 0.5125385072690914, 0.94835)\n",
      "epoch 10: (0.51615, 0.56931330472103, 0.13265)\n",
      "epoch 11: (0.5301875, 0.5169380970416193, 0.9213)\n",
      "epoch 12: (0.520825, 0.5760591672753835, 0.157725)\n",
      "epoch 13: (0.5331, 0.5190723134543359, 0.90085)\n",
      "epoch 14: (0.5224125, 0.5774380236676169, 0.167125)\n",
      "epoch 15: (0.536225, 0.5212675394821816, 0.887875)\n",
      "epoch 16: (0.5242, 0.5743015044519496, 0.18705)\n",
      "epoch 17: (0.5373375, 0.5222541759175098, 0.876225)\n",
      "epoch 18: (0.524925, 0.5751318764129616, 0.1908)\n",
      "epoch 19: (0.5393875, 0.5239740097691618, 0.86085)\n",
      "epoch 20: (0.5253875, 0.5768444948921679, 0.190575)\n",
      "epoch 21: (0.540475, 0.5250347920210299, 0.84885)\n",
      "epoch 22: (0.5259125, 0.5752450090744101, 0.1981)\n",
      "epoch 23: (0.5409875, 0.5254253058945768, 0.847025)\n",
      "epoch 24: (0.526625, 0.5784126049182742, 0.1964)\n",
      "epoch 25: (0.5420375, 0.5266748100322033, 0.83)\n",
      "epoch 26: (0.527525, 0.5756597031335899, 0.209425)\n",
      "epoch 27: (0.5432375, 0.5277746551253433, 0.8216)\n",
      "epoch 28: (0.5274375, 0.5716992225779055, 0.218775)\n",
      "epoch 29: (0.5435, 0.5282146910977785, 0.814375)\n",
      "epoch 30: (0.5275625, 0.568841710896035, 0.22775)\n",
      "epoch 31: (0.5445875, 0.5292967787505954, 0.80555)\n",
      "epoch 32: (0.5266875, 0.570906675523082, 0.214875)\n",
      "epoch 33: (0.5450875, 0.5302119105452718, 0.791275)\n",
      "epoch 34: (0.529775, 0.5692522386323992, 0.24475)\n",
      "epoch 35: (0.545075, 0.5298549476751888, 0.799975)\n",
      "epoch 36: (0.5283875, 0.5693774057554836, 0.232975)\n",
      "epoch 37: (0.5458875, 0.5308482210383019, 0.78965)\n",
      "epoch 38: (0.527825, 0.5694583125312032, 0.228125)\n",
      "epoch 39: (0.545825, 0.530899160513806, 0.78735)\n",
      "epoch 40: (0.52765, 0.5697879858657244, 0.22575)\n",
      "epoch 41: (0.545825, 0.5310909831060452, 0.782775)\n",
      "epoch 42: (0.5291375, 0.5694369973190349, 0.23895)\n",
      "epoch 43: (0.5463, 0.5312943562014194, 0.78605)\n",
      "epoch 44: (0.528675, 0.5687649880095923, 0.237175)\n",
      "epoch 45: (0.5461875, 0.5313843069971291, 0.782025)\n",
      "epoch 46: (0.5285875, 0.5686168616861687, 0.2369)\n",
      "epoch 47: (0.5463375, 0.5315871095281106, 0.779825)\n",
      "epoch 48: (0.5283, 0.5686976574827042, 0.234275)\n",
      "epoch 49: (0.5463, 0.5315997815997816, 0.7789)\n",
      "epoch 50: (0.52825, 0.5682367149758454, 0.23525)\n",
      "epoch 51: (0.5460875, 0.5315176693850336, 0.777225)\n",
      "epoch 52: (0.528725, 0.5688601222581805, 0.2373)\n",
      "epoch 53: (0.546075, 0.5314956593068563, 0.777525)\n",
      "epoch 54: (0.5287, 0.5684637404580153, 0.2383)\n",
      "epoch 55: (0.5460375, 0.5315158049665417, 0.776425)\n",
      "epoch 56: (0.5286875, 0.5683076373593666, 0.238675)\n",
      "epoch 57: (0.5459875, 0.5315020636035142, 0.7759)\n",
      "epoch 58: (0.528775, 0.5680179647795769, 0.2403)\n",
      "epoch 59: (0.546125, 0.5316152027142809, 0.7756)\n",
      "epoch 60: (0.528825, 0.567719957711735, 0.24165)\n",
      "epoch 61: (0.5461375, 0.531636238964601, 0.775325)\n",
      "epoch 62: (0.5288125, 0.5679339817270852, 0.240875)\n",
      "epoch 63: (0.5460625, 0.5316173316173316, 0.7745)\n",
      "epoch 64: (0.5289125, 0.5675881012214365, 0.2428)\n",
      "epoch 65: (0.546125, 0.5316195372750643, 0.7755)\n",
      "epoch 66: (0.5291125, 0.5682310892365383, 0.24245)\n",
      "epoch 67: (0.5463375, 0.5317755567365552, 0.775475)\n",
      "epoch 68: (0.5289, 0.568426660352788, 0.240075)\n",
      "epoch 69: (0.5465125, 0.5319492384043412, 0.774425)\n",
      "epoch 70: (0.5292375, 0.5699419891154835, 0.23825)\n",
      "epoch 71: (0.54665, 0.5320255380496345, 0.774975)\n",
      "epoch 72: (0.5292375, 0.569875126964211, 0.23845)\n",
      "epoch 73: (0.5467875, 0.532127100750176, 0.77495)\n",
      "epoch 74: (0.529025, 0.5682780522230063, 0.241575)\n",
      "epoch 75: (0.54665, 0.5320046652030735, 0.77545)\n",
      "epoch 76: (0.5291, 0.5684705882352942, 0.2416)\n",
      "epoch 77: (0.5467375, 0.5320685455512291, 0.77545)\n",
      "epoch 78: (0.529175, 0.5685825105782792, 0.241875)\n",
      "epoch 79: (0.5470125, 0.5322472777158536, 0.77595)\n",
      "epoch 80: (0.5292, 0.5685124354763023, 0.2423)\n",
      "epoch 81: (0.547025, 0.5322464513474594, 0.776175)\n",
      "epoch 82: (0.5293375, 0.5686779422953122, 0.242925)\n",
      "epoch 83: (0.5469875, 0.5322047257586402, 0.7765)\n",
      "epoch 84: (0.529325, 0.5685243603224676, 0.2433)\n",
      "epoch 85: (0.547125, 0.5323227819884084, 0.7761)\n",
      "epoch 86: (0.5295375, 0.5696598077943518, 0.24155)\n",
      "epoch 87: (0.5471375, 0.5323141784777803, 0.7765)\n",
      "epoch 88: (0.5296, 0.5696798493408662, 0.242)\n",
      "epoch 89: (0.5472375, 0.532366090546258, 0.776975)\n",
      "epoch 90: (0.529575, 0.5694411833763794, 0.242525)\n",
      "epoch 91: (0.5471125, 0.5322948263156992, 0.776525)\n",
      "epoch 92: (0.5297625, 0.5701242857984332, 0.241975)\n",
      "epoch 93: (0.54705, 0.5322381719140772, 0.776775)\n",
      "epoch 94: (0.529825, 0.5700775375939849, 0.242625)\n",
      "epoch 95: (0.54705, 0.5322304425263735, 0.77695)\n",
      "epoch 96: (0.529775, 0.5699682763482552, 0.24255)\n",
      "epoch 97: (0.547075, 0.5322299055182802, 0.777375)\n",
      "epoch 98: (0.5299125, 0.5700403910320201, 0.24345)\n",
      "epoch 99: (0.54705, 0.5322017657928958, 0.7776)\n",
      "epoch 100: (0.530025, 0.5701928696668614, 0.2439)\n",
      "epoch 101: (0.5470875, 0.5322114480187436, 0.778)\n",
      "epoch 102: (0.5301375, 0.5702628664684968, 0.2446)\n",
      "epoch 103: (0.5469625, 0.5321336321182367, 0.7777)\n",
      "epoch 104: (0.5298875, 0.5699900474211111, 0.2434)\n",
      "epoch 105: (0.54695, 0.5321124448548271, 0.777975)\n",
      "epoch 106: (0.530025, 0.5701354823639336, 0.244075)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 107: (0.5468875, 0.5320538018492249, 0.778275)\n",
      "epoch 108: (0.5301875, 0.5703958491226024, 0.2446)\n",
      "epoch 109: (0.54705, 0.5321984602224124, 0.777675)\n",
      "epoch 110: (0.5300875, 0.5708816773661582, 0.242325)\n",
      "epoch 111: (0.546975, 0.5321218544857768, 0.778175)\n",
      "epoch 112: (0.530075, 0.5708731000353482, 0.24225)\n",
      "epoch 113: (0.5469875, 0.532128754337681, 0.778225)\n",
      "epoch 114: (0.5301, 0.570923656927427, 0.2423)\n",
      "epoch 115: (0.5470625, 0.5321800372655943, 0.7783)\n",
      "epoch 116: (0.530175, 0.5710668864813943, 0.242475)\n",
      "epoch 117: (0.547075, 0.5321924365725227, 0.778225)\n",
      "epoch 118: (0.53015, 0.5709996467679266, 0.242475)\n",
      "epoch 119: (0.54705, 0.5321753402174656, 0.7782)\n",
      "epoch 120: (0.5303375, 0.5712775330396476, 0.24315)\n",
      "epoch 121: (0.5470625, 0.5321756371032526, 0.7784)\n",
      "epoch 122: (0.53035, 0.5713194689225708, 0.243125)\n",
      "epoch 123: (0.5469875, 0.5321408416984456, 0.77795)\n",
      "epoch 124: (0.530275, 0.5712101611196049, 0.24285)\n",
      "epoch 125: (0.5470625, 0.5321866397661019, 0.77815)\n",
      "epoch 126: (0.5301875, 0.570991827855841, 0.2428)\n",
      "epoch 127: (0.5471, 0.532212837260199, 0.778175)\n",
      "epoch 128: (0.5302, 0.5710504646512174, 0.242725)\n",
      "epoch 129: (0.5471125, 0.5322208353993195, 0.7782)\n",
      "epoch 130: (0.53025, 0.5711513583441138, 0.242825)\n",
      "epoch 131: (0.5471, 0.5322150405252898, 0.778125)\n",
      "epoch 132: (0.530225, 0.5710841956726247, 0.242825)\n",
      "epoch 133: (0.54715, 0.5322503419972641, 0.77815)\n",
      "epoch 134: (0.5302, 0.5710253998118533, 0.2428)\n",
      "epoch 135: (0.547125, 0.532234344539827, 0.7781)\n",
      "epoch 136: (0.53025, 0.5711095439586271, 0.24295)\n",
      "epoch 137: (0.5471125, 0.5322219372488672, 0.778175)\n",
      "epoch 138: (0.5303, 0.5711685261303582, 0.243175)\n",
      "epoch 139: (0.5470625, 0.5321877404462683, 0.778125)\n",
      "epoch 140: (0.5302625, 0.5710595832110361, 0.2432)\n",
      "epoch 141: (0.547025, 0.5321780484466949, 0.777725)\n",
      "epoch 142: (0.53025, 0.5707767898923725, 0.24395)\n",
      "epoch 143: (0.5471625, 0.5322318850484375, 0.778775)\n",
      "epoch 144: (0.5303375, 0.570969062518276, 0.244075)\n",
      "epoch 145: (0.547125, 0.5322090082701114, 0.778675)\n",
      "epoch 146: (0.5303625, 0.570961145194274, 0.2443)\n",
      "epoch 147: (0.5471625, 0.5322362912458776, 0.778675)\n",
      "epoch 148: (0.5303, 0.5706705539358601, 0.244675)\n",
      "epoch 149: (0.5471125, 0.5321977139537665, 0.778725)\n",
      "epoch 150: (0.5303, 0.5706129107434165, 0.24485)\n",
      "epoch 151: (0.547075, 0.532169337479072, 0.77875)\n",
      "epoch 152: (0.530325, 0.5706382483112042, 0.244975)\n",
      "epoch 153: (0.547025, 0.532145054344111, 0.778475)\n",
      "epoch 154: (0.5303125, 0.5706791023025357, 0.24475)\n",
      "epoch 155: (0.547075, 0.532177033492823, 0.778575)\n",
      "epoch 156: (0.530325, 0.5706711722209276, 0.244875)\n",
      "epoch 157: (0.5470625, 0.5321646419601209, 0.77865)\n",
      "epoch 158: (0.5302125, 0.5703639010189229, 0.2449)\n",
      "epoch 159: (0.547075, 0.532169337479072, 0.77875)\n",
      "epoch 160: (0.5302625, 0.5703983716196569, 0.2452)\n",
      "epoch 161: (0.54705, 0.5321500563736377, 0.778775)\n",
      "epoch 162: (0.530325, 0.5704740878456891, 0.245475)\n",
      "epoch 163: (0.54705, 0.5321489579774513, 0.7788)\n",
      "epoch 164: (0.5304, 0.570788217487484, 0.245125)\n",
      "epoch 165: (0.5470625, 0.5321569498300337, 0.778825)\n",
      "epoch 166: (0.5303375, 0.5706550218340611, 0.245025)\n",
      "epoch 167: (0.5470625, 0.5321547527542916, 0.778875)\n",
      "epoch 168: (0.5304125, 0.5707390823980927, 0.245375)\n",
      "epoch 169: (0.5470625, 0.5321525559787529, 0.778925)\n",
      "epoch 170: (0.5304875, 0.5708723194048934, 0.245575)\n",
      "epoch 171: (0.547025, 0.5321209016393442, 0.779025)\n",
      "epoch 172: (0.5304, 0.570525461083401, 0.245925)\n",
      "epoch 173: (0.5469875, 0.5321375442436264, 0.778025)\n",
      "epoch 174: (0.5298125, 0.5710794540144245, 0.239525)\n",
      "epoch 175: (0.5469875, 0.5321353463162755, 0.778075)\n",
      "epoch 176: (0.52985, 0.5711307041582271, 0.239675)\n",
      "epoch 177: (0.5469375, 0.5320989553948471, 0.778075)\n",
      "epoch 178: (0.5298125, 0.5710117310784255, 0.239725)\n",
      "epoch 179: (0.5469375, 0.5320989553948471, 0.778075)\n",
      "epoch 180: (0.5298125, 0.5709779179810726, 0.239825)\n",
      "epoch 181: (0.5469625, 0.5321138558851184, 0.77815)\n",
      "epoch 182: (0.5298375, 0.5710205296042844, 0.2399)\n",
      "epoch 183: (0.5469625, 0.5321116600283765, 0.7782)\n",
      "epoch 184: (0.5298375, 0.571012078300708, 0.239925)\n",
      "epoch 185: (0.5469625, 0.5321105622126118, 0.778225)\n",
      "epoch 186: (0.5299, 0.5711312001903176, 0.240075)\n",
      "epoch 187: (0.54695, 0.5320992718695519, 0.778275)\n",
      "epoch 188: (0.5299125, 0.5711397823889649, 0.24015)\n",
      "epoch 189: (0.5469625, 0.5321072692156494, 0.7783)\n",
      "epoch 190: (0.5298875, 0.5710634250728169, 0.240175)\n",
      "epoch 191: (0.5469625, 0.5321061717000803, 0.778325)\n",
      "epoch 192: (0.5298875, 0.5710634250728169, 0.240175)\n",
      "epoch 193: (0.5469625, 0.5321061717000803, 0.778325)\n",
      "epoch 194: (0.529925, 0.571139902531796, 0.24025)\n",
      "epoch 195: (0.5469625, 0.5321061717000803, 0.778325)\n",
      "epoch 196: (0.52995, 0.5711908723555978, 0.2403)\n",
      "epoch 197: (0.5469875, 0.5321210671132911, 0.7784)\n",
      "epoch 198: (0.52995, 0.5711908723555978, 0.2403)\n",
      "epoch 199: (0.5469875, 0.5321210671132911, 0.7784)\n",
      "epoch 0: (0.5077375, 0.5128417907970624, 0.309)\n",
      "epoch 1: (0.5064875, 0.5073043037689644, 0.450575)\n",
      "epoch 2: (0.51235, 0.5105636814643743, 0.5969)\n",
      "epoch 3: (0.519325, 0.5203774977592661, 0.4935)\n",
      "epoch 4: (0.5152, 0.508312597413251, 0.929475)\n",
      "epoch 5: (0.5116875, 0.5653754719619634, 0.101075)\n",
      "epoch 6: (0.5150375, 0.5083150167959192, 0.919275)\n",
      "epoch 7: (0.5075625, 0.5891541408782788, 0.049975)\n",
      "epoch 8: (0.5158375, 0.5087680447329449, 0.918975)\n",
      "epoch 9: (0.5068125, 0.590803065644785, 0.044325)\n",
      "epoch 10: (0.521275, 0.5118352247441033, 0.920075)\n",
      "epoch 11: (0.5095375, 0.6017062116768862, 0.056425)\n",
      "epoch 12: (0.527975, 0.5157127611772635, 0.918175)\n",
      "epoch 13: (0.517125, 0.5776116020847496, 0.12745)\n",
      "epoch 14: (0.532675, 0.5189453238244333, 0.895025)\n",
      "epoch 15: (0.5172, 0.587420584498094, 0.115575)\n",
      "epoch 16: (0.5360625, 0.5213858949459608, 0.8792)\n",
      "epoch 17: (0.520575, 0.5740507468058305, 0.1595)\n",
      "epoch 18: (0.53575, 0.5211801647017004, 0.8797)\n",
      "epoch 19: (0.5215625, 0.5694276744747645, 0.17685)\n",
      "epoch 20: (0.537175, 0.5223999758978067, 0.866975)\n",
      "epoch 21: (0.5216, 0.571345995045417, 0.172975)\n",
      "epoch 22: (0.5386625, 0.523644981270545, 0.856225)\n",
      "epoch 23: (0.5248875, 0.5657573155426382, 0.214125)\n",
      "epoch 24: (0.53945, 0.5243518518518518, 0.84945)\n",
      "epoch 25: (0.5242, 0.5660570492698239, 0.207375)\n",
      "epoch 26: (0.5400875, 0.5250331746155648, 0.840775)\n",
      "epoch 27: (0.5252375, 0.5655306718597858, 0.2178)\n",
      "epoch 28: (0.540025, 0.5251626693490082, 0.83535)\n",
      "epoch 29: (0.5249, 0.5643910007757952, 0.21825)\n",
      "epoch 30: (0.54075, 0.5257479543803115, 0.832075)\n",
      "epoch 31: (0.52525, 0.5669140055651252, 0.213925)\n",
      "epoch 32: (0.5409125, 0.5260850853563288, 0.825125)\n",
      "epoch 33: (0.5267, 0.5649003403014098, 0.2324)\n",
      "epoch 34: (0.5414875, 0.5265600742625758, 0.8225)\n",
      "epoch 35: (0.5274125, 0.563517349244048, 0.2432)\n",
      "epoch 36: (0.5415625, 0.5265936175317923, 0.823)\n",
      "epoch 37: (0.5271, 0.5638473318412063, 0.239325)\n",
      "epoch 38: (0.5421125, 0.5271417752928476, 0.8179)\n",
      "epoch 39: (0.5305, 0.5622385470870319, 0.275525)\n",
      "epoch 40: (0.5422125, 0.5269036503561129, 0.826725)\n",
      "epoch 41: (0.5311125, 0.5631053192028802, 0.277625)\n",
      "epoch 42: (0.542475, 0.5271883501360217, 0.8236)\n",
      "epoch 43: (0.531525, 0.5632080200501253, 0.2809)\n",
      "epoch 44: (0.542475, 0.5273714396185075, 0.818375)\n",
      "epoch 45: (0.5303875, 0.5636287494110873, 0.269175)\n",
      "epoch 46: (0.542375, 0.5274841094824232, 0.813275)\n",
      "epoch 47: (0.5307, 0.5637326136599543, 0.27155)\n",
      "epoch 48: (0.54255, 0.5277063324108742, 0.810425)\n",
      "epoch 49: (0.5315375, 0.5640452860841753, 0.27775)\n",
      "epoch 50: (0.5427375, 0.5278397524631545, 0.8103)\n",
      "epoch 51: (0.53125, 0.5650364203954215, 0.2715)\n",
      "epoch 52: (0.543125, 0.5282203972123155, 0.8072)\n",
      "epoch 53: (0.5309875, 0.565523074483269, 0.26745)\n",
      "epoch 54: (0.5435875, 0.5286651431202012, 0.803875)\n",
      "epoch 55: (0.5315, 0.5648815653964985, 0.27425)\n",
      "epoch 56: (0.543775, 0.528933540434251, 0.80025)\n",
      "epoch 57: (0.5311375, 0.5657776604172168, 0.267825)\n",
      "epoch 58: (0.543875, 0.5289260284810127, 0.802275)\n",
      "epoch 59: (0.5327, 0.5639796517315594, 0.28825)\n",
      "epoch 60: (0.5436375, 0.5284956330095503, 0.809325)\n",
      "epoch 61: (0.5323125, 0.5637799161115223, 0.285625)\n",
      "epoch 62: (0.54375, 0.528625642032257, 0.807925)\n",
      "epoch 63: (0.531975, 0.5634110064452157, 0.2841)\n",
      "epoch 64: (0.5437, 0.5286294549266247, 0.8069)\n",
      "epoch 65: (0.5322125, 0.5642611341080246, 0.28285)\n",
      "epoch 66: (0.543925, 0.5288837744533947, 0.8043)\n",
      "epoch 67: (0.5323625, 0.5637590503866423, 0.28615)\n",
      "epoch 68: (0.5438, 0.5287580841075473, 0.805325)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 69: (0.5329125, 0.564060143058732, 0.2898)\n",
      "epoch 70: (0.543825, 0.5287896206273608, 0.80495)\n",
      "epoch 71: (0.5329, 0.5638896980289348, 0.290375)\n",
      "epoch 72: (0.5439375, 0.5288810740637273, 0.8046)\n",
      "epoch 73: (0.5328875, 0.5638251419145117, 0.290525)\n",
      "epoch 74: (0.54415, 0.5290871957044504, 0.803075)\n",
      "epoch 75: (0.53255, 0.5637048634895783, 0.288025)\n",
      "epoch 76: (0.54425, 0.5291463575286524, 0.80335)\n",
      "epoch 77: (0.53255, 0.5635059994146913, 0.288825)\n",
      "epoch 78: (0.5443875, 0.5292239321866513, 0.803825)\n",
      "epoch 79: (0.532875, 0.5638101708074534, 0.290475)\n",
      "epoch 80: (0.54455, 0.5293923599656924, 0.8024)\n",
      "epoch 81: (0.532475, 0.563372036296224, 0.2887)\n",
      "epoch 82: (0.5446625, 0.5295587286354837, 0.80015)\n",
      "epoch 83: (0.532275, 0.562871335346255, 0.28895)\n",
      "epoch 84: (0.5447625, 0.5296288328837848, 0.80015)\n",
      "epoch 85: (0.5324625, 0.5615140461414563, 0.296325)\n",
      "epoch 86: (0.5447625, 0.5297173490896416, 0.7979)\n",
      "epoch 87: (0.533425, 0.562116706931797, 0.302475)\n",
      "epoch 88: (0.5443875, 0.5292865979381444, 0.8022)\n",
      "epoch 89: (0.5333625, 0.5620380270559249, 0.30225)\n",
      "epoch 90: (0.544425, 0.5293273039345128, 0.801825)\n",
      "epoch 91: (0.5333875, 0.5619635317589199, 0.3028)\n",
      "epoch 92: (0.544675, 0.5294903954056374, 0.802125)\n",
      "epoch 93: (0.5335875, 0.5621789234970148, 0.303675)\n",
      "epoch 94: (0.5444125, 0.5293205037217977, 0.801775)\n",
      "epoch 95: (0.5338375, 0.5622671021760133, 0.30555)\n",
      "epoch 96: (0.5444125, 0.5292750852792381, 0.80295)\n",
      "epoch 97: (0.533925, 0.5627253397429971, 0.30435)\n",
      "epoch 98: (0.544525, 0.5293904089243869, 0.802)\n",
      "epoch 99: (0.5339125, 0.5624740938608207, 0.305325)\n",
      "epoch 100: (0.5447, 0.5295254136530269, 0.801675)\n",
      "epoch 101: (0.53385, 0.562540415704388, 0.304475)\n",
      "epoch 102: (0.5448625, 0.529664589291323, 0.801025)\n",
      "epoch 103: (0.5343875, 0.5627194382381104, 0.308525)\n",
      "epoch 104: (0.544675, 0.5294660818520595, 0.80275)\n",
      "epoch 105: (0.5347375, 0.5626719588651843, 0.311875)\n",
      "epoch 106: (0.544725, 0.5295204778720174, 0.80225)\n",
      "epoch 107: (0.5341625, 0.562703620428578, 0.306575)\n",
      "epoch 108: (0.54475, 0.5295594160776802, 0.8017)\n",
      "epoch 109: (0.53425, 0.5627806800476584, 0.307025)\n",
      "epoch 110: (0.5448875, 0.5296654275092937, 0.80145)\n",
      "epoch 111: (0.5340375, 0.5624799229039512, 0.306425)\n",
      "epoch 112: (0.5450125, 0.5297382112478322, 0.801825)\n",
      "epoch 113: (0.5341625, 0.5626978664831384, 0.3066)\n",
      "epoch 114: (0.5449, 0.5297144369809074, 0.800425)\n",
      "epoch 115: (0.5346125, 0.5623339786592229, 0.31225)\n",
      "epoch 116: (0.54495, 0.5296328037444789, 0.8034)\n",
      "epoch 117: (0.53455, 0.5621458764277363, 0.312525)\n",
      "epoch 118: (0.545, 0.5296775044516256, 0.80315)\n",
      "epoch 119: (0.5346625, 0.5622111544846772, 0.31325)\n",
      "epoch 120: (0.545125, 0.5297668128896071, 0.8031)\n",
      "epoch 121: (0.5347, 0.5623652048885693, 0.3129)\n",
      "epoch 122: (0.5451375, 0.5297696581971673, 0.80325)\n",
      "epoch 123: (0.5344875, 0.5622153069047942, 0.31165)\n",
      "epoch 124: (0.54505, 0.5297379364974586, 0.8025)\n",
      "epoch 125: (0.534325, 0.5621660780584986, 0.3104)\n",
      "epoch 126: (0.5451375, 0.5298513631929633, 0.801175)\n",
      "epoch 127: (0.533975, 0.5619190814652816, 0.308325)\n",
      "epoch 128: (0.5451625, 0.5298817302125548, 0.80085)\n",
      "epoch 129: (0.5339125, 0.5618925947894329, 0.307875)\n",
      "epoch 130: (0.5451125, 0.5298516104484773, 0.800725)\n",
      "epoch 131: (0.5340375, 0.5620301608273726, 0.3084)\n",
      "epoch 132: (0.5454, 0.5301100941769465, 0.7993)\n",
      "epoch 133: (0.5337125, 0.5617586443782917, 0.30665)\n",
      "epoch 134: (0.5453, 0.5300497512437811, 0.79905)\n",
      "epoch 135: (0.5337375, 0.5618327605956472, 0.30655)\n",
      "epoch 136: (0.545275, 0.5300281876968993, 0.79915)\n",
      "epoch 137: (0.5338875, 0.5620110709547554, 0.307125)\n",
      "epoch 138: (0.54525, 0.5300175793558659, 0.798975)\n",
      "epoch 139: (0.5338, 0.5617915904936015, 0.3073)\n",
      "epoch 140: (0.5454, 0.5301430800385087, 0.798475)\n",
      "epoch 141: (0.53365, 0.5614948830409356, 0.30725)\n",
      "epoch 142: (0.5452375, 0.5300127713920817, 0.798875)\n",
      "epoch 143: (0.533675, 0.5615237051246917, 0.30735)\n",
      "epoch 144: (0.54525, 0.5300355115993495, 0.798525)\n",
      "epoch 145: (0.53385, 0.5616351056081573, 0.30845)\n",
      "epoch 146: (0.5451125, 0.5299646302784743, 0.797875)\n",
      "epoch 147: (0.5336625, 0.5613188214399563, 0.30815)\n",
      "epoch 148: (0.5454125, 0.5301889614598394, 0.79755)\n",
      "epoch 149: (0.5337125, 0.561449077238551, 0.308025)\n",
      "epoch 150: (0.54565, 0.5304140710883107, 0.796125)\n",
      "epoch 151: (0.533325, 0.5610571637962624, 0.306225)\n",
      "epoch 152: (0.5455875, 0.5303972394939073, 0.79545)\n",
      "epoch 153: (0.5333625, 0.5611847233047544, 0.306)\n",
      "epoch 154: (0.5457, 0.5304880082724573, 0.795175)\n",
      "epoch 155: (0.5335125, 0.5614091346374089, 0.306375)\n",
      "epoch 156: (0.545775, 0.5305584298541339, 0.79475)\n",
      "epoch 157: (0.533425, 0.5613809567532825, 0.3057)\n",
      "epoch 158: (0.5458, 0.5306026994520914, 0.7941)\n",
      "epoch 159: (0.5341625, 0.5618689726988726, 0.31025)\n",
      "epoch 160: (0.5457375, 0.5305125168865391, 0.795225)\n",
      "epoch 161: (0.5342, 0.5619509102436373, 0.310225)\n",
      "epoch 162: (0.5459, 0.5306736166800321, 0.7941)\n",
      "epoch 163: (0.534, 0.5617732558139535, 0.3092)\n",
      "epoch 164: (0.54595, 0.5307470975944327, 0.793175)\n",
      "epoch 165: (0.5341125, 0.5620650443484194, 0.308925)\n",
      "epoch 166: (0.545975, 0.530771032728733, 0.793025)\n",
      "epoch 167: (0.5339625, 0.5618483951741406, 0.308525)\n",
      "epoch 168: (0.54595, 0.530769745873372, 0.792625)\n",
      "epoch 169: (0.5339, 0.56175988340317, 0.30835)\n",
      "epoch 170: (0.546075, 0.5308875779312194, 0.791925)\n",
      "epoch 171: (0.5338375, 0.5617557147419812, 0.3078)\n",
      "epoch 172: (0.5461, 0.5309209202495138, 0.79155)\n",
      "epoch 173: (0.53365, 0.5615849194729137, 0.30685)\n",
      "epoch 174: (0.5463, 0.5311030498454924, 0.7906)\n",
      "epoch 175: (0.5334625, 0.5614188042031845, 0.305875)\n",
      "epoch 176: (0.5464125, 0.5311885762284755, 0.790475)\n",
      "epoch 177: (0.533375, 0.5612385321100918, 0.305875)\n",
      "epoch 178: (0.5465375, 0.5313093936590699, 0.789725)\n",
      "epoch 179: (0.5337625, 0.5612777349244521, 0.30925)\n",
      "epoch 180: (0.54625, 0.5310642442153339, 0.790675)\n",
      "epoch 181: (0.53395, 0.561303719754424, 0.31085)\n",
      "epoch 182: (0.5463, 0.5310863434940244, 0.791)\n",
      "epoch 183: (0.5338625, 0.5612037413582758, 0.3105)\n",
      "epoch 184: (0.5463, 0.5311061842856662, 0.790525)\n",
      "epoch 185: (0.533725, 0.5610407239819004, 0.309975)\n",
      "epoch 186: (0.54645, 0.5312384411042739, 0.789925)\n",
      "epoch 187: (0.5337, 0.5612115157569703, 0.308975)\n",
      "epoch 188: (0.5463875, 0.5312105767775143, 0.789525)\n",
      "epoch 189: (0.5336125, 0.5611330878006638, 0.308525)\n",
      "epoch 190: (0.546475, 0.5313363899939316, 0.788025)\n",
      "epoch 191: (0.534525, 0.5617289468979081, 0.314175)\n",
      "epoch 192: (0.5464, 0.5311754627607753, 0.790575)\n",
      "epoch 193: (0.5344375, 0.561575253676635, 0.314075)\n",
      "epoch 194: (0.54645, 0.5311964807414621, 0.790925)\n",
      "epoch 195: (0.534325, 0.5614482635159327, 0.313625)\n",
      "epoch 196: (0.54655, 0.5313099041533547, 0.789925)\n",
      "epoch 197: (0.534175, 0.5612510081548526, 0.31315)\n",
      "epoch 198: (0.546475, 0.5312573561556311, 0.7899)\n",
      "epoch 199: (0.53415, 0.5612062012725154, 0.313125)\n",
      "epoch 0: (0.4997625, 0.047619047619047616, 2.5e-05)\n",
      "epoch 1: (0.504875, 0.5025360905189231, 0.966)\n",
      "epoch 2: (0.5, 0.5, 0.0004)\n",
      "epoch 3: (0.5095625, 0.5049581956056777, 0.973875)\n",
      "epoch 4: (0.5035, 0.6391650099403579, 0.016075)\n",
      "epoch 5: (0.5133625, 0.5070246684803322, 0.964475)\n",
      "epoch 6: (0.50405, 0.6148936170212767, 0.021675)\n",
      "epoch 7: (0.51545, 0.5082351687010287, 0.9535)\n",
      "epoch 8: (0.5074, 0.6226180613090306, 0.037575)\n",
      "epoch 9: (0.518125, 0.5098251795636265, 0.9405)\n",
      "epoch 10: (0.510125, 0.6097560975609756, 0.05625)\n",
      "epoch 11: (0.5219625, 0.5121593378455065, 0.925075)\n",
      "epoch 12: (0.5117125, 0.6091820088557446, 0.06535)\n",
      "epoch 13: (0.528375, 0.5161207851603556, 0.90845)\n",
      "epoch 14: (0.5135625, 0.6047499517281328, 0.0783)\n",
      "epoch 15: (0.5323875, 0.5190070276852653, 0.884375)\n",
      "epoch 16: (0.515175, 0.6054918317692041, 0.0871)\n",
      "epoch 17: (0.5361375, 0.5216408413803428, 0.871075)\n",
      "epoch 18: (0.5159375, 0.5999059708509638, 0.0957)\n",
      "epoch 19: (0.5393875, 0.5241859965306028, 0.85365)\n",
      "epoch 20: (0.515625, 0.606473594548552, 0.089)\n",
      "epoch 21: (0.5408, 0.52530075654223, 0.8471)\n",
      "epoch 22: (0.5169, 0.6065237945162307, 0.096225)\n",
      "epoch 23: (0.542, 0.5262016906328956, 0.843475)\n",
      "epoch 24: (0.5169, 0.6054602184087363, 0.097025)\n",
      "epoch 25: (0.543025, 0.5269909977729682, 0.84005)\n",
      "epoch 26: (0.51695, 0.604179471419791, 0.0983)\n",
      "epoch 27: (0.5436125, 0.5275622896686838, 0.834775)\n",
      "epoch 28: (0.5171, 0.6043637473298749, 0.099025)\n",
      "epoch 29: (0.543925, 0.5278614696647743, 0.8322)\n",
      "epoch 30: (0.5174, 0.6026245945148924, 0.102175)\n",
      "epoch 31: (0.5440625, 0.5279837416445707, 0.83135)\n",
      "epoch 32: (0.517875, 0.6030259365994236, 0.104625)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33: (0.5443125, 0.528334159246767, 0.826275)\n",
      "epoch 34: (0.518225, 0.6021008403361344, 0.107475)\n",
      "epoch 35: (0.5442, 0.5283842794759825, 0.8228)\n",
      "epoch 36: (0.5187125, 0.6012170385395538, 0.11115)\n",
      "epoch 37: (0.5441875, 0.5282985638578908, 0.824925)\n",
      "epoch 38: (0.5189, 0.599290780141844, 0.114075)\n",
      "epoch 39: (0.544275, 0.528411460839991, 0.82345)\n",
      "epoch 40: (0.5188625, 0.5975184179914695, 0.115575)\n",
      "epoch 41: (0.5442875, 0.5283762354034183, 0.82465)\n",
      "epoch 42: (0.5191625, 0.5975563192058038, 0.117375)\n",
      "epoch 43: (0.5442125, 0.5283172946055433, 0.824875)\n",
      "epoch 44: (0.5194875, 0.5971581702605011, 0.119775)\n",
      "epoch 45: (0.5441625, 0.5282952379426887, 0.82455)\n",
      "epoch 46: (0.519675, 0.5974251052240653, 0.12065)\n",
      "epoch 47: (0.544275, 0.5283795910518556, 0.824325)\n",
      "epoch 48: (0.51975, 0.597844934357196, 0.120675)\n",
      "epoch 49: (0.5445, 0.5285402770651616, 0.8241)\n",
      "epoch 50: (0.519525, 0.5963008631319359, 0.1209)\n",
      "epoch 51: (0.5443875, 0.5284941663590699, 0.823275)\n",
      "epoch 52: (0.5195875, 0.596264897407544, 0.121325)\n",
      "epoch 53: (0.5445375, 0.5286170947584855, 0.8227)\n",
      "epoch 54: (0.5196375, 0.5961797477653973, 0.121725)\n",
      "epoch 55: (0.5447125, 0.5287480108658962, 0.822375)\n",
      "epoch 56: (0.5196875, 0.5947311439913389, 0.1236)\n",
      "epoch 57: (0.5446625, 0.528716786420408, 0.8223)\n",
      "epoch 58: (0.51995, 0.596028880866426, 0.123825)\n",
      "epoch 59: (0.5447, 0.5287515276259085, 0.82205)\n",
      "epoch 60: (0.5199875, 0.5957829160177309, 0.124325)\n",
      "epoch 61: (0.5445875, 0.5286934697620541, 0.82155)\n",
      "epoch 62: (0.519925, 0.5958624007697859, 0.12385)\n",
      "epoch 63: (0.5447125, 0.5287915130636359, 0.8212)\n",
      "epoch 64: (0.5199625, 0.5964022697090426, 0.1235)\n",
      "epoch 65: (0.5447, 0.5287802208415157, 0.821275)\n",
      "epoch 66: (0.5201875, 0.5966487133453022, 0.124625)\n",
      "epoch 67: (0.5444875, 0.5286281954342895, 0.821475)\n",
      "epoch 68: (0.520025, 0.5960662029263613, 0.12425)\n",
      "epoch 69: (0.544675, 0.528769681553273, 0.8211)\n",
      "epoch 70: (0.519875, 0.5954840259428297, 0.12395)\n",
      "epoch 71: (0.544825, 0.5288932577027201, 0.820525)\n",
      "epoch 72: (0.5198375, 0.5955218490429758, 0.123675)\n",
      "epoch 73: (0.54475, 0.5288328339937503, 0.820775)\n",
      "epoch 74: (0.5198125, 0.5957703927492447, 0.12325)\n",
      "epoch 75: (0.544675, 0.5288086409801709, 0.82005)\n",
      "epoch 76: (0.5199, 0.5955123590112791, 0.124075)\n",
      "epoch 77: (0.5446375, 0.5287700810492902, 0.8204)\n",
      "epoch 78: (0.5198375, 0.5952924222409031, 0.123925)\n",
      "epoch 79: (0.544725, 0.5288408834434951, 0.8201)\n",
      "epoch 80: (0.5198125, 0.5953096812988575, 0.12375)\n",
      "epoch 81: (0.5448375, 0.528926952791084, 0.81985)\n",
      "epoch 82: (0.5198, 0.5953757225433526, 0.1236)\n",
      "epoch 83: (0.5449375, 0.5290167401165512, 0.819275)\n",
      "epoch 84: (0.5198, 0.5955829109341058, 0.123375)\n",
      "epoch 85: (0.5449, 0.5290023576526822, 0.818975)\n",
      "epoch 86: (0.5198125, 0.5958167089831943, 0.1232)\n",
      "epoch 87: (0.5448875, 0.5290059934411399, 0.81865)\n",
      "epoch 88: (0.5197, 0.5955151515151516, 0.122825)\n",
      "epoch 89: (0.544925, 0.5290438324282389, 0.818325)\n",
      "epoch 90: (0.5196625, 0.5953680126106463, 0.12275)\n",
      "epoch 91: (0.5449625, 0.5290788856731717, 0.818075)\n",
      "epoch 92: (0.5196375, 0.5951544518473653, 0.122825)\n",
      "epoch 93: (0.545075, 0.5291643751415354, 0.81785)\n",
      "epoch 94: (0.5196125, 0.5945294613808892, 0.12335)\n",
      "epoch 95: (0.5449875, 0.529111057186767, 0.817675)\n",
      "epoch 96: (0.5196625, 0.5949993960623263, 0.12315)\n",
      "epoch 97: (0.5449, 0.5290643104508528, 0.817325)\n",
      "epoch 98: (0.519675, 0.5951862602806, 0.123025)\n",
      "epoch 99: (0.5449125, 0.5290625252770363, 0.8176)\n",
      "epoch 100: (0.5196875, 0.5952582557154953, 0.123025)\n",
      "epoch 101: (0.544975, 0.5291138011393061, 0.817375)\n",
      "epoch 102: (0.519725, 0.5954743465634076, 0.123025)\n",
      "epoch 103: (0.5450375, 0.5291594503164403, 0.8173)\n",
      "epoch 104: (0.5196875, 0.5953736223810101, 0.1229)\n",
      "epoch 105: (0.5449875, 0.5291450042919845, 0.816775)\n",
      "epoch 106: (0.5196125, 0.5950563431479462, 0.122775)\n",
      "epoch 107: (0.544975, 0.5291392659302212, 0.8167)\n",
      "epoch 108: (0.5196, 0.5950764006791172, 0.122675)\n",
      "epoch 109: (0.5450125, 0.5291640345335861, 0.816725)\n",
      "epoch 110: (0.519625, 0.5951515151515151, 0.12275)\n",
      "epoch 111: (0.5450125, 0.5291734854254095, 0.816475)\n",
      "epoch 112: (0.5196625, 0.595460614152203, 0.12265)\n",
      "epoch 113: (0.5450375, 0.5291896884164817, 0.8165)\n",
      "epoch 114: (0.5196875, 0.5955356059687007, 0.122725)\n",
      "epoch 115: (0.5450375, 0.5291877966980444, 0.81655)\n",
      "epoch 116: (0.5196875, 0.5954661171051037, 0.1228)\n",
      "epoch 117: (0.545, 0.5291743654575513, 0.816225)\n",
      "epoch 118: (0.519625, 0.5953132588635259, 0.122575)\n",
      "epoch 119: (0.545025, 0.5291886810800298, 0.8163)\n",
      "epoch 120: (0.5196625, 0.5954374469117826, 0.122675)\n",
      "epoch 121: (0.545, 0.529165856503986, 0.81645)\n",
      "epoch 122: (0.5196875, 0.5955356059687007, 0.122725)\n",
      "epoch 123: (0.5449875, 0.5291572824343374, 0.81645)\n",
      "epoch 124: (0.5197, 0.5955846676370694, 0.12275)\n",
      "epoch 125: (0.545025, 0.5291896272285251, 0.816275)\n",
      "epoch 126: (0.519625, 0.5953595724003887, 0.122525)\n",
      "epoch 127: (0.545075, 0.5292210949401964, 0.81635)\n",
      "epoch 128: (0.5196375, 0.5953855494839101, 0.122575)\n",
      "epoch 129: (0.5450375, 0.5291944187855511, 0.816375)\n",
      "epoch 130: (0.5196875, 0.5955587914088096, 0.1227)\n",
      "epoch 131: (0.545025, 0.5291867889670372, 0.81635)\n",
      "epoch 132: (0.5196875, 0.5955356059687007, 0.122725)\n",
      "epoch 133: (0.5450375, 0.5291953650433514, 0.81635)\n",
      "epoch 134: (0.5196875, 0.5955356059687007, 0.122725)\n",
      "epoch 135: (0.545025, 0.5291877349928692, 0.816325)\n",
      "epoch 136: (0.519675, 0.5954633672974284, 0.122725)\n",
      "epoch 137: (0.5450125, 0.5291801046950716, 0.8163)\n",
      "epoch 138: (0.5196625, 0.5953911461491813, 0.122725)\n",
      "epoch 139: (0.5449875, 0.529164843357482, 0.81625)\n",
      "epoch 140: (0.5196625, 0.5953911461491813, 0.122725)\n",
      "epoch 141: (0.545, 0.5291743654575513, 0.816225)\n",
      "epoch 142: (0.5196625, 0.5953911461491813, 0.122725)\n",
      "epoch 143: (0.5450125, 0.5291819964667175, 0.81625)\n",
      "epoch 144: (0.519625, 0.5953827460510328, 0.1225)\n",
      "epoch 145: (0.5450375, 0.5291982041848328, 0.816275)\n",
      "epoch 146: (0.5196125, 0.5952872585934653, 0.122525)\n",
      "epoch 147: (0.54505, 0.5292181470311639, 0.815975)\n",
      "epoch 148: (0.5195875, 0.5950734134207014, 0.1226)\n",
      "epoch 149: (0.54505, 0.5292181470311639, 0.815975)\n",
      "epoch 150: (0.519625, 0.5951976715983507, 0.1227)\n",
      "epoch 151: (0.5450625, 0.5292257802999595, 0.816)\n",
      "epoch 152: (0.5196625, 0.5953448902897321, 0.122775)\n",
      "epoch 153: (0.54505, 0.5292190945647944, 0.81595)\n",
      "epoch 154: (0.5197125, 0.5955873439204752, 0.122825)\n",
      "epoch 155: (0.5450375, 0.5292105135148282, 0.81595)\n",
      "epoch 156: (0.519725, 0.5956131846825012, 0.122875)\n",
      "epoch 157: (0.5450625, 0.5292276758930453, 0.81595)\n",
      "epoch 158: (0.51975, 0.5957111703416526, 0.122925)\n",
      "epoch 159: (0.54505, 0.5292190945647944, 0.81595)\n",
      "epoch 160: (0.5197625, 0.5957601453664446, 0.12295)\n",
      "epoch 161: (0.54505, 0.5292190945647944, 0.81595)\n",
      "epoch 162: (0.5197625, 0.5957369504662711, 0.122975)\n",
      "epoch 163: (0.5450625, 0.5292267280657662, 0.815975)\n",
      "epoch 164: (0.5196875, 0.5955819881053526, 0.122675)\n",
      "epoch 165: (0.5450625, 0.5292267280657662, 0.815975)\n",
      "epoch 166: (0.5196625, 0.5954374469117826, 0.122675)\n",
      "epoch 167: (0.5450625, 0.5292267280657662, 0.815975)\n",
      "epoch 168: (0.5196625, 0.5954374469117826, 0.122675)\n",
      "epoch 169: (0.54505, 0.5292190945647944, 0.81595)\n",
      "epoch 170: (0.5196375, 0.5952698605215282, 0.1227)\n",
      "epoch 171: (0.5450375, 0.5292114608162669, 0.815925)\n",
      "epoch 172: (0.5196375, 0.5952698605215282, 0.1227)\n",
      "epoch 173: (0.54505, 0.5292190945647944, 0.81595)\n",
      "epoch 174: (0.5196875, 0.5954661171051037, 0.1228)\n",
      "epoch 175: (0.5450625, 0.5292267280657662, 0.815975)\n",
      "epoch 176: (0.5196875, 0.5954661171051037, 0.1228)\n",
      "epoch 177: (0.545075, 0.5292343613191944, 0.816)\n",
      "epoch 178: (0.519725, 0.5955900169614732, 0.1229)\n",
      "epoch 179: (0.5450625, 0.5292257802999595, 0.816)\n",
      "epoch 180: (0.5197375, 0.5956390066626287, 0.122925)\n",
      "epoch 181: (0.5450625, 0.5292257802999595, 0.816)\n",
      "epoch 182: (0.5197625, 0.5957137667998547, 0.123)\n",
      "epoch 183: (0.5450875, 0.5292457878606062, 0.815925)\n",
      "epoch 184: (0.5197375, 0.5955464117148735, 0.123025)\n",
      "epoch 185: (0.5450625, 0.5292295717320447, 0.8159)\n",
      "epoch 186: (0.519725, 0.5954743465634076, 0.123025)\n",
      "epoch 187: (0.54505, 0.5292219375344598, 0.815875)\n",
      "epoch 188: (0.519725, 0.5954512460682313, 0.12305)\n",
      "epoch 189: (0.54505, 0.5292219375344598, 0.815875)\n",
      "epoch 190: (0.5196125, 0.5950793843170524, 0.12275)\n",
      "epoch 191: (0.5450625, 0.5292295717320447, 0.8159)\n",
      "epoch 192: (0.5196375, 0.5951544518473653, 0.122825)\n",
      "epoch 193: (0.54505, 0.5292171995589857, 0.816)\n",
      "epoch 194: (0.51965, 0.595203488372093, 0.12285)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 195: (0.54505, 0.5292171995589857, 0.816)\n",
      "epoch 196: (0.5196625, 0.595229446664245, 0.1229)\n",
      "epoch 197: (0.54505, 0.5292171995589857, 0.816)\n",
      "epoch 198: (0.5197, 0.5953764221738078, 0.122975)\n",
      "epoch 199: (0.54505, 0.5292181470311639, 0.815975)\n",
      "epoch 0: (0.5107125, 0.5204290822407628, 0.2729)\n",
      "epoch 1: (0.5001, 0.5000500125031258, 0.99985)\n",
      "epoch 2: (0.513, 0.534805890227577, 0.19975)\n",
      "epoch 3: (0.5005625, 0.5002814505335051, 0.99985)\n",
      "epoch 4: (0.5131125, 0.5447563785305913, 0.1596)\n",
      "epoch 5: (0.5034875, 0.501751478398433, 0.999075)\n",
      "epoch 6: (0.5150625, 0.5653399848172649, 0.130325)\n",
      "epoch 7: (0.5082375, 0.5041784495986406, 0.99395)\n",
      "epoch 8: (0.5144375, 0.5797321551843159, 0.104975)\n",
      "epoch 9: (0.511125, 0.5057041043915195, 0.9863)\n",
      "epoch 10: (0.5125, 0.5899280575539568, 0.082)\n",
      "epoch 11: (0.512425, 0.5064107525217346, 0.9815)\n",
      "epoch 12: (0.5117375, 0.5967841682127396, 0.072375)\n",
      "epoch 13: (0.5149375, 0.5077851177214036, 0.9743)\n",
      "epoch 14: (0.5106875, 0.6024442846872753, 0.06285)\n",
      "epoch 15: (0.51945, 0.5102527608655544, 0.967975)\n",
      "epoch 16: (0.5102125, 0.6109150149334781, 0.05625)\n",
      "epoch 17: (0.5239875, 0.5128873248895276, 0.95465)\n",
      "epoch 18: (0.50985, 0.6204892966360857, 0.050725)\n",
      "epoch 19: (0.5270625, 0.5147654576950882, 0.943475)\n",
      "epoch 20: (0.50965, 0.6294433266264252, 0.046925)\n",
      "epoch 21: (0.5294375, 0.5162698796512512, 0.9341)\n",
      "epoch 22: (0.5096375, 0.629145728643216, 0.04695)\n",
      "epoch 23: (0.5306625, 0.5170449018163625, 0.930125)\n",
      "epoch 24: (0.5100125, 0.6220664431575739, 0.051025)\n",
      "epoch 25: (0.5313625, 0.5175594529904959, 0.9244)\n",
      "epoch 26: (0.5101625, 0.6253469010175763, 0.0507)\n",
      "epoch 27: (0.5324125, 0.5182469424232615, 0.920575)\n",
      "epoch 28: (0.5103125, 0.6286248830682881, 0.0504)\n",
      "epoch 29: (0.5328625, 0.518608173723475, 0.915875)\n",
      "epoch 30: (0.510675, 0.6303418803418803, 0.051625)\n",
      "epoch 31: (0.5341375, 0.5194723707664884, 0.9107)\n",
      "epoch 32: (0.5105375, 0.6330072578100348, 0.05015)\n",
      "epoch 33: (0.53495, 0.5200499096463299, 0.906525)\n",
      "epoch 34: (0.5108625, 0.6339808818994758, 0.0514)\n",
      "epoch 35: (0.535375, 0.5203702637337326, 0.903675)\n",
      "epoch 36: (0.5113, 0.6357357357357357, 0.052925)\n",
      "epoch 37: (0.53585, 0.5206824934375631, 0.902525)\n",
      "epoch 38: (0.511575, 0.6387058118633913, 0.0533)\n",
      "epoch 39: (0.53665, 0.5212445294612063, 0.899225)\n",
      "epoch 40: (0.5118875, 0.6418133015210259, 0.0538)\n",
      "epoch 41: (0.537025, 0.5215211578702628, 0.897225)\n",
      "epoch 42: (0.5119, 0.6412462908011869, 0.054025)\n",
      "epoch 43: (0.537675, 0.5219813880218209, 0.89465)\n",
      "epoch 44: (0.5120875, 0.6405114792211566, 0.0551)\n",
      "epoch 45: (0.5376, 0.5219940920125179, 0.892375)\n",
      "epoch 46: (0.512075, 0.6410630841121495, 0.054875)\n",
      "epoch 47: (0.5382625, 0.5225235831702256, 0.88765)\n",
      "epoch 48: (0.5121625, 0.6402421447102912, 0.055525)\n",
      "epoch 49: (0.5387, 0.5228089821418047, 0.88705)\n",
      "epoch 50: (0.5125125, 0.6409462123345536, 0.0569)\n",
      "epoch 51: (0.538425, 0.5226355630172896, 0.8872)\n",
      "epoch 52: (0.5133375, 0.6402839863265842, 0.060875)\n",
      "epoch 53: (0.5388625, 0.5228875572372974, 0.88785)\n",
      "epoch 54: (0.5132875, 0.6400527009222662, 0.060725)\n",
      "epoch 55: (0.53905, 0.5230989914524858, 0.884325)\n",
      "epoch 56: (0.5137125, 0.6389663035216621, 0.06305)\n",
      "epoch 57: (0.5392125, 0.5232078123844048, 0.884025)\n",
      "epoch 58: (0.5137625, 0.6386999244142101, 0.063375)\n",
      "epoch 59: (0.539375, 0.5233901627658311, 0.881075)\n",
      "epoch 60: (0.5142625, 0.6369090472762179, 0.06635)\n",
      "epoch 61: (0.5396375, 0.5235136217354551, 0.8825)\n",
      "epoch 62: (0.514725, 0.6349060925332112, 0.0693)\n",
      "epoch 63: (0.5394, 0.5233260316144692, 0.88395)\n",
      "epoch 64: (0.514725, 0.6357142857142857, 0.068975)\n",
      "epoch 65: (0.5396875, 0.523568448713571, 0.88165)\n",
      "epoch 66: (0.51475, 0.6397441970630033, 0.067525)\n",
      "epoch 67: (0.539725, 0.5236585075337978, 0.879275)\n",
      "epoch 68: (0.51465, 0.6396568160152526, 0.0671)\n",
      "epoch 69: (0.5399875, 0.5238315180952665, 0.87895)\n",
      "epoch 70: (0.514825, 0.6399905571293674, 0.067775)\n",
      "epoch 71: (0.5400375, 0.5238598948168234, 0.87905)\n",
      "epoch 72: (0.514775, 0.6393867924528301, 0.067775)\n",
      "epoch 73: (0.540425, 0.5241848638947053, 0.876175)\n",
      "epoch 74: (0.5148375, 0.64060649135276, 0.0676)\n",
      "epoch 75: (0.5404625, 0.5242069367792884, 0.876225)\n",
      "epoch 76: (0.514875, 0.64, 0.068)\n",
      "epoch 77: (0.541, 0.5246142762802425, 0.87385)\n",
      "epoch 78: (0.5147875, 0.6404654476371409, 0.067425)\n",
      "epoch 79: (0.5410125, 0.5246243676918689, 0.873775)\n",
      "epoch 80: (0.5154875, 0.6340038935756003, 0.073275)\n",
      "epoch 81: (0.541025, 0.5246878290958327, 0.8719)\n",
      "epoch 82: (0.51565, 0.6375824175824176, 0.072525)\n",
      "epoch 83: (0.541375, 0.5249314573227682, 0.87115)\n",
      "epoch 84: (0.5155875, 0.637244111820383, 0.072375)\n",
      "epoch 85: (0.5415625, 0.5250727675811, 0.8704)\n",
      "epoch 86: (0.515625, 0.637544014084507, 0.072425)\n",
      "epoch 87: (0.541675, 0.5251698626000302, 0.86955)\n",
      "epoch 88: (0.5155375, 0.6367436743674367, 0.07235)\n",
      "epoch 89: (0.5415625, 0.5251356949547179, 0.868325)\n",
      "epoch 90: (0.515425, 0.6358432408630559, 0.0722)\n",
      "epoch 91: (0.5418375, 0.5253265130075518, 0.8678)\n",
      "epoch 92: (0.51545, 0.635943686757589, 0.072275)\n",
      "epoch 93: (0.5418125, 0.525345133279789, 0.866675)\n",
      "epoch 94: (0.515425, 0.6356043956043956, 0.0723)\n",
      "epoch 95: (0.5419, 0.5253731795197868, 0.867575)\n",
      "epoch 96: (0.515475, 0.635330126803673, 0.07265)\n",
      "epoch 97: (0.5419375, 0.5254047341400251, 0.867325)\n",
      "epoch 98: (0.5154875, 0.6355283307810107, 0.072625)\n",
      "epoch 99: (0.5419625, 0.525419878541897, 0.86735)\n",
      "epoch 100: (0.515425, 0.6358432408630559, 0.0722)\n",
      "epoch 101: (0.5419875, 0.5254473552629585, 0.866975)\n",
      "epoch 102: (0.515475, 0.6324914383561644, 0.073875)\n",
      "epoch 103: (0.542, 0.5254306560503769, 0.867775)\n",
      "epoch 104: (0.5154875, 0.6324567030147531, 0.07395)\n",
      "epoch 105: (0.542, 0.5254514604290389, 0.8671)\n",
      "epoch 106: (0.515475, 0.6325481798715203, 0.07385)\n",
      "epoch 107: (0.542075, 0.5255108227732977, 0.866725)\n",
      "epoch 108: (0.5153875, 0.6330235573805921, 0.073225)\n",
      "epoch 109: (0.5419625, 0.5254460834103968, 0.8665)\n",
      "epoch 110: (0.5154625, 0.6332686920922215, 0.073475)\n",
      "epoch 111: (0.5421, 0.5255538694992413, 0.86585)\n",
      "epoch 112: (0.5154, 0.6333333333333333, 0.07315)\n",
      "epoch 113: (0.5424125, 0.5257916901044438, 0.864625)\n",
      "epoch 114: (0.5154125, 0.6324382384532761, 0.0736)\n",
      "epoch 115: (0.5424625, 0.5258488182745134, 0.863825)\n",
      "epoch 116: (0.5153625, 0.6318952564928096, 0.0736)\n",
      "epoch 117: (0.5424875, 0.5258545935831318, 0.86415)\n",
      "epoch 118: (0.5153125, 0.6318622174381054, 0.073375)\n",
      "epoch 119: (0.5424, 0.5257938922009977, 0.8643)\n",
      "epoch 120: (0.5152625, 0.6310929783122181, 0.073475)\n",
      "epoch 121: (0.5423875, 0.5257819746666058, 0.864425)\n",
      "epoch 122: (0.5153625, 0.6315564119032328, 0.07375)\n",
      "epoch 123: (0.542375, 0.5257755474452555, 0.864375)\n",
      "epoch 124: (0.5155, 0.632083510864934, 0.074175)\n",
      "epoch 125: (0.542325, 0.5257318296501201, 0.86475)\n",
      "epoch 126: (0.5162375, 0.6307630360378498, 0.078325)\n",
      "epoch 127: (0.54225, 0.5256254738438211, 0.866625)\n",
      "epoch 128: (0.516325, 0.6307569082899479, 0.07875)\n",
      "epoch 129: (0.5421375, 0.5255661565064389, 0.866225)\n",
      "epoch 130: (0.516275, 0.6304609218436874, 0.07865)\n",
      "epoch 131: (0.542175, 0.525583864118896, 0.866425)\n",
      "epoch 132: (0.51625, 0.6301561874249099, 0.078675)\n",
      "epoch 133: (0.5421375, 0.5255700350440706, 0.8661)\n",
      "epoch 134: (0.516175, 0.6294, 0.078675)\n",
      "epoch 135: (0.5422, 0.5256067961165048, 0.8662)\n",
      "epoch 136: (0.5162375, 0.6302908726178535, 0.07855)\n",
      "epoch 137: (0.5423125, 0.5256965004175207, 0.865625)\n",
      "epoch 138: (0.516225, 0.6304784881383193, 0.0784)\n",
      "epoch 139: (0.5423125, 0.5256957201633595, 0.86565)\n",
      "epoch 140: (0.5162375, 0.6303431667670079, 0.078525)\n",
      "epoch 141: (0.5423375, 0.525707779886148, 0.865775)\n",
      "epoch 142: (0.5162125, 0.6292090057780434, 0.07895)\n",
      "epoch 143: (0.5423375, 0.525707779886148, 0.865775)\n",
      "epoch 144: (0.516075, 0.62829209896249, 0.078725)\n",
      "epoch 145: (0.542325, 0.5257169765463604, 0.865225)\n",
      "epoch 146: (0.516125, 0.6292585170340681, 0.0785)\n",
      "epoch 147: (0.542275, 0.5256741163609863, 0.865575)\n",
      "epoch 148: (0.5161625, 0.6294294294294295, 0.0786)\n",
      "epoch 149: (0.5423125, 0.5257004023992103, 0.8655)\n",
      "epoch 150: (0.516125, 0.63019781994348, 0.07805)\n",
      "epoch 151: (0.542425, 0.5258122414212704, 0.864225)\n",
      "epoch 152: (0.5159375, 0.6288139017983431, 0.0778)\n",
      "epoch 153: (0.5423875, 0.5258015917702737, 0.8638)\n",
      "epoch 154: (0.5159875, 0.6291658250858413, 0.077875)\n",
      "epoch 155: (0.542375, 0.5257983014215701, 0.86365)\n",
      "epoch 156: (0.515925, 0.6298410110069302, 0.07725)\n",
      "epoch 157: (0.5423875, 0.5258133763683145, 0.863425)\n",
      "epoch 158: (0.5149125, 0.6388177798464044, 0.068625)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 159: (0.54235, 0.5257830811847433, 0.863625)\n",
      "epoch 160: (0.5149375, 0.6389858106536404, 0.068675)\n",
      "epoch 161: (0.54245, 0.525851044394373, 0.8635)\n",
      "epoch 162: (0.5148, 0.6378667908709827, 0.068475)\n",
      "epoch 163: (0.542275, 0.5257609457359618, 0.8628)\n",
      "epoch 164: (0.51485, 0.6375636868920797, 0.068825)\n",
      "epoch 165: (0.542375, 0.5258140172398038, 0.86315)\n",
      "epoch 166: (0.51495, 0.6381062355658199, 0.069075)\n",
      "epoch 167: (0.5423875, 0.5258235983977336, 0.8631)\n",
      "epoch 168: (0.5149125, 0.6373474556758001, 0.0692)\n",
      "epoch 169: (0.5424375, 0.5258422518915463, 0.863525)\n",
      "epoch 170: (0.5148375, 0.6367826688177, 0.069075)\n",
      "epoch 171: (0.5425, 0.5258948971820259, 0.863125)\n",
      "epoch 172: (0.5148625, 0.6370763200368919, 0.069075)\n",
      "epoch 173: (0.5425875, 0.525920177720972, 0.8641)\n",
      "epoch 174: (0.515, 0.6377410468319559, 0.06945)\n",
      "epoch 175: (0.5425875, 0.5259312255491453, 0.86375)\n",
      "epoch 176: (0.5149625, 0.6374913852515507, 0.069375)\n",
      "epoch 177: (0.5426, 0.5259479214253083, 0.863475)\n",
      "epoch 178: (0.5160125, 0.628023186088347, 0.07855)\n",
      "epoch 179: (0.5426, 0.5259352835530121, 0.863875)\n",
      "epoch 180: (0.5160125, 0.627972027972028, 0.078575)\n",
      "epoch 181: (0.5427125, 0.5260176344282517, 0.86355)\n",
      "epoch 182: (0.51595, 0.6278044871794872, 0.07835)\n",
      "epoch 183: (0.5428125, 0.5260864929090439, 0.8634)\n",
      "epoch 184: (0.51585, 0.6271560369033293, 0.078175)\n",
      "epoch 185: (0.5427125, 0.5260231824897568, 0.863375)\n",
      "epoch 186: (0.515975, 0.6278, 0.078475)\n",
      "epoch 187: (0.54285, 0.5261121267519805, 0.86335)\n",
      "epoch 188: (0.5161375, 0.6278470984353337, 0.07925)\n",
      "epoch 189: (0.5426625, 0.5259808474034378, 0.8637)\n",
      "epoch 190: (0.5162125, 0.6282380858216334, 0.079425)\n",
      "epoch 191: (0.5427125, 0.5260144651693948, 0.86365)\n",
      "epoch 192: (0.516275, 0.6196691176470588, 0.084275)\n",
      "epoch 193: (0.542675, 0.5259880640643079, 0.863725)\n",
      "epoch 194: (0.5162875, 0.619783048354477, 0.084275)\n",
      "epoch 195: (0.5426875, 0.5259960720429944, 0.863725)\n",
      "epoch 196: (0.5164, 0.6191860465116279, 0.0852)\n",
      "epoch 197: (0.54255, 0.5259001126091852, 0.863975)\n",
      "epoch 198: (0.5164125, 0.6192552225249773, 0.085225)\n",
      "epoch 199: (0.54295, 0.5261874275958783, 0.863)\n",
      "epoch 0: (0.5, 0, 0.0)\n",
      "epoch 1: (0.5026625, 0.5013384946020335, 0.99725)\n",
      "epoch 2: (0.500025, 0.6666666666666666, 0.0001)\n",
      "epoch 3: (0.50305, 0.5015321628613769, 0.998375)\n",
      "epoch 4: (0.501075, 0.8071428571428572, 0.002825)\n",
      "epoch 5: (0.5053, 0.5026718423108916, 0.997125)\n",
      "epoch 6: (0.5017625, 0.7456445993031359, 0.00535)\n",
      "epoch 7: (0.5084375, 0.5042829405718201, 0.99345)\n",
      "epoch 8: (0.5024, 0.7388059701492538, 0.007425)\n",
      "epoch 9: (0.511025, 0.5056316085202023, 0.989875)\n",
      "epoch 10: (0.503375, 0.7242524916943521, 0.0109)\n",
      "epoch 11: (0.51535, 0.5079363027686581, 0.982425)\n",
      "epoch 12: (0.5042875, 0.6911928651059086, 0.0155)\n",
      "epoch 13: (0.519875, 0.5104207628784899, 0.9735)\n",
      "epoch 14: (0.505475, 0.6849662162162162, 0.020275)\n",
      "epoch 15: (0.5242875, 0.512946601100761, 0.962275)\n",
      "epoch 16: (0.506, 0.6734104046242775, 0.0233)\n",
      "epoch 17: (0.525575, 0.5137840896841651, 0.953275)\n",
      "epoch 18: (0.506575, 0.6725721784776902, 0.025625)\n",
      "epoch 19: (0.528, 0.5153001284117921, 0.943025)\n",
      "epoch 20: (0.5066625, 0.6679269061121613, 0.0265)\n",
      "epoch 21: (0.5312, 0.5172786177105831, 0.93405)\n",
      "epoch 22: (0.507225, 0.6684149184149184, 0.028675)\n",
      "epoch 23: (0.533475, 0.5187645393648925, 0.92545)\n",
      "epoch 24: (0.507725, 0.6703417861080485, 0.0304)\n",
      "epoch 25: (0.5357, 0.5201757608296363, 0.920425)\n",
      "epoch 26: (0.508075, 0.6710805084745762, 0.031675)\n",
      "epoch 27: (0.5369, 0.5209927464087613, 0.915775)\n",
      "epoch 28: (0.508175, 0.6666666666666666, 0.0327)\n",
      "epoch 29: (0.5375, 0.5214702851253865, 0.9108)\n",
      "epoch 30: (0.508175, 0.6617210682492581, 0.03345)\n",
      "epoch 31: (0.5382625, 0.5220174643591846, 0.907175)\n",
      "epoch 32: (0.5083, 0.6630648330058939, 0.03375)\n",
      "epoch 33: (0.5389875, 0.5225423165319958, 0.90375)\n",
      "epoch 34: (0.508475, 0.6645631067961165, 0.034225)\n",
      "epoch 35: (0.53965, 0.522993504987242, 0.90185)\n",
      "epoch 36: (0.5085875, 0.6653827636013481, 0.03455)\n",
      "epoch 37: (0.54005, 0.5232889457463511, 0.8999)\n",
      "epoch 38: (0.508675, 0.6649239543726235, 0.034975)\n",
      "epoch 39: (0.5400875, 0.5233389127428862, 0.8989)\n",
      "epoch 40: (0.5087875, 0.6652562294311236, 0.035375)\n",
      "epoch 41: (0.5400875, 0.5234002188982123, 0.89665)\n",
      "epoch 42: (0.5088875, 0.6646595646132468, 0.035875)\n",
      "epoch 43: (0.5403125, 0.5235976760862248, 0.894475)\n",
      "epoch 44: (0.509025, 0.6659007352941176, 0.036225)\n",
      "epoch 45: (0.5402, 0.5235666549419628, 0.8931)\n",
      "epoch 46: (0.509075, 0.6653005464480874, 0.036525)\n",
      "epoch 47: (0.5403, 0.5236592596941322, 0.891975)\n",
      "epoch 48: (0.509125, 0.6639712488769093, 0.03695)\n",
      "epoch 49: (0.540725, 0.5239558823529412, 0.890725)\n",
      "epoch 50: (0.5093, 0.6654804270462633, 0.0374)\n",
      "epoch 51: (0.540725, 0.5239608154620069, 0.89055)\n",
      "epoch 52: (0.5093125, 0.6654820079964461, 0.03745)\n",
      "epoch 53: (0.5405875, 0.5238585095595691, 0.891175)\n",
      "epoch 54: (0.509475, 0.6666666666666666, 0.0379)\n",
      "epoch 55: (0.540675, 0.5239278781104771, 0.890625)\n",
      "epoch 56: (0.5094625, 0.6665200175978883, 0.037875)\n",
      "epoch 57: (0.54075, 0.523974819085721, 0.8906)\n",
      "epoch 58: (0.509525, 0.6673989455184535, 0.037975)\n",
      "epoch 59: (0.5407375, 0.5239657023517127, 0.89065)\n",
      "epoch 60: (0.5096375, 0.6684141546526867, 0.03825)\n",
      "epoch 61: (0.540725, 0.5239551777888886, 0.89075)\n",
      "epoch 62: (0.50965, 0.6681184668989547, 0.03835)\n",
      "epoch 63: (0.5407125, 0.5239481772326877, 0.890725)\n",
      "epoch 64: (0.509725, 0.6683982683982684, 0.0386)\n",
      "epoch 65: (0.54095, 0.5241031225168487, 0.890425)\n",
      "epoch 66: (0.5097375, 0.6682505399568035, 0.038675)\n",
      "epoch 67: (0.5409375, 0.5240918654092307, 0.89055)\n",
      "epoch 68: (0.5098, 0.6686746987951807, 0.03885)\n",
      "epoch 69: (0.54105, 0.524171230053583, 0.8902)\n",
      "epoch 70: (0.5098375, 0.6691018478727976, 0.038925)\n",
      "epoch 71: (0.5410875, 0.5241922425848238, 0.890275)\n",
      "epoch 72: (0.5098375, 0.6685224839400429, 0.039025)\n",
      "epoch 73: (0.541075, 0.524188087035892, 0.89015)\n",
      "epoch 74: (0.5098875, 0.6693790149892933, 0.039075)\n",
      "epoch 75: (0.54115, 0.5242301124654066, 0.8903)\n",
      "epoch 76: (0.5098625, 0.6682302771855011, 0.039175)\n",
      "epoch 77: (0.541175, 0.5242476885931335, 0.890225)\n",
      "epoch 78: (0.5099125, 0.6686516376010209, 0.0393)\n",
      "epoch 79: (0.5410625, 0.5241704068869104, 0.8905)\n",
      "epoch 80: (0.5099, 0.6679389312977099, 0.039375)\n",
      "epoch 81: (0.5410625, 0.5241704068869104, 0.8905)\n",
      "epoch 82: (0.5099125, 0.6677951756242065, 0.03945)\n",
      "epoch 83: (0.5410625, 0.5241760991477649, 0.8903)\n",
      "epoch 84: (0.5099375, 0.6677923174335163, 0.03955)\n",
      "epoch 85: (0.54105, 0.5241662496688547, 0.890375)\n",
      "epoch 86: (0.5099625, 0.6680725432307043, 0.0396)\n",
      "epoch 87: (0.5410625, 0.5241625844035482, 0.890775)\n",
      "epoch 88: (0.5099625, 0.6680725432307043, 0.0396)\n",
      "epoch 89: (0.54105, 0.5241570058259283, 0.8907)\n",
      "epoch 90: (0.50995, 0.6677908937605397, 0.0396)\n",
      "epoch 91: (0.5409, 0.5240510423098409, 0.891175)\n",
      "epoch 92: (0.50995, 0.6676495366470092, 0.039625)\n",
      "epoch 93: (0.5411125, 0.5241991259178598, 0.890575)\n",
      "epoch 94: (0.5099125, 0.6673701983959477, 0.039525)\n",
      "epoch 95: (0.5410625, 0.524168984240498, 0.89055)\n",
      "epoch 96: (0.5099375, 0.667650780261493, 0.039575)\n",
      "epoch 97: (0.5411, 0.5241942604856512, 0.890475)\n",
      "epoch 98: (0.5099375, 0.667650780261493, 0.039575)\n",
      "epoch 99: (0.5411375, 0.5242166919307127, 0.8905)\n",
      "epoch 100: (0.5099375, 0.667650780261493, 0.039575)\n",
      "epoch 101: (0.54125, 0.5242897099955837, 0.890375)\n",
      "epoch 102: (0.5099375, 0.6675094816687737, 0.0396)\n",
      "epoch 103: (0.541275, 0.5243065779400506, 0.890325)\n",
      "epoch 104: (0.5099625, 0.6677894736842105, 0.03965)\n",
      "epoch 105: (0.541225, 0.5242835684622861, 0.89005)\n",
      "epoch 106: (0.5099625, 0.6676482961716449, 0.039675)\n",
      "epoch 107: (0.541225, 0.524282853272074, 0.890075)\n",
      "epoch 108: (0.509975, 0.6677880571909167, 0.0397)\n",
      "epoch 109: (0.5412375, 0.5242855670558443, 0.89025)\n",
      "epoch 110: (0.509975, 0.6677880571909167, 0.0397)\n",
      "epoch 111: (0.5412625, 0.5242995745182044, 0.8903)\n",
      "epoch 112: (0.5099625, 0.6675073560319462, 0.0397)\n",
      "epoch 113: (0.5413125, 0.5243304524507133, 0.8903)\n",
      "epoch 114: (0.5099625, 0.6675073560319462, 0.0397)\n",
      "epoch 115: (0.5413, 0.5243341975017676, 0.8899)\n",
      "epoch 116: (0.5099375, 0.6679340937896071, 0.039525)\n",
      "epoch 117: (0.5412875, 0.5243264740974237, 0.8899)\n",
      "epoch 118: (0.509975, 0.6683544303797468, 0.0396)\n",
      "epoch 119: (0.5412375, 0.5242970142438392, 0.88985)\n",
      "epoch 120: (0.5099875, 0.6684943061999157, 0.039625)\n",
      "epoch 121: (0.5412625, 0.5243124604121555, 0.88985)\n",
      "epoch 122: (0.51, 0.6686340640809444, 0.03965)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 123: (0.5412625, 0.5243117441706314, 0.889875)\n",
      "epoch 124: (0.5100125, 0.6687737041719343, 0.039675)\n",
      "epoch 125: (0.541275, 0.5243187509206069, 0.8899)\n",
      "epoch 126: (0.5100125, 0.6687737041719343, 0.039675)\n",
      "epoch 127: (0.541275, 0.5243201838376101, 0.88985)\n",
      "epoch 128: (0.5100125, 0.6687737041719343, 0.039675)\n",
      "epoch 129: (0.5412375, 0.5242970142438392, 0.88985)\n",
      "epoch 130: (0.5100125, 0.6687737041719343, 0.039675)\n",
      "epoch 131: (0.54125, 0.5243054532598769, 0.889825)\n",
      "epoch 132: (0.5100125, 0.6687737041719343, 0.039675)\n",
      "epoch 133: (0.54125, 0.5243054532598769, 0.889825)\n",
      "epoch 134: (0.5100375, 0.6690526315789473, 0.039725)\n",
      "epoch 135: (0.54125, 0.5243061693477108, 0.8898)\n",
      "epoch 136: (0.5100125, 0.6686315789473685, 0.0397)\n",
      "epoch 137: (0.54125, 0.5243068854777407, 0.889775)\n",
      "epoch 138: (0.510025, 0.6687710437710438, 0.039725)\n",
      "epoch 139: (0.5412625, 0.5243160422528986, 0.889725)\n",
      "epoch 140: (0.510025, 0.6687710437710438, 0.039725)\n",
      "epoch 141: (0.5412875, 0.5243322086838654, 0.8897)\n",
      "epoch 142: (0.510025, 0.6690556492411467, 0.039675)\n",
      "epoch 143: (0.5412875, 0.5243322086838654, 0.8897)\n",
      "epoch 144: (0.510025, 0.6690556492411467, 0.039675)\n",
      "epoch 145: (0.541325, 0.5243553852954177, 0.8897)\n",
      "epoch 146: (0.510025, 0.6690556492411467, 0.039675)\n",
      "epoch 147: (0.5413375, 0.5243631112879223, 0.8897)\n",
      "epoch 148: (0.510025, 0.6690556492411467, 0.039675)\n",
      "epoch 149: (0.5413125, 0.5243483770204365, 0.889675)\n",
      "epoch 150: (0.510025, 0.6690556492411467, 0.039675)\n",
      "epoch 151: (0.541325, 0.5243568207939174, 0.88965)\n",
      "epoch 152: (0.510025, 0.6690556492411467, 0.039675)\n",
      "epoch 153: (0.5412375, 0.5242755596108847, 0.8906)\n",
      "epoch 154: (0.5100125, 0.6689160691691269, 0.03965)\n",
      "epoch 155: (0.5412375, 0.524276274154856, 0.890575)\n",
      "epoch 156: (0.5100125, 0.6689160691691269, 0.03965)\n",
      "epoch 157: (0.5412375, 0.524276274154856, 0.890575)\n",
      "epoch 158: (0.510025, 0.6690556492411467, 0.039675)\n",
      "epoch 159: (0.5412375, 0.524276274154856, 0.890575)\n",
      "epoch 160: (0.5100125, 0.6687737041719343, 0.039675)\n",
      "epoch 161: (0.5412125, 0.5242594145953821, 0.890625)\n",
      "epoch 162: (0.5100125, 0.6689160691691269, 0.03965)\n",
      "epoch 163: (0.5411875, 0.5242461257707987, 0.89055)\n",
      "epoch 164: (0.5100125, 0.6689160691691269, 0.03965)\n",
      "epoch 165: (0.5412, 0.5242538411726615, 0.89055)\n",
      "epoch 166: (0.5100125, 0.6689160691691269, 0.03965)\n",
      "epoch 167: (0.5412125, 0.5242608426908416, 0.890575)\n",
      "epoch 168: (0.5100125, 0.6689160691691269, 0.03965)\n",
      "epoch 169: (0.5412, 0.5242531272994849, 0.890575)\n",
      "epoch 170: (0.5100125, 0.6689160691691269, 0.03965)\n",
      "epoch 171: (0.5412125, 0.5242601286220954, 0.8906)\n",
      "epoch 172: (0.510025, 0.6690556492411467, 0.039675)\n",
      "epoch 173: (0.541225, 0.5242671297386391, 0.890625)\n",
      "epoch 174: (0.5100125, 0.6687737041719343, 0.039675)\n",
      "epoch 175: (0.5412, 0.5242531272994849, 0.890575)\n",
      "epoch 176: (0.5100125, 0.6687737041719343, 0.039675)\n",
      "epoch 177: (0.5412, 0.5242531272994849, 0.890575)\n",
      "epoch 178: (0.5100125, 0.6687737041719343, 0.039675)\n",
      "epoch 179: (0.5412, 0.5242531272994849, 0.890575)\n",
      "epoch 180: (0.5100125, 0.6687737041719343, 0.039675)\n",
      "epoch 181: (0.5412, 0.5242531272994849, 0.890575)\n",
      "epoch 182: (0.5100125, 0.6687737041719343, 0.039675)\n",
      "epoch 183: (0.5412, 0.5242531272994849, 0.890575)\n",
      "epoch 184: (0.5100125, 0.6687737041719343, 0.039675)\n",
      "epoch 185: (0.5411875, 0.5242461257707987, 0.89055)\n",
      "epoch 186: (0.5100125, 0.6687737041719343, 0.039675)\n",
      "epoch 187: (0.5412, 0.5242538411726615, 0.89055)\n",
      "epoch 188: (0.5100125, 0.6687737041719343, 0.039675)\n",
      "epoch 189: (0.5412, 0.5242538411726615, 0.89055)\n",
      "epoch 190: (0.5100125, 0.6687737041719343, 0.039675)\n",
      "epoch 191: (0.5412, 0.5242538411726615, 0.89055)\n",
      "epoch 192: (0.510025, 0.6689132266217355, 0.0397)\n",
      "epoch 193: (0.541175, 0.5242391240360276, 0.890525)\n",
      "epoch 194: (0.510025, 0.6689132266217355, 0.0397)\n",
      "epoch 195: (0.5411875, 0.5242461257707987, 0.89055)\n",
      "epoch 196: (0.510025, 0.6689132266217355, 0.0397)\n",
      "epoch 197: (0.541175, 0.5242391240360276, 0.890525)\n",
      "epoch 198: (0.510025, 0.6689132266217355, 0.0397)\n",
      "epoch 199: (0.5411875, 0.5242468394483936, 0.890525)\n",
      "epoch 0: (0.5, 0, 0.0)\n",
      "epoch 1: (0.500175, 0.5000875218804701, 0.999925)\n",
      "epoch 2: (0.5, 0, 0.0)\n",
      "epoch 3: (0.502125, 0.5010657772650902, 0.99905)\n",
      "epoch 4: (0.5, 0, 0.0)\n",
      "epoch 5: (0.5060375, 0.503053521981565, 0.99465)\n",
      "epoch 6: (0.501475, 0.7731481481481481, 0.004175)\n",
      "epoch 7: (0.509175, 0.504679331888308, 0.98955)\n",
      "epoch 8: (0.501875, 0.7450980392156863, 0.0057)\n",
      "epoch 9: (0.5122875, 0.5063354773843437, 0.982025)\n",
      "epoch 10: (0.5025125, 0.7457212713936431, 0.007625)\n",
      "epoch 11: (0.51595, 0.508310104983458, 0.975625)\n",
      "epoch 12: (0.5031375, 0.739961759082218, 0.009675)\n",
      "epoch 13: (0.518875, 0.5099175073560319, 0.970475)\n",
      "epoch 14: (0.5031, 0.7403100775193798, 0.00955)\n",
      "epoch 15: (0.522275, 0.511833297917552, 0.963475)\n",
      "epoch 16: (0.5031125, 0.7353497164461248, 0.009725)\n",
      "epoch 17: (0.5249125, 0.5133584460501093, 0.957375)\n",
      "epoch 18: (0.504525, 0.6937901498929336, 0.0162)\n",
      "epoch 19: (0.5274, 0.5147812483141825, 0.95425)\n",
      "epoch 20: (0.505325, 0.6884955752212389, 0.01945)\n",
      "epoch 21: (0.53005, 0.5164176250443904, 0.945225)\n",
      "epoch 22: (0.5062125, 0.6809905316824472, 0.023375)\n",
      "epoch 23: (0.532175, 0.5176999669930685, 0.941075)\n",
      "epoch 24: (0.5073, 0.6776155717761557, 0.02785)\n",
      "epoch 25: (0.5339, 0.518795220802262, 0.935725)\n",
      "epoch 26: (0.5075375, 0.6739757645701097, 0.0292)\n",
      "epoch 27: (0.5345875, 0.5193121065341504, 0.930075)\n",
      "epoch 28: (0.50815, 0.6706806282722513, 0.032025)\n",
      "epoch 29: (0.535325, 0.5198087814725509, 0.926975)\n",
      "epoch 30: (0.5082, 0.6699481865284974, 0.032325)\n",
      "epoch 31: (0.5358375, 0.5202137710281033, 0.9223)\n",
      "epoch 32: (0.5083875, 0.6666666666666666, 0.03355)\n",
      "epoch 33: (0.536675, 0.5208197326218387, 0.91745)\n",
      "epoch 34: (0.5085, 0.6666666666666666, 0.034)\n",
      "epoch 35: (0.537025, 0.5211468715195476, 0.91245)\n",
      "epoch 36: (0.5085875, 0.6668285575522098, 0.034325)\n",
      "epoch 37: (0.537125, 0.521213073538655, 0.912175)\n",
      "epoch 38: (0.508675, 0.6669874879692012, 0.03465)\n",
      "epoch 39: (0.5371625, 0.5212877171375789, 0.910025)\n",
      "epoch 40: (0.508875, 0.6677693761814745, 0.035325)\n",
      "epoch 41: (0.53715, 0.521296110521941, 0.909375)\n",
      "epoch 42: (0.509225, 0.6694214876033058, 0.03645)\n",
      "epoch 43: (0.537275, 0.5213696038525483, 0.909425)\n",
      "epoch 44: (0.50945, 0.6684491978609626, 0.0375)\n",
      "epoch 45: (0.5374375, 0.5214784641643121, 0.90895)\n",
      "epoch 46: (0.5096125, 0.6678306416412048, 0.03825)\n",
      "epoch 47: (0.5376, 0.5215633423180593, 0.90945)\n",
      "epoch 48: (0.5096625, 0.6681165724227925, 0.0384)\n",
      "epoch 49: (0.537625, 0.5216043179925928, 0.9084)\n",
      "epoch 50: (0.50975, 0.6679586563307494, 0.038775)\n",
      "epoch 51: (0.5376375, 0.521610564846049, 0.90845)\n",
      "epoch 52: (0.509725, 0.6681071737251513, 0.03865)\n",
      "epoch 53: (0.5376125, 0.5216048939500553, 0.908075)\n",
      "epoch 54: (0.5097625, 0.6685369011653, 0.038725)\n",
      "epoch 55: (0.5377875, 0.521752270208816, 0.906375)\n",
      "epoch 56: (0.5097375, 0.6688339835283919, 0.038575)\n",
      "epoch 57: (0.5378, 0.5217773296845744, 0.905675)\n",
      "epoch 58: (0.509775, 0.6679553264604811, 0.038875)\n",
      "epoch 59: (0.537925, 0.5218531216687314, 0.90565)\n",
      "epoch 60: (0.5097375, 0.6678155967255494, 0.03875)\n",
      "epoch 61: (0.5378125, 0.5217823350663191, 0.905775)\n",
      "epoch 62: (0.509725, 0.6669527896995708, 0.03885)\n",
      "epoch 63: (0.5378875, 0.5218400080702108, 0.905275)\n",
      "epoch 64: (0.5097125, 0.6668097896092744, 0.038825)\n",
      "epoch 65: (0.5380375, 0.5219517825453391, 0.904425)\n",
      "epoch 66: (0.5098625, 0.6669487939060517, 0.0394)\n",
      "epoch 67: (0.538175, 0.5220454479831375, 0.904)\n",
      "epoch 68: (0.509875, 0.6673728813559322, 0.039375)\n",
      "epoch 69: (0.5383125, 0.5221533168538676, 0.903025)\n",
      "epoch 70: (0.5099125, 0.6672290172922818, 0.03955)\n",
      "epoch 71: (0.538525, 0.522299076780598, 0.90235)\n",
      "epoch 72: (0.509925, 0.6679357021996616, 0.039475)\n",
      "epoch 73: (0.5385375, 0.522298245360258, 0.902675)\n",
      "epoch 74: (0.509975, 0.6679292929292929, 0.039675)\n",
      "epoch 75: (0.5385, 0.5222846062570544, 0.902325)\n",
      "epoch 76: (0.5099375, 0.6675094816687737, 0.0396)\n",
      "epoch 77: (0.5385625, 0.5223359735878017, 0.9018)\n",
      "epoch 78: (0.5099625, 0.6669459572685379, 0.0398)\n",
      "epoch 79: (0.5387625, 0.5224303797468355, 0.902825)\n",
      "epoch 80: (0.5100375, 0.6682027649769585, 0.039875)\n",
      "epoch 81: (0.538775, 0.5224353410866169, 0.902925)\n",
      "epoch 82: (0.510225, 0.6683127572016461, 0.0406)\n",
      "epoch 83: (0.5388375, 0.5224939547948975, 0.902125)\n",
      "epoch 84: (0.5102, 0.6683168316831684, 0.0405)\n",
      "epoch 85: (0.5388375, 0.5225056861807699, 0.901675)\n",
      "epoch 86: (0.51025, 0.668724279835391, 0.040625)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 87: (0.538975, 0.5225883102958648, 0.9017)\n",
      "epoch 88: (0.510275, 0.6689967105263158, 0.040675)\n",
      "epoch 89: (0.53895, 0.5225764381973627, 0.901575)\n",
      "epoch 90: (0.510275, 0.6684426229508197, 0.040775)\n",
      "epoch 91: (0.5388375, 0.5225448793301116, 0.900175)\n",
      "epoch 92: (0.5102625, 0.66872174270448, 0.040675)\n",
      "epoch 93: (0.5388125, 0.5225094604978904, 0.90095)\n",
      "epoch 94: (0.510275, 0.6674816625916871, 0.04095)\n",
      "epoch 95: (0.5390125, 0.5226846535157216, 0.8989)\n",
      "epoch 96: (0.5102875, 0.6683026584867076, 0.04085)\n",
      "epoch 97: (0.539, 0.5226684878956087, 0.899225)\n",
      "epoch 98: (0.51045, 0.668141592920354, 0.041525)\n",
      "epoch 99: (0.539175, 0.5227616059496834, 0.899725)\n",
      "epoch 100: (0.5104375, 0.6678729392842783, 0.041525)\n",
      "epoch 101: (0.5392375, 0.5228188017039589, 0.899)\n",
      "epoch 102: (0.5104375, 0.6677380474085979, 0.04155)\n",
      "epoch 103: (0.539325, 0.522887323943662, 0.898425)\n",
      "epoch 104: (0.510425, 0.6673354735152488, 0.041575)\n",
      "epoch 105: (0.539375, 0.5229177579884756, 0.898425)\n",
      "epoch 106: (0.5104375, 0.6674689129562775, 0.0416)\n",
      "epoch 107: (0.53925, 0.5228363636363637, 0.898625)\n",
      "epoch 108: (0.5104375, 0.6674689129562775, 0.0416)\n",
      "epoch 109: (0.5394125, 0.522955283428222, 0.897875)\n",
      "epoch 110: (0.5104125, 0.6672019269369731, 0.04155)\n",
      "epoch 111: (0.5395125, 0.5230356648350848, 0.89715)\n",
      "epoch 112: (0.5104625, 0.6677354709418838, 0.04165)\n",
      "epoch 113: (0.5395125, 0.5230484301401426, 0.896675)\n",
      "epoch 114: (0.5104625, 0.6677354709418838, 0.04165)\n",
      "epoch 115: (0.5396625, 0.5231575413449328, 0.896025)\n",
      "epoch 116: (0.5104375, 0.6673346693386774, 0.041625)\n",
      "epoch 117: (0.5396875, 0.5231775509906121, 0.89585)\n",
      "epoch 118: (0.51045, 0.6673338670936749, 0.041675)\n",
      "epoch 119: (0.539725, 0.5232092778686609, 0.895525)\n",
      "epoch 120: (0.510425, 0.6664006384676776, 0.04175)\n",
      "epoch 121: (0.5396625, 0.5232049613128757, 0.894275)\n",
      "epoch 122: (0.510425, 0.6670673076923077, 0.041625)\n",
      "epoch 123: (0.539725, 0.5232445874780574, 0.894225)\n",
      "epoch 124: (0.5104375, 0.6672006407689227, 0.04165)\n",
      "epoch 125: (0.5396375, 0.523176097411235, 0.894775)\n",
      "epoch 126: (0.51045, 0.6673338670936749, 0.041675)\n",
      "epoch 127: (0.5395375, 0.5230973696893575, 0.895425)\n",
      "epoch 128: (0.5104625, 0.6673330667732906, 0.041725)\n",
      "epoch 129: (0.539725, 0.5232391482391482, 0.894425)\n",
      "epoch 130: (0.51045, 0.6672, 0.0417)\n",
      "epoch 131: (0.5397875, 0.5232910392062168, 0.893925)\n",
      "epoch 132: (0.5103125, 0.6661296818364881, 0.04135)\n",
      "epoch 133: (0.5398125, 0.5233002180051795, 0.89415)\n",
      "epoch 134: (0.5106, 0.6675889328063241, 0.042225)\n",
      "epoch 135: (0.5398375, 0.5232998493953883, 0.894725)\n",
      "epoch 136: (0.5106125, 0.66798575385833, 0.0422)\n",
      "epoch 137: (0.53985, 0.523308182722115, 0.8947)\n",
      "epoch 138: (0.5106125, 0.6681188118811882, 0.042175)\n",
      "epoch 139: (0.5399625, 0.523374325529706, 0.8948)\n",
      "epoch 140: (0.510625, 0.6681170886075949, 0.042225)\n",
      "epoch 141: (0.53995, 0.5233646226277159, 0.894875)\n",
      "epoch 142: (0.510625, 0.6681170886075949, 0.042225)\n",
      "epoch 143: (0.53995, 0.5233817160248156, 0.89425)\n",
      "epoch 144: (0.5105875, 0.6674574930802689, 0.0422)\n",
      "epoch 145: (0.539925, 0.5233684518583552, 0.894175)\n",
      "epoch 146: (0.5106125, 0.667060212514758, 0.042375)\n",
      "epoch 147: (0.539925, 0.5233643492509363, 0.894325)\n",
      "epoch 148: (0.51055, 0.6656200941915228, 0.0424)\n",
      "epoch 149: (0.5400125, 0.5234179530324091, 0.894325)\n",
      "epoch 150: (0.510525, 0.6654874213836478, 0.042325)\n",
      "epoch 151: (0.540075, 0.5234603676384498, 0.894175)\n",
      "epoch 152: (0.5105625, 0.6660117878192534, 0.042375)\n",
      "epoch 153: (0.5400625, 0.5234540797658251, 0.894125)\n",
      "epoch 154: (0.5105125, 0.664966653589643, 0.042375)\n",
      "epoch 155: (0.5400625, 0.5234575129912904, 0.894)\n",
      "epoch 156: (0.510575, 0.6656225528582616, 0.0425)\n",
      "epoch 157: (0.540025, 0.5234297254580578, 0.894175)\n",
      "epoch 158: (0.510625, 0.6652410575427683, 0.042775)\n",
      "epoch 159: (0.5401, 0.523468133668871, 0.89445)\n",
      "epoch 160: (0.5106125, 0.6648543689320389, 0.0428)\n",
      "epoch 161: (0.5402, 0.5235397452788757, 0.894075)\n",
      "epoch 162: (0.510625, 0.6649844720496895, 0.042825)\n",
      "epoch 163: (0.5401, 0.5234915055653193, 0.8936)\n",
      "epoch 164: (0.5106375, 0.665242718446602, 0.042825)\n",
      "epoch 165: (0.5401, 0.5234908174921649, 0.893625)\n",
      "epoch 166: (0.5106375, 0.6651144741948002, 0.04285)\n",
      "epoch 167: (0.5401125, 0.5235046804271714, 0.8934)\n",
      "epoch 168: (0.5106375, 0.6651144741948002, 0.04285)\n",
      "epoch 169: (0.540075, 0.5234768599882835, 0.893575)\n",
      "epoch 170: (0.5106375, 0.6646034816247582, 0.04295)\n",
      "epoch 171: (0.5401, 0.5234942582610733, 0.8935)\n",
      "epoch 172: (0.5106625, 0.6647354190807262, 0.043025)\n",
      "epoch 173: (0.5400375, 0.5234387577385221, 0.894125)\n",
      "epoch 174: (0.510775, 0.665641813989239, 0.0433)\n",
      "epoch 175: (0.5400875, 0.5234645945827298, 0.8943)\n",
      "epoch 176: (0.5108125, 0.6658995013425393, 0.0434)\n",
      "epoch 177: (0.54, 0.5234130352073517, 0.894225)\n",
      "epoch 178: (0.5108, 0.6656441717791411, 0.0434)\n",
      "epoch 179: (0.539875, 0.5233508037361286, 0.8937)\n",
      "epoch 180: (0.510775, 0.665641813989239, 0.0433)\n",
      "epoch 181: (0.539975, 0.5234134770258002, 0.89365)\n",
      "epoch 182: (0.5107625, 0.6655132641291811, 0.043275)\n",
      "epoch 183: (0.5399125, 0.523375159226343, 0.89365)\n",
      "epoch 184: (0.510775, 0.6657692307692308, 0.043275)\n",
      "epoch 185: (0.5399625, 0.5234030716073964, 0.89375)\n",
      "epoch 186: (0.5107375, 0.6651287966166859, 0.04325)\n",
      "epoch 187: (0.5398, 0.5233089311859443, 0.89355)\n",
      "epoch 188: (0.5107375, 0.6651287966166859, 0.04325)\n",
      "epoch 189: (0.5398, 0.5233219067709707, 0.893075)\n",
      "epoch 190: (0.51075, 0.6657671549730146, 0.043175)\n",
      "epoch 191: (0.539775, 0.5233011130638547, 0.893275)\n",
      "epoch 192: (0.51075, 0.6658950617283951, 0.04315)\n",
      "epoch 193: (0.539825, 0.523329720863478, 0.89335)\n",
      "epoch 194: (0.5107375, 0.6655105973025048, 0.043175)\n",
      "epoch 195: (0.53985, 0.5233464174819848, 0.8933)\n",
      "epoch 196: (0.5107375, 0.6652558676414005, 0.043225)\n",
      "epoch 197: (0.5398125, 0.5233357267412042, 0.89285)\n",
      "epoch 198: (0.510725, 0.6652542372881356, 0.043175)\n",
      "epoch 199: (0.5399375, 0.523415170392085, 0.89275)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "attack_params = model_params('attack_model')\n",
    "attack_params.learning_rate = 0.001\n",
    "attack_params.weight_decay = 1e-5\n",
    "attack_params.epoch = 200\n",
    "attack_params.h_neurons=64\n",
    "attack_params.do=0\n",
    "\n",
    "for attack_params.learning_rate in [0.001, 0.01]:\n",
    "    for attack_params.h_neurons in [32,64,128]:\n",
    "        for attack_params.do in [0, 0.5]:\n",
    "            # attack_train_data = torch.tensor(np.array(df.drop(['a_target'], axis=1)), dtype=torch.float, requires_grad=True)   \n",
    "            # attack_train_target = torch.tensor(np.array(df['a_target']), dtype=torch.float)\n",
    "            attack_train_args = Train_args(attack_params.learning_rate, attack_params.weight_decay, attack_params.epoch)\n",
    "            attack_model = Net_attack(attack_params.h_neurons, attack_params.do, input_size=attack_train_data.shape[1])\n",
    "            for epoch in range(attack_train_args.epoch):\n",
    "                attack_model = attack.train_attack_model(attack_model, attack_train_data, attack_train_target, attack_train_args)\n",
    "                print(f'epoch {epoch}: {attack_evaluation(attack_model, attack_train_data, attack_train_target)}' )        \n",
    "                \n",
    "                train_res = attack_evaluation(attack_model, attack_train_data, attack_train_target)\n",
    "                test_res = attack.mi_attack_test(model, attack_model, x_target_train, y_target_train, x_target_test, y_target_test)\n",
    "\n",
    "                attack_params.number_of_sms = number_of_sms\n",
    "                attack_params.shadow_size = shadow_size\n",
    "\n",
    "                attack_params.train_acc, attack_params.train_pre, attack_params.train_rec = train_res\n",
    "                attack_params.test_acc, attack_params.test_pre, attack_params.test_rec = test_res\n",
    "\n",
    "                a_param = dict(shadow_model.__dict__)\n",
    "                a_param.pop('theta')\n",
    "                a_param.pop('pred_func')\n",
    "                a_param.pop('accuracy')\n",
    "                a_param.update(dict(attack_params.__dict__))\n",
    "                a_param\n",
    "\n",
    "                k+=1\n",
    "                at_path = 'mia/loan/attack_model'+str(k)\n",
    "                torch.save(attack_model, at_path)\n",
    "                with open(at_path+'_params.json', 'w') as file:\n",
    "                    json.dump(a_param, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "199458b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b3593172",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "35e597cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_classes': 7,\n",
       " 'alpha': 0.001,\n",
       " 'max_iter': 100,\n",
       " 'lambda_': 1e-05,\n",
       " 'tolerance': 1e-05,\n",
       " 'sgdDP': False,\n",
       " 'L': 1,\n",
       " 'C': 1,\n",
       " 'epsilon': 1,\n",
       " 'delta': 1e-05,\n",
       " 'sigma': 0,\n",
       " 'DP': False,\n",
       " 'model_name': 'attack_model',\n",
       " 'learning_rate': 0.001,\n",
       " 'weight_decay': 1e-05,\n",
       " 'epoch': 200,\n",
       " 'h_neurons': 64,\n",
       " 'do': 0,\n",
       " 'number_of_sms': 10,\n",
       " 'shadow_size': 20000,\n",
       " 'train_acc': 0.58185,\n",
       " 'train_pre': 0.5673219279486758,\n",
       " 'train_rec': 0.68975,\n",
       " 'test_acc': 0.6395,\n",
       " 'test_pre': 0.6368989205103042,\n",
       " 'test_rec': 0.649}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_res = attack_evaluation(attack_model, attack_train_data, attack_train_target)\n",
    "test_res = attack.mi_attack_test(model, attack_model, x_target_train, y_target_train, x_target_test, y_target_test)\n",
    "\n",
    "attack_params.number_of_sms = number_of_sms\n",
    "attack_params.shadow_size = shadow_size\n",
    "\n",
    "attack_params.train_acc, attack_params.train_pre, attack_params.train_rec = train_res\n",
    "attack_params.test_acc, attack_params.test_pre, attack_params.test_rec = test_res\n",
    "\n",
    "a_param = dict(shadow_model.__dict__)\n",
    "a_param.pop('theta')\n",
    "a_param.pop('pred_func')\n",
    "a_param.pop('accuracy')\n",
    "a_param.update(dict(attack_params.__dict__))\n",
    "a_param\n",
    "\n",
    "k+=1\n",
    "at_path = 'mia/loan/attack_model'+str(k)\n",
    "torch.save(attack_model, at_path)\n",
    "with open(at_path+'_params.json', 'w') as file:\n",
    "    json.dump(a_param, file)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "60cd5e8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c6d1108d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sh_path = f'mia/shms{number_of_sms}_shtrsize{shadow_size}_shlr{shadow_model.alpha}_shiter{int(shadow_model.max_iter/shadow_batch_size)}_shreg{shadow_model.lambda_}/'      \n",
    "os.mkdir(sh_path)\n",
    "\n",
    "torch.save(attack_train_data, sh_path+'attack_train_data.pt')\n",
    "torch.save(attack_train_target, sh_path+'attack_train_target.pt')\n",
    "\n",
    "at_path = sh_path+f'attack_model_aneur{attack_model.h_neurons}_ado{attack_model.do}_alr{attack_train_args.learning_rate}_alreg{attack_train_args.weight_decay}_aepoch{attack_train_args.epoch}'\n",
    "torch.save(attack_model, at_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2e82b131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.59217, 0.5930014328093153, 0.5877)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_acc, train_pre, train_rec = attack_evaluation(attack_model, attack_train_data, attack_train_target)\n",
    "train_acc, train_pre, train_rec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "655d2c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6260389215487533, 0.5935737236701178, 0.8313)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc, test_pre, test_rec = attack_evaluation(attack_model, attack_test_data, attack_test_target)\n",
    "test_acc, test_pre, test_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1193a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MI optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f833cccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e2178b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_seed=42\n",
    "np.random.seed(rand_seed)\n",
    "# random.seed(rand_seed)\n",
    "torch.manual_seed(rand_seed)\n",
    "\n",
    "epo = [200]\n",
    "wd = [1e-5, 1e-6]\n",
    "ams = {}\n",
    "for ep in epo:\n",
    "    for w_d in wd:\n",
    "        attack_train_args = Train_args(learning_rate=l_r, weight_decay=w_d, epoch=ep)\n",
    "        attack_model = Net_attack(h_neurons=64, do=0, input_size=attack_train_data.shape[1])\n",
    "        for epoch in range(attack_train_args.epoch):\n",
    "\n",
    "            attack_model = train_model(attack_model, attack_train_data, attack_train_target, attack_train_args)\n",
    "            ams[(l_r,w_d)] = attack_model\n",
    "        at_path = sh_path+f'attack_model_aneur{attack_model.h_neurons}_ado{attack_model.do}_alr{attack_train_args.learning_rate}_alreg{attack_train_args.weight_decay}_aepoch{attack_train_args.epoch}'\n",
    "        torch.save(attack_model, at_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3371d8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 1e-05\n",
      "Train:  0.8081 0.8207236842105263 0.78842\n",
      "Test:  0.6895398337725522 0.6209717711716213 0.9943\n",
      "200 1e-06\n",
      "Train:  0.80328 0.8273606493674712 0.7665\n",
      "Test:  0.7008919521589296 0.6304929308368361 0.99\n",
      "500 1e-05\n",
      "Train:  0.8081 0.8207236842105263 0.78842\n",
      "Test:  0.6895398337725522 0.6209717711716213 0.9943\n",
      "500 1e-06\n",
      "Train:  0.80328 0.8273606493674712 0.7665\n",
      "Test:  0.7008919521589296 0.6304929308368361 0.99\n"
     ]
    }
   ],
   "source": [
    "epo = [200,500]\n",
    "wd = [1e-5, 1e-6]\n",
    "\n",
    "for ep in epo:\n",
    "    for w_d in wd:\n",
    "        print(ep, w_d)\n",
    "        attack_train_args = Train_args(learning_rate=l_r, weight_decay=w_d, epoch=500)\n",
    "        attack_model = Net_attack(h_neurons=64, do=0, input_size=attack_train_data.shape[1])\n",
    "        at_path = sh_path+f'attack_model_aneur{attack_model.h_neurons}_ado{attack_model.do}_alr{attack_train_args.learning_rate}_alreg{attack_train_args.weight_decay}_aepoch{attack_train_args.epoch}'\n",
    "        attack_model = torch.load(at_path)\n",
    "        \n",
    "        train_acc, train_pre, train_rec = attack_evaluation(attack_model, attack_train_data, attack_train_target)\n",
    "        print('Train: ', train_acc, train_pre, train_rec)\n",
    "        test_acc, test_pre, test_rec = attack_evaluation(attack_model, attack_test_data, attack_test_target)\n",
    "        print('Test: ' , test_acc, test_pre, test_rec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f715562f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for l_r in lr:\n",
    "    for w_d in wd:\n",
    "        ams[(l_r,w_d)]\n",
    "        train_acc, train_pre, train_rec = attack_evaluation(attack_model, attack_train_data, attack_train_target)\n",
    "        print(\"Train acc pre rec: \", train_acc, train_pre, train_rec)\n",
    "        test_acc, test_pre, test_rec = attack_evaluation(attack_model, attack_test_data, attack_test_target)\n",
    "        print(\"Test acc pre rec: \", test_acc, test_pre, test_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325080ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba7ecbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "shadow_size = 20000\n",
    "shadow_clf = LogisticRegression(random_state=1).fit(x_shadow[:shadow_size], y_shadow[:shadow_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ead4496",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(shadow_clf.score(x_shadow[:shadow_size], y_shadow[:shadow_size]))\n",
    "print(shadow_clf.score(x_shadow[shadow_size:shadow_size*2], y_shadow[shadow_size:shadow_size*2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988f7ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "shadow_train_pred = shadow_clf.predict_proba(x_shadow[:shadow_size])\n",
    "shadow_test_pred = shadow_clf.predict_proba(x_shadow[shadow_size:shadow_size*2])\n",
    "y_shadow_train = y_shadow[:shadow_size]\n",
    "y_shadow_test = y_shadow[shadow_size:shadow_size*2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258d38bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# members\n",
    "labels = np.ones(shadow_train_pred.shape[0])\n",
    "# non-members\n",
    "test_labels = np.zeros(shadow_test_pred.shape[0])\n",
    "\n",
    "x_1 = np.concatenate((shadow_train_pred, shadow_test_pred))\n",
    "x_2 = np.concatenate((y_shadow_train, y_shadow_test)).reshape((-1, 1))\n",
    "y_new = np.concatenate((labels, test_labels))\n",
    "\n",
    "attack_train_data = np.concatenate((x_1,x_2),axis=1)\n",
    "attack_train_target = y_new\n",
    "df = pd.DataFrame(attack_train_data)\n",
    "df['a_target'] = attack_train_target\n",
    "df = df.sample(frac = 1)\n",
    "\n",
    "attack_train_data = np.array(df.drop(['a_target'], axis=1))\n",
    "attack_train_target = np.array(df['a_target'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e799369",
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_train_data = torch.tensor(np.array(df.drop(['a_target'], axis=1)), dtype=torch.float, requires_grad=True)   \n",
    "attack_train_target = torch.tensor(np.array(df['a_target']), dtype=torch.float)\n",
    "attack_train_args = Train_args(learning_rate=0.001, weight_decay=1e-3, epoch=200)\n",
    "attack_model = Net_attack(h_neurons=64, do=0, input_size=attack_train_data.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91bbc86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4930a1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_train_data = torch.tensor(np.array(df.drop(['a_target'], axis=1)), dtype=torch.float, requires_grad=True)   \n",
    "attack_train_target = torch.tensor(np.array(df['a_target']), dtype=torch.float)\n",
    "attack_train_args = Train_args(learning_rate=0.001, weight_decay=1e-3, epoch=500)\n",
    "attack_model = Net_attack(h_neurons=64, do=0, input_size=attack_train_data.shape[1])\n",
    "for epoch in range(attack_train_args.epoch):\n",
    "            \n",
    "    attack_model = train_model(attack_model, attack_train_data, attack_train_target, attack_train_args)\n",
    "    train_acc, train_pre, train_rec = attack_evaluation(attack_model, attack_train_data, attack_train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046e9287",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc, train_pre, train_rec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "16bbe8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = model.predict(x_target_train, y_target_train)\n",
    "test_pred = model.predict(x_target_test, y_target_test)\n",
    "\n",
    "y_target_train_ohe = OneHotEncoder(sparse=False).fit_transform(y_target_train.reshape(-1,1)) #encoode the target values\n",
    "y_target_test_ohe = OneHotEncoder(sparse=False).fit_transform(y_target_test.reshape(-1,1)) #encoode the target values\n",
    "    \n",
    "# members\n",
    "labels = np.ones(train_pred.shape[0])\n",
    "# non-members\n",
    "test_labels = np.zeros(test_pred.shape[0])\n",
    "\n",
    "x_1 = np.concatenate((train_pred, test_pred))\n",
    "x_2 = np.concatenate((y_target_train_ohe, y_target_test_ohe))#.reshape((-1, 1))\n",
    "y_new = np.concatenate((labels, test_labels))\n",
    "\n",
    "attack_test_data = np.concatenate((x_1,x_2),axis=1)\n",
    "attack_test_target = y_new\n",
    "df = pd.DataFrame(attack_test_data)\n",
    "df['a_target'] = attack_test_target\n",
    "df = df.sample(frac = 1)\n",
    "\n",
    "attack_test_data = torch.tensor(np.array(df.drop(['a_target'], axis=1)), dtype=torch.float, requires_grad=True)\n",
    "attack_test_target = torch.tensor(np.array(df['a_target']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af443ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc, test_pre, test_rec = attack_evaluation(a_model, attack_test_data, attack_test_target)\n",
    "test_acc, test_pre, test_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f32a7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_model = Net_attack(h_neurons=64, do=0, input_size=100)\n",
    "a_model = torch.load('attack_model') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891b5b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rand_seed=42\n",
    "np.random.seed(rand_seed)\n",
    "# random.seed(rand_seed)\n",
    "torch.manual_seed(rand_seed)\n",
    "\n",
    "lr = [0.001]\n",
    "wd = [1e-4, 1e-6]\n",
    "tms = {}\n",
    "for l_r in lr:\n",
    "    for w_d in wd:\n",
    "        model = algo.LogisticRegression_DPSGD()\n",
    "\n",
    "        model.n_classes      = 100\n",
    "        model.alpha          = 0.001\n",
    "        model.max_iter       = 100*X_train_size \n",
    "        model.lambda_        = 1e-3\n",
    "        model.tolerance      = 10e-5\n",
    "        model.DP             = True\n",
    "        model.epsilon\n",
    "\n",
    "        X,y = model.init_theta(x_target_train, y_target_train)\n",
    "        model.SGD(X,y)\n",
    "        model.evaluate(x_target_train, y_target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3e39e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import algo\n",
    "# import attack\n",
    "\n",
    "# from torch import nn,optim\n",
    "import torch\n",
    "\n",
    "rand_seed=42\n",
    "np.random.seed(rand_seed)\n",
    "torch.manual_seed(rand_seed)\n",
    "        \n",
    "\n",
    "raw_data_path = '../datasets/dataset_purchase'\n",
    "raw_data = pd.read_csv(raw_data_path)\n",
    "y=raw_data['63']\n",
    "X=raw_data.drop('63', axis=1)\n",
    "y =  y.replace(100, 0)\n",
    "print('Dataset: ', raw_data_path)\n",
    "print('Classes in classification task: ', y.nunique())\n",
    "n_classes = y.nunique()\n",
    "\n",
    "X_train, x_shadow, y_train, y_shadow = train_test_split(X, y, train_size=0.2, random_state=rand_seed)\n",
    "print(X_train.shape, x_shadow.shape)\n",
    "\n",
    "#Target model\n",
    "X_train_size = 10000\n",
    "X_test_size = 10000\n",
    "x_target_train = np.array(X_train[:X_train_size])\n",
    "y_target_train = np.array(y_train[:X_train_size])\n",
    "x_target_test = np.array(X_train[X_train_size:X_train_size+X_test_size])\n",
    "y_target_test = np.array(y_train[X_train_size:X_train_size+X_test_size])\n",
    "if y_target_test.shape[0]<X_test_size or y_target_train.shape[0]<X_train_size:\n",
    "    raise ValueError(\n",
    "            \"Not enough traning or test data for the target model\")\n",
    "\n",
    "for L in [1,10,100]:\n",
    "    for epsilon in np.arange(0,1,0.1):\n",
    "        model = algo.LogisticRegression_DPSGD()\n",
    "\n",
    "        model.n_classes      = n_classes\n",
    "        model.alpha          = 0.001\n",
    "        model.max_iter       = 100*X_train_size\n",
    "        model.lambda_        = 1e-3\n",
    "        model.tolerance      = 10e-5\n",
    "        model.DP             = True\n",
    "        model.L              = L\n",
    "        model.epsilon        = epsilon\n",
    "\n",
    "\n",
    "        X,y = model.init_theta(x_target_train, y_target_train)\n",
    "        model.train(X,y)\n",
    "        model.evaluate(x_target_train, y_target_train, acc=True)\n",
    "        model.evaluate(x_target_test, y_target_test, acc=True)\n",
    "\n",
    "        tm_path = f'tm/lr{model.alpha}_iter{int(model.max_iter/X_train_size)}_reg{model.lambda_}_DP{model.DP}'\n",
    "        if model.DP:\n",
    "            tm_path += f'_eps{model.epsilon}_L{model.L}'\n",
    "        np.save(tm_path+'_target_model', model.theta)\n",
    "\n",
    "        print(tm_path)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e9f215",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shadow models\n",
    "# s_ms = {}\n",
    "# number_of_sms = 10\n",
    "# shadow_size = 50000\n",
    "# shadow_batch_size = int(shadow_size/number_of_sms)\n",
    "\n",
    "# x_shadow_train = np.array(x_shadow[:shadow_size])\n",
    "# y_shadow_train = np.array(y_shadow[:shadow_size])\n",
    "# x_shadow_test = np.array(x_shadow[shadow_size:2*shadow_size])\n",
    "# y_shadow_test = np.array(y_shadow[shadow_size:2*shadow_size])\n",
    "\n",
    "# attack.train_shadow_models(number_of_sms,)\n",
    "\n",
    "# for i in range(number_of_sms):  \n",
    "#     batch_start = i*shadow_batch_size\n",
    "#     batch_end = (i+1)*shadow_batch_size\n",
    "    \n",
    "#     shadow_model = algo.LogisticRegression_DPSGD()\n",
    "\n",
    "#     shadow_model.n_classes      = n_classes\n",
    "#     shadow_model.alpha          = 0.001\n",
    "#     shadow_model.max_iter       = 100*shadow_batch_size\n",
    "#     shadow_model.lambda_        = 10e-3\n",
    "#     shadow_model.tolerance      = 10e-5\n",
    "#     shadow_model.DP             = False\n",
    "\n",
    "#     X,y = shadow_model.init_theta(x_shadow_train[batch_start:batch_end], y_shadow_train[batch_start:batch_end] )\n",
    "#     shadow_model.SGD(X,y)\n",
    "#     print('Shadow model: ', i)\n",
    "#     shadow_model.evaluate(x_shadow_train[batch_start:batch_end], y_shadow_train[batch_start:batch_end])\n",
    "#     shadow_model.evaluate(x_shadow_test[batch_start:batch_end], y_shadow_test[batch_start:batch_end])\n",
    "#     s_ms[i] = shadow_model\n",
    "\n",
    "# #Attack model\n",
    "\n",
    "# shadow_train_pred = []\n",
    "# shadow_test_pred = []\n",
    "\n",
    "# for i in range(number_of_sms): \n",
    "#     batch_start = i*shadow_batch_size\n",
    "#     batch_end = (i+1)*shadow_batch_size\n",
    "    \n",
    "#     train_prediciton = s_ms[i].predict(x_shadow_train[batch_start:batch_end], y_shadow_train[batch_start:batch_end])\n",
    "#     test_prediciton = s_ms[i].predict(x_shadow_test[batch_start:batch_end], y_shadow_test[batch_start:batch_end])\n",
    "    \n",
    "#     shadow_train_pred.append(train_prediciton)\n",
    "#     shadow_test_pred.append(test_prediciton)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bdfc1ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/10000 == 1e-5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8851e49e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(0,1,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd702ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
